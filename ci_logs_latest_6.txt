2026-02-14T13:00:32.1337769Z Current runner version: '2.331.0'
2026-02-14T13:00:32.1372156Z ##[group]Runner Image Provisioner
2026-02-14T13:00:32.1373406Z Hosted Compute Agent
2026-02-14T13:00:32.1374382Z Version: 20260123.484
2026-02-14T13:00:32.1375289Z Commit: 6bd6555ca37d84114959e1c76d2c01448ff61c5d
2026-02-14T13:00:32.1376475Z Build Date: 2026-01-23T19:41:17Z
2026-02-14T13:00:32.1377492Z Worker ID: {8e006291-ae2f-456b-92e7-0073b1eccac0}
2026-02-14T13:00:32.1378597Z Azure Region: eastus2
2026-02-14T13:00:32.1379546Z ##[endgroup]
2026-02-14T13:00:32.1382194Z ##[group]Operating System
2026-02-14T13:00:32.1383145Z Ubuntu
2026-02-14T13:00:32.1384027Z 24.04.3
2026-02-14T13:00:32.1384781Z LTS
2026-02-14T13:00:32.1385455Z ##[endgroup]
2026-02-14T13:00:32.1386314Z ##[group]Runner Image
2026-02-14T13:00:32.1387169Z Image: ubuntu-24.04
2026-02-14T13:00:32.1388044Z Version: 20260209.23.1
2026-02-14T13:00:32.1390114Z Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20260209.23/images/ubuntu/Ubuntu2404-Readme.md
2026-02-14T13:00:32.1393078Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20260209.23
2026-02-14T13:00:32.1394616Z ##[endgroup]
2026-02-14T13:00:32.1396398Z ##[group]GITHUB_TOKEN Permissions
2026-02-14T13:00:32.1399021Z Contents: read
2026-02-14T13:00:32.1399887Z Metadata: read
2026-02-14T13:00:32.1400647Z Packages: read
2026-02-14T13:00:32.1401801Z ##[endgroup]
2026-02-14T13:00:32.1404667Z Secret source: Actions
2026-02-14T13:00:32.1405750Z Prepare workflow directory
2026-02-14T13:00:32.2022135Z Prepare all required actions
2026-02-14T13:00:32.2079149Z Getting action download info
2026-02-14T13:00:32.4538256Z Download action repository 'actions/checkout@v4' (SHA:34e114876b0b11c390a56381ad16ebd13914f8d5)
2026-02-14T13:00:32.5956739Z Download action repository 'actions/setup-python@v5' (SHA:a26af69be951a213d495a4c3e4e4022e16d87065)
2026-02-14T13:00:32.7872887Z Complete job name: Run Tests
2026-02-14T13:00:32.8403433Z ##[group]Checking docker version
2026-02-14T13:00:32.8416252Z ##[command]/usr/bin/docker version --format '{{.Server.APIVersion}}'
2026-02-14T13:00:32.9397429Z '1.52'
2026-02-14T13:00:32.9412704Z Docker daemon API version: '1.52'
2026-02-14T13:00:32.9413441Z ##[command]/usr/bin/docker version --format '{{.Client.APIVersion}}'
2026-02-14T13:00:32.9593811Z '1.52'
2026-02-14T13:00:32.9607370Z Docker client API version: '1.52'
2026-02-14T13:00:32.9612873Z ##[endgroup]
2026-02-14T13:00:32.9615695Z ##[group]Clean up resources from previous jobs
2026-02-14T13:00:32.9620968Z ##[command]/usr/bin/docker ps --all --quiet --no-trunc --filter "label=fff484"
2026-02-14T13:00:32.9777362Z ##[command]/usr/bin/docker network prune --force --filter "label=fff484"
2026-02-14T13:00:32.9915378Z ##[endgroup]
2026-02-14T13:00:32.9915869Z ##[group]Create local container network
2026-02-14T13:00:32.9925704Z ##[command]/usr/bin/docker network create --label fff484 github_network_57f4fd6cd88f4d4cb79575ba7eeeead5
2026-02-14T13:00:33.0411448Z c0b321d14df26b38705af973cfa6494f4e6979d9adb41268086f0703003ae18b
2026-02-14T13:00:33.0429926Z ##[endgroup]
2026-02-14T13:00:33.0454034Z ##[group]Starting postgres service container
2026-02-14T13:00:33.0474144Z ##[command]/usr/bin/docker pull postgres:15
2026-02-14T13:00:33.3138184Z 15: Pulling from library/postgres
2026-02-14T13:00:33.6163566Z 49b40a0a623d: Pulling fs layer
2026-02-14T13:00:33.6164741Z 0c8d55a45c0d: Pulling fs layer
2026-02-14T13:00:33.6165505Z 03cf9c337134: Pulling fs layer
2026-02-14T13:00:33.6166507Z ea5e741a30ce: Pulling fs layer
2026-02-14T13:00:33.6167513Z d64dbdf800a2: Pulling fs layer
2026-02-14T13:00:33.6168528Z e60549838c5a: Pulling fs layer
2026-02-14T13:00:33.6169789Z 2710e764d89a: Pulling fs layer
2026-02-14T13:00:33.6170749Z 7b098c79e38c: Pulling fs layer
2026-02-14T13:00:33.6171783Z c50a02fe2f5f: Pulling fs layer
2026-02-14T13:00:33.6172812Z b64f280cfa2b: Pulling fs layer
2026-02-14T13:00:33.6173649Z 0ace4c983c3e: Pulling fs layer
2026-02-14T13:00:33.6174918Z 049b2237836a: Pulling fs layer
2026-02-14T13:00:33.6175848Z 7aa308802868: Pulling fs layer
2026-02-14T13:00:33.6177253Z 6771773ef0da: Pulling fs layer
2026-02-14T13:00:33.7669496Z 6771773ef0da: Download complete
2026-02-14T13:00:33.7673517Z 49b40a0a623d: Download complete
2026-02-14T13:00:33.7674725Z 7b098c79e38c: Download complete
2026-02-14T13:00:33.7680471Z 049b2237836a: Download complete
2026-02-14T13:00:33.7684756Z 0ace4c983c3e: Download complete
2026-02-14T13:00:33.7688077Z ea5e741a30ce: Download complete
2026-02-14T13:00:33.7693070Z b64f280cfa2b: Download complete
2026-02-14T13:00:33.7696713Z 7aa308802868: Download complete
2026-02-14T13:00:33.8654113Z d64dbdf800a2: Download complete
2026-02-14T13:00:33.8659688Z 2710e764d89a: Download complete
2026-02-14T13:00:33.9662275Z c50a02fe2f5f: Download complete
2026-02-14T13:00:33.9666337Z 0c8d55a45c0d: Download complete
2026-02-14T13:00:34.1665007Z 45604b1409ee: Download complete
2026-02-14T13:00:34.1667987Z 99548d060f18: Download complete
2026-02-14T13:00:34.3659120Z 03cf9c337134: Download complete
2026-02-14T13:00:34.4656491Z e60549838c5a: Download complete
2026-02-14T13:00:34.8708864Z 0c8d55a45c0d: Pull complete
2026-02-14T13:00:34.8716703Z 03cf9c337134: Pull complete
2026-02-14T13:00:35.0715031Z d64dbdf800a2: Pull complete
2026-02-14T13:00:35.0720874Z 2710e764d89a: Pull complete
2026-02-14T13:00:35.2679782Z 0ace4c983c3e: Pull complete
2026-02-14T13:00:35.2688121Z ea5e741a30ce: Pull complete
2026-02-14T13:00:35.2694383Z b64f280cfa2b: Pull complete
2026-02-14T13:00:35.2707990Z c50a02fe2f5f: Pull complete
2026-02-14T13:00:37.1496493Z 6771773ef0da: Pull complete
2026-02-14T13:00:37.1502703Z 49b40a0a623d: Pull complete
2026-02-14T13:00:37.1508391Z 7b098c79e38c: Pull complete
2026-02-14T13:00:37.1515881Z 049b2237836a: Pull complete
2026-02-14T13:00:37.1522308Z 7aa308802868: Pull complete
2026-02-14T13:00:37.1528135Z e60549838c5a: Pull complete
2026-02-14T13:00:37.1529378Z Digest: sha256:dafc4d8e8369da730a5ee9a320a0f0b3c6aa516f41244689c4493a27dc84472d
2026-02-14T13:00:37.1530252Z Status: Downloaded newer image for postgres:15
2026-02-14T13:00:37.1537127Z docker.io/library/postgres:15
2026-02-14T13:00:37.1596953Z ##[command]/usr/bin/docker create --name abae9058ae674410bf9fa3ccfc161078_postgres15_27ffaa --label fff484 --network github_network_57f4fd6cd88f4d4cb79575ba7eeeead5 --network-alias postgres -p 5432:5432 --health-cmd pg_isready --health-interval 10s --health-timeout 5s --health-retries 5 -e "POSTGRES_USER=postgres" -e "POSTGRES_PASSWORD=postgres" -e "POSTGRES_DB=job_search_test" -e GITHUB_ACTIONS=true -e CI=true postgres:15
2026-02-14T13:00:39.8422628Z 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:39.8447145Z ##[command]/usr/bin/docker start 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:40.1453559Z 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:40.1474457Z ##[command]/usr/bin/docker ps --all --filter id=3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505 --filter status=running --no-trunc --format "{{.ID}} {{.Status}}"
2026-02-14T13:00:40.1773656Z 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505 Up Less than a second (health: starting)
2026-02-14T13:00:40.1801493Z ##[command]/usr/bin/docker port 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:40.1935785Z 5432/tcp -> 0.0.0.0:5432
2026-02-14T13:00:40.1936617Z 5432/tcp -> [::]:5432
2026-02-14T13:00:40.1987072Z ##[endgroup]
2026-02-14T13:00:40.1995603Z ##[group]Waiting for all services to be ready
2026-02-14T13:00:40.2009509Z ##[command]/usr/bin/docker inspect --format="{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}" 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:40.2152046Z starting
2026-02-14T13:00:40.2177028Z postgres service is starting, waiting 2 seconds before checking again.
2026-02-14T13:00:42.2172090Z ##[command]/usr/bin/docker inspect --format="{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}" 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:42.2295902Z starting
2026-02-14T13:00:42.2310745Z postgres service is starting, waiting 4 seconds before checking again.
2026-02-14T13:00:46.4429059Z ##[command]/usr/bin/docker inspect --format="{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}" 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:46.4557119Z starting
2026-02-14T13:00:46.4576884Z postgres service is starting, waiting 7 seconds before checking again.
2026-02-14T13:00:53.7529291Z ##[command]/usr/bin/docker inspect --format="{{if .Config.Healthcheck}}{{print .State.Health.Status}}{{end}}" 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:00:53.7663076Z healthy
2026-02-14T13:00:53.7682069Z postgres service is healthy.
2026-02-14T13:00:53.7682772Z ##[endgroup]
2026-02-14T13:00:53.8011874Z ##[group]Run actions/checkout@v4
2026-02-14T13:00:53.8012457Z with:
2026-02-14T13:00:53.8012688Z   repository: filmozolevskiy/job-etl-project
2026-02-14T13:00:53.8013238Z   token: ***
2026-02-14T13:00:53.8013427Z   ssh-strict: true
2026-02-14T13:00:53.8013607Z   ssh-user: git
2026-02-14T13:00:53.8013784Z   persist-credentials: true
2026-02-14T13:00:53.8014002Z   clean: true
2026-02-14T13:00:53.8014185Z   sparse-checkout-cone-mode: true
2026-02-14T13:00:53.8014415Z   fetch-depth: 1
2026-02-14T13:00:53.8014580Z   fetch-tags: false
2026-02-14T13:00:53.8014754Z   show-progress: true
2026-02-14T13:00:53.8014930Z   lfs: false
2026-02-14T13:00:53.8015094Z   submodules: false
2026-02-14T13:00:53.8015276Z   set-safe-directory: true
2026-02-14T13:00:53.8015660Z env:
2026-02-14T13:00:53.8016116Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:00:53.8016413Z ##[endgroup]
2026-02-14T13:00:53.9157640Z Syncing repository: filmozolevskiy/job-etl-project
2026-02-14T13:00:53.9159769Z ##[group]Getting Git version info
2026-02-14T13:00:53.9160503Z Working directory is '/home/runner/work/job-etl-project/job-etl-project'
2026-02-14T13:00:53.9161900Z [command]/usr/bin/git version
2026-02-14T13:00:53.9174252Z git version 2.52.0
2026-02-14T13:00:53.9200967Z ##[endgroup]
2026-02-14T13:00:53.9217157Z Temporarily overriding HOME='/home/runner/work/_temp/ad28e594-92e9-45ae-9939-5a6e8e322b74' before making global git config changes
2026-02-14T13:00:53.9218559Z Adding repository directory to the temporary git global config as a safe directory
2026-02-14T13:00:53.9223752Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/job-etl-project/job-etl-project
2026-02-14T13:00:53.9266171Z Deleting the contents of '/home/runner/work/job-etl-project/job-etl-project'
2026-02-14T13:00:53.9270197Z ##[group]Initializing the repository
2026-02-14T13:00:53.9275375Z [command]/usr/bin/git init /home/runner/work/job-etl-project/job-etl-project
2026-02-14T13:00:53.9389007Z hint: Using 'master' as the name for the initial branch. This default branch name
2026-02-14T13:00:53.9390119Z hint: will change to "main" in Git 3.0. To configure the initial branch name
2026-02-14T13:00:53.9390671Z hint: to use in all of your new repositories, which will suppress this warning,
2026-02-14T13:00:53.9391290Z hint: call:
2026-02-14T13:00:53.9391485Z hint:
2026-02-14T13:00:53.9391831Z hint: 	git config --global init.defaultBranch <name>
2026-02-14T13:00:53.9392392Z hint:
2026-02-14T13:00:53.9392890Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2026-02-14T13:00:53.9393552Z hint: 'development'. The just-created branch can be renamed via this command:
2026-02-14T13:00:53.9393919Z hint:
2026-02-14T13:00:53.9394107Z hint: 	git branch -m <name>
2026-02-14T13:00:53.9394499Z hint:
2026-02-14T13:00:53.9395028Z hint: Disable this message with "git config set advice.defaultBranchName false"
2026-02-14T13:00:53.9396110Z Initialized empty Git repository in /home/runner/work/job-etl-project/job-etl-project/.git/
2026-02-14T13:00:53.9406792Z [command]/usr/bin/git remote add origin https://github.com/filmozolevskiy/job-etl-project
2026-02-14T13:00:53.9444353Z ##[endgroup]
2026-02-14T13:00:53.9445263Z ##[group]Disabling automatic garbage collection
2026-02-14T13:00:53.9449973Z [command]/usr/bin/git config --local gc.auto 0
2026-02-14T13:00:53.9480027Z ##[endgroup]
2026-02-14T13:00:53.9480555Z ##[group]Setting up auth
2026-02-14T13:00:53.9487434Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-14T13:00:53.9519476Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-14T13:00:53.9899982Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-14T13:00:53.9933115Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-14T13:00:54.0183468Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-14T13:00:54.0218201Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-14T13:00:54.0467402Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2026-02-14T13:00:54.0506792Z ##[endgroup]
2026-02-14T13:00:54.0507477Z ##[group]Fetching the repository
2026-02-14T13:00:54.0517366Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +e0c2865e6a1ffd62233469605bb2e4a4c7aafc21:refs/remotes/pull/29/merge
2026-02-14T13:00:54.3574253Z From https://github.com/filmozolevskiy/job-etl-project
2026-02-14T13:00:54.3575035Z  * [new ref]         e0c2865e6a1ffd62233469605bb2e4a4c7aafc21 -> pull/29/merge
2026-02-14T13:00:54.3612866Z ##[endgroup]
2026-02-14T13:00:54.3613438Z ##[group]Determining the checkout info
2026-02-14T13:00:54.3614362Z ##[endgroup]
2026-02-14T13:00:54.3619591Z [command]/usr/bin/git sparse-checkout disable
2026-02-14T13:00:54.3665912Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2026-02-14T13:00:54.3697884Z ##[group]Checking out the ref
2026-02-14T13:00:54.3698564Z [command]/usr/bin/git checkout --progress --force refs/remotes/pull/29/merge
2026-02-14T13:00:54.4076657Z Note: switching to 'refs/remotes/pull/29/merge'.
2026-02-14T13:00:54.4077106Z 
2026-02-14T13:00:54.4077481Z You are in 'detached HEAD' state. You can look around, make experimental
2026-02-14T13:00:54.4078010Z changes and commit them, and you can discard any commits you make in this
2026-02-14T13:00:54.4078486Z state without impacting any branches by switching back to a branch.
2026-02-14T13:00:54.4078763Z 
2026-02-14T13:00:54.4078985Z If you want to create a new branch to retain commits you create, you may
2026-02-14T13:00:54.4079424Z do so (now or later) by using -c with the switch command. Example:
2026-02-14T13:00:54.4079681Z 
2026-02-14T13:00:54.4079785Z   git switch -c <new-branch-name>
2026-02-14T13:00:54.4079963Z 
2026-02-14T13:00:54.4080057Z Or undo this operation with:
2026-02-14T13:00:54.4080214Z 
2026-02-14T13:00:54.4080299Z   git switch -
2026-02-14T13:00:54.4080430Z 
2026-02-14T13:00:54.4080652Z Turn off this advice by setting config variable advice.detachedHead to false
2026-02-14T13:00:54.4081350Z 
2026-02-14T13:00:54.4081942Z HEAD is now at e0c2865 Merge 0b761a9fdc8dd13a6881192110746f5c49259c35 into 15538d61e29046a4cda7dec520634bd0f2ac0c83
2026-02-14T13:00:54.4087708Z ##[endgroup]
2026-02-14T13:00:54.4131436Z [command]/usr/bin/git log -1 --format=%H
2026-02-14T13:00:54.4157267Z e0c2865e6a1ffd62233469605bb2e4a4c7aafc21
2026-02-14T13:00:54.4380253Z ##[group]Run actions/setup-python@v5
2026-02-14T13:00:54.4380533Z with:
2026-02-14T13:00:54.4380700Z   python-version: 3.11
2026-02-14T13:00:54.4380901Z   check-latest: false
2026-02-14T13:00:54.4381383Z   token: ***
2026-02-14T13:00:54.4381568Z   update-environment: true
2026-02-14T13:00:54.4381791Z   allow-prereleases: false
2026-02-14T13:00:54.4382199Z   freethreaded: false
2026-02-14T13:00:54.4382382Z env:
2026-02-14T13:00:54.4382818Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:00:54.4383106Z ##[endgroup]
2026-02-14T13:00:54.6069651Z ##[group]Installed versions
2026-02-14T13:00:54.6179261Z Successfully set up CPython (3.11.14)
2026-02-14T13:00:54.6179989Z ##[endgroup]
2026-02-14T13:00:54.6289388Z ##[group]Run sudo apt-get update
2026-02-14T13:00:54.6289755Z [36;1msudo apt-get update[0m
2026-02-14T13:00:54.6290045Z [36;1msudo apt-get install -y postgresql-client[0m
2026-02-14T13:00:54.6359781Z shell: /usr/bin/bash -e {0}
2026-02-14T13:00:54.6360025Z env:
2026-02-14T13:00:54.6360541Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:00:54.6360925Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:00:54.6361764Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:00:54.6362168Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:00:54.6362528Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:00:54.6362881Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:00:54.6363235Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:00:54.6363533Z ##[endgroup]
2026-02-14T13:00:54.7388095Z Get:1 file:/etc/apt/apt-mirrors.txt Mirrorlist [144 B]
2026-02-14T13:00:54.7719085Z Hit:2 http://azure.archive.ubuntu.com/ubuntu noble InRelease
2026-02-14T13:00:54.7769696Z Get:3 http://azure.archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]
2026-02-14T13:00:54.7781429Z Get:4 http://azure.archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]
2026-02-14T13:00:54.7815459Z Get:5 http://azure.archive.ubuntu.com/ubuntu noble-security InRelease [126 kB]
2026-02-14T13:00:54.7952580Z Get:6 https://packages.microsoft.com/repos/azure-cli noble InRelease [3564 B]
2026-02-14T13:00:54.8033058Z Get:7 https://packages.microsoft.com/ubuntu/24.04/prod noble InRelease [3600 B]
2026-02-14T13:00:54.9312396Z Get:8 http://azure.archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [1742 kB]
2026-02-14T13:00:54.9523433Z Get:9 http://azure.archive.ubuntu.com/ubuntu noble-updates/main Translation-en [325 kB]
2026-02-14T13:00:54.9556296Z Get:10 http://azure.archive.ubuntu.com/ubuntu noble-updates/main amd64 Components [175 kB]
2026-02-14T13:00:54.9569069Z Get:11 http://azure.archive.ubuntu.com/ubuntu noble-updates/main amd64 c-n-f Metadata [16.5 kB]
2026-02-14T13:00:54.9576780Z Get:12 http://azure.archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1529 kB]
2026-02-14T13:00:54.9708302Z Get:13 http://azure.archive.ubuntu.com/ubuntu noble-updates/universe Translation-en [313 kB]
2026-02-14T13:00:54.9744860Z Get:14 http://azure.archive.ubuntu.com/ubuntu noble-updates/universe amd64 Components [386 kB]
2026-02-14T13:00:54.9787634Z Get:15 http://azure.archive.ubuntu.com/ubuntu noble-updates/universe amd64 c-n-f Metadata [31.9 kB]
2026-02-14T13:00:54.9804356Z Get:16 http://azure.archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [2594 kB]
2026-02-14T13:00:54.9972819Z Get:17 http://azure.archive.ubuntu.com/ubuntu noble-updates/restricted Translation-en [595 kB]
2026-02-14T13:00:55.0407495Z Get:18 http://azure.archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Components [212 B]
2026-02-14T13:00:55.0413554Z Get:19 http://azure.archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Components [940 B]
2026-02-14T13:00:55.0420097Z Get:20 http://azure.archive.ubuntu.com/ubuntu noble-backports/main amd64 Components [7312 B]
2026-02-14T13:00:55.0434849Z Get:21 http://azure.archive.ubuntu.com/ubuntu noble-backports/universe amd64 Components [10.5 kB]
2026-02-14T13:00:55.0450827Z Get:22 http://azure.archive.ubuntu.com/ubuntu noble-backports/restricted amd64 Components [216 B]
2026-02-14T13:00:55.0465064Z Get:23 http://azure.archive.ubuntu.com/ubuntu noble-backports/multiverse amd64 Components [212 B]
2026-02-14T13:00:55.1032488Z Get:24 http://azure.archive.ubuntu.com/ubuntu noble-security/main amd64 Packages [1448 kB]
2026-02-14T13:00:55.1180814Z Get:25 http://azure.archive.ubuntu.com/ubuntu noble-security/main Translation-en [234 kB]
2026-02-14T13:00:55.1189177Z Get:26 http://azure.archive.ubuntu.com/ubuntu noble-security/main amd64 Components [21.5 kB]
2026-02-14T13:00:55.1210658Z Get:27 http://azure.archive.ubuntu.com/ubuntu noble-security/main amd64 c-n-f Metadata [9892 B]
2026-02-14T13:00:55.1272372Z Get:28 http://azure.archive.ubuntu.com/ubuntu noble-security/universe amd64 Packages [930 kB]
2026-02-14T13:00:55.1343891Z Get:29 http://azure.archive.ubuntu.com/ubuntu noble-security/universe Translation-en [212 kB]
2026-02-14T13:00:55.1347157Z Get:30 http://azure.archive.ubuntu.com/ubuntu noble-security/universe amd64 Components [74.2 kB]
2026-02-14T13:00:55.1361839Z Get:31 http://azure.archive.ubuntu.com/ubuntu noble-security/universe amd64 c-n-f Metadata [19.9 kB]
2026-02-14T13:00:55.1764918Z Get:36 https://packages.microsoft.com/repos/azure-cli noble/main amd64 Packages [2129 B]
2026-02-14T13:00:55.1819056Z Get:32 http://azure.archive.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [2452 kB]
2026-02-14T13:00:55.1951525Z Get:33 http://azure.archive.ubuntu.com/ubuntu noble-security/restricted Translation-en [564 kB]
2026-02-14T13:00:55.2004205Z Get:34 http://azure.archive.ubuntu.com/ubuntu noble-security/restricted amd64 Components [212 B]
2026-02-14T13:00:55.2012317Z Get:35 http://azure.archive.ubuntu.com/ubuntu noble-security/multiverse amd64 Components [212 B]
2026-02-14T13:00:55.2363955Z Get:37 https://packages.microsoft.com/ubuntu/24.04/prod noble/main arm64 Packages [69.0 kB]
2026-02-14T13:00:55.2519566Z Get:38 https://packages.microsoft.com/ubuntu/24.04/prod noble/main amd64 Packages [89.5 kB]
2026-02-14T13:00:55.2626801Z Get:39 https://packages.microsoft.com/ubuntu/24.04/prod noble/main armhf Packages [11.4 kB]
2026-02-14T13:00:55.2711271Z Get:40 https://packages.microsoft.com/ubuntu/24.04/prod noble/main all Packages [643 B]
2026-02-14T13:01:00.6042671Z Fetched 14.3 MB in 2s (8507 kB/s)
2026-02-14T13:01:01.3931313Z Reading package lists...
2026-02-14T13:01:01.4276639Z Reading package lists...
2026-02-14T13:01:01.6388998Z Building dependency tree...
2026-02-14T13:01:01.6396660Z Reading state information...
2026-02-14T13:01:01.8421619Z The following NEW packages will be installed:
2026-02-14T13:01:01.8422438Z   postgresql-client
2026-02-14T13:01:01.8602037Z 0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.
2026-02-14T13:01:01.8602435Z Need to get 11.6 kB of archives.
2026-02-14T13:01:01.8602763Z After this operation, 17.4 kB of additional disk space will be used.
2026-02-14T13:01:01.8603153Z Get:1 file:/etc/apt/apt-mirrors.txt Mirrorlist [144 B]
2026-02-14T13:01:01.8782001Z Get:2 http://azure.archive.ubuntu.com/ubuntu noble-updates/main amd64 postgresql-client all 16+257build1.1 [11.6 kB]
2026-02-14T13:01:02.1446809Z Fetched 11.6 kB in 0s (402 kB/s)
2026-02-14T13:01:02.1682554Z Selecting previously unselected package postgresql-client.
2026-02-14T13:01:02.2008202Z (Reading database ... 
2026-02-14T13:01:02.2008875Z (Reading database ... 5%
2026-02-14T13:01:02.2009282Z (Reading database ... 10%
2026-02-14T13:01:02.2009686Z (Reading database ... 15%
2026-02-14T13:01:02.2010155Z (Reading database ... 20%
2026-02-14T13:01:02.2010556Z (Reading database ... 25%
2026-02-14T13:01:02.2010989Z (Reading database ... 30%
2026-02-14T13:01:02.2011657Z (Reading database ... 35%
2026-02-14T13:01:02.2012142Z (Reading database ... 40%
2026-02-14T13:01:02.2012525Z (Reading database ... 45%
2026-02-14T13:01:02.2012998Z (Reading database ... 50%
2026-02-14T13:01:02.2113112Z (Reading database ... 55%
2026-02-14T13:01:02.2748021Z (Reading database ... 60%
2026-02-14T13:01:02.3238493Z (Reading database ... 65%
2026-02-14T13:01:02.3704744Z (Reading database ... 70%
2026-02-14T13:01:02.4194624Z (Reading database ... 75%
2026-02-14T13:01:02.5252118Z (Reading database ... 80%
2026-02-14T13:01:02.7307682Z (Reading database ... 85%
2026-02-14T13:01:02.9075543Z (Reading database ... 90%
2026-02-14T13:01:03.0779674Z (Reading database ... 95%
2026-02-14T13:01:03.0780106Z (Reading database ... 100%
2026-02-14T13:01:03.0780587Z (Reading database ... 218331 files and directories currently installed.)
2026-02-14T13:01:03.0825251Z Preparing to unpack .../postgresql-client_16+257build1.1_all.deb ...
2026-02-14T13:01:03.0851705Z Unpacking postgresql-client (16+257build1.1) ...
2026-02-14T13:01:03.1254079Z Setting up postgresql-client (16+257build1.1) ...
2026-02-14T13:01:03.8136619Z 
2026-02-14T13:01:03.8137196Z Running kernel seems to be up-to-date.
2026-02-14T13:01:03.8137831Z 
2026-02-14T13:01:03.8138105Z No services need to be restarted.
2026-02-14T13:01:03.8138383Z 
2026-02-14T13:01:03.8138705Z No containers need to be restarted.
2026-02-14T13:01:03.8139101Z 
2026-02-14T13:01:03.8139534Z No user sessions are running outdated binaries.
2026-02-14T13:01:03.8140111Z 
2026-02-14T13:01:03.8140420Z No VM guests are running outdated hypervisor (qemu) binaries on this host.
2026-02-14T13:01:04.8056513Z ##[group]Run until pg_isready -h 127.0.0.1 -p 5432 -U postgres; do
2026-02-14T13:01:04.8057299Z [36;1muntil pg_isready -h 127.0.0.1 -p 5432 -U postgres; do[0m
2026-02-14T13:01:04.8057903Z [36;1m  echo "Waiting for PostgreSQL..."[0m
2026-02-14T13:01:04.8058341Z [36;1m  sleep 2[0m
2026-02-14T13:01:04.8058638Z [36;1mdone[0m
2026-02-14T13:01:04.8115960Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:04.8116340Z env:
2026-02-14T13:01:04.8117179Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:04.8117835Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8118558Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:04.8119168Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8119514Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8119891Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8120401Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:04.8121310Z ##[endgroup]
2026-02-14T13:01:04.8755206Z 127.0.0.1:5432 - accepting connections
2026-02-14T13:01:04.8792615Z ##[group]Run set -e
2026-02-14T13:01:04.8792865Z [36;1mset -e[0m
2026-02-14T13:01:04.8793304Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/01_create_schemas.sql[0m
2026-02-14T13:01:04.8844873Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:04.8845096Z env:
2026-02-14T13:01:04.8845604Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:04.8845989Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8846400Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:04.8846822Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8847187Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8847540Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.8847917Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:04.8848208Z ##[endgroup]
2026-02-14T13:01:04.9788646Z CREATE SCHEMA
2026-02-14T13:01:04.9791480Z CREATE SCHEMA
2026-02-14T13:01:04.9795265Z CREATE SCHEMA
2026-02-14T13:01:04.9820464Z DO
2026-02-14T13:01:04.9824444Z GRANT
2026-02-14T13:01:04.9828086Z GRANT
2026-02-14T13:01:04.9831273Z GRANT
2026-02-14T13:01:04.9877073Z ##[group]Run set -e
2026-02-14T13:01:04.9877312Z [36;1mset -e[0m
2026-02-14T13:01:04.9877736Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/02_create_tables.sql[0m
2026-02-14T13:01:04.9933374Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:04.9933605Z env:
2026-02-14T13:01:04.9934177Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:04.9934557Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.9934976Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:04.9935589Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.9935952Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.9936308Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:04.9936660Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:04.9936960Z ##[endgroup]
2026-02-14T13:01:05.0416564Z CREATE TABLE
2026-02-14T13:01:05.0441813Z COMMENT
2026-02-14T13:01:05.0442089Z CREATE TABLE
2026-02-14T13:01:05.0442344Z COMMENT
2026-02-14T13:01:05.0470632Z CREATE TABLE
2026-02-14T13:01:05.0474864Z COMMENT
2026-02-14T13:01:05.0525636Z CREATE TABLE
2026-02-14T13:01:05.0529017Z COMMENT
2026-02-14T13:01:05.0562346Z CREATE TABLE
2026-02-14T13:01:05.0568058Z COMMENT
2026-02-14T13:01:05.0597476Z CREATE TABLE
2026-02-14T13:01:05.0601513Z COMMENT
2026-02-14T13:01:05.0626020Z CREATE TABLE
2026-02-14T13:01:05.0629483Z COMMENT
2026-02-14T13:01:05.0668320Z CREATE TABLE
2026-02-14T13:01:05.0672950Z COMMENT
2026-02-14T13:01:05.0684891Z CREATE INDEX
2026-02-14T13:01:05.0699758Z CREATE INDEX
2026-02-14T13:01:05.0712782Z CREATE INDEX
2026-02-14T13:01:05.0735344Z CREATE INDEX
2026-02-14T13:01:05.0754118Z CREATE INDEX
2026-02-14T13:01:05.0766148Z CREATE INDEX
2026-02-14T13:01:05.0778375Z CREATE INDEX
2026-02-14T13:01:05.0789978Z CREATE INDEX
2026-02-14T13:01:05.0801708Z CREATE INDEX
2026-02-14T13:01:05.0814096Z CREATE INDEX
2026-02-14T13:01:05.0825214Z CREATE INDEX
2026-02-14T13:01:05.0836406Z CREATE INDEX
2026-02-14T13:01:05.0847463Z CREATE INDEX
2026-02-14T13:01:05.0858337Z CREATE INDEX
2026-02-14T13:01:05.0868251Z CREATE INDEX
2026-02-14T13:01:05.0880985Z CREATE INDEX
2026-02-14T13:01:05.0893641Z CREATE INDEX
2026-02-14T13:01:05.0904553Z CREATE INDEX
2026-02-14T13:01:05.0916339Z CREATE INDEX
2026-02-14T13:01:05.0935081Z DO
2026-02-14T13:01:05.0938539Z GRANT
2026-02-14T13:01:05.0942211Z GRANT
2026-02-14T13:01:05.0945192Z GRANT
2026-02-14T13:01:05.0948715Z GRANT
2026-02-14T13:01:05.0951847Z GRANT
2026-02-14T13:01:05.0955640Z GRANT
2026-02-14T13:01:05.0958452Z GRANT
2026-02-14T13:01:05.0962295Z GRANT
2026-02-14T13:01:05.1012778Z ##[group]Run set -e
2026-02-14T13:01:05.1013091Z [36;1mset -e[0m
2026-02-14T13:01:05.1013568Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/08_add_resume_cover_letter_tables.sql[0m
2026-02-14T13:01:05.1064013Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.1064251Z env:
2026-02-14T13:01:05.1064756Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.1065145Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1065573Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.1065973Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1066314Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1066672Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1067044Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.1067365Z ##[endgroup]
2026-02-14T13:01:05.1542657Z CREATE TABLE
2026-02-14T13:01:05.1547080Z COMMENT
2026-02-14T13:01:05.1576431Z CREATE TABLE
2026-02-14T13:01:05.1580186Z COMMENT
2026-02-14T13:01:05.1619815Z CREATE TABLE
2026-02-14T13:01:05.1623243Z COMMENT
2026-02-14T13:01:05.1634110Z CREATE INDEX
2026-02-14T13:01:05.1645630Z CREATE INDEX
2026-02-14T13:01:05.1656391Z CREATE INDEX
2026-02-14T13:01:05.1667540Z CREATE INDEX
2026-02-14T13:01:05.1679328Z CREATE INDEX
2026-02-14T13:01:05.1689402Z CREATE INDEX
2026-02-14T13:01:05.1700342Z CREATE INDEX
2026-02-14T13:01:05.1711198Z CREATE INDEX
2026-02-14T13:01:05.1728393Z DO
2026-02-14T13:01:05.1731627Z GRANT
2026-02-14T13:01:05.1734704Z GRANT
2026-02-14T13:01:05.1737737Z GRANT
2026-02-14T13:01:05.1780237Z ##[group]Run set -e
2026-02-14T13:01:05.1780497Z [36;1mset -e[0m
2026-02-14T13:01:05.1780696Z [36;1mecho "Running migration script..."[0m
2026-02-14T13:01:05.1781547Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/09_add_documents_section_flag.sql[0m
2026-02-14T13:01:05.1782349Z [36;1mecho "Verifying migration..."[0m
2026-02-14T13:01:05.1782666Z [36;1m# Verify migration succeeded - check both tables[0m
2026-02-14T13:01:05.1783649Z [36;1mRESUME_COUNT=$(PGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -t -A -c "SELECT COUNT(*) FROM information_schema.columns WHERE table_schema = 'marts' AND table_name = 'user_resumes' AND column_name = 'in_documents_section';")[0m
2026-02-14T13:01:05.1785306Z [36;1mCOVER_LETTER_COUNT=$(PGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -t -A -c "SELECT COUNT(*) FROM information_schema.columns WHERE table_schema = 'marts' AND table_name = 'user_cover_letters' AND column_name = 'in_documents_section';")[0m
2026-02-14T13:01:05.1786267Z [36;1mif [ "$RESUME_COUNT" -ne "1" ]; then[0m
2026-02-14T13:01:05.1786770Z [36;1m  echo "ERROR: Migration failed - in_documents_section column not found in user_resumes (count: $RESUME_COUNT)"[0m
2026-02-14T13:01:05.1787258Z [36;1m  exit 1[0m
2026-02-14T13:01:05.1787418Z [36;1mfi[0m
2026-02-14T13:01:05.1787617Z [36;1mif [ "$COVER_LETTER_COUNT" -ne "1" ]; then[0m
2026-02-14T13:01:05.1788167Z [36;1m  echo "ERROR: Migration failed - in_documents_section column not found in user_cover_letters (count: $COVER_LETTER_COUNT)"[0m
2026-02-14T13:01:05.1788682Z [36;1m  exit 1[0m
2026-02-14T13:01:05.1788836Z [36;1mfi[0m
2026-02-14T13:01:05.1789105Z [36;1mecho "Migration verification: Both columns exist successfully"[0m
2026-02-14T13:01:05.1839029Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.1839260Z env:
2026-02-14T13:01:05.1839755Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.1840156Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1840580Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.1840982Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1841680Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1842044Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.1842395Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.1842691Z ##[endgroup]
2026-02-14T13:01:05.1913911Z Running migration script...
2026-02-14T13:01:05.2365553Z DO
2026-02-14T13:01:05.2394364Z DO
2026-02-14T13:01:05.2409592Z CREATE INDEX
2026-02-14T13:01:05.2422465Z CREATE INDEX
2026-02-14T13:01:05.2435903Z Verifying migration...
2026-02-14T13:01:05.3281355Z Migration verification: Both columns exist successfully
2026-02-14T13:01:05.3310409Z ##[group]Run set -e
2026-02-14T13:01:05.3310655Z [36;1mset -e[0m
2026-02-14T13:01:05.3311417Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/14_create_user_job_status_table.sql[0m
2026-02-14T13:01:05.3362161Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.3362402Z env:
2026-02-14T13:01:05.3362911Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.3363286Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.3363712Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.3364117Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.3364490Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.3364853Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.3365204Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.3365533Z ##[endgroup]
2026-02-14T13:01:05.3888429Z DO
2026-02-14T13:01:05.3892987Z COMMENT
2026-02-14T13:01:05.3905602Z CREATE INDEX
2026-02-14T13:01:05.3917122Z CREATE INDEX
2026-02-14T13:01:05.3927252Z CREATE INDEX
2026-02-14T13:01:05.3934481Z DO
2026-02-14T13:01:05.3937428Z GRANT
2026-02-14T13:01:05.3982595Z ##[group]Run set -e
2026-02-14T13:01:05.3983014Z [36;1mset -e[0m
2026-02-14T13:01:05.3983486Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/14_add_job_status_history_table.sql[0m
2026-02-14T13:01:05.4035796Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.4036018Z env:
2026-02-14T13:01:05.4036525Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.4036927Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4037332Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.4037718Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4038066Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4038417Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4038768Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.4039097Z ##[endgroup]
2026-02-14T13:01:05.4563577Z DO
2026-02-14T13:01:05.4568241Z COMMENT
2026-02-14T13:01:05.4572236Z COMMENT
2026-02-14T13:01:05.4575197Z COMMENT
2026-02-14T13:01:05.4578006Z COMMENT
2026-02-14T13:01:05.4581431Z COMMENT
2026-02-14T13:01:05.4595218Z CREATE INDEX
2026-02-14T13:01:05.4613170Z CREATE INDEX
2026-02-14T13:01:05.4622300Z CREATE INDEX
2026-02-14T13:01:05.4635106Z CREATE INDEX
2026-02-14T13:01:05.4648251Z CREATE INDEX
2026-02-14T13:01:05.4657143Z DO
2026-02-14T13:01:05.4672343Z GRANT
2026-02-14T13:01:05.4704867Z ##[group]Run set -e
2026-02-14T13:01:05.4705104Z [36;1mset -e[0m
2026-02-14T13:01:05.4705581Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/15_modify_job_notes_multi_note.sql[0m
2026-02-14T13:01:05.4762770Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.4763002Z env:
2026-02-14T13:01:05.4763678Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.4764070Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4764497Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.4764909Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4765264Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4765614Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.4765975Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.4766316Z ##[endgroup]
2026-02-14T13:01:05.5236391Z psql:docker/init/15_modify_job_notes_multi_note.sql:25: NOTICE:  Dropped unique constraint unique_job_user_note
2026-02-14T13:01:05.5240333Z DO
2026-02-14T13:01:05.5248615Z CREATE FUNCTION
2026-02-14T13:01:05.5252519Z COMMENT
2026-02-14T13:01:05.5256638Z DO
2026-02-14T13:01:05.5262168Z ALTER TABLE
2026-02-14T13:01:05.5265974Z COMMENT
2026-02-14T13:01:05.5269502Z COMMENT
2026-02-14T13:01:05.5274264Z DELETE 0
2026-02-14T13:01:05.5277202Z DO
2026-02-14T13:01:05.5316150Z ##[group]Run set -e
2026-02-14T13:01:05.5316390Z [36;1mset -e[0m
2026-02-14T13:01:05.5316852Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/16_add_job_notes_indexes.sql[0m
2026-02-14T13:01:05.5369001Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.5369230Z env:
2026-02-14T13:01:05.5369717Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.5370120Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5370529Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.5370934Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5371502Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5371868Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5372223Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.5372525Z ##[endgroup]
2026-02-14T13:01:05.5838325Z CREATE INDEX
2026-02-14T13:01:05.5847811Z CREATE INDEX
2026-02-14T13:01:05.5858056Z CREATE INDEX
2026-02-14T13:01:05.5863033Z COMMENT
2026-02-14T13:01:05.5866690Z COMMENT
2026-02-14T13:01:05.5870445Z COMMENT
2026-02-14T13:01:05.5910080Z ##[group]Run set -e
2026-02-14T13:01:05.5910308Z [36;1mset -e[0m
2026-02-14T13:01:05.5910769Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/18_create_staging_slots_table.sql[0m
2026-02-14T13:01:05.5961890Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.5962114Z env:
2026-02-14T13:01:05.5962587Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.5962966Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5963377Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.5963768Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5964118Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5964465Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.5964830Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.5965155Z ##[endgroup]
2026-02-14T13:01:05.6463090Z DO
2026-02-14T13:01:05.6467137Z COMMENT
2026-02-14T13:01:05.6474230Z INSERT 0 10
2026-02-14T13:01:05.6478875Z UPDATE 1
2026-02-14T13:01:05.6483109Z UPDATE 1
2026-02-14T13:01:05.6488741Z DO
2026-02-14T13:01:05.6491860Z GRANT
2026-02-14T13:01:05.6535339Z ##[group]Run set -e
2026-02-14T13:01:05.6535723Z [36;1mset -e[0m
2026-02-14T13:01:05.6536232Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/19_seed_admin_user.sql[0m
2026-02-14T13:01:05.6587133Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.6587448Z env:
2026-02-14T13:01:05.6588139Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.6588638Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.6589101Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.6589721Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.6590202Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.6590617Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.6591429Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.6591787Z ##[endgroup]
2026-02-14T13:01:05.7076681Z INSERT 0 1
2026-02-14T13:01:05.7081524Z INSERT 0 1
2026-02-14T13:01:05.7125363Z ##[group]Run set -e
2026-02-14T13:01:05.7125603Z [36;1mset -e[0m
2026-02-14T13:01:05.7126076Z [36;1mPGPASSWORD=postgres psql -h 127.0.0.1 -U postgres -d job_search_test -f docker/init/21_add_campaign_id_to_user_tables.sql[0m
2026-02-14T13:01:05.7177967Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.7178195Z env:
2026-02-14T13:01:05.7178683Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.7179077Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7179483Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.7179897Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7180259Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7180639Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7181008Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.7181615Z ##[endgroup]
2026-02-14T13:01:05.7732673Z psql:docker/init/21_add_campaign_id_to_user_tables.sql:52: NOTICE:  Added campaign_id column to user_job_status and populated existing records
2026-02-14T13:01:05.7734586Z DO
2026-02-14T13:01:05.7749168Z psql:docker/init/21_add_campaign_id_to_user_tables.sql:72: NOTICE:  Added FK constraint fk_user_job_status_campaign
2026-02-14T13:01:05.7750492Z DO
2026-02-14T13:01:05.7765134Z CREATE INDEX
2026-02-14T13:01:05.7829740Z psql:docker/init/21_add_campaign_id_to_user_tables.sql:162: NOTICE:  Added campaign_id column to job_notes and populated existing records
2026-02-14T13:01:05.7831255Z DO
2026-02-14T13:01:05.7842160Z psql:docker/init/21_add_campaign_id_to_user_tables.sql:182: NOTICE:  Added FK constraint fk_job_notes_campaign
2026-02-14T13:01:05.7843456Z DO
2026-02-14T13:01:05.7856407Z CREATE INDEX
2026-02-14T13:01:05.7860501Z COMMENT
2026-02-14T13:01:05.7864127Z COMMENT
2026-02-14T13:01:05.7903667Z ##[group]Run python -m pip install --upgrade pip
2026-02-14T13:01:05.7904025Z [36;1mpython -m pip install --upgrade pip[0m
2026-02-14T13:01:05.7904309Z [36;1mpip install -r requirements.txt[0m
2026-02-14T13:01:05.7956641Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:05.7956877Z env:
2026-02-14T13:01:05.7957354Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:05.7957739Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7958158Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:05.7958551Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7958921Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7959286Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:05.7959663Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:05.7959961Z ##[endgroup]
2026-02-14T13:01:06.5992685Z Requirement already satisfied: pip in /opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages (26.0.1)
2026-02-14T13:01:07.2600598Z Collecting Flask>=3.0.0 (from -r requirements.txt (line 2))
2026-02-14T13:01:07.3374736Z   Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)
2026-02-14T13:01:07.3615141Z Collecting flask-cors>=4.0.0 (from -r requirements.txt (line 3))
2026-02-14T13:01:07.3690551Z   Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)
2026-02-14T13:01:07.3898111Z Collecting flask-jwt-extended>=4.6.0 (from -r requirements.txt (line 4))
2026-02-14T13:01:07.3999449Z   Downloading Flask_JWT_Extended-4.7.1-py2.py3-none-any.whl.metadata (3.8 kB)
2026-02-14T13:01:07.4817109Z Collecting psycopg2-binary>=2.9.9 (from -r requirements.txt (line 5))
2026-02-14T13:01:07.4899141Z   Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)
2026-02-14T13:01:07.5138964Z Collecting requests>=2.31.0 (from -r requirements.txt (line 6))
2026-02-14T13:01:07.5215613Z   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
2026-02-14T13:01:07.5405744Z Collecting python-dotenv>=1.0.0 (from -r requirements.txt (line 7))
2026-02-14T13:01:07.5480157Z   Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)
2026-02-14T13:01:07.7963220Z Collecting sqlalchemy>=2.0.0 (from -r requirements.txt (line 8))
2026-02-14T13:01:07.8044911Z   Downloading sqlalchemy-2.0.46-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)
2026-02-14T13:01:07.9137185Z Collecting pandas>=2.1.0 (from -r requirements.txt (line 9))
2026-02-14T13:01:07.9217691Z   Downloading pandas-3.0.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)
2026-02-14T13:01:08.0767847Z Collecting spacy>=3.7.0 (from -r requirements.txt (line 10))
2026-02-14T13:01:08.0848076Z   Downloading spacy-3.8.11-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (27 kB)
2026-02-14T13:01:08.5716215Z Collecting rapidfuzz>=3.0.0 (from -r requirements.txt (line 11))
2026-02-14T13:01:08.5794381Z   Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)
2026-02-14T13:01:08.6224198Z Collecting bcrypt>=4.0.0 (from -r requirements.txt (line 12))
2026-02-14T13:01:08.6306917Z   Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)
2026-02-14T13:01:08.6473170Z Collecting Flask-Login>=0.6.3 (from -r requirements.txt (line 13))
2026-02-14T13:01:08.6550008Z   Downloading Flask_Login-0.6.3-py3-none-any.whl.metadata (5.8 kB)
2026-02-14T13:01:08.7096893Z Collecting openai>=1.0.0 (from -r requirements.txt (line 14))
2026-02-14T13:01:08.7175023Z   Downloading openai-2.21.0-py3-none-any.whl.metadata (29 kB)
2026-02-14T13:01:08.7385664Z Collecting PyPDF2>=3.0.0 (from -r requirements.txt (line 15))
2026-02-14T13:01:08.7460451Z   Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)
2026-02-14T13:01:08.7625107Z Collecting python-docx>=1.1.0 (from -r requirements.txt (line 16))
2026-02-14T13:01:08.7700095Z   Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)
2026-02-14T13:01:08.7985054Z Collecting pytest>=7.4.0 (from -r requirements.txt (line 19))
2026-02-14T13:01:08.8069374Z   Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)
2026-02-14T13:01:08.8268068Z Collecting pytest-cov>=4.1.0 (from -r requirements.txt (line 20))
2026-02-14T13:01:08.8345185Z   Downloading pytest_cov-7.0.0-py3-none-any.whl.metadata (31 kB)
2026-02-14T13:01:08.8562520Z Collecting pytest-mock>=3.12.0 (from -r requirements.txt (line 21))
2026-02-14T13:01:08.8635258Z   Downloading pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)
2026-02-14T13:01:09.2005718Z Collecting ruff>=0.1.0 (from -r requirements.txt (line 22))
2026-02-14T13:01:09.2086397Z   Downloading ruff-0.15.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (26 kB)
2026-02-14T13:01:09.2298856Z Collecting PyGithub>=2.1.0 (from -r requirements.txt (line 23))
2026-02-14T13:01:09.2384637Z   Downloading pygithub-2.8.1-py3-none-any.whl.metadata (3.9 kB)
2026-02-14T13:01:09.2533874Z Collecting blinker>=1.9.0 (from Flask>=3.0.0->-r requirements.txt (line 2))
2026-02-14T13:01:09.2610220Z   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)
2026-02-14T13:01:09.2824509Z Collecting click>=8.1.3 (from Flask>=3.0.0->-r requirements.txt (line 2))
2026-02-14T13:01:09.2902114Z   Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)
2026-02-14T13:01:09.3066957Z Collecting itsdangerous>=2.2.0 (from Flask>=3.0.0->-r requirements.txt (line 2))
2026-02-14T13:01:09.3143613Z   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)
2026-02-14T13:01:09.3320319Z Collecting jinja2>=3.1.2 (from Flask>=3.0.0->-r requirements.txt (line 2))
2026-02-14T13:01:09.3396161Z   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
2026-02-14T13:01:09.3928074Z Collecting markupsafe>=2.1.1 (from Flask>=3.0.0->-r requirements.txt (line 2))
2026-02-14T13:01:09.4006395Z   Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)
2026-02-14T13:01:09.4225160Z Collecting werkzeug>=3.1.0 (from Flask>=3.0.0->-r requirements.txt (line 2))
2026-02-14T13:01:09.4300238Z   Downloading werkzeug-3.1.5-py3-none-any.whl.metadata (4.0 kB)
2026-02-14T13:01:09.4555173Z Collecting PyJWT<3.0,>=2.0 (from flask-jwt-extended>=4.6.0->-r requirements.txt (line 4))
2026-02-14T13:01:09.4630055Z   Downloading pyjwt-2.11.0-py3-none-any.whl.metadata (4.0 kB)
2026-02-14T13:01:09.5407321Z Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->-r requirements.txt (line 6))
2026-02-14T13:01:09.5490154Z   Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)
2026-02-14T13:01:09.5680596Z Collecting idna<4,>=2.5 (from requests>=2.31.0->-r requirements.txt (line 6))
2026-02-14T13:01:09.5758793Z   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)
2026-02-14T13:01:09.6020362Z Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->-r requirements.txt (line 6))
2026-02-14T13:01:09.6100208Z   Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)
2026-02-14T13:01:09.6316697Z Collecting certifi>=2017.4.17 (from requests>=2.31.0->-r requirements.txt (line 6))
2026-02-14T13:01:09.6390565Z   Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)
2026-02-14T13:01:09.8122873Z Collecting greenlet>=1 (from sqlalchemy>=2.0.0->-r requirements.txt (line 8))
2026-02-14T13:01:09.8201828Z   Downloading greenlet-3.3.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)
2026-02-14T13:01:09.8407262Z Collecting typing-extensions>=4.6.0 (from sqlalchemy>=2.0.0->-r requirements.txt (line 8))
2026-02-14T13:01:09.8483321Z   Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
2026-02-14T13:01:10.0215067Z Collecting numpy>=1.26.0 (from pandas>=2.1.0->-r requirements.txt (line 9))
2026-02-14T13:01:10.0295502Z   Downloading numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)
2026-02-14T13:01:10.0473249Z Collecting python-dateutil>=2.8.2 (from pandas>=2.1.0->-r requirements.txt (line 9))
2026-02-14T13:01:10.0553127Z   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
2026-02-14T13:01:10.0732727Z Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.0808583Z   Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)
2026-02-14T13:01:10.0952540Z Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.1029015Z   Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)
2026-02-14T13:01:10.1410755Z Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.1495655Z   Downloading murmurhash-1.0.15-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (2.3 kB)
2026-02-14T13:01:10.1863358Z Collecting cymem<2.1.0,>=2.0.2 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.1940720Z   Downloading cymem-2.0.13-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (9.7 kB)
2026-02-14T13:01:10.2277648Z Collecting preshed<3.1.0,>=3.0.2 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.2355913Z   Downloading preshed-3.0.12-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (2.5 kB)
2026-02-14T13:01:10.4326294Z Collecting thinc<8.4.0,>=8.3.4 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.4405996Z   Downloading thinc-8.3.10-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (15 kB)
2026-02-14T13:01:10.4623964Z Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.4703159Z   Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)
2026-02-14T13:01:10.5152692Z Collecting srsly<3.0.0,>=2.4.3 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.5228723Z   Downloading srsly-2.5.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)
2026-02-14T13:01:10.5391022Z Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.5466781Z   Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)
2026-02-14T13:01:10.5617130Z Collecting weasel<0.5.0,>=0.4.2 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.5694704Z   Downloading weasel-0.4.3-py3-none-any.whl.metadata (4.6 kB)
2026-02-14T13:01:10.5871665Z Collecting typer-slim<1.0.0,>=0.3.0 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.5945813Z   Downloading typer_slim-0.23.1-py3-none-any.whl.metadata (4.2 kB)
2026-02-14T13:01:10.6253745Z Collecting tqdm<5.0.0,>=4.38.0 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.6340727Z   Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)
2026-02-14T13:01:10.7499092Z Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.7578462Z   Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)
2026-02-14T13:01:10.7647454Z Requirement already satisfied: setuptools in /opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages (from spacy>=3.7.0->-r requirements.txt (line 10)) (79.0.1)
2026-02-14T13:01:10.7803348Z Collecting packaging>=20.0 (from spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.7878689Z   Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)
2026-02-14T13:01:10.8056345Z Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:10.8131207Z   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
2026-02-14T13:01:11.4709036Z Collecting pydantic-core==2.41.5 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.4787306Z   Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)
2026-02-14T13:01:11.4946432Z Collecting typing-inspection>=0.4.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.5021793Z   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)
2026-02-14T13:01:11.5536817Z Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.5616260Z   Downloading blis-1.3.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.5 kB)
2026-02-14T13:01:11.5800715Z Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.5887664Z   Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)
2026-02-14T13:01:11.6212172Z Collecting typer>=0.23.1 (from typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.6288644Z   Downloading typer-0.23.1-py3-none-any.whl.metadata (16 kB)
2026-02-14T13:01:11.6495906Z Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.4.2->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.6579996Z   Downloading cloudpathlib-0.23.0-py3-none-any.whl.metadata (16 kB)
2026-02-14T13:01:11.6784367Z Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.4.2->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.6859596Z   Downloading smart_open-7.5.0-py3-none-any.whl.metadata (24 kB)
2026-02-14T13:01:11.8281906Z Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:11.8359942Z   Downloading wrapt-2.1.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (7.4 kB)
2026-02-14T13:01:11.8609444Z Collecting anyio<5,>=3.5.0 (from openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:11.8684321Z   Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)
2026-02-14T13:01:11.8831560Z Collecting distro<2,>=1.7.0 (from openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:11.8913337Z   Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
2026-02-14T13:01:11.9119194Z Collecting httpx<1,>=0.23.0 (from openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:11.9199800Z   Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2026-02-14T13:01:11.9926799Z Collecting jiter<1,>=0.10.0 (from openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:12.0007256Z   Downloading jiter-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
2026-02-14T13:01:12.0222056Z Collecting sniffio (from openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:12.0304119Z   Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
2026-02-14T13:01:12.0605395Z Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:12.0687375Z   Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2026-02-14T13:01:12.0861733Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->-r requirements.txt (line 14))
2026-02-14T13:01:12.0938555Z   Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2026-02-14T13:01:12.3760618Z Collecting lxml>=3.1.0 (from python-docx>=1.1.0->-r requirements.txt (line 16))
2026-02-14T13:01:12.3839017Z   Downloading lxml-6.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)
2026-02-14T13:01:12.4016313Z Collecting iniconfig>=1.0.1 (from pytest>=7.4.0->-r requirements.txt (line 19))
2026-02-14T13:01:12.4090544Z   Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)
2026-02-14T13:01:12.4249534Z Collecting pluggy<2,>=1.5 (from pytest>=7.4.0->-r requirements.txt (line 19))
2026-02-14T13:01:12.4324814Z   Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2026-02-14T13:01:12.4530474Z Collecting pygments>=2.7.2 (from pytest>=7.4.0->-r requirements.txt (line 19))
2026-02-14T13:01:12.4607153Z   Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)
2026-02-14T13:01:12.7931699Z Collecting coverage>=7.10.6 (from coverage[toml]>=7.10.6->pytest-cov>=4.1.0->-r requirements.txt (line 20))
2026-02-14T13:01:12.8015507Z   Downloading coverage-7.13.4-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.5 kB)
2026-02-14T13:01:12.8352603Z Collecting pynacl>=1.4.0 (from PyGithub>=2.1.0->-r requirements.txt (line 23))
2026-02-14T13:01:12.8428212Z   Downloading pynacl-1.6.2-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (10.0 kB)
2026-02-14T13:01:13.0245635Z Collecting cryptography>=3.4.0 (from pyjwt[crypto]>=2.4.0->PyGithub>=2.1.0->-r requirements.txt (line 23))
2026-02-14T13:01:13.0324046Z   Downloading cryptography-46.0.5-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)
2026-02-14T13:01:13.1301703Z Collecting cffi>=2.0.0 (from cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub>=2.1.0->-r requirements.txt (line 23))
2026-02-14T13:01:13.1385750Z   Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)
2026-02-14T13:01:13.1542975Z Collecting pycparser (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.4.0->PyGithub>=2.1.0->-r requirements.txt (line 23))
2026-02-14T13:01:13.1618466Z   Downloading pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)
2026-02-14T13:01:13.1799483Z Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas>=2.1.0->-r requirements.txt (line 9))
2026-02-14T13:01:13.1875630Z   Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
2026-02-14T13:01:13.2064621Z Collecting shellingham>=1.3.0 (from typer>=0.23.1->typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:13.2140681Z   Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)
2026-02-14T13:01:13.2483217Z Collecting rich>=10.11.0 (from typer>=0.23.1->typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:13.2575799Z   Downloading rich-14.3.2-py3-none-any.whl.metadata (18 kB)
2026-02-14T13:01:13.2721896Z Collecting annotated-doc>=0.0.2 (from typer>=0.23.1->typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:13.2796877Z   Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)
2026-02-14T13:01:13.2983979Z Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.23.1->typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:13.3060556Z   Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)
2026-02-14T13:01:13.3239707Z Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim<1.0.0,>=0.3.0->spacy>=3.7.0->-r requirements.txt (line 10))
2026-02-14T13:01:13.3313344Z   Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)
2026-02-14T13:01:13.3526383Z Downloading flask-3.1.2-py3-none-any.whl (103 kB)
2026-02-14T13:01:13.3632404Z Downloading flask_cors-6.0.2-py3-none-any.whl (13 kB)
2026-02-14T13:01:13.3741640Z Downloading Flask_JWT_Extended-4.7.1-py2.py3-none-any.whl (22 kB)
2026-02-14T13:01:13.3834684Z Downloading pyjwt-2.11.0-py3-none-any.whl (28 kB)
2026-02-14T13:01:13.3928976Z Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)
2026-02-14T13:01:13.4276580Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.2/4.2 MB 148.4 MB/s  0:00:00
2026-02-14T13:01:13.4354413Z Downloading requests-2.32.5-py3-none-any.whl (64 kB)
2026-02-14T13:01:13.4451287Z Downloading charset_normalizer-3.4.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (151 kB)
2026-02-14T13:01:13.4549269Z Downloading idna-3.11-py3-none-any.whl (71 kB)
2026-02-14T13:01:13.4652084Z Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)
2026-02-14T13:01:13.4772694Z Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)
2026-02-14T13:01:13.4883889Z Downloading sqlalchemy-2.0.46-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.3 MB)
2026-02-14T13:01:13.5129410Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 143.7 MB/s  0:00:00
2026-02-14T13:01:13.5216944Z Downloading pandas-3.0.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (11.2 MB)
2026-02-14T13:01:13.5746111Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.2/11.2 MB 220.1 MB/s  0:00:00
2026-02-14T13:01:13.5855679Z Downloading spacy-3.8.11-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (32.3 MB)
2026-02-14T13:01:13.7505211Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 32.3/32.3 MB 197.4 MB/s  0:00:00
2026-02-14T13:01:13.7582944Z Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)
2026-02-14T13:01:13.7681310Z Downloading cymem-2.0.13-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (244 kB)
2026-02-14T13:01:13.7786924Z Downloading murmurhash-1.0.15-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (128 kB)
2026-02-14T13:01:13.7884280Z Downloading preshed-3.0.12-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (824 kB)
2026-02-14T13:01:13.7963063Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 824.7/824.7 kB 127.0 MB/s  0:00:00
2026-02-14T13:01:13.8039757Z Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)
2026-02-14T13:01:13.8156116Z Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
2026-02-14T13:01:13.8275885Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 210.5 MB/s  0:00:00
2026-02-14T13:01:13.8350382Z Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)
2026-02-14T13:01:13.8446684Z Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)
2026-02-14T13:01:13.8602617Z Downloading srsly-2.5.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)
2026-02-14T13:01:13.8684910Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 163.8 MB/s  0:00:00
2026-02-14T13:01:13.8803045Z Downloading thinc-8.3.10-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.1 MB)
2026-02-14T13:01:13.9087168Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 152.1 MB/s  0:00:00
2026-02-14T13:01:13.9172216Z Downloading blis-1.3.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (11.4 MB)
2026-02-14T13:01:13.9684521Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.4/11.4 MB 238.2 MB/s  0:00:00
2026-02-14T13:01:13.9759902Z Downloading confection-0.1.5-py3-none-any.whl (35 kB)
2026-02-14T13:01:13.9860352Z Downloading numpy-2.4.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)
2026-02-14T13:01:14.0631697Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.9/16.9 MB 228.5 MB/s  0:00:00
2026-02-14T13:01:14.0709810Z Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)
2026-02-14T13:01:14.0807480Z Downloading typer_slim-0.23.1-py3-none-any.whl (3.4 kB)
2026-02-14T13:01:14.0897296Z Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)
2026-02-14T13:01:14.0989647Z Downloading weasel-0.4.3-py3-none-any.whl (50 kB)
2026-02-14T13:01:14.1082316Z Downloading cloudpathlib-0.23.0-py3-none-any.whl (62 kB)
2026-02-14T13:01:14.1175095Z Downloading smart_open-7.5.0-py3-none-any.whl (63 kB)
2026-02-14T13:01:14.1267903Z Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)
2026-02-14T13:01:14.1471589Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 180.7 MB/s  0:00:00
2026-02-14T13:01:14.1548376Z Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)
2026-02-14T13:01:14.1654126Z Downloading Flask_Login-0.6.3-py3-none-any.whl (17 kB)
2026-02-14T13:01:14.1751296Z Downloading openai-2.21.0-py3-none-any.whl (1.1 MB)
2026-02-14T13:01:14.1832278Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 154.3 MB/s  0:00:00
2026-02-14T13:01:14.1905611Z Downloading anyio-4.12.1-py3-none-any.whl (113 kB)
2026-02-14T13:01:14.2000849Z Downloading distro-1.9.0-py3-none-any.whl (20 kB)
2026-02-14T13:01:14.2095145Z Downloading httpx-0.28.1-py3-none-any.whl (73 kB)
2026-02-14T13:01:14.2192670Z Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)
2026-02-14T13:01:14.2288362Z Downloading jiter-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (362 kB)
2026-02-14T13:01:14.2400258Z Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)
2026-02-14T13:01:14.2510337Z Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)
2026-02-14T13:01:14.2616736Z Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)
2026-02-14T13:01:14.2730373Z Downloading pytest-9.0.2-py3-none-any.whl (374 kB)
2026-02-14T13:01:14.2838960Z Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)
2026-02-14T13:01:14.2933520Z Downloading pytest_cov-7.0.0-py3-none-any.whl (22 kB)
2026-02-14T13:01:14.3029417Z Downloading pytest_mock-3.15.1-py3-none-any.whl (10 kB)
2026-02-14T13:01:14.3128620Z Downloading ruff-0.15.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)
2026-02-14T13:01:14.3655999Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.1/11.1 MB 222.0 MB/s  0:00:00
2026-02-14T13:01:14.3743686Z Downloading pygithub-2.8.1-py3-none-any.whl (432 kB)
2026-02-14T13:01:14.3864936Z Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)
2026-02-14T13:01:14.3958427Z Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)
2026-02-14T13:01:14.4051579Z Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)
2026-02-14T13:01:14.4151614Z Downloading click-8.3.1-py3-none-any.whl (108 kB)
2026-02-14T13:01:14.4258950Z Downloading coverage-7.13.4-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (252 kB)
2026-02-14T13:01:14.4370120Z Downloading greenlet-3.3.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (590 kB)
2026-02-14T13:01:14.4428206Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 590.3/590.3 kB 97.2 MB/s  0:00:00
2026-02-14T13:01:14.4503419Z Downloading h11-0.16.0-py3-none-any.whl (37 kB)
2026-02-14T13:01:14.4596464Z Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)
2026-02-14T13:01:14.4688141Z Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)
2026-02-14T13:01:14.4781707Z Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)
2026-02-14T13:01:14.4888857Z Downloading lxml-6.0.2-cp311-cp311-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.2 MB)
2026-02-14T13:01:14.5154263Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 222.4 MB/s  0:00:00
2026-02-14T13:01:14.5230919Z Downloading markupsafe-3.0.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)
2026-02-14T13:01:14.5324025Z Downloading packaging-26.0-py3-none-any.whl (74 kB)
2026-02-14T13:01:14.5421604Z Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)
2026-02-14T13:01:14.5511685Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 168.6 MB/s  0:00:00
2026-02-14T13:01:14.5598460Z Downloading cryptography-46.0.5-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)
2026-02-14T13:01:14.5847471Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 201.9 MB/s  0:00:00
2026-02-14T13:01:14.5928108Z Downloading cffi-2.0.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (215 kB)
2026-02-14T13:01:14.6037905Z Downloading pynacl-1.6.2-cp38-abi3-manylinux_2_34_x86_64.whl (1.4 MB)
2026-02-14T13:01:14.6135424Z    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 164.2 MB/s  0:00:00
2026-02-14T13:01:14.6210754Z Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
2026-02-14T13:01:14.6313677Z Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)
2026-02-14T13:01:14.6401945Z Downloading typer-0.23.1-py3-none-any.whl (56 kB)
2026-02-14T13:01:14.6494799Z Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)
2026-02-14T13:01:14.6586853Z Downloading rich-14.3.2-py3-none-any.whl (309 kB)
2026-02-14T13:01:14.6689972Z Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)
2026-02-14T13:01:14.6784304Z Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)
2026-02-14T13:01:14.6872891Z Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)
2026-02-14T13:01:14.6965860Z Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)
2026-02-14T13:01:14.7057443Z Downloading werkzeug-3.1.5-py3-none-any.whl (225 kB)
2026-02-14T13:01:14.7168533Z Downloading pycparser-3.0-py3-none-any.whl (48 kB)
2026-02-14T13:01:14.7258832Z Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)
2026-02-14T13:01:14.7355033Z Downloading wrapt-2.1.1-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (113 kB)
2026-02-14T13:01:15.0346651Z Installing collected packages: wrapt, wasabi, urllib3, typing-extensions, tqdm, spacy-loggers, spacy-legacy, sniffio, six, shellingham, ruff, rapidfuzz, python-dotenv, PyPDF2, PyJWT, pygments, pycparser, psycopg2-binary, pluggy, packaging, numpy, murmurhash, mdurl, markupsafe, lxml, jiter, itsdangerous, iniconfig, idna, h11, greenlet, distro, cymem, coverage, cloudpathlib, click, charset_normalizer, certifi, catalogue, blinker, bcrypt, annotated-types, annotated-doc, werkzeug, typing-inspection, srsly, sqlalchemy, smart-open, requests, python-docx, python-dateutil, pytest, pydantic-core, preshed, markdown-it-py, jinja2, httpcore, cffi, blis, anyio, rich, pytest-mock, pytest-cov, pynacl, pydantic, pandas, httpx, Flask, cryptography, typer, openai, Flask-Login, flask-jwt-extended, flask-cors, confection, typer-slim, thinc, PyGithub, weasel, spacy
2026-02-14T13:01:28.9783414Z 
2026-02-14T13:01:28.9823098Z Successfully installed Flask-3.1.2 Flask-Login-0.6.3 PyGithub-2.8.1 PyJWT-2.11.0 PyPDF2-3.0.1 annotated-doc-0.0.4 annotated-types-0.7.0 anyio-4.12.1 bcrypt-5.0.0 blinker-1.9.0 blis-1.3.3 catalogue-2.0.10 certifi-2026.1.4 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 cloudpathlib-0.23.0 confection-0.1.5 coverage-7.13.4 cryptography-46.0.5 cymem-2.0.13 distro-1.9.0 flask-cors-6.0.2 flask-jwt-extended-4.7.1 greenlet-3.3.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 iniconfig-2.3.0 itsdangerous-2.2.0 jinja2-3.1.6 jiter-0.13.0 lxml-6.0.2 markdown-it-py-4.0.0 markupsafe-3.0.3 mdurl-0.1.2 murmurhash-1.0.15 numpy-2.4.2 openai-2.21.0 packaging-26.0 pandas-3.0.0 pluggy-1.6.0 preshed-3.0.12 psycopg2-binary-2.9.11 pycparser-3.0 pydantic-2.12.5 pydantic-core-2.41.5 pygments-2.19.2 pynacl-1.6.2 pytest-9.0.2 pytest-cov-7.0.0 pytest-mock-3.15.1 python-dateutil-2.9.0.post0 python-docx-1.2.0 python-dotenv-1.2.1 rapidfuzz-3.14.3 requests-2.32.5 rich-14.3.2 ruff-0.15.1 shellingham-1.5.4 six-1.17.0 smart-open-7.5.0 sniffio-1.3.1 spacy-3.8.11 spacy-legacy-3.0.12 spacy-loggers-1.0.5 sqlalchemy-2.0.46 srsly-2.5.2 thinc-8.3.10 tqdm-4.67.3 typer-0.23.1 typer-slim-0.23.1 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 wasabi-1.1.3 weasel-0.4.3 werkzeug-3.1.5 wrapt-2.1.1
2026-02-14T13:01:30.0240145Z ##[group]Run pytest tests/ --ignore=tests/browser -v --cov=services --cov-report=term-missing
2026-02-14T13:01:30.0240767Z [36;1mpytest tests/ --ignore=tests/browser -v --cov=services --cov-report=term-missing[0m
2026-02-14T13:01:30.0293067Z shell: /usr/bin/bash -e {0}
2026-02-14T13:01:30.0293296Z env:
2026-02-14T13:01:30.0293777Z   TEST_DB_CONNECTION_STRING: ***127.0.0.1:5432/job_search_test
2026-02-14T13:01:30.0294157Z   pythonLocation: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:30.0294552Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib/pkgconfig
2026-02-14T13:01:30.0294957Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:30.0295309Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:30.0295682Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.11.14/x64
2026-02-14T13:01:30.0296040Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.11.14/x64/lib
2026-02-14T13:01:30.0296349Z ##[endgroup]
2026-02-14T13:01:30.9657194Z ============================= test session starts ==============================
2026-02-14T13:01:30.9658079Z platform linux -- Python 3.11.14, pytest-9.0.2, pluggy-1.6.0 -- /opt/hostedtoolcache/Python/3.11.14/x64/bin/python
2026-02-14T13:01:30.9658734Z cachedir: .pytest_cache
2026-02-14T13:01:30.9659087Z rootdir: /home/runner/work/job-etl-project/job-etl-project
2026-02-14T13:01:30.9659491Z configfile: pyproject.toml
2026-02-14T13:01:30.9659791Z plugins: anyio-4.12.1, mock-3.15.1, cov-7.0.0
2026-02-14T13:01:34.8319737Z collecting ... collected 476 items
2026-02-14T13:01:34.8320121Z 
2026-02-14T13:01:34.8338778Z tests/integration/test_auth_integration.py::TestAuthIntegration::test_full_registration_and_login_flow SKIPPED [  0%]
2026-02-14T13:01:34.8351247Z tests/integration/test_auth_integration.py::TestAuthIntegration::test_registration_prevents_duplicate_username SKIPPED [  0%]
2026-02-14T13:01:34.8364119Z tests/integration/test_auth_integration.py::TestAuthIntegration::test_registration_prevents_duplicate_email SKIPPED [  0%]
2026-02-14T13:01:35.0253656Z tests/integration/test_bug_fixes.py::TestBug3Deduplication::test_extractor_skips_duplicate_jobs ERROR [  0%]
2026-02-14T13:01:35.0685105Z tests/integration/test_bug_fixes.py::TestBug3Deduplication::test_extractor_handles_mixed_duplicates ERROR [  1%]
2026-02-14T13:01:35.0696396Z tests/integration/test_bug_fixes.py::TestBug4FieldCasing::test_staging_model_normalizes_salary_period SKIPPED [  1%]
2026-02-14T13:01:35.0707333Z tests/integration/test_bug_fixes.py::TestBug4FieldCasing::test_staging_model_normalizes_employment_type SKIPPED [  1%]
2026-02-14T13:01:35.1140989Z tests/integration/test_bug_fixes.py::TestBug5UKCountryCode::test_ranker_uses_gb_not_uk ERROR [  1%]
2026-02-14T13:01:35.1571806Z tests/integration/test_bug_fixes.py::TestBug5UKCountryCode::test_campaign_stored_with_gb_country_code ERROR [  1%]
2026-02-14T13:01:35.1582721Z tests/integration/test_bug_fixes.py::TestBug7JobNotFound::test_job_retrievable_from_other_user_campaign SKIPPED [  2%]
2026-02-14T13:01:35.2007321Z tests/integration/test_bug_fixes.py::TestBug7JobNotFound::test_job_retrievable_from_own_campaign ERROR [  2%]
2026-02-14T13:01:35.2424307Z tests/integration/test_campaign_deletion.py::TestCampaignUniqueness::test_campaign_ids_are_unique ERROR [  2%]
2026-02-14T13:01:35.2832343Z tests/integration/test_campaign_deletion.py::TestCampaignUniqueness::test_campaign_ids_increment ERROR [  2%]
2026-02-14T13:01:35.3251731Z tests/integration/test_campaign_deletion.py::TestCampaignUniqueness::test_campaign_id_primary_key_constraint ERROR [  2%]
2026-02-14T13:01:35.3669671Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_rankings ERROR [  3%]
2026-02-14T13:01:35.4100345Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_fact_jobs ERROR [  3%]
2026-02-14T13:01:35.4541722Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_staging_jobs ERROR [  3%]
2026-02-14T13:01:35.4974627Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_etl_metrics ERROR [  3%]
2026-02-14T13:01:35.5400395Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_comprehensive_cleanup ERROR [  3%]
2026-02-14T13:01:35.5825186Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_new_campaign_does_not_show_old_jobs ERROR [  4%]
2026-02-14T13:01:35.6257961Z tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_job_queries_only_show_existing_campaigns ERROR [  4%]
2026-02-14T13:01:35.6688489Z tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_companies_identified_from_staging_jobs ERROR [  4%]
2026-02-14T13:01:35.7111437Z tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_company_extracted_to_raw_layer ERROR [  4%]
2026-02-14T13:01:35.7532034Z tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_enrichment_queue_updated ERROR [  5%]
2026-02-14T13:01:35.7948980Z tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_normalize_companies_to_staging ERROR [  5%]
2026-02-14T13:01:35.8369681Z tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_companies_in_marts_dim_companies ERROR [  5%]
2026-02-14T13:01:35.8782086Z tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_complete_company_enrichment_flow ERROR [  5%]
2026-02-14T13:01:35.9206057Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_after_successful_dag ERROR [  5%]
2026-02-14T13:01:35.9628419Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_after_failed_dag ERROR [  6%]
2026-02-14T13:01:36.0042379Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_no_cooldown_before_first_run ERROR [  6%]
2026-02-14T13:01:36.0479083Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_expires_after_one_hour ERROR [  6%]
2026-02-14T13:01:36.1564710Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_multiple_campaigns_independent_cooldown ERROR [  6%]
2026-02-14T13:01:36.2003416Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_concurrent_dag_triggers_same_campaign ERROR [  6%]
2026-02-14T13:01:36.2450895Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_dag_completion_with_no_jobs ERROR [  7%]
2026-02-14T13:01:36.2879260Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_page_refresh_preserves_cooldown ERROR [  7%]
2026-02-14T13:01:36.3324467Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_force_start_bypasses_cooldown ERROR [  7%]
2026-02-14T13:01:36.3747388Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_calculation_edge_cases ERROR [  7%]
2026-02-14T13:01:36.4173637Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_status_derived_from_metrics ERROR [  7%]
2026-02-14T13:01:36.4603845Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_concurrent_triggers_different_users ERROR [  8%]
2026-02-14T13:01:36.5067596Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_with_timezone_issues ERROR [  8%]
2026-02-14T13:01:36.5506015Z tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_reset_on_force_start ERROR [  8%]
2026-02-14T13:01:36.5928799Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_invalid_campaign_id_handling ERROR [  8%]
2026-02-14T13:01:36.6350940Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_missing_dag_run_id_handling ERROR [  9%]
2026-02-14T13:01:36.6790654Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_concurrent_status_check_race_condition ERROR [  9%]
2026-02-14T13:01:36.7219844Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_airflow_api_timeout_simulation ERROR [  9%]
2026-02-14T13:01:36.7652682Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_airflow_connection_error_simulation ERROR [  9%]
2026-02-14T13:01:36.8083955Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_response_validation ERROR [  9%]
2026-02-14T13:01:36.8526684Z tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_campaign_ownership_validation ERROR [ 10%]
2026-02-14T13:01:36.8962163Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_success ERROR [ 10%]
2026-02-14T13:01:36.9386963Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_with_comments ERROR [ 10%]
2026-02-14T13:01:36.9822001Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_missing_resume_id ERROR [ 10%]
2026-02-14T13:01:37.0255855Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_invalid_resume_id ERROR [ 10%]
2026-02-14T13:01:37.0693773Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_not_json ERROR [ 11%]
2026-02-14T13:01:37.1122769Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_generation_error ERROR [ 11%]
2026-02-14T13:01:37.1544310Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_validation_error ERROR [ 11%]
2026-02-14T13:01:37.1977543Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_requires_login ERROR [ 11%]
2026-02-14T13:01:37.2393667Z tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_general_exception ERROR [ 11%]
2026-02-14T13:01:37.2905251Z tests/integration/test_dag_end_to_end.py::test_dag_end_to_end_full_pipeline ERROR [ 12%]
2026-02-14T13:01:37.2938138Z tests/integration/test_dag_task_order.py::TestDAGTaskOrder::test_dag_task_order_ensures_fact_jobs_before_ranking SKIPPED [ 12%]
2026-02-14T13:01:37.2958171Z tests/integration/test_dag_task_order.py::TestDAGTaskOrder::test_dag_topological_sort_places_rank_jobs_after_dbt_modelling SKIPPED [ 12%]
2026-02-14T13:01:37.3388824Z tests/integration/test_data_preservation.py::TestDataPreservation::test_fact_jobs_preserves_all_campaigns_on_single_campaign_dag ERROR [ 12%]
2026-02-14T13:01:37.3807850Z tests/integration/test_data_preservation.py::TestDataPreservation::test_staging_incremental_preserves_other_campaigns ERROR [ 13%]
2026-02-14T13:01:37.4222584Z tests/integration/test_data_preservation.py::TestDataPreservation::test_incremental_materialization_processes_only_new_records ERROR [ 13%]
2026-02-14T13:01:37.4661332Z tests/integration/test_data_preservation.py::TestDataPreservation::test_fact_jobs_incremental_without_campaign_filter ERROR [ 13%]
2026-02-14T13:01:37.5090905Z tests/integration/test_data_preservation.py::TestDataPreservation::test_ranking_upsert_preserves_other_campaigns ERROR [ 13%]
2026-02-14T13:01:37.5519621Z tests/integration/test_data_preservation.py::TestDataPreservation::test_ranking_upsert_updates_existing_rankings ERROR [ 13%]
2026-02-14T13:01:37.5961886Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_resume_linked_to_multiple_jobs ERROR [ 14%]
2026-02-14T13:01:37.6404761Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_delete_resume_linked_to_jobs ERROR [ 14%]
2026-02-14T13:01:37.6830918Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_cover_letter_same_name_different_jobs ERROR [ 14%]
2026-02-14T13:01:37.7268545Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_switch_from_inline_text_to_cover_letter_id ERROR [ 14%]
2026-02-14T13:01:37.7712371Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_switch_from_cover_letter_id_to_inline_text ERROR [ 14%]
2026-02-14T13:01:37.8132762Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_concurrent_updates_same_document ERROR [ 15%]
2026-02-14T13:01:37.8560085Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_file_with_special_characters_in_name ERROR [ 15%]
2026-02-14T13:01:37.8972311Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_very_long_cover_letter_text ERROR [ 15%]
2026-02-14T13:01:37.9385538Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_multiple_resumes_same_name ERROR [ 15%]
2026-02-14T13:01:37.9808216Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_get_documents_for_nonexistent_user ERROR [ 15%]
2026-02-14T13:01:38.0226208Z tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_update_document_with_all_none_values ERROR [ 16%]
2026-02-14T13:01:38.0654207Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_upload_resume_and_link_to_job ERROR [ 16%]
2026-02-14T13:01:38.1716818Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_create_text_cover_letter_and_link ERROR [ 16%]
2026-02-14T13:01:38.2155002Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_upload_cover_letter_file_and_link ERROR [ 16%]
2026-02-14T13:01:38.2600940Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_update_job_application_document ERROR [ 17%]
2026-02-14T13:01:38.3037335Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_delete_resume_removes_file ERROR [ 17%]
2026-02-14T13:01:38.3475940Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_get_user_resumes_list ERROR [ 17%]
2026-02-14T13:01:38.3912062Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_inline_cover_letter_text_workflow ERROR [ 17%]
2026-02-14T13:01:38.4344993Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_mixed_document_types_workflow ERROR [ 17%]
2026-02-14T13:01:38.4785531Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_get_user_cover_letters_filtered_by_job ERROR [ 18%]
2026-02-14T13:01:38.5250307Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_documents_uploaded_from_job_details_not_in_documents_section ERROR [ 18%]
2026-02-14T13:01:38.5677573Z tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_only_documents_section_documents_in_job_attachment_dropdowns ERROR [ 18%]
2026-02-14T13:01:38.6113223Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_upload_resume_route_success ERROR [ 18%]
2026-02-14T13:01:38.6545339Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_resume_route_success ERROR [ 18%]
2026-02-14T13:01:38.6973452Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_inline_text ERROR [ 19%]
2026-02-14T13:01:38.7397846Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_text_based ERROR [ 19%]
2026-02-14T13:01:38.7833257Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_link_resume_to_job_route ERROR [ 19%]
2026-02-14T13:01:38.8260877Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_update_application_documents_route ERROR [ 19%]
2026-02-14T13:01:38.8696192Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_get_user_resumes_api ERROR [ 19%]
2026-02-14T13:01:38.9132677Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_get_user_cover_letters_api ERROR [ 20%]
2026-02-14T13:01:38.9558199Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_file_based ERROR [ 20%]
2026-02-14T13:01:38.9983076Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_text_based_raises_error ERROR [ 20%]
2026-02-14T13:01:39.0404242Z tests/integration/test_document_routes.py::TestDocumentRoutes::test_cover_letter_download_handles_both_types ERROR [ 20%]
2026-02-14T13:01:39.0826774Z tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_resume_from_documents_section ERROR [ 21%]
2026-02-14T13:01:39.1248875Z tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_resume_from_job_details_not_in_documents_section ERROR [ 21%]
2026-02-14T13:01:39.1667332Z tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_resume_from_documents_section ERROR [ 21%]
2026-02-14T13:01:39.2089952Z tests/integration/test_documents_page.py::TestDocumentsPage::test_create_cover_letter_from_documents_section ERROR [ 21%]
2026-02-14T13:01:39.2510517Z tests/integration/test_documents_page.py::TestDocumentsPage::test_create_cover_letter_from_job_details_not_in_documents_section ERROR [ 21%]
2026-02-14T13:01:39.2930302Z tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_cover_letter_from_documents_section ERROR [ 22%]
2026-02-14T13:01:39.3359796Z tests/integration/test_documents_page.py::TestDocumentsPage::test_only_documents_section_resumes_appear_in_job_attachment ERROR [ 22%]
2026-02-14T13:01:39.3779336Z tests/integration/test_documents_page.py::TestDocumentsPage::test_only_documents_section_cover_letters_appear_in_job_attachment ERROR [ 22%]
2026-02-14T13:01:39.4212455Z tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_nonexistent_resume ERROR [ 22%]
2026-02-14T13:01:39.4646064Z tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_nonexistent_cover_letter ERROR [ 22%]
2026-02-14T13:01:39.5081282Z tests/integration/test_documents_page.py::TestDocumentsPage::test_get_resume_by_id_not_found ERROR [ 23%]
2026-02-14T13:01:39.5516446Z tests/integration/test_documents_page.py::TestDocumentsPage::test_get_cover_letter_by_id_not_found ERROR [ 23%]
2026-02-14T13:01:39.5940990Z tests/integration/test_documents_page.py::TestDocumentsPage::test_download_text_based_cover_letter_fails ERROR [ 23%]
2026-02-14T13:01:39.6378081Z tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_resume_invalid_file_type ERROR [ 23%]
2026-02-14T13:01:39.6802430Z tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_cover_letter_invalid_file_type ERROR [ 23%]
2026-02-14T13:01:39.7226962Z tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_extract_jobs_to_raw_layer ERROR [ 24%]
2026-02-14T13:01:39.7654723Z tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_normalize_jobs_to_staging ERROR [ 24%]
2026-02-14T13:01:39.8087735Z tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_build_marts_and_rank_jobs ERROR [ 24%]
2026-02-14T13:01:39.8511366Z tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_complete_flow_end_to_end ERROR [ 24%]
2026-02-14T13:01:39.8931994Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_job_found_creates_history ERROR [ 25%]
2026-02-14T13:01:39.9375913Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_ai_update_creates_history ERROR [ 25%]
2026-02-14T13:01:39.9813887Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_chatgpt_update_creates_history ERROR [ 25%]
2026-02-14T13:01:40.0242246Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_document_change_creates_history ERROR [ 25%]
2026-02-14T13:01:40.0678097Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_note_change_creates_history ERROR [ 25%]
2026-02-14T13:01:40.1692053Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_upsert_status_records_history ERROR [ 26%]
2026-02-14T13:01:40.2126524Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_get_user_status_history_returns_all_jobs ERROR [ 26%]
2026-02-14T13:01:40.2557551Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_get_job_status_history_returns_all_users ERROR [ 26%]
2026-02-14T13:01:40.2986423Z tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_history_metadata_stores_json_correctly ERROR [ 26%]
2026-02-14T13:01:40.3413924Z tests/integration/test_jwt_auth_api.py::test_auth_login_returns_token ERROR [ 26%]
2026-02-14T13:01:40.3832568Z tests/integration/test_jwt_auth_api.py::test_update_campaign_with_jwt_token ERROR [ 27%]
2026-02-14T13:01:40.4262439Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_add_multiple_notes ERROR [ 27%]
2026-02-14T13:01:40.4698115Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_notes_ordered_newest_first ERROR [ 27%]
2026-02-14T13:01:40.5168615Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_update_note ERROR [ 27%]
2026-02-14T13:01:40.5665423Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_delete_note ERROR [ 27%]
2026-02-14T13:01:40.6100175Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_note_count_in_job_listing ERROR [ 28%]
2026-02-14T13:01:40.6540390Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_authorization_user_cannot_access_other_users_notes ERROR [ 28%]
2026-02-14T13:01:40.6989489Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_is_modified_flag ERROR [ 28%]
2026-02-14T13:01:40.7426090Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_empty_note_list ERROR [ 28%]
2026-02-14T13:01:40.7866108Z tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_whitespace_stripping ERROR [ 28%]
2026-02-14T13:01:40.8309032Z tests/integration/test_ranker_validation.py::TestRankerValidation::test_ranker_validates_jobs_before_ranking ERROR [ 29%]
2026-02-14T13:01:40.8750273Z tests/integration/test_ranker_validation.py::TestRankerValidation::test_ranker_skips_jobs_not_in_fact_jobs ERROR [ 29%]
2026-02-14T13:01:40.9204215Z tests/integration/test_ranker_validation.py::TestRankerValidation::test_ranker_handles_mixed_valid_and_invalid_jobs ERROR [ 29%]
2026-02-14T13:01:40.9632893Z tests/integration/test_ranker_validation.py::TestRankerValidation::test_validation_query_works_correctly ERROR [ 29%]
2026-02-14T13:01:40.9648341Z tests/unit/test_airflow_client.py::TestAirflowClient::test_init_strips_trailing_slash PASSED [ 30%]
2026-02-14T13:01:40.9663229Z tests/unit/test_airflow_client.py::TestAirflowClient::test_init_sets_auth PASSED [ 30%]
2026-02-14T13:01:40.9738765Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_success PASSED [ 30%]
2026-02-14T13:01:40.9792272Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_without_conf PASSED [ 30%]
2026-02-14T13:01:40.9846124Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_401_unauthorized PASSED [ 30%]
2026-02-14T13:01:40.9899983Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_403_forbidden PASSED [ 31%]
2026-02-14T13:01:40.9951357Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_404_not_found PASSED [ 31%]
2026-02-14T13:01:40.9998476Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_timeout PASSED [ 31%]
2026-02-14T13:01:41.0043239Z tests/unit/test_airflow_client.py::TestAirflowClient::test_trigger_dag_connection_error PASSED [ 31%]
2026-02-14T13:01:41.0069535Z tests/unit/test_airflow_client.py::TestAirflowClient::test_get_dag_run_status_success PASSED [ 31%]
2026-02-14T13:01:41.0090541Z tests/unit/test_airflow_client.py::TestAirflowClient::test_get_dag_run_status_404_not_found PASSED [ 32%]
2026-02-14T13:01:41.0118801Z tests/unit/test_airflow_client.py::TestAirflowClient::test_get_dag_run_status_401_unauthorized PASSED [ 32%]
2026-02-14T13:01:41.0139542Z tests/unit/test_airflow_client.py::TestAirflowClient::test_get_dag_run_status_timeout PASSED [ 32%]
2026-02-14T13:01:41.0154800Z tests/unit/test_auth_service.py::TestAuthService::test_init_requires_user_service PASSED [ 32%]
2026-02-14T13:01:41.0173931Z tests/unit/test_auth_service.py::TestAuthService::test_init_with_valid_user_service PASSED [ 32%]
2026-02-14T13:01:41.0199154Z tests/unit/test_auth_service.py::TestAuthService::test_authenticate_user_success_by_username PASSED [ 33%]
2026-02-14T13:01:41.0225881Z tests/unit/test_auth_service.py::TestAuthService::test_authenticate_user_success_by_email PASSED [ 33%]
2026-02-14T13:01:41.0251537Z tests/unit/test_auth_service.py::TestAuthService::test_authenticate_user_invalid_username PASSED [ 33%]
2026-02-14T13:01:41.0274932Z tests/unit/test_auth_service.py::TestAuthService::test_authenticate_user_invalid_password PASSED [ 33%]
2026-02-14T13:01:41.0293430Z tests/unit/test_auth_service.py::TestAuthService::test_authenticate_user_empty_credentials PASSED [ 34%]
2026-02-14T13:01:41.0333863Z tests/unit/test_auth_service.py::TestAuthService::test_authenticate_user_handles_last_login_error PASSED [ 34%]
2026-02-14T13:01:41.0356260Z tests/unit/test_auth_service.py::TestAuthService::test_register_user_success PASSED [ 34%]
2026-02-14T13:01:41.0378060Z tests/unit/test_auth_service.py::TestAuthService::test_register_user_with_custom_role PASSED [ 34%]
2026-02-14T13:01:41.0403374Z tests/unit/test_auth_service.py::TestAuthService::test_is_admin_returns_true_for_admin PASSED [ 34%]
2026-02-14T13:01:41.0423057Z tests/unit/test_auth_service.py::TestAuthService::test_is_admin_returns_false_for_regular_user PASSED [ 35%]
2026-02-14T13:01:41.0442867Z tests/unit/test_auth_service.py::TestAuthService::test_is_admin_returns_false_for_missing_role PASSED [ 35%]
2026-02-14T13:01:41.0478765Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_all_tasks_success PASSED [ 35%]
2026-02-14T13:01:41.0513878Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_task_failed PASSED [ 35%]
2026-02-14T13:01:41.0550369Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_multiple_tasks_failed PASSED [ 35%]
2026-02-14T13:01:41.0585788Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_partial_completion PASSED [ 36%]
2026-02-14T13:01:41.0625229Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_no_metrics PASSED [ 36%]
2026-02-14T13:01:41.0659776Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_specific_dag_run PASSED [ 36%]
2026-02-14T13:01:41.0694339Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_database_error PASSED [ 36%]
2026-02-14T13:01:41.0729781Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_missing_critical_tasks_some_complete PASSED [ 36%]
2026-02-14T13:01:41.0769018Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_missing_critical_tasks_none_complete PASSED [ 37%]
2026-02-14T13:01:41.0804118Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_is_complete_flag_success PASSED [ 37%]
2026-02-14T13:01:41.0840230Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_is_complete_flag_error PASSED [ 37%]
2026-02-14T13:01:41.0874889Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_is_complete_flag_running PASSED [ 37%]
2026-02-14T13:01:41.0914900Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_is_complete_flag_pending PASSED [ 38%]
2026-02-14T13:01:41.0963369Z tests/unit/test_campaign_service.py::TestCampaignServiceStatusFromMetrics::test_get_status_most_recent_dag_run PASSED [ 38%]
2026-02-14T13:01:41.0987973Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherInitialization::test_init_with_valid_params PASSED [ 38%]
2026-02-14T13:01:41.1008499Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherInitialization::test_init_without_openai_raises_error PASSED [ 38%]
2026-02-14T13:01:41.1045156Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherInitialization::test_init_without_api_key_raises_error PASSED [ 38%]
2026-02-14T13:01:41.1072099Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherInitialization::test_init_with_invalid_batch_size_raises_error PASSED [ 39%]
2026-02-14T13:01:41.1097783Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_build_api_params_older_model PASSED [ 39%]
2026-02-14T13:01:41.1121543Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_build_api_params_newer_model PASSED [ 39%]
2026-02-14T13:01:41.1145103Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_build_api_params_reasoning_model PASSED [ 39%]
2026-02-14T13:01:41.1168508Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_build_api_params_batch PASSED [ 39%]
2026-02-14T13:01:41.1198442Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_extract_error_details_from_dict_body PASSED [ 40%]
2026-02-14T13:01:41.1227821Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_extract_error_details_from_string_body PASSED [ 40%]
2026-02-14T13:01:41.1251372Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_should_retry_without_json PASSED [ 40%]
2026-02-14T13:01:41.1276413Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_is_authentication_error PASSED [ 40%]
2026-02-14T13:01:41.1300047Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_parse_json_response_plain_json PASSED [ 40%]
2026-02-14T13:01:41.1324150Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_parse_json_response_markdown_wrapped PASSED [ 41%]
2026-02-14T13:01:41.1348004Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_extract_enrichment_from_result PASSED [ 41%]
2026-02-14T13:01:41.1374269Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_extract_enrichment_invalid_seniority PASSED [ 41%]
2026-02-14T13:01:41.1398452Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_extract_enrichment_invalid_remote_type PASSED [ 41%]
2026-02-14T13:01:41.1421592Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherHelperMethods::test_get_empty_enrichment PASSED [ 42%]
2026-02-14T13:01:41.1462292Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherAPICalls::test_call_openai_api_success PASSED [ 42%]
2026-02-14T13:01:41.1504355Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherAPICalls::test_call_openai_api_empty_response PASSED [ 42%]
2026-02-14T13:01:41.1573974Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherAPICalls::test_call_openai_api_retry_on_error PASSED [ 42%]
2026-02-14T13:01:41.1616618Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherAPICalls::test_call_openai_api_auth_error_no_retry PASSED [ 42%]
2026-02-14T13:01:41.1660770Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherEnrichment::test_enrich_job_success PASSED [ 43%]
2026-02-14T13:01:41.1704955Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherEnrichment::test_enrich_job_api_failure PASSED [ 43%]
2026-02-14T13:01:41.1746275Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherEnrichment::test_enrich_jobs_batch_success PASSED [ 43%]
2026-02-14T13:01:41.1787927Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherEnrichment::test_enrich_jobs_batch_fewer_results PASSED [ 43%]
2026-02-14T13:01:41.1820444Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherDatabaseOperations::test_get_jobs_to_enrich PASSED [ 43%]
2026-02-14T13:01:41.1854299Z tests/unit/test_chatgpt_enricher.py::TestChatGPTEnricherDatabaseOperations::test_update_job_enrichment PASSED [ 44%]
2026-02-14T13:01:41.1875138Z tests/unit/test_company_extractor.py::TestCompanyExtractorFuzzyMatching::test_select_best_match_single_result_above_threshold PASSED [ 44%]
2026-02-14T13:01:41.1898932Z tests/unit/test_company_extractor.py::TestCompanyExtractorFuzzyMatching::test_select_best_match_single_result_below_threshold PASSED [ 44%]
2026-02-14T13:01:41.1919062Z tests/unit/test_company_extractor.py::TestCompanyExtractorFuzzyMatching::test_select_best_match_multiple_results PASSED [ 44%]
2026-02-14T13:01:41.1939593Z tests/unit/test_company_extractor.py::TestCompanyExtractorFuzzyMatching::test_select_best_match_empty_list PASSED [ 44%]
2026-02-14T13:01:41.1959982Z tests/unit/test_company_extractor.py::TestCompanyExtractorFuzzyMatching::test_select_best_match_no_company_name PASSED [ 45%]
2026-02-14T13:01:41.2003263Z tests/unit/test_company_extractor.py::TestCompanyExtractorSQLInjection::test_get_companies_to_enrich_parameterized_query PASSED [ 45%]
2026-02-14T13:01:41.2026558Z tests/unit/test_company_extractor.py::TestCompanyExtractorSQLInjection::test_get_companies_to_enrich_invalid_limit PASSED [ 45%]
2026-02-14T13:01:41.2070021Z tests/unit/test_company_extractor.py::TestCompanyExtractorExistingCompanyCheck::test_get_companies_to_enrich_excludes_existing_companies PASSED [ 45%]
2026-02-14T13:01:41.2140819Z tests/unit/test_cover_letter_generator.py::TestCoverLetterGeneratorInitialization::test_init_success PASSED [ 46%]
2026-02-14T13:01:41.2198427Z tests/unit/test_cover_letter_generator.py::TestCoverLetterGeneratorInitialization::test_init_without_openai_raises_error PASSED [ 46%]
2026-02-14T13:01:41.2227753Z tests/unit/test_cover_letter_generator.py::TestCoverLetterGeneratorInitialization::test_init_without_database_raises_error PASSED [ 46%]
2026-02-14T13:01:41.2284457Z tests/unit/test_cover_letter_generator.py::TestCoverLetterGeneratorInitialization::test_init_without_api_key_raises_error PASSED [ 46%]
2026-02-14T13:01:41.2331881Z tests/unit/test_cover_letter_generator.py::TestBuildPrompt::test_build_prompt_basic PASSED [ 46%]
2026-02-14T13:01:41.2379719Z tests/unit/test_cover_letter_generator.py::TestBuildPrompt::test_build_prompt_with_user_comments PASSED [ 47%]
2026-02-14T13:01:41.2446551Z tests/unit/test_cover_letter_generator.py::TestCallChatGPTAPI::test_call_chatgpt_api_success PASSED [ 47%]
2026-02-14T13:01:44.2522970Z tests/unit/test_cover_letter_generator.py::TestCallChatGPTAPI::test_call_chatgpt_api_empty_response PASSED [ 47%]
2026-02-14T13:01:44.2601332Z tests/unit/test_cover_letter_generator.py::TestCallChatGPTAPI::test_call_chatgpt_api_authentication_error PASSED [ 47%]
2026-02-14T13:01:44.2674640Z tests/unit/test_cover_letter_generator.py::TestCallChatGPTAPI::test_call_chatgpt_api_retry_on_failure PASSED [ 47%]
2026-02-14T13:01:44.2741599Z tests/unit/test_cover_letter_generator.py::TestCallChatGPTAPI::test_call_chatgpt_api_max_retries_exceeded PASSED [ 48%]
2026-02-14T13:01:44.2816103Z tests/unit/test_cover_letter_generator.py::TestGenerateCoverLetter::test_generate_cover_letter_success PASSED [ 48%]
2026-02-14T13:01:44.2871221Z tests/unit/test_cover_letter_generator.py::TestGenerateCoverLetter::test_generate_cover_letter_job_not_found PASSED [ 48%]
2026-02-14T13:01:44.2936859Z tests/unit/test_cover_letter_generator.py::TestGenerateCoverLetter::test_generate_cover_letter_resume_extraction_fails PASSED [ 48%]
2026-02-14T13:01:44.2990340Z tests/unit/test_cover_letter_generator.py::TestGenerateCoverLetter::test_generate_cover_letter_empty_resume_text PASSED [ 48%]
2026-02-14T13:01:44.3062143Z tests/unit/test_cover_letter_generator.py::TestGenerateCoverLetter::test_generate_cover_letter_api_fails PASSED [ 49%]
2026-02-14T13:01:44.3138466Z tests/unit/test_cover_letter_generator.py::TestGenerateCoverLetter::test_generate_cover_letter_with_user_comments PASSED [ 49%]
2026-02-14T13:01:44.3153047Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_init_requires_database PASSED [ 49%]
2026-02-14T13:01:44.3191676Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_create_cover_letter_text_based PASSED [ 49%]
2026-02-14T13:01:44.3224866Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_create_cover_letter_requires_text_or_file PASSED [ 50%]
2026-02-14T13:01:44.3321638Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_upload_cover_letter_file_success PASSED [ 50%]
2026-02-14T13:01:44.3361373Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_get_user_cover_letters PASSED [ 50%]
2026-02-14T13:01:44.3400236Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_get_cover_letter_by_id_success PASSED [ 50%]
2026-02-14T13:01:44.3440951Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_delete_cover_letter_text_based PASSED [ 50%]
2026-02-14T13:01:44.3479086Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_get_user_cover_letters_with_job_filter PASSED [ 51%]
2026-02-14T13:01:44.3517529Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_get_user_cover_letters_all_jobs PASSED [ 51%]
2026-02-14T13:01:44.3558849Z tests/unit/test_cover_letter_service.py::TestCoverLetterService::test_download_cover_letter_text_based_raises_error PASSED [ 51%]
2026-02-14T13:01:44.3603199Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_create_cover_letter_empty_text PASSED [ 51%]
2026-02-14T13:01:44.3641460Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_create_cover_letter_whitespace_only_text PASSED [ 51%]
2026-02-14T13:01:44.3679406Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_create_cover_letter_very_long_text PASSED [ 52%]
2026-02-14T13:01:44.3717581Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_create_cover_letter_special_characters PASSED [ 52%]
2026-02-14T13:01:44.3756892Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_create_cover_letter_unicode_emojis PASSED [ 52%]
2026-02-14T13:01:44.3795997Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_get_cover_letter_by_id_wrong_user PASSED [ 52%]
2026-02-14T13:01:44.3833364Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_delete_cover_letter_not_owned PASSED [ 52%]
2026-02-14T13:01:44.3873063Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_download_cover_letter_text_based_raises PASSED [ 53%]
2026-02-14T13:01:44.3913833Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_download_cover_letter_file_not_on_disk PASSED [ 53%]
2026-02-14T13:01:44.3951593Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_get_user_cover_letters_empty_result PASSED [ 53%]
2026-02-14T13:01:44.3989790Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_create_cover_letter_same_name_different_jobs PASSED [ 53%]
2026-02-14T13:01:44.4066033Z tests/unit/test_cover_letter_service_edge_cases.py::TestCoverLetterServiceEdgeCases::test_upload_cover_letter_file_exactly_max_size PASSED [ 53%]
2026-02-14T13:01:44.4079900Z tests/unit/test_document_service.py::TestDocumentService::test_init_requires_database PASSED [ 54%]
2026-02-14T13:01:44.4117415Z tests/unit/test_document_service.py::TestDocumentService::test_link_documents_to_job_success PASSED [ 54%]
2026-02-14T13:01:44.4151424Z tests/unit/test_document_service.py::TestDocumentService::test_get_job_application_document_found PASSED [ 54%]
2026-02-14T13:01:44.4189506Z tests/unit/test_document_service.py::TestDocumentService::test_get_job_application_document_not_found PASSED [ 54%]
2026-02-14T13:01:44.4225558Z tests/unit/test_document_service.py::TestDocumentService::test_update_job_application_document_success PASSED [ 55%]
2026-02-14T13:01:44.4259195Z tests/unit/test_document_service.py::TestDocumentService::test_delete_job_application_document_success PASSED [ 55%]
2026-02-14T13:01:44.4293641Z tests/unit/test_document_service.py::TestDocumentService::test_delete_job_application_document_not_found PASSED [ 55%]
2026-02-14T13:01:44.4331850Z tests/unit/test_document_service.py::TestDocumentService::test_link_documents_with_inline_text PASSED [ 55%]
2026-02-14T13:01:44.4368061Z tests/unit/test_document_service.py::TestDocumentService::test_update_document_partial_update PASSED [ 55%]
2026-02-14T13:01:44.4406616Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_link_documents_nonexistent_job PASSED [ 56%]
2026-02-14T13:01:44.4443818Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_link_documents_both_resume_and_cover_letter PASSED [ 56%]
2026-02-14T13:01:44.4481243Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_link_documents_inline_text_and_cover_letter_id PASSED [ 56%]
2026-02-14T13:01:44.4518199Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_update_document_clear_resume PASSED [ 56%]
2026-02-14T13:01:44.4553686Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_update_document_clear_cover_letter PASSED [ 56%]
2026-02-14T13:01:44.4587148Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_get_document_nonexistent_job PASSED [ 57%]
2026-02-14T13:01:44.4622447Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_get_document_different_user PASSED [ 57%]
2026-02-14T13:01:44.4657554Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_update_document_not_found PASSED [ 57%]
2026-02-14T13:01:44.4690922Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_delete_document_not_found PASSED [ 57%]
2026-02-14T13:01:44.4725351Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_delete_document_wrong_user PASSED [ 57%]
2026-02-14T13:01:44.4763627Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_link_documents_all_fields_none PASSED [ 58%]
2026-02-14T13:01:44.4798814Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_update_document_very_long_notes PASSED [ 58%]
2026-02-14T13:01:44.4836530Z tests/unit/test_document_service_edge_cases.py::TestDocumentServiceEdgeCases::test_link_documents_special_characters_in_job_id PASSED [ 58%]
2026-02-14T13:01:44.7542840Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_basic_technical_skills PASSED [ 58%]
2026-02-14T13:01:44.8770482Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_case_insensitive PASSED [ 59%]
2026-02-14T13:01:44.9977267Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_word_boundaries PASSED [ 59%]
2026-02-14T13:01:45.1175710Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_empty_description PASSED [ 59%]
2026-02-14T13:01:45.2390964Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_no_matches PASSED [ 59%]
2026-02-14T13:01:45.3665846Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_with_title PASSED [ 59%]
2026-02-14T13:01:45.4883940Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_multiple_occurrences PASSED [ 60%]
2026-02-14T13:01:45.6111939Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_sorted PASSED [ 60%]
2026-02-14T13:01:45.7336107Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_category_based_iteration PASSED [ 60%]
2026-02-14T13:01:45.8588454Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_multi_word_skills PASSED [ 60%]
2026-02-14T13:01:45.9812341Z tests/unit/test_job_enricher.py::TestJobEnricherSkillsExtraction::test_extract_skills_alternative_names PASSED [ 60%]
2026-02-14T13:01:46.1018630Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_intern PASSED [ 61%]
2026-02-14T13:01:46.2217779Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_junior PASSED [ 61%]
2026-02-14T13:01:46.3424543Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_mid PASSED [ 61%]
2026-02-14T13:01:46.4644128Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_senior PASSED [ 61%]
2026-02-14T13:01:46.5856965Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_lead PASSED [ 61%]
2026-02-14T13:01:46.7090438Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_executive PASSED [ 62%]
2026-02-14T13:01:46.8947401Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_no_match PASSED [ 62%]
2026-02-14T13:01:47.0180690Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_empty_title PASSED [ 62%]
2026-02-14T13:01:47.1392606Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_case_insensitive PASSED [ 62%]
2026-02-14T13:01:47.2601344Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_with_description PASSED [ 63%]
2026-02-14T13:01:47.3799157Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_title_priority PASSED [ 63%]
2026-02-14T13:01:47.4988218Z tests/unit/test_job_enricher.py::TestJobEnricherSeniorityExtraction::test_extract_seniority_internship_vs_intern PASSED [ 63%]
2026-02-14T13:01:47.6320094Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_complete PASSED [ 63%]
2026-02-14T13:01:47.7569675Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_no_seniority PASSED [ 63%]
2026-02-14T13:01:47.8780950Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_empty_description PASSED [ 64%]
2026-02-14T13:01:48.0004512Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_ignores_non_salary_numbers PASSED [ 64%]
2026-02-14T13:01:48.1220062Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_decimal_hourly_salary PASSED [ 64%]
2026-02-14T13:01:48.2460002Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_ignores_financial_market_amounts PASSED [ 64%]
2026-02-14T13:01:48.3697471Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_per_annum_salary_range PASSED [ 64%]
2026-02-14T13:01:48.4967238Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_ignores_unrelated_per_week_context PASSED [ 65%]
2026-02-14T13:01:48.6205065Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_detects_cad_currency PASSED [ 65%]
2026-02-14T13:01:48.7442204Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_detects_gbp_currency PASSED [ 65%]
2026-02-14T13:01:48.8674417Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_hourly_range_with_slash_hr PASSED [ 65%]
2026-02-14T13:01:48.9908885Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_defaults_currency_to_country_ca PASSED [ 65%]
2026-02-14T13:01:49.1168218Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_defaults_currency_to_country_us PASSED [ 66%]
2026-02-14T13:01:49.2412993Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_canadian_dollar_prefix PASSED [ 66%]
2026-02-14T13:01:49.3632650Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_decimal_salary_ranges PASSED [ 66%]
2026-02-14T13:01:49.4846274Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_salary_with_location_prefix PASSED [ 66%]
2026-02-14T13:01:49.6079521Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_salary_with_cad_suffix PASSED [ 67%]
2026-02-14T13:01:49.7330811Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_excludes_sign_on_bonus PASSED [ 67%]
2026-02-14T13:01:49.8566294Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_with_doe_suffix PASSED [ 67%]
2026-02-14T13:01:49.9799982Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichment::test_enrich_job_extracts_with_double_dash_and_annually PASSED [ 67%]
2026-02-14T13:01:50.1008495Z tests/unit/test_job_enricher.py::TestJobEnricherInitialization::test_init_with_valid_params PASSED [ 67%]
2026-02-14T13:01:50.1023829Z tests/unit/test_job_enricher.py::TestJobEnricherInitialization::test_init_without_database PASSED [ 68%]
2026-02-14T13:01:50.1042441Z tests/unit/test_job_enricher.py::TestJobEnricherInitialization::test_init_with_invalid_batch_size PASSED [ 68%]
2026-02-14T13:01:50.2246196Z tests/unit/test_job_enricher.py::TestJobEnricherInitialization::test_init_loads_nlp_model PASSED [ 68%]
2026-02-14T13:01:50.3483185Z tests/unit/test_job_enricher.py::TestJobEnricherDatabaseOperations::test_get_jobs_to_enrich PASSED [ 68%]
2026-02-14T13:01:50.4743869Z tests/unit/test_job_enricher.py::TestJobEnricherDatabaseOperations::test_update_job_enrichment PASSED [ 68%]
2026-02-14T13:01:50.6029520Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_remote PASSED [ 69%]
2026-02-14T13:01:50.7290328Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_hybrid PASSED [ 69%]
2026-02-14T13:01:50.8533685Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_onsite PASSED [ 69%]
2026-02-14T13:01:50.9767298Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_no_match PASSED [ 69%]
2026-02-14T13:01:51.0981956Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_empty_input PASSED [ 69%]
2026-02-14T13:01:51.2220466Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_hybrid_working_environment PASSED [ 70%]
2026-02-14T13:01:51.3444989Z tests/unit/test_job_enricher.py::TestJobEnricherRemoteTypeExtraction::test_extract_remote_type_both_remote_and_onsite PASSED [ 70%]
2026-02-14T13:01:51.4705649Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichmentStatus::test_enrich_jobs_with_status_tracking PASSED [ 70%]
2026-02-14T13:01:51.5934629Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichmentStatus::test_enrich_jobs_partial_enrichment PASSED [ 70%]
2026-02-14T13:01:51.7175303Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichmentStatus::test_enrich_jobs_marks_salary_enriched_when_salary_exists PASSED [ 71%]
2026-02-14T13:01:51.8496456Z tests/unit/test_job_enricher.py::TestJobEnricherEnrichmentStatus::test_enrich_jobs_handles_malformed_enrichment_status PASSED [ 71%]
2026-02-14T13:01:51.8516417Z tests/unit/test_job_note_service.py::TestJobNoteService::test_init_requires_database PASSED [ 71%]
2026-02-14T13:01:51.8569798Z tests/unit/test_job_note_service.py::TestJobNoteService::test_get_notes_empty_list PASSED [ 71%]
2026-02-14T13:01:51.8624077Z tests/unit/test_job_note_service.py::TestJobNoteService::test_get_notes_returns_list PASSED [ 71%]
2026-02-14T13:01:51.8674556Z tests/unit/test_job_note_service.py::TestJobNoteService::test_get_notes_detects_modified_notes PASSED [ 72%]
2026-02-14T13:01:51.8718223Z tests/unit/test_job_note_service.py::TestJobNoteService::test_get_note_by_id_not_found PASSED [ 72%]
2026-02-14T13:01:51.8766512Z tests/unit/test_job_note_service.py::TestJobNoteService::test_get_note_by_id_found PASSED [ 72%]
2026-02-14T13:01:51.8829612Z tests/unit/test_job_note_service.py::TestJobNoteService::test_add_note_success PASSED [ 72%]
2026-02-14T13:01:51.8877251Z tests/unit/test_job_note_service.py::TestJobNoteService::test_add_note_strips_whitespace PASSED [ 72%]
2026-02-14T13:01:51.8928183Z tests/unit/test_job_note_service.py::TestJobNoteService::test_add_note_handles_exceptions PASSED [ 73%]
2026-02-14T13:01:51.8989728Z tests/unit/test_job_note_service.py::TestJobNoteService::test_add_note_fails_when_no_result PASSED [ 73%]
2026-02-14T13:01:51.9038855Z tests/unit/test_job_note_service.py::TestJobNoteService::test_update_note_success PASSED [ 73%]
2026-02-14T13:01:51.9091903Z tests/unit/test_job_note_service.py::TestJobNoteService::test_update_note_strips_whitespace PASSED [ 73%]
2026-02-14T13:01:51.9129087Z tests/unit/test_job_note_service.py::TestJobNoteService::test_update_note_not_found PASSED [ 73%]
2026-02-14T13:01:51.9168618Z tests/unit/test_job_note_service.py::TestJobNoteService::test_update_note_handles_exceptions PASSED [ 74%]
2026-02-14T13:01:51.9210766Z tests/unit/test_job_note_service.py::TestJobNoteService::test_delete_note_success PASSED [ 74%]
2026-02-14T13:01:51.9248521Z tests/unit/test_job_note_service.py::TestJobNoteService::test_delete_note_not_found PASSED [ 74%]
2026-02-14T13:01:51.9289483Z tests/unit/test_job_note_service.py::TestJobNoteService::test_delete_note_handles_exceptions PASSED [ 74%]
2026-02-14T13:01:51.9320548Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_remote_type_match_multiple_preferences_exact PASSED [ 75%]
2026-02-14T13:01:51.9346221Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_remote_type_match_multiple_preferences_hybrid PASSED [ 75%]
2026-02-14T13:01:51.9368391Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_remote_type_match_multiple_preferences_partial PASSED [ 75%]
2026-02-14T13:01:51.9390483Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_remote_type_match_no_preference PASSED [ 75%]
2026-02-14T13:01:51.9412903Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_seniority_match_multiple_preferences_exact PASSED [ 75%]
2026-02-14T13:01:51.9444798Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_seniority_match_multiple_preferences_adjacent PASSED [ 76%]
2026-02-14T13:01:51.9466258Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_seniority_match_multiple_preferences_two_levels_apart PASSED [ 76%]
2026-02-14T13:01:51.9487738Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_seniority_match_no_preference PASSED [ 76%]
2026-02-14T13:01:51.9510043Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_company_size_match_multiple_preferences_exact PASSED [ 76%]
2026-02-14T13:01:51.9535518Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_company_size_match_multiple_preferences_numeric_exact PASSED [ 76%]
2026-02-14T13:01:51.9556864Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_company_size_match_multiple_preferences_close PASSED [ 77%]
2026-02-14T13:01:51.9578007Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_company_size_match_no_preference PASSED [ 77%]
2026-02-14T13:01:51.9599824Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_employment_type_match_multiple_preferences_exact PASSED [ 77%]
2026-02-14T13:01:51.9623248Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_employment_type_match_multiple_preferences_comma_list PASSED [ 77%]
2026-02-14T13:01:51.9644327Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_employment_type_match_multiple_job_types PASSED [ 77%]
2026-02-14T13:01:51.9665610Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_employment_type_match_partial PASSED [ 78%]
2026-02-14T13:01:51.9689856Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_employment_type_match_no_preference PASSED [ 78%]
2026-02-14T13:01:51.9712095Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_remote_type_match_with_remote_work_type PASSED [ 78%]
2026-02-14T13:01:51.9734054Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_remote_type_match_onsite_default PASSED [ 78%]
2026-02-14T13:01:51.9755901Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_seniority_match_empty_string PASSED [ 78%]
2026-02-14T13:01:51.9779620Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_company_size_match_range_format PASSED [ 79%]
2026-02-14T13:01:51.9801941Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_all_methods_handle_missing_job_data PASSED [ 79%]
2026-02-14T13:01:51.9823746Z tests/unit/test_job_ranker.py::TestJobRankerMultiplePreferences::test_score_comma_separated_parsing PASSED [ 79%]
2026-02-14T13:01:51.9866465Z tests/unit/test_job_ranker.py::TestJobRankerValidation::test_validate_job_exists_returns_true_when_job_exists PASSED [ 79%]
2026-02-14T13:01:51.9909576Z tests/unit/test_job_ranker.py::TestJobRankerValidation::test_validate_job_exists_returns_false_when_job_not_exists PASSED [ 80%]
2026-02-14T13:01:51.9951881Z tests/unit/test_job_ranker.py::TestJobRankerValidation::test_validate_job_exists_returns_false_when_no_result PASSED [ 80%]
2026-02-14T13:01:52.0014276Z tests/unit/test_job_ranker.py::TestJobRankerValidation::test_rank_jobs_for_campaign_skips_invalid_jobs PASSED [ 80%]
2026-02-14T13:01:52.0064386Z tests/unit/test_job_ranker.py::TestJobRankerValidation::test_rank_jobs_for_campaign_handles_all_invalid_jobs PASSED [ 80%]
2026-02-14T13:01:52.0077769Z tests/unit/test_job_service.py::TestJobService::test_init_requires_database PASSED [ 80%]
2026-02-14T13:01:52.0112133Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_campaign_filters_rejected_by_default PASSED [ 81%]
2026-02-14T13:01:52.0158820Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_campaign_includes_rejected_when_requested PASSED [ 81%]
2026-02-14T13:01:52.0192246Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_user_filters_rejected_by_default PASSED [ 81%]
2026-02-14T13:01:52.0226053Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_user_includes_rejected_when_requested PASSED [ 81%]
2026-02-14T13:01:52.0253339Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_campaign_negative_limit_raises_error PASSED [ 81%]
2026-02-14T13:01:52.0280488Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_campaign_negative_offset_raises_error PASSED [ 82%]
2026-02-14T13:01:52.0306749Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_user_negative_limit_raises_error PASSED [ 82%]
2026-02-14T13:01:52.0333911Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_user_negative_offset_raises_error PASSED [ 82%]
2026-02-14T13:01:52.0367326Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_campaign_returns_jobs PASSED [ 82%]
2026-02-14T13:01:52.0401744Z tests/unit/test_job_service.py::TestJobService::test_get_jobs_for_user_returns_jobs PASSED [ 82%]
2026-02-14T13:01:52.0415470Z tests/unit/test_job_status_service.py::TestJobStatusService::test_init_requires_database PASSED [ 83%]
2026-02-14T13:01:52.0448902Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_status_not_found PASSED [ 83%]
2026-02-14T13:01:52.0483657Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_status_found PASSED [ 83%]
2026-02-14T13:01:52.0529079Z tests/unit/test_job_status_service.py::TestJobStatusService::test_upsert_status_valid_status PASSED [ 83%]
2026-02-14T13:01:52.0561763Z tests/unit/test_job_status_service.py::TestJobStatusService::test_upsert_status_invalid_status PASSED [ 84%]
2026-02-14T13:01:52.0641686Z tests/unit/test_job_status_service.py::TestJobStatusService::test_upsert_status_all_valid_statuses PASSED [ 84%]
2026-02-14T13:01:52.0678379Z tests/unit/test_job_status_service.py::TestJobStatusService::test_upsert_status_handles_exceptions PASSED [ 84%]
2026-02-14T13:01:52.0711839Z tests/unit/test_job_status_service.py::TestJobStatusService::test_record_status_history PASSED [ 84%]
2026-02-14T13:01:52.0745248Z tests/unit/test_job_status_service.py::TestJobStatusService::test_record_job_found PASSED [ 84%]
2026-02-14T13:01:52.0780018Z tests/unit/test_job_status_service.py::TestJobStatusService::test_record_ai_update PASSED [ 85%]
2026-02-14T13:01:52.0813956Z tests/unit/test_job_status_service.py::TestJobStatusService::test_record_document_change PASSED [ 85%]
2026-02-14T13:01:52.0846778Z tests/unit/test_job_status_service.py::TestJobStatusService::test_record_note_change PASSED [ 85%]
2026-02-14T13:01:52.0880128Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_status_history PASSED [ 85%]
2026-02-14T13:01:52.0915012Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_user_status_history PASSED [ 85%]
2026-02-14T13:01:52.0947962Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_job_status_history PASSED [ 86%]
2026-02-14T13:01:52.0992651Z tests/unit/test_job_status_service.py::TestJobStatusService::test_upsert_status_records_history_on_change PASSED [ 86%]
2026-02-14T13:01:52.1020907Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_status_history_invalid_limit PASSED [ 86%]
2026-02-14T13:01:52.1048827Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_user_status_history_invalid_limit PASSED [ 86%]
2026-02-14T13:01:52.1076088Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_user_status_history_invalid_offset PASSED [ 86%]
2026-02-14T13:01:52.1102512Z tests/unit/test_job_status_service.py::TestJobStatusService::test_get_job_status_history_invalid_limit PASSED [ 87%]
2026-02-14T13:01:52.1115792Z tests/unit/test_resume_service.py::TestResumeService::test_init_requires_database PASSED [ 87%]
2026-02-14T13:01:52.1147236Z tests/unit/test_resume_service.py::TestResumeService::test_validate_file_valid_pdf PASSED [ 87%]
2026-02-14T13:01:52.1177856Z tests/unit/test_resume_service.py::TestResumeService::test_validate_file_valid_docx PASSED [ 87%]
2026-02-14T13:01:52.1208775Z tests/unit/test_resume_service.py::TestResumeService::test_validate_file_no_file PASSED [ 88%]
2026-02-14T13:01:52.1257177Z tests/unit/test_resume_service.py::TestResumeService::test_validate_file_too_large PASSED [ 88%]
2026-02-14T13:01:52.1288660Z tests/unit/test_resume_service.py::TestResumeService::test_validate_file_invalid_extension PASSED [ 88%]
2026-02-14T13:01:52.1339679Z tests/unit/test_resume_service.py::TestResumeService::test_upload_resume_success PASSED [ 88%]
2026-02-14T13:01:52.1377733Z tests/unit/test_resume_service.py::TestResumeService::test_get_user_resumes PASSED [ 88%]
2026-02-14T13:01:52.1415377Z tests/unit/test_resume_service.py::TestResumeService::test_get_resume_by_id_success PASSED [ 89%]
2026-02-14T13:01:52.1455033Z tests/unit/test_resume_service.py::TestResumeService::test_get_resume_by_id_not_found PASSED [ 89%]
2026-02-14T13:01:52.1495847Z tests/unit/test_resume_service.py::TestResumeService::test_delete_resume_success PASSED [ 89%]
2026-02-14T13:01:52.1536064Z tests/unit/test_resume_service.py::TestResumeService::test_download_resume_success PASSED [ 89%]
2026-02-14T13:01:52.1567758Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_empty_file PASSED [ 89%]
2026-02-14T13:01:52.1597373Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_no_extension PASSED [ 90%]
2026-02-14T13:01:52.1643240Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_exactly_max_size PASSED [ 90%]
2026-02-14T13:01:52.1674962Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_one_byte_over_limit PASSED [ 90%]
2026-02-14T13:01:52.1704726Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_special_characters_in_filename PASSED [ 90%]
2026-02-14T13:01:52.1734052Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_path_traversal_attempt PASSED [ 90%]
2026-02-14T13:01:52.1763402Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_very_long_filename PASSED [ 91%]
2026-02-14T13:01:52.1793172Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_validate_file_wrong_extension_correct_mime PASSED [ 91%]
2026-02-14T13:01:52.1849663Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_upload_resume_duplicate_name PASSED [ 91%]
2026-02-14T13:01:52.1887742Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_get_resume_by_id_wrong_user PASSED [ 91%]
2026-02-14T13:01:52.1924703Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_delete_resume_not_owned_by_user PASSED [ 92%]
2026-02-14T13:01:52.1968743Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_download_resume_file_not_on_disk PASSED [ 92%]
2026-02-14T13:01:52.2016243Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_upload_resume_storage_failure_rollback PASSED [ 92%]
2026-02-14T13:01:52.2064264Z tests/unit/test_resume_service_edge_cases.py::TestResumeServiceEdgeCases::test_upload_resume_empty_name PASSED [ 92%]
2026-02-14T13:01:52.2092018Z tests/unit/test_resume_text_extractor.py::TestExtractPdfText::test_extract_pdf_text_success PASSED [ 92%]
2026-02-14T13:01:52.2125385Z tests/unit/test_resume_text_extractor.py::TestExtractPdfText::test_extract_pdf_text_multiple_pages PASSED [ 93%]
2026-02-14T13:01:52.2155448Z tests/unit/test_resume_text_extractor.py::TestExtractPdfText::test_extract_pdf_text_no_text PASSED [ 93%]
2026-02-14T13:01:52.2171724Z tests/unit/test_resume_text_extractor.py::TestExtractPdfText::test_extract_pdf_text_pypdf2_not_installed PASSED [ 93%]
2026-02-14T13:01:52.2193496Z tests/unit/test_resume_text_extractor.py::TestExtractPdfText::test_extract_pdf_text_error_handling PASSED [ 93%]
2026-02-14T13:01:52.2218985Z tests/unit/test_resume_text_extractor.py::TestExtractDocxText::test_extract_docx_text_success PASSED [ 93%]
2026-02-14T13:01:52.2250813Z tests/unit/test_resume_text_extractor.py::TestExtractDocxText::test_extract_docx_text_with_tables PASSED [ 94%]
2026-02-14T13:01:52.2273274Z tests/unit/test_resume_text_extractor.py::TestExtractDocxText::test_extract_docx_text_no_text PASSED [ 94%]
2026-02-14T13:01:52.2289166Z tests/unit/test_resume_text_extractor.py::TestExtractDocxText::test_extract_docx_text_python_docx_not_installed PASSED [ 94%]
2026-02-14T13:01:52.2308007Z tests/unit/test_resume_text_extractor.py::TestExtractDocxText::test_extract_docx_text_error_handling PASSED [ 94%]
2026-02-14T13:01:52.2360084Z tests/unit/test_resume_text_extractor.py::TestExtractTextFromResume::test_extract_text_from_resume_pdf_success PASSED [ 94%]
2026-02-14T13:01:52.2410576Z tests/unit/test_resume_text_extractor.py::TestExtractTextFromResume::test_extract_text_from_resume_docx_success PASSED [ 95%]
2026-02-14T13:01:52.2458024Z tests/unit/test_resume_text_extractor.py::TestExtractTextFromResume::test_extract_text_from_resume_not_found PASSED [ 95%]
2026-02-14T13:01:52.2517262Z tests/unit/test_resume_text_extractor.py::TestExtractTextFromResume::test_extract_text_from_resume_no_file_path PASSED [ 95%]
2026-02-14T13:01:52.2563883Z tests/unit/test_resume_text_extractor.py::TestExtractTextFromResume::test_extract_text_from_resume_file_not_found PASSED [ 95%]
2026-02-14T13:01:52.2613358Z tests/unit/test_resume_text_extractor.py::TestExtractTextFromResume::test_extract_text_from_resume_unsupported_format PASSED [ 96%]
2026-02-14T13:01:52.2656714Z tests/unit/test_staging_management.py::test_get_all_slots PASSED         [ 96%]
2026-02-14T13:01:52.2700059Z tests/unit/test_staging_management.py::test_get_slot_by_id PASSED        [ 96%]
2026-02-14T13:01:52.2742229Z tests/unit/test_staging_management.py::test_update_slot_status PASSED    [ 96%]
2026-02-14T13:01:52.2783897Z tests/unit/test_staging_management.py::test_release_slot PASSED          [ 96%]
2026-02-14T13:01:52.2797229Z tests/unit/test_user_service.py::TestUserService::test_init_requires_database PASSED [ 97%]
2026-02-14T13:01:52.5502012Z tests/unit/test_user_service.py::TestUserService::test_hash_password PASSED [ 97%]
2026-02-14T13:01:53.0882094Z tests/unit/test_user_service.py::TestUserService::test_verify_password_correct PASSED [ 97%]
2026-02-14T13:01:53.6265952Z tests/unit/test_user_service.py::TestUserService::test_verify_password_incorrect PASSED [ 97%]
2026-02-14T13:01:53.6295936Z tests/unit/test_user_service.py::TestUserService::test_create_user_validation_empty_username PASSED [ 97%]
2026-02-14T13:01:53.6323195Z tests/unit/test_user_service.py::TestUserService::test_create_user_validation_empty_email PASSED [ 98%]
2026-02-14T13:01:53.6352098Z tests/unit/test_user_service.py::TestUserService::test_create_user_validation_short_password PASSED [ 98%]
2026-02-14T13:01:53.6379689Z tests/unit/test_user_service.py::TestUserService::test_create_user_validation_invalid_role PASSED [ 98%]
2026-02-14T13:01:53.6409716Z tests/unit/test_user_service.py::TestUserService::test_create_user_checks_username_exists PASSED [ 98%]
2026-02-14T13:01:53.6441837Z tests/unit/test_user_service.py::TestUserService::test_create_user_checks_email_exists PASSED [ 98%]
2026-02-14T13:01:53.9157355Z tests/unit/test_user_service.py::TestUserService::test_create_user_success PASSED [ 99%]
2026-02-14T13:01:53.9193488Z tests/unit/test_user_service.py::TestUserService::test_get_user_by_username_not_found PASSED [ 99%]
2026-02-14T13:01:53.9229316Z tests/unit/test_user_service.py::TestUserService::test_get_user_by_email_not_found PASSED [ 99%]
2026-02-14T13:01:53.9263156Z tests/unit/test_user_service.py::TestUserService::test_get_user_by_id_not_found PASSED [ 99%]
2026-02-14T13:01:56.0902864Z tests/unit/test_user_service.py::TestUserService::test_verify_password_handles_exceptions PASSED [100%]
2026-02-14T13:01:56.0903716Z 
2026-02-14T13:01:56.0903945Z ==================================== ERRORS ====================================
2026-02-14T13:01:56.0904766Z _ ERROR at setup of TestBug3Deduplication.test_extractor_skips_duplicate_jobs __
2026-02-14T13:01:56.0905363Z 
2026-02-14T13:01:56.0906027Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.0906477Z 
2026-02-14T13:01:56.0906644Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.0907136Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.0907579Z         """
2026-02-14T13:01:56.0907995Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.0908500Z     
2026-02-14T13:01:56.0908886Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.0909516Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.0910011Z         """
2026-02-14T13:01:56.0910334Z         # Read schema and table creation scripts
2026-02-14T13:01:56.0910893Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.0911604Z     
2026-02-14T13:01:56.0911935Z         # Parse connection string to get database name
2026-02-14T13:01:56.0912785Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.0913516Z     
2026-02-14T13:01:56.0913993Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.0914930Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.0915643Z     
2026-02-14T13:01:56.0916041Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.0916649Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.0917135Z         if len(parts) >= 4:
2026-02-14T13:01:56.0917851Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.0918363Z         else:
2026-02-14T13:01:56.0918709Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.0919156Z     
2026-02-14T13:01:56.0919464Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.0920451Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.0921407Z         import time
2026-02-14T13:01:56.0921695Z     
2026-02-14T13:01:56.0921964Z         max_retries = 5
2026-02-14T13:01:56.0922293Z         retry_delay = 2
2026-02-14T13:01:56.0922609Z     
2026-02-14T13:01:56.0922892Z         for attempt in range(max_retries):
2026-02-14T13:01:56.0923303Z             try:
2026-02-14T13:01:56.0923645Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.0924165Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.0924643Z                 conn.autocommit = True
2026-02-14T13:01:56.0925032Z                 try:
2026-02-14T13:01:56.0925363Z                     cur = conn.cursor()
2026-02-14T13:01:56.0925979Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.0926653Z                     if not cur.fetchone():
2026-02-14T13:01:56.0927236Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.0927910Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.0928415Z                     cur.close()
2026-02-14T13:01:56.0928763Z                 finally:
2026-02-14T13:01:56.0929084Z                     conn.close()
2026-02-14T13:01:56.0929449Z                 break  # Success
2026-02-14T13:01:56.0930052Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.0930728Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.0931351Z                     print(
2026-02-14T13:01:56.0931975Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.0932673Z                     )
2026-02-14T13:01:56.0933021Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.0933431Z                 else:
2026-02-14T13:01:56.0933990Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.0934882Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.0935572Z                     pass
2026-02-14T13:01:56.0935986Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.0936487Z                 break  # Already exists
2026-02-14T13:01:56.0936866Z     
2026-02-14T13:01:56.0937415Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.0938336Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.0939079Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.0939597Z     
2026-02-14T13:01:56.0939864Z         close_all_pools()
2026-02-14T13:01:56.0940185Z     
2026-02-14T13:01:56.0940516Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.0941393Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.0942142Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.0942695Z             conn.autocommit = True
2026-02-14T13:01:56.0943111Z             with conn.cursor() as cur:
2026-02-14T13:01:56.0943741Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.0944439Z                 # EXCEPT our current connection
2026-02-14T13:01:56.0944878Z                 cur.execute(
2026-02-14T13:01:56.0945235Z                     """
2026-02-14T13:01:56.0945603Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.0946077Z                     FROM pg_stat_activity
2026-02-14T13:01:56.0946772Z                     WHERE datname = current_database()
2026-02-14T13:01:56.0947286Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.0947724Z                     """
2026-02-14T13:01:56.0948022Z                 )
2026-02-14T13:01:56.0948502Z     
2026-02-14T13:01:56.0948996Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.0949859Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.0950499Z                 try:
2026-02-14T13:01:56.0950894Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.0951624Z                     cur.execute("""
2026-02-14T13:01:56.0951994Z                         DO $$
2026-02-14T13:01:56.0952340Z                         DECLARE
2026-02-14T13:01:56.0952698Z                             r RECORD;
2026-02-14T13:01:56.0953085Z                         BEGIN
2026-02-14T13:01:56.0953453Z                             FOR r IN (
2026-02-14T13:01:56.0953902Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.0954387Z                                 FROM pg_views
2026-02-14T13:01:56.0954905Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.0955448Z                             )
2026-02-14T13:01:56.0955789Z                             LOOP
2026-02-14T13:01:56.0956594Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.0957461Z                             END LOOP;
2026-02-14T13:01:56.0957843Z                         END $$;
2026-02-14T13:01:56.0958198Z                     """)
2026-02-14T13:01:56.0958530Z                     # Drop tables
2026-02-14T13:01:56.0958913Z                     cur.execute("""
2026-02-14T13:01:56.0959283Z                         DO $$
2026-02-14T13:01:56.0959634Z                         DECLARE
2026-02-14T13:01:56.0959997Z                             r RECORD;
2026-02-14T13:01:56.0960377Z                         BEGIN
2026-02-14T13:01:56.0960728Z                             FOR r IN (
2026-02-14T13:01:56.0961346Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.0961850Z                                 FROM pg_tables
2026-02-14T13:01:56.0962370Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.0962899Z                             )
2026-02-14T13:01:56.0963231Z                             LOOP
2026-02-14T13:01:56.0964052Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.0964935Z                             END LOOP;
2026-02-14T13:01:56.0965309Z                         END $$;
2026-02-14T13:01:56.0965659Z                     """)
2026-02-14T13:01:56.0966018Z                 except psycopg2.Error:
2026-02-14T13:01:56.0966638Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.0967251Z                     pass
2026-02-14T13:01:56.0967565Z     
2026-02-14T13:01:56.0968005Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.0968682Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.0969173Z                 if init_dir.exists():
2026-02-14T13:01:56.0969633Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.0970143Z                     for script_path in scripts:
2026-02-14T13:01:56.0970701Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.0971398Z                             sql = f.read()
2026-02-14T13:01:56.0972061Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.0972871Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.0973643Z                             statements = []
2026-02-14T13:01:56.0974059Z     
2026-02-14T13:01:56.0974515Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.0975372Z                             do_blocks = []
2026-02-14T13:01:56.0975849Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.0976304Z     
2026-02-14T13:01:56.0976688Z                             def replace_do_block(match):
2026-02-14T13:01:56.0977185Z                                 block = match.group(0)
2026-02-14T13:01:56.0977738Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.0978317Z                                 do_blocks.append(block)
2026-02-14T13:01:56.0978808Z                                 return placeholder
2026-02-14T13:01:56.0979217Z     
2026-02-14T13:01:56.0979555Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.0980095Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.0980584Z                                                     ^^
2026-02-14T13:01:56.0981408Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.0982058Z                             )
2026-02-14T13:01:56.0982476Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.0982834Z 
2026-02-14T13:01:56.0983012Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.0983732Z _ ERROR at setup of TestBug3Deduplication.test_extractor_handles_mixed_duplicates _
2026-02-14T13:01:56.0984301Z 
2026-02-14T13:01:56.0985166Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.0985630Z 
2026-02-14T13:01:56.0985799Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.0986270Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.0986726Z         """
2026-02-14T13:01:56.0987133Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.0987650Z     
2026-02-14T13:01:56.0988027Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.0988661Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.0989156Z         """
2026-02-14T13:01:56.0989475Z         # Read schema and table creation scripts
2026-02-14T13:01:56.0990024Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.0990503Z     
2026-02-14T13:01:56.0990835Z         # Parse connection string to get database name
2026-02-14T13:01:56.0991806Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.0992542Z     
2026-02-14T13:01:56.0993028Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.0994424Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.0995145Z     
2026-02-14T13:01:56.0995533Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.0996151Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.0996613Z         if len(parts) >= 4:
2026-02-14T13:01:56.0997052Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.0997541Z         else:
2026-02-14T13:01:56.0997879Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.0998326Z     
2026-02-14T13:01:56.0998634Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.0999398Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1000110Z         import time
2026-02-14T13:01:56.1000400Z     
2026-02-14T13:01:56.1000652Z         max_retries = 5
2026-02-14T13:01:56.1000981Z         retry_delay = 2
2026-02-14T13:01:56.1001458Z     
2026-02-14T13:01:56.1001745Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1002363Z             try:
2026-02-14T13:01:56.1002720Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1003241Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1003713Z                 conn.autocommit = True
2026-02-14T13:01:56.1004301Z                 try:
2026-02-14T13:01:56.1004623Z                     cur = conn.cursor()
2026-02-14T13:01:56.1005265Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1005936Z                     if not cur.fetchone():
2026-02-14T13:01:56.1006499Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1007167Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1007659Z                     cur.close()
2026-02-14T13:01:56.1008010Z                 finally:
2026-02-14T13:01:56.1008335Z                     conn.close()
2026-02-14T13:01:56.1008714Z                 break  # Success
2026-02-14T13:01:56.1009298Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1010032Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1010463Z                     print(
2026-02-14T13:01:56.1011250Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1011953Z                     )
2026-02-14T13:01:56.1012286Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1012698Z                 else:
2026-02-14T13:01:56.1013254Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1014139Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1014789Z                     pass
2026-02-14T13:01:56.1015199Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1015709Z                 break  # Already exists
2026-02-14T13:01:56.1016100Z     
2026-02-14T13:01:56.1016648Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1017560Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1018318Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1018819Z     
2026-02-14T13:01:56.1019072Z         close_all_pools()
2026-02-14T13:01:56.1019388Z     
2026-02-14T13:01:56.1019737Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1020416Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1021338Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1021907Z             conn.autocommit = True
2026-02-14T13:01:56.1022316Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1022958Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1023674Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1024110Z                 cur.execute(
2026-02-14T13:01:56.1024454Z                     """
2026-02-14T13:01:56.1024813Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1025294Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1025754Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1026242Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1026664Z                     """
2026-02-14T13:01:56.1026973Z                 )
2026-02-14T13:01:56.1027247Z     
2026-02-14T13:01:56.1027725Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1028590Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1029219Z                 try:
2026-02-14T13:01:56.1029627Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1030327Z                     cur.execute("""
2026-02-14T13:01:56.1030722Z                         DO $$
2026-02-14T13:01:56.1031245Z                         DECLARE
2026-02-14T13:01:56.1031627Z                             r RECORD;
2026-02-14T13:01:56.1032193Z                         BEGIN
2026-02-14T13:01:56.1032543Z                             FOR r IN (
2026-02-14T13:01:56.1032989Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1033466Z                                 FROM pg_views
2026-02-14T13:01:56.1033991Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1034513Z                             )
2026-02-14T13:01:56.1034858Z                             LOOP
2026-02-14T13:01:56.1035671Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1036523Z                             END LOOP;
2026-02-14T13:01:56.1036924Z                         END $$;
2026-02-14T13:01:56.1037288Z                     """)
2026-02-14T13:01:56.1037623Z                     # Drop tables
2026-02-14T13:01:56.1037997Z                     cur.execute("""
2026-02-14T13:01:56.1038378Z                         DO $$
2026-02-14T13:01:56.1038720Z                         DECLARE
2026-02-14T13:01:56.1039076Z                             r RECORD;
2026-02-14T13:01:56.1039452Z                         BEGIN
2026-02-14T13:01:56.1039803Z                             FOR r IN (
2026-02-14T13:01:56.1040259Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1040738Z                                 FROM pg_tables
2026-02-14T13:01:56.1041482Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1041998Z                             )
2026-02-14T13:01:56.1042350Z                             LOOP
2026-02-14T13:01:56.1043174Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1044077Z                             END LOOP;
2026-02-14T13:01:56.1044460Z                         END $$;
2026-02-14T13:01:56.1044796Z                     """)
2026-02-14T13:01:56.1045160Z                 except psycopg2.Error:
2026-02-14T13:01:56.1045763Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1046473Z                     pass
2026-02-14T13:01:56.1072564Z     
2026-02-14T13:01:56.1073082Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1073813Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1074328Z                 if init_dir.exists():
2026-02-14T13:01:56.1074805Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1075310Z                     for script_path in scripts:
2026-02-14T13:01:56.1075879Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1076486Z                             sql = f.read()
2026-02-14T13:01:56.1077152Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1077967Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1078527Z                             statements = []
2026-02-14T13:01:56.1078926Z     
2026-02-14T13:01:56.1079388Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1080030Z                             do_blocks = []
2026-02-14T13:01:56.1080487Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1080927Z     
2026-02-14T13:01:56.1081433Z                             def replace_do_block(match):
2026-02-14T13:01:56.1081936Z                                 block = match.group(0)
2026-02-14T13:01:56.1082728Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1083322Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1083808Z                                 return placeholder
2026-02-14T13:01:56.1084234Z     
2026-02-14T13:01:56.1084743Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1085292Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1085777Z                                                     ^^
2026-02-14T13:01:56.1086413Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1087056Z                             )
2026-02-14T13:01:56.1087485Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1087843Z 
2026-02-14T13:01:56.1088036Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1088710Z ______ ERROR at setup of TestBug5UKCountryCode.test_ranker_uses_gb_not_uk ______
2026-02-14T13:01:56.1089240Z 
2026-02-14T13:01:56.1089854Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1090360Z 
2026-02-14T13:01:56.1090521Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1091008Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1091640Z         """
2026-02-14T13:01:56.1092040Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1092544Z     
2026-02-14T13:01:56.1092945Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1093587Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1094087Z         """
2026-02-14T13:01:56.1094419Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1094982Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1095484Z     
2026-02-14T13:01:56.1095817Z         # Parse connection string to get database name
2026-02-14T13:01:56.1096633Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1097355Z     
2026-02-14T13:01:56.1097822Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1098779Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1099502Z     
2026-02-14T13:01:56.1099901Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1100527Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1101021Z         if len(parts) >= 4:
2026-02-14T13:01:56.1101639Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1102134Z         else:
2026-02-14T13:01:56.1102478Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1102932Z     
2026-02-14T13:01:56.1103239Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1104007Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1104736Z         import time
2026-02-14T13:01:56.1105021Z     
2026-02-14T13:01:56.1105287Z         max_retries = 5
2026-02-14T13:01:56.1105627Z         retry_delay = 2
2026-02-14T13:01:56.1105942Z     
2026-02-14T13:01:56.1106227Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1106644Z             try:
2026-02-14T13:01:56.1107000Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1107525Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1107993Z                 conn.autocommit = True
2026-02-14T13:01:56.1108403Z                 try:
2026-02-14T13:01:56.1108727Z                     cur = conn.cursor()
2026-02-14T13:01:56.1109328Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1110004Z                     if not cur.fetchone():
2026-02-14T13:01:56.1110778Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1111649Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1112147Z                     cur.close()
2026-02-14T13:01:56.1112512Z                 finally:
2026-02-14T13:01:56.1113044Z                     conn.close()
2026-02-14T13:01:56.1113423Z                 break  # Success
2026-02-14T13:01:56.1114016Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1114701Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1115136Z                     print(
2026-02-14T13:01:56.1115759Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1116453Z                     )
2026-02-14T13:01:56.1116789Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1117205Z                 else:
2026-02-14T13:01:56.1117776Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1118660Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1119303Z                     pass
2026-02-14T13:01:56.1119728Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1120243Z                 break  # Already exists
2026-02-14T13:01:56.1120615Z     
2026-02-14T13:01:56.1121353Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1122286Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1123035Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1123538Z     
2026-02-14T13:01:56.1123803Z         close_all_pools()
2026-02-14T13:01:56.1124131Z     
2026-02-14T13:01:56.1124486Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1125151Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1125896Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1126449Z             conn.autocommit = True
2026-02-14T13:01:56.1126868Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1127505Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1128211Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1128657Z                 cur.execute(
2026-02-14T13:01:56.1128999Z                     """
2026-02-14T13:01:56.1129378Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1129842Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1130302Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1130785Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1131395Z                     """
2026-02-14T13:01:56.1131691Z                 )
2026-02-14T13:01:56.1131969Z     
2026-02-14T13:01:56.1132501Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1133370Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1134012Z                 try:
2026-02-14T13:01:56.1134412Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1134925Z                     cur.execute("""
2026-02-14T13:01:56.1135303Z                         DO $$
2026-02-14T13:01:56.1135654Z                         DECLARE
2026-02-14T13:01:56.1136005Z                             r RECORD;
2026-02-14T13:01:56.1136395Z                         BEGIN
2026-02-14T13:01:56.1136752Z                             FOR r IN (
2026-02-14T13:01:56.1137181Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1137673Z                                 FROM pg_views
2026-02-14T13:01:56.1138198Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1139012Z                             )
2026-02-14T13:01:56.1139387Z                             LOOP
2026-02-14T13:01:56.1140218Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1141447Z                             END LOOP;
2026-02-14T13:01:56.1141828Z                         END $$;
2026-02-14T13:01:56.1142177Z                     """)
2026-02-14T13:01:56.1142498Z                     # Drop tables
2026-02-14T13:01:56.1142865Z                     cur.execute("""
2026-02-14T13:01:56.1143237Z                         DO $$
2026-02-14T13:01:56.1143587Z                         DECLARE
2026-02-14T13:01:56.1143937Z                             r RECORD;
2026-02-14T13:01:56.1144318Z                         BEGIN
2026-02-14T13:01:56.1144676Z                             FOR r IN (
2026-02-14T13:01:56.1145118Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1145627Z                                 FROM pg_tables
2026-02-14T13:01:56.1146159Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1146692Z                             )
2026-02-14T13:01:56.1147028Z                             LOOP
2026-02-14T13:01:56.1147855Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1148729Z                             END LOOP;
2026-02-14T13:01:56.1149110Z                         END $$;
2026-02-14T13:01:56.1149457Z                     """)
2026-02-14T13:01:56.1149804Z                 except psycopg2.Error:
2026-02-14T13:01:56.1150409Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1151222Z                     pass
2026-02-14T13:01:56.1151556Z     
2026-02-14T13:01:56.1152014Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1152710Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1153204Z                 if init_dir.exists():
2026-02-14T13:01:56.1153667Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1154171Z                     for script_path in scripts:
2026-02-14T13:01:56.1154715Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1155247Z                             sql = f.read()
2026-02-14T13:01:56.1155906Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1156709Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1157266Z                             statements = []
2026-02-14T13:01:56.1157648Z     
2026-02-14T13:01:56.1158123Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1158751Z                             do_blocks = []
2026-02-14T13:01:56.1159214Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1159646Z     
2026-02-14T13:01:56.1159965Z                             def replace_do_block(match):
2026-02-14T13:01:56.1160461Z                                 block = match.group(0)
2026-02-14T13:01:56.1161017Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1161775Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1162251Z                                 return placeholder
2026-02-14T13:01:56.1162668Z     
2026-02-14T13:01:56.1162999Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1163544Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1164030Z                                                     ^^
2026-02-14T13:01:56.1164668Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1165303Z                             )
2026-02-14T13:01:56.1165930Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1166310Z 
2026-02-14T13:01:56.1166489Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1167206Z _ ERROR at setup of TestBug5UKCountryCode.test_campaign_stored_with_gb_country_code _
2026-02-14T13:01:56.1167969Z 
2026-02-14T13:01:56.1168613Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1169043Z 
2026-02-14T13:01:56.1169202Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1169693Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1170138Z         """
2026-02-14T13:01:56.1170533Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1171285Z     
2026-02-14T13:01:56.1171702Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1172349Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1172840Z         """
2026-02-14T13:01:56.1173177Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1173727Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1174220Z     
2026-02-14T13:01:56.1174551Z         # Parse connection string to get database name
2026-02-14T13:01:56.1175353Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1176065Z     
2026-02-14T13:01:56.1176608Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1177555Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1178269Z     
2026-02-14T13:01:56.1178672Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1179287Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1179774Z         if len(parts) >= 4:
2026-02-14T13:01:56.1180224Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1180706Z         else:
2026-02-14T13:01:56.1181232Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1181672Z     
2026-02-14T13:01:56.1181976Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1182739Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1183462Z         import time
2026-02-14T13:01:56.1183743Z     
2026-02-14T13:01:56.1184008Z         max_retries = 5
2026-02-14T13:01:56.1184340Z         retry_delay = 2
2026-02-14T13:01:56.1184649Z     
2026-02-14T13:01:56.1184934Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1185349Z             try:
2026-02-14T13:01:56.1185709Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1186220Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1186689Z                 conn.autocommit = True
2026-02-14T13:01:56.1187080Z                 try:
2026-02-14T13:01:56.1187400Z                     cur = conn.cursor()
2026-02-14T13:01:56.1188012Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1188686Z                     if not cur.fetchone():
2026-02-14T13:01:56.1189268Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1189928Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1190445Z                     cur.close()
2026-02-14T13:01:56.1190798Z                 finally:
2026-02-14T13:01:56.1191304Z                     conn.close()
2026-02-14T13:01:56.1191672Z                 break  # Success
2026-02-14T13:01:56.1192255Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1192919Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1193342Z                     print(
2026-02-14T13:01:56.1194182Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1194880Z                     )
2026-02-14T13:01:56.1195229Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1195635Z                 else:
2026-02-14T13:01:56.1196198Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1197287Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1197931Z                     pass
2026-02-14T13:01:56.1198341Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1198822Z                 break  # Already exists
2026-02-14T13:01:56.1199217Z     
2026-02-14T13:01:56.1199760Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1200682Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1201619Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1202131Z     
2026-02-14T13:01:56.1202405Z         close_all_pools()
2026-02-14T13:01:56.1202735Z     
2026-02-14T13:01:56.1203090Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1203755Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1204488Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1205041Z             conn.autocommit = True
2026-02-14T13:01:56.1205459Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1206102Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1206807Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1207250Z                 cur.execute(
2026-02-14T13:01:56.1207592Z                     """
2026-02-14T13:01:56.1207970Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1208438Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1208925Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1209414Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1209841Z                     """
2026-02-14T13:01:56.1210135Z                 )
2026-02-14T13:01:56.1210425Z     
2026-02-14T13:01:56.1210920Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1211979Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1212625Z                 try:
2026-02-14T13:01:56.1213024Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1213538Z                     cur.execute("""
2026-02-14T13:01:56.1213920Z                         DO $$
2026-02-14T13:01:56.1214266Z                         DECLARE
2026-02-14T13:01:56.1214640Z                             r RECORD;
2026-02-14T13:01:56.1215011Z                         BEGIN
2026-02-14T13:01:56.1215370Z                             FOR r IN (
2026-02-14T13:01:56.1215806Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1216302Z                                 FROM pg_views
2026-02-14T13:01:56.1216827Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1217370Z                             )
2026-02-14T13:01:56.1217713Z                             LOOP
2026-02-14T13:01:56.1218537Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1219411Z                             END LOOP;
2026-02-14T13:01:56.1219790Z                         END $$;
2026-02-14T13:01:56.1220154Z                     """)
2026-02-14T13:01:56.1220480Z                     # Drop tables
2026-02-14T13:01:56.1220851Z                     cur.execute("""
2026-02-14T13:01:56.1221426Z                         DO $$
2026-02-14T13:01:56.1221789Z                         DECLARE
2026-02-14T13:01:56.1222344Z                             r RECORD;
2026-02-14T13:01:56.1222763Z                         BEGIN
2026-02-14T13:01:56.1223133Z                             FOR r IN (
2026-02-14T13:01:56.1223585Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1224248Z                                 FROM pg_tables
2026-02-14T13:01:56.1224777Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1225308Z                             )
2026-02-14T13:01:56.1225654Z                             LOOP
2026-02-14T13:01:56.1226483Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1227380Z                             END LOOP;
2026-02-14T13:01:56.1227764Z                         END $$;
2026-02-14T13:01:56.1228117Z                     """)
2026-02-14T13:01:56.1228466Z                 except psycopg2.Error:
2026-02-14T13:01:56.1229098Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1229726Z                     pass
2026-02-14T13:01:56.1230043Z     
2026-02-14T13:01:56.1230490Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1231365Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1231866Z                 if init_dir.exists():
2026-02-14T13:01:56.1232330Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1232832Z                     for script_path in scripts:
2026-02-14T13:01:56.1233380Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1233911Z                             sql = f.read()
2026-02-14T13:01:56.1234567Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1235397Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1235960Z                             statements = []
2026-02-14T13:01:56.1236354Z     
2026-02-14T13:01:56.1236805Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1237457Z                             do_blocks = []
2026-02-14T13:01:56.1237915Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1238360Z     
2026-02-14T13:01:56.1238681Z                             def replace_do_block(match):
2026-02-14T13:01:56.1239167Z                                 block = match.group(0)
2026-02-14T13:01:56.1239722Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1240294Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1240778Z                                 return placeholder
2026-02-14T13:01:56.1241397Z     
2026-02-14T13:01:56.1241735Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1242293Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1242772Z                                                     ^^
2026-02-14T13:01:56.1243413Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1244052Z                             )
2026-02-14T13:01:56.1244479Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1244841Z 
2026-02-14T13:01:56.1245022Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1245715Z _ ERROR at setup of TestBug7JobNotFound.test_job_retrievable_from_own_campaign _
2026-02-14T13:01:56.1246268Z 
2026-02-14T13:01:56.1246824Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1247255Z 
2026-02-14T13:01:56.1247417Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1247902Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1248345Z         """
2026-02-14T13:01:56.1248928Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1249434Z     
2026-02-14T13:01:56.1249826Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1250452Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1251387Z         """
2026-02-14T13:01:56.1251729Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1252286Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1252777Z     
2026-02-14T13:01:56.1253110Z         # Parse connection string to get database name
2026-02-14T13:01:56.1253891Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1254631Z     
2026-02-14T13:01:56.1255097Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1256039Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1256757Z     
2026-02-14T13:01:56.1257150Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1257777Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1258266Z         if len(parts) >= 4:
2026-02-14T13:01:56.1258710Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1259188Z         else:
2026-02-14T13:01:56.1259520Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1259958Z     
2026-02-14T13:01:56.1260250Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1260999Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1261941Z         import time
2026-02-14T13:01:56.1262228Z     
2026-02-14T13:01:56.1262491Z         max_retries = 5
2026-02-14T13:01:56.1262812Z         retry_delay = 2
2026-02-14T13:01:56.1263121Z     
2026-02-14T13:01:56.1263408Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1263831Z             try:
2026-02-14T13:01:56.1264180Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1264689Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1265148Z                 conn.autocommit = True
2026-02-14T13:01:56.1265548Z                 try:
2026-02-14T13:01:56.1265859Z                     cur = conn.cursor()
2026-02-14T13:01:56.1266480Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1267154Z                     if not cur.fetchone():
2026-02-14T13:01:56.1267724Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1268387Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1268882Z                     cur.close()
2026-02-14T13:01:56.1269239Z                 finally:
2026-02-14T13:01:56.1269576Z                     conn.close()
2026-02-14T13:01:56.1269945Z                 break  # Success
2026-02-14T13:01:56.1270528Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1271509Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1271934Z                     print(
2026-02-14T13:01:56.1272613Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1273308Z                     )
2026-02-14T13:01:56.1273638Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1274057Z                 else:
2026-02-14T13:01:56.1274626Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1275503Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1276143Z                     pass
2026-02-14T13:01:56.1276650Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1277156Z                 break  # Already exists
2026-02-14T13:01:56.1277818Z     
2026-02-14T13:01:56.1278414Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1279340Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1280284Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1280793Z     
2026-02-14T13:01:56.1281270Z         close_all_pools()
2026-02-14T13:01:56.1281617Z     
2026-02-14T13:01:56.1281963Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1282632Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1283359Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1283922Z             conn.autocommit = True
2026-02-14T13:01:56.1284334Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1284965Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1285678Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1286115Z                 cur.execute(
2026-02-14T13:01:56.1286467Z                     """
2026-02-14T13:01:56.1286846Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1287331Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1287790Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1288265Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1288690Z                     """
2026-02-14T13:01:56.1288982Z                 )
2026-02-14T13:01:56.1289251Z     
2026-02-14T13:01:56.1289736Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1290611Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1291431Z                 try:
2026-02-14T13:01:56.1291835Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1292359Z                     cur.execute("""
2026-02-14T13:01:56.1292738Z                         DO $$
2026-02-14T13:01:56.1293098Z                         DECLARE
2026-02-14T13:01:56.1293454Z                             r RECORD;
2026-02-14T13:01:56.1293844Z                         BEGIN
2026-02-14T13:01:56.1294189Z                             FOR r IN (
2026-02-14T13:01:56.1294625Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1295095Z                                 FROM pg_views
2026-02-14T13:01:56.1295626Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1296155Z                             )
2026-02-14T13:01:56.1296500Z                             LOOP
2026-02-14T13:01:56.1297321Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1298187Z                             END LOOP;
2026-02-14T13:01:56.1298583Z                         END $$;
2026-02-14T13:01:56.1298924Z                     """)
2026-02-14T13:01:56.1299257Z                     # Drop tables
2026-02-14T13:01:56.1299642Z                     cur.execute("""
2026-02-14T13:01:56.1300002Z                         DO $$
2026-02-14T13:01:56.1300340Z                         DECLARE
2026-02-14T13:01:56.1300687Z                             r RECORD;
2026-02-14T13:01:56.1301257Z                         BEGIN
2026-02-14T13:01:56.1301623Z                             FOR r IN (
2026-02-14T13:01:56.1302075Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1302558Z                                 FROM pg_tables
2026-02-14T13:01:56.1303091Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1303619Z                             )
2026-02-14T13:01:56.1303956Z                             LOOP
2026-02-14T13:01:56.1305009Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1305920Z                             END LOOP;
2026-02-14T13:01:56.1306313Z                         END $$;
2026-02-14T13:01:56.1306672Z                     """)
2026-02-14T13:01:56.1307261Z                 except psycopg2.Error:
2026-02-14T13:01:56.1307877Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1308492Z                     pass
2026-02-14T13:01:56.1308804Z     
2026-02-14T13:01:56.1309249Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1309936Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1310419Z                 if init_dir.exists():
2026-02-14T13:01:56.1310895Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1311612Z                     for script_path in scripts:
2026-02-14T13:01:56.1312151Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1312683Z                             sql = f.read()
2026-02-14T13:01:56.1313345Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1314156Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1314715Z                             statements = []
2026-02-14T13:01:56.1315112Z     
2026-02-14T13:01:56.1315570Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1316204Z                             do_blocks = []
2026-02-14T13:01:56.1316664Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1317097Z     
2026-02-14T13:01:56.1317393Z                             def replace_do_block(match):
2026-02-14T13:01:56.1317887Z                                 block = match.group(0)
2026-02-14T13:01:56.1318449Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1319019Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1319526Z                                 return placeholder
2026-02-14T13:01:56.1319954Z     
2026-02-14T13:01:56.1320296Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1320838Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1321537Z                                                     ^^
2026-02-14T13:01:56.1322201Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1322836Z                             )
2026-02-14T13:01:56.1323244Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1323610Z 
2026-02-14T13:01:56.1323795Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1324479Z ____ ERROR at setup of TestCampaignUniqueness.test_campaign_ids_are_unique _____
2026-02-14T13:01:56.1325024Z 
2026-02-14T13:01:56.1325680Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1326150Z 
2026-02-14T13:01:56.1326313Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1326790Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1327254Z         """
2026-02-14T13:01:56.1327658Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1328159Z     
2026-02-14T13:01:56.1328531Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1329152Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1329646Z         """
2026-02-14T13:01:56.1329960Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1330512Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1330994Z     
2026-02-14T13:01:56.1331501Z         # Parse connection string to get database name
2026-02-14T13:01:56.1332549Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1333276Z     
2026-02-14T13:01:56.1333751Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1334669Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1335677Z     
2026-02-14T13:01:56.1336070Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1336694Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1337177Z         if len(parts) >= 4:
2026-02-14T13:01:56.1337614Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1338089Z         else:
2026-02-14T13:01:56.1338438Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1338878Z     
2026-02-14T13:01:56.1339187Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1339945Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1340652Z         import time
2026-02-14T13:01:56.1340944Z     
2026-02-14T13:01:56.1341375Z         max_retries = 5
2026-02-14T13:01:56.1341700Z         retry_delay = 2
2026-02-14T13:01:56.1342016Z     
2026-02-14T13:01:56.1342305Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1342717Z             try:
2026-02-14T13:01:56.1343064Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1343574Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1344037Z                 conn.autocommit = True
2026-02-14T13:01:56.1344448Z                 try:
2026-02-14T13:01:56.1344773Z                     cur = conn.cursor()
2026-02-14T13:01:56.1345378Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1346033Z                     if not cur.fetchone():
2026-02-14T13:01:56.1346610Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1347279Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1347774Z                     cur.close()
2026-02-14T13:01:56.1348137Z                 finally:
2026-02-14T13:01:56.1348478Z                     conn.close()
2026-02-14T13:01:56.1348852Z                 break  # Success
2026-02-14T13:01:56.1349441Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1350105Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1350534Z                     print(
2026-02-14T13:01:56.1351305Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1352041Z                     )
2026-02-14T13:01:56.1352388Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1352804Z                 else:
2026-02-14T13:01:56.1353370Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1354259Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1354895Z                     pass
2026-02-14T13:01:56.1355299Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1355806Z                 break  # Already exists
2026-02-14T13:01:56.1356179Z     
2026-02-14T13:01:56.1356698Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1357610Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1358362Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1358881Z     
2026-02-14T13:01:56.1359142Z         close_all_pools()
2026-02-14T13:01:56.1359476Z     
2026-02-14T13:01:56.1359820Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1360500Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1361623Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1362230Z             conn.autocommit = True
2026-02-14T13:01:56.1362649Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1363265Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1364195Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1364637Z                 cur.execute(
2026-02-14T13:01:56.1364996Z                     """
2026-02-14T13:01:56.1365372Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1365863Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1366316Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1366811Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1367240Z                     """
2026-02-14T13:01:56.1367535Z                 )
2026-02-14T13:01:56.1367817Z     
2026-02-14T13:01:56.1368304Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1369170Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1369801Z                 try:
2026-02-14T13:01:56.1370209Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1370718Z                     cur.execute("""
2026-02-14T13:01:56.1371279Z                         DO $$
2026-02-14T13:01:56.1371640Z                         DECLARE
2026-02-14T13:01:56.1371997Z                             r RECORD;
2026-02-14T13:01:56.1372378Z                         BEGIN
2026-02-14T13:01:56.1372728Z                             FOR r IN (
2026-02-14T13:01:56.1373174Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1373653Z                                 FROM pg_views
2026-02-14T13:01:56.1374168Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1374697Z                             )
2026-02-14T13:01:56.1375044Z                             LOOP
2026-02-14T13:01:56.1375857Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1376828Z                             END LOOP;
2026-02-14T13:01:56.1377207Z                         END $$;
2026-02-14T13:01:56.1377556Z                     """)
2026-02-14T13:01:56.1377894Z                     # Drop tables
2026-02-14T13:01:56.1378268Z                     cur.execute("""
2026-02-14T13:01:56.1378653Z                         DO $$
2026-02-14T13:01:56.1378993Z                         DECLARE
2026-02-14T13:01:56.1379345Z                             r RECORD;
2026-02-14T13:01:56.1379715Z                         BEGIN
2026-02-14T13:01:56.1380053Z                             FOR r IN (
2026-02-14T13:01:56.1380502Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1380986Z                                 FROM pg_tables
2026-02-14T13:01:56.1381734Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1382259Z                             )
2026-02-14T13:01:56.1382613Z                             LOOP
2026-02-14T13:01:56.1383447Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1384327Z                             END LOOP;
2026-02-14T13:01:56.1384710Z                         END $$;
2026-02-14T13:01:56.1385049Z                     """)
2026-02-14T13:01:56.1385399Z                 except psycopg2.Error:
2026-02-14T13:01:56.1385980Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1386605Z                     pass
2026-02-14T13:01:56.1386921Z     
2026-02-14T13:01:56.1387367Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1388264Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1388765Z                 if init_dir.exists():
2026-02-14T13:01:56.1389234Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1389742Z                     for script_path in scripts:
2026-02-14T13:01:56.1390456Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1390978Z                             sql = f.read()
2026-02-14T13:01:56.1391791Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1392598Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1393147Z                             statements = []
2026-02-14T13:01:56.1393539Z     
2026-02-14T13:01:56.1393994Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1394638Z                             do_blocks = []
2026-02-14T13:01:56.1395112Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1395551Z     
2026-02-14T13:01:56.1395865Z                             def replace_do_block(match):
2026-02-14T13:01:56.1396353Z                                 block = match.group(0)
2026-02-14T13:01:56.1396909Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1397492Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1397983Z                                 return placeholder
2026-02-14T13:01:56.1398395Z     
2026-02-14T13:01:56.1398728Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1399270Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1399812Z                                                     ^^
2026-02-14T13:01:56.1400456Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1401295Z                             )
2026-02-14T13:01:56.1401757Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1402119Z 
2026-02-14T13:01:56.1402294Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1402979Z _____ ERROR at setup of TestCampaignUniqueness.test_campaign_ids_increment _____
2026-02-14T13:01:56.1403532Z 
2026-02-14T13:01:56.1404175Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1404613Z 
2026-02-14T13:01:56.1404770Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1405243Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1405697Z         """
2026-02-14T13:01:56.1406110Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1406620Z     
2026-02-14T13:01:56.1407005Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1407624Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1408114Z         """
2026-02-14T13:01:56.1408436Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1408990Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1409466Z     
2026-02-14T13:01:56.1409805Z         # Parse connection string to get database name
2026-02-14T13:01:56.1410614Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1411491Z     
2026-02-14T13:01:56.1411965Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1412894Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1413602Z     
2026-02-14T13:01:56.1413996Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1414619Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1415099Z         if len(parts) >= 4:
2026-02-14T13:01:56.1415775Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1416295Z         else:
2026-02-14T13:01:56.1416635Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1417079Z     
2026-02-14T13:01:56.1417384Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1418318Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1419027Z         import time
2026-02-14T13:01:56.1419313Z     
2026-02-14T13:01:56.1419582Z         max_retries = 5
2026-02-14T13:01:56.1419906Z         retry_delay = 2
2026-02-14T13:01:56.1420211Z     
2026-02-14T13:01:56.1420499Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1420917Z             try:
2026-02-14T13:01:56.1421475Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1421988Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1422457Z                 conn.autocommit = True
2026-02-14T13:01:56.1422860Z                 try:
2026-02-14T13:01:56.1423186Z                     cur = conn.cursor()
2026-02-14T13:01:56.1423803Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1424804Z                     if not cur.fetchone():
2026-02-14T13:01:56.1425595Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1426369Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1427109Z                     cur.close()
2026-02-14T13:01:56.1427739Z                 finally:
2026-02-14T13:01:56.1428174Z                     conn.close()
2026-02-14T13:01:56.1428854Z                 break  # Success
2026-02-14T13:01:56.1429558Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1430498Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1431367Z                     print(
2026-02-14T13:01:56.1432175Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1433178Z                     )
2026-02-14T13:01:56.1433630Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1434179Z                 else:
2026-02-14T13:01:56.1434964Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1436174Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1437030Z                     pass
2026-02-14T13:01:56.1437563Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1438292Z                 break  # Already exists
2026-02-14T13:01:56.1438819Z     
2026-02-14T13:01:56.1439538Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1440542Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1441826Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1486518Z     
2026-02-14T13:01:56.1486927Z         close_all_pools()
2026-02-14T13:01:56.1487269Z     
2026-02-14T13:01:56.1487604Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1488265Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1488982Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1489536Z             conn.autocommit = True
2026-02-14T13:01:56.1489923Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1490532Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1491351Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1491774Z                 cur.execute(
2026-02-14T13:01:56.1492119Z                     """
2026-02-14T13:01:56.1492441Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1492731Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1493281Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1493580Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1493823Z                     """
2026-02-14T13:01:56.1494003Z                 )
2026-02-14T13:01:56.1494288Z     
2026-02-14T13:01:56.1494570Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1495052Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1495397Z                 try:
2026-02-14T13:01:56.1495627Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1495900Z                     cur.execute("""
2026-02-14T13:01:56.1496114Z                         DO $$
2026-02-14T13:01:56.1496316Z                         DECLARE
2026-02-14T13:01:56.1496525Z                             r RECORD;
2026-02-14T13:01:56.1496743Z                         BEGIN
2026-02-14T13:01:56.1496945Z                             FOR r IN (
2026-02-14T13:01:56.1497202Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1497472Z                                 FROM pg_views
2026-02-14T13:01:56.1497770Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1498072Z                             )
2026-02-14T13:01:56.1498281Z                             LOOP
2026-02-14T13:01:56.1498747Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1499235Z                             END LOOP;
2026-02-14T13:01:56.1499463Z                         END $$;
2026-02-14T13:01:56.1499665Z                     """)
2026-02-14T13:01:56.1499866Z                     # Drop tables
2026-02-14T13:01:56.1500079Z                     cur.execute("""
2026-02-14T13:01:56.1500299Z                         DO $$
2026-02-14T13:01:56.1500492Z                         DECLARE
2026-02-14T13:01:56.1500694Z                             r RECORD;
2026-02-14T13:01:56.1500908Z                         BEGIN
2026-02-14T13:01:56.1501367Z                             FOR r IN (
2026-02-14T13:01:56.1501643Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1501926Z                                 FROM pg_tables
2026-02-14T13:01:56.1502221Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1502511Z                             )
2026-02-14T13:01:56.1502707Z                             LOOP
2026-02-14T13:01:56.1503163Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1503638Z                             END LOOP;
2026-02-14T13:01:56.1503852Z                         END $$;
2026-02-14T13:01:56.1504037Z                     """)
2026-02-14T13:01:56.1504237Z                 except psycopg2.Error:
2026-02-14T13:01:56.1504576Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1504938Z                     pass
2026-02-14T13:01:56.1505114Z     
2026-02-14T13:01:56.1505379Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1505499Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1505588Z                 if init_dir.exists():
2026-02-14T13:01:56.1505701Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1505796Z                     for script_path in scripts:
2026-02-14T13:01:56.1505928Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1506008Z                             sql = f.read()
2026-02-14T13:01:56.1506220Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1506353Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1506584Z                             statements = []
2026-02-14T13:01:56.1506648Z     
2026-02-14T13:01:56.1506831Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1507028Z                             do_blocks = []
2026-02-14T13:01:56.1507133Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1507192Z     
2026-02-14T13:01:56.1507294Z                             def replace_do_block(match):
2026-02-14T13:01:56.1507387Z                                 block = match.group(0)
2026-02-14T13:01:56.1507516Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1507611Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1507704Z                                 return placeholder
2026-02-14T13:01:56.1507761Z     
2026-02-14T13:01:56.1507870Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1507981Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1508065Z                                                     ^^
2026-02-14T13:01:56.1508258Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1508339Z                             )
2026-02-14T13:01:56.1508446Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1508455Z 
2026-02-14T13:01:56.1508560Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1508791Z _ ERROR at setup of TestCampaignUniqueness.test_campaign_id_primary_key_constraint _
2026-02-14T13:01:56.1508796Z 
2026-02-14T13:01:56.1509221Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1509237Z 
2026-02-14T13:01:56.1509335Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1509445Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1509509Z         """
2026-02-14T13:01:56.1509663Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1509724Z     
2026-02-14T13:01:56.1509859Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1509995Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1510060Z         """
2026-02-14T13:01:56.1510156Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1510283Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1510349Z     
2026-02-14T13:01:56.1510460Z         # Parse connection string to get database name
2026-02-14T13:01:56.1510721Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1510784Z     
2026-02-14T13:01:56.1510985Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1511410Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1511479Z     
2026-02-14T13:01:56.1511625Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1511744Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1511832Z         if len(parts) >= 4:
2026-02-14T13:01:56.1511971Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1512035Z         else:
2026-02-14T13:01:56.1512142Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1512213Z     
2026-02-14T13:01:56.1512311Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1512544Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1512622Z         import time
2026-02-14T13:01:56.1512682Z     
2026-02-14T13:01:56.1512757Z         max_retries = 5
2026-02-14T13:01:56.1512826Z         retry_delay = 2
2026-02-14T13:01:56.1512897Z     
2026-02-14T13:01:56.1512988Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1513173Z             try:
2026-02-14T13:01:56.1513288Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1513384Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1513467Z                 conn.autocommit = True
2026-02-14T13:01:56.1513679Z                 try:
2026-02-14T13:01:56.1513766Z                     cur = conn.cursor()
2026-02-14T13:01:56.1513960Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1514043Z                     if not cur.fetchone():
2026-02-14T13:01:56.1514207Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1514327Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1514402Z                     cur.close()
2026-02-14T13:01:56.1514478Z                 finally:
2026-02-14T13:01:56.1514552Z                     conn.close()
2026-02-14T13:01:56.1514625Z                 break  # Success
2026-02-14T13:01:56.1514820Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1514920Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1514992Z                     print(
2026-02-14T13:01:56.1515221Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1515293Z                     )
2026-02-14T13:01:56.1515378Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1515442Z                 else:
2026-02-14T13:01:56.1515654Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1515839Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1515909Z                     pass
2026-02-14T13:01:56.1516028Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1516114Z                 break  # Already exists
2026-02-14T13:01:56.1516174Z     
2026-02-14T13:01:56.1516394Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1516573Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1516707Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1516769Z     
2026-02-14T13:01:56.1516841Z         close_all_pools()
2026-02-14T13:01:56.1516899Z     
2026-02-14T13:01:56.1517020Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1517189Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1517330Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1517411Z             conn.autocommit = True
2026-02-14T13:01:56.1517494Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1517688Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1517786Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1517865Z                 cur.execute(
2026-02-14T13:01:56.1517929Z                     """
2026-02-14T13:01:56.1518025Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1518107Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1518208Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1518297Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1518359Z                     """
2026-02-14T13:01:56.1518424Z                 )
2026-02-14T13:01:56.1518481Z     
2026-02-14T13:01:56.1518669Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1518849Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1518917Z                 try:
2026-02-14T13:01:56.1519034Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1519197Z                     cur.execute("""
2026-02-14T13:01:56.1519274Z                         DO $$
2026-02-14T13:01:56.1519341Z                         DECLARE
2026-02-14T13:01:56.1519413Z                             r RECORD;
2026-02-14T13:01:56.1519558Z                         BEGIN
2026-02-14T13:01:56.1519632Z                             FOR r IN (
2026-02-14T13:01:56.1519734Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1519815Z                                 FROM pg_views
2026-02-14T13:01:56.1519948Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1520012Z                             )
2026-02-14T13:01:56.1520080Z                             LOOP
2026-02-14T13:01:56.1520400Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1520473Z                             END LOOP;
2026-02-14T13:01:56.1520542Z                         END $$;
2026-02-14T13:01:56.1520609Z                     """)
2026-02-14T13:01:56.1520680Z                     # Drop tables
2026-02-14T13:01:56.1520752Z                     cur.execute("""
2026-02-14T13:01:56.1520818Z                         DO $$
2026-02-14T13:01:56.1520889Z                         DECLARE
2026-02-14T13:01:56.1520959Z                             r RECORD;
2026-02-14T13:01:56.1521021Z                         BEGIN
2026-02-14T13:01:56.1521216Z                             FOR r IN (
2026-02-14T13:01:56.1521321Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1521404Z                                 FROM pg_tables
2026-02-14T13:01:56.1521542Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1521608Z                             )
2026-02-14T13:01:56.1521674Z                             LOOP
2026-02-14T13:01:56.1522002Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1522077Z                             END LOOP;
2026-02-14T13:01:56.1522142Z                         END $$;
2026-02-14T13:01:56.1522205Z                     """)
2026-02-14T13:01:56.1522297Z                 except psycopg2.Error:
2026-02-14T13:01:56.1522474Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1522545Z                     pass
2026-02-14T13:01:56.1522608Z     
2026-02-14T13:01:56.1522781Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1522892Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1522968Z                 if init_dir.exists():
2026-02-14T13:01:56.1523079Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1523167Z                     for script_path in scripts:
2026-02-14T13:01:56.1523296Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1523380Z                             sql = f.read()
2026-02-14T13:01:56.1523591Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1523726Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1523810Z                             statements = []
2026-02-14T13:01:56.1523869Z     
2026-02-14T13:01:56.1524045Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1524122Z                             do_blocks = []
2026-02-14T13:01:56.1524232Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1524288Z     
2026-02-14T13:01:56.1524385Z                             def replace_do_block(match):
2026-02-14T13:01:56.1524483Z                                 block = match.group(0)
2026-02-14T13:01:56.1524725Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1524824Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1524918Z                                 return placeholder
2026-02-14T13:01:56.1524976Z     
2026-02-14T13:01:56.1525182Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1525277Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1525361Z                                                     ^^
2026-02-14T13:01:56.1525550Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1525618Z                             )
2026-02-14T13:01:56.1525735Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1525741Z 
2026-02-14T13:01:56.1525842Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1526047Z _ ERROR at setup of TestCampaignDeletion.test_delete_campaign_removes_rankings _
2026-02-14T13:01:56.1526052Z 
2026-02-14T13:01:56.1526357Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1526362Z 
2026-02-14T13:01:56.1526461Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1526572Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1526640Z         """
2026-02-14T13:01:56.1526785Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1526849Z     
2026-02-14T13:01:56.1526984Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1527110Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1527178Z         """
2026-02-14T13:01:56.1527276Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1527403Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1527468Z     
2026-02-14T13:01:56.1527579Z         # Parse connection string to get database name
2026-02-14T13:01:56.1527829Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1527889Z     
2026-02-14T13:01:56.1528082Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1528313Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1528374Z     
2026-02-14T13:01:56.1528530Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1528641Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1528718Z         if len(parts) >= 4:
2026-02-14T13:01:56.1528845Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1528907Z         else:
2026-02-14T13:01:56.1529007Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1529066Z     
2026-02-14T13:01:56.1529170Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1529402Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1529472Z         import time
2026-02-14T13:01:56.1529539Z     
2026-02-14T13:01:56.1529609Z         max_retries = 5
2026-02-14T13:01:56.1529678Z         retry_delay = 2
2026-02-14T13:01:56.1529742Z     
2026-02-14T13:01:56.1529828Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1529891Z             try:
2026-02-14T13:01:56.1529992Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1530092Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1530175Z                 conn.autocommit = True
2026-02-14T13:01:56.1530240Z                 try:
2026-02-14T13:01:56.1530325Z                     cur = conn.cursor()
2026-02-14T13:01:56.1530517Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1530599Z                     if not cur.fetchone():
2026-02-14T13:01:56.1530837Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1530966Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1531189Z                     cur.close()
2026-02-14T13:01:56.1531260Z                 finally:
2026-02-14T13:01:56.1531455Z                     conn.close()
2026-02-14T13:01:56.1531525Z                 break  # Success
2026-02-14T13:01:56.1531719Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1531819Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1531893Z                     print(
2026-02-14T13:01:56.1532120Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1532185Z                     )
2026-02-14T13:01:56.1532275Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1532340Z                 else:
2026-02-14T13:01:56.1532548Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1532743Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1532814Z                     pass
2026-02-14T13:01:56.1532932Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1533019Z                 break  # Already exists
2026-02-14T13:01:56.1533076Z     
2026-02-14T13:01:56.1533293Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1533476Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1533615Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1533674Z     
2026-02-14T13:01:56.1533748Z         close_all_pools()
2026-02-14T13:01:56.1533813Z     
2026-02-14T13:01:56.1533932Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1534100Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1534250Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1534334Z             conn.autocommit = True
2026-02-14T13:01:56.1534414Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1534610Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1534713Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1534785Z                 cur.execute(
2026-02-14T13:01:56.1534851Z                     """
2026-02-14T13:01:56.1534955Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1535036Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1535133Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1535228Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1535293Z                     """
2026-02-14T13:01:56.1535354Z                 )
2026-02-14T13:01:56.1535413Z     
2026-02-14T13:01:56.1535613Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1535798Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1535862Z                 try:
2026-02-14T13:01:56.1535993Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1536071Z                     cur.execute("""
2026-02-14T13:01:56.1536144Z                         DO $$
2026-02-14T13:01:56.1536218Z                         DECLARE
2026-02-14T13:01:56.1536291Z                             r RECORD;
2026-02-14T13:01:56.1536358Z                         BEGIN
2026-02-14T13:01:56.1536431Z                             FOR r IN (
2026-02-14T13:01:56.1536539Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1536630Z                                 FROM pg_views
2026-02-14T13:01:56.1536762Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1536955Z                             )
2026-02-14T13:01:56.1537032Z                             LOOP
2026-02-14T13:01:56.1537356Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1537514Z                             END LOOP;
2026-02-14T13:01:56.1537585Z                         END $$;
2026-02-14T13:01:56.1537652Z                     """)
2026-02-14T13:01:56.1537725Z                     # Drop tables
2026-02-14T13:01:56.1537809Z                     cur.execute("""
2026-02-14T13:01:56.1537876Z                         DO $$
2026-02-14T13:01:56.1537946Z                         DECLARE
2026-02-14T13:01:56.1538022Z                             r RECORD;
2026-02-14T13:01:56.1538087Z                         BEGIN
2026-02-14T13:01:56.1538159Z                             FOR r IN (
2026-02-14T13:01:56.1538262Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1538349Z                                 FROM pg_tables
2026-02-14T13:01:56.1538481Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1538548Z                             )
2026-02-14T13:01:56.1538622Z                             LOOP
2026-02-14T13:01:56.1538946Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1539018Z                             END LOOP;
2026-02-14T13:01:56.1539092Z                         END $$;
2026-02-14T13:01:56.1539157Z                     """)
2026-02-14T13:01:56.1539242Z                 except psycopg2.Error:
2026-02-14T13:01:56.1539418Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1539491Z                     pass
2026-02-14T13:01:56.1539551Z     
2026-02-14T13:01:56.1539721Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1539839Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1539917Z                 if init_dir.exists():
2026-02-14T13:01:56.1540022Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1540117Z                     for script_path in scripts:
2026-02-14T13:01:56.1540247Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1540323Z                             sql = f.read()
2026-02-14T13:01:56.1540532Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1540671Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1540749Z                             statements = []
2026-02-14T13:01:56.1540807Z     
2026-02-14T13:01:56.1540993Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1541289Z                             do_blocks = []
2026-02-14T13:01:56.1541424Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1541489Z     
2026-02-14T13:01:56.1541591Z                             def replace_do_block(match):
2026-02-14T13:01:56.1541682Z                                 block = match.group(0)
2026-02-14T13:01:56.1541820Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1541920Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1542010Z                                 return placeholder
2026-02-14T13:01:56.1542069Z     
2026-02-14T13:01:56.1542197Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1542299Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1542382Z                                                     ^^
2026-02-14T13:01:56.1542575Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1542644Z                             )
2026-02-14T13:01:56.1542907Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1542913Z 
2026-02-14T13:01:56.1543024Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1543236Z _ ERROR at setup of TestCampaignDeletion.test_delete_campaign_removes_fact_jobs _
2026-02-14T13:01:56.1543340Z 
2026-02-14T13:01:56.1543646Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1543652Z 
2026-02-14T13:01:56.1543741Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1543847Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1543915Z         """
2026-02-14T13:01:56.1544051Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1544111Z     
2026-02-14T13:01:56.1544253Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1544379Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1544441Z         """
2026-02-14T13:01:56.1544543Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1544670Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1544729Z     
2026-02-14T13:01:56.1544836Z         # Parse connection string to get database name
2026-02-14T13:01:56.1545092Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1545151Z     
2026-02-14T13:01:56.1545336Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1545569Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1545628Z     
2026-02-14T13:01:56.1545771Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1545886Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1545966Z         if len(parts) >= 4:
2026-02-14T13:01:56.1546089Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1546153Z         else:
2026-02-14T13:01:56.1546260Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1546319Z     
2026-02-14T13:01:56.1546423Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1546660Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1546728Z         import time
2026-02-14T13:01:56.1546788Z     
2026-02-14T13:01:56.1546859Z         max_retries = 5
2026-02-14T13:01:56.1546934Z         retry_delay = 2
2026-02-14T13:01:56.1546993Z     
2026-02-14T13:01:56.1547079Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1547147Z             try:
2026-02-14T13:01:56.1547248Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1547341Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1547429Z                 conn.autocommit = True
2026-02-14T13:01:56.1547493Z                 try:
2026-02-14T13:01:56.1547573Z                     cur = conn.cursor()
2026-02-14T13:01:56.1547759Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1547846Z                     if not cur.fetchone():
2026-02-14T13:01:56.1548002Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1548120Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1548199Z                     cur.close()
2026-02-14T13:01:56.1548267Z                 finally:
2026-02-14T13:01:56.1548341Z                     conn.close()
2026-02-14T13:01:56.1548412Z                 break  # Success
2026-02-14T13:01:56.1548608Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1548699Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1548767Z                     print(
2026-02-14T13:01:56.1549086Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1549156Z                     )
2026-02-14T13:01:56.1549242Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1549312Z                 else:
2026-02-14T13:01:56.1549518Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1549792Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1549868Z                     pass
2026-02-14T13:01:56.1549983Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1550060Z                 break  # Already exists
2026-02-14T13:01:56.1550117Z     
2026-02-14T13:01:56.1550344Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1550526Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1550658Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1550725Z     
2026-02-14T13:01:56.1550798Z         close_all_pools()
2026-02-14T13:01:56.1550856Z     
2026-02-14T13:01:56.1550973Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1551380Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1551531Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1551614Z             conn.autocommit = True
2026-02-14T13:01:56.1551699Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1551890Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1551982Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1552059Z                 cur.execute(
2026-02-14T13:01:56.1552124Z                     """
2026-02-14T13:01:56.1552222Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1552302Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1552407Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1552498Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1552563Z                     """
2026-02-14T13:01:56.1552630Z                 )
2026-02-14T13:01:56.1552692Z     
2026-02-14T13:01:56.1552886Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1553081Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1553145Z                 try:
2026-02-14T13:01:56.1553263Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1553338Z                     cur.execute("""
2026-02-14T13:01:56.1553411Z                         DO $$
2026-02-14T13:01:56.1553479Z                         DECLARE
2026-02-14T13:01:56.1553551Z                             r RECORD;
2026-02-14T13:01:56.1553622Z                         BEGIN
2026-02-14T13:01:56.1553699Z                             FOR r IN (
2026-02-14T13:01:56.1553799Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1553886Z                                 FROM pg_views
2026-02-14T13:01:56.1554016Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1554088Z                             )
2026-02-14T13:01:56.1554159Z                             LOOP
2026-02-14T13:01:56.1554481Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1554555Z                             END LOOP;
2026-02-14T13:01:56.1554623Z                         END $$;
2026-02-14T13:01:56.1554693Z                     """)
2026-02-14T13:01:56.1554765Z                     # Drop tables
2026-02-14T13:01:56.1554839Z                     cur.execute("""
2026-02-14T13:01:56.1554910Z                         DO $$
2026-02-14T13:01:56.1554977Z                         DECLARE
2026-02-14T13:01:56.1555171Z                             r RECORD;
2026-02-14T13:01:56.1555240Z                         BEGIN
2026-02-14T13:01:56.1555322Z                             FOR r IN (
2026-02-14T13:01:56.1555423Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1555612Z                                 FROM pg_tables
2026-02-14T13:01:56.1555745Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1555811Z                             )
2026-02-14T13:01:56.1555881Z                             LOOP
2026-02-14T13:01:56.1556202Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1556276Z                             END LOOP;
2026-02-14T13:01:56.1556345Z                         END $$;
2026-02-14T13:01:56.1556409Z                     """)
2026-02-14T13:01:56.1556499Z                 except psycopg2.Error:
2026-02-14T13:01:56.1556678Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1556748Z                     pass
2026-02-14T13:01:56.1556816Z     
2026-02-14T13:01:56.1556990Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1557103Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1557188Z                 if init_dir.exists():
2026-02-14T13:01:56.1557295Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1557384Z                     for script_path in scripts:
2026-02-14T13:01:56.1557508Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1557590Z                             sql = f.read()
2026-02-14T13:01:56.1557804Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1557934Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1558022Z                             statements = []
2026-02-14T13:01:56.1558081Z     
2026-02-14T13:01:56.1558260Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1558345Z                             do_blocks = []
2026-02-14T13:01:56.1558446Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1558505Z     
2026-02-14T13:01:56.1558610Z                             def replace_do_block(match):
2026-02-14T13:01:56.1558702Z                                 block = match.group(0)
2026-02-14T13:01:56.1558827Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1558924Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1559017Z                                 return placeholder
2026-02-14T13:01:56.1559074Z     
2026-02-14T13:01:56.1559183Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1559289Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1559371Z                                                     ^^
2026-02-14T13:01:56.1559558Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1559635Z                             )
2026-02-14T13:01:56.1559743Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1559749Z 
2026-02-14T13:01:56.1559850Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1560069Z _ ERROR at setup of TestCampaignDeletion.test_delete_campaign_removes_staging_jobs _
2026-02-14T13:01:56.1560081Z 
2026-02-14T13:01:56.1560387Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1560392Z 
2026-02-14T13:01:56.1560495Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1560602Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1560669Z         """
2026-02-14T13:01:56.1560936Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1561001Z     
2026-02-14T13:01:56.1561291Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1561426Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1561688Z         """
2026-02-14T13:01:56.1561787Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1561912Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1561978Z     
2026-02-14T13:01:56.1562084Z         # Parse connection string to get database name
2026-02-14T13:01:56.1562327Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1562393Z     
2026-02-14T13:01:56.1562578Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1562808Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1562881Z     
2026-02-14T13:01:56.1563024Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1563132Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1563209Z         if len(parts) >= 4:
2026-02-14T13:01:56.1563336Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1563398Z         else:
2026-02-14T13:01:56.1563499Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1563562Z     
2026-02-14T13:01:56.1563658Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1563886Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1563961Z         import time
2026-02-14T13:01:56.1564019Z     
2026-02-14T13:01:56.1564088Z         max_retries = 5
2026-02-14T13:01:56.1564159Z         retry_delay = 2
2026-02-14T13:01:56.1564223Z     
2026-02-14T13:01:56.1564310Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1564374Z             try:
2026-02-14T13:01:56.1564478Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1564572Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1564653Z                 conn.autocommit = True
2026-02-14T13:01:56.1564719Z                 try:
2026-02-14T13:01:56.1564801Z                     cur = conn.cursor()
2026-02-14T13:01:56.1564989Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1565069Z                     if not cur.fetchone():
2026-02-14T13:01:56.1565226Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1565343Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1565414Z                     cur.close()
2026-02-14T13:01:56.1565487Z                 finally:
2026-02-14T13:01:56.1565561Z                     conn.close()
2026-02-14T13:01:56.1565636Z                 break  # Success
2026-02-14T13:01:56.1565826Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1565922Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1565993Z                     print(
2026-02-14T13:01:56.1566220Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1566293Z                     )
2026-02-14T13:01:56.1566383Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1566446Z                 else:
2026-02-14T13:01:56.1566654Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1566839Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1566907Z                     pass
2026-02-14T13:01:56.1567021Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1567106Z                 break  # Already exists
2026-02-14T13:01:56.1567294Z     
2026-02-14T13:01:56.1567515Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1567703Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1567914Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1567974Z     
2026-02-14T13:01:56.1568055Z         close_all_pools()
2026-02-14T13:01:56.1568113Z     
2026-02-14T13:01:56.1568231Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1568397Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1568544Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1568625Z             conn.autocommit = True
2026-02-14T13:01:56.1568704Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1568905Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1568998Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1569071Z                 cur.execute(
2026-02-14T13:01:56.1569142Z                     """
2026-02-14T13:01:56.1569242Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1569326Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1569422Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1569520Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1569584Z                     """
2026-02-14T13:01:56.1569645Z                 )
2026-02-14T13:01:56.1569709Z     
2026-02-14T13:01:56.1569898Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1570082Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1570146Z                 try:
2026-02-14T13:01:56.1570271Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1570355Z                     cur.execute("""
2026-02-14T13:01:56.1570425Z                         DO $$
2026-02-14T13:01:56.1570500Z                         DECLARE
2026-02-14T13:01:56.1570573Z                             r RECORD;
2026-02-14T13:01:56.1570644Z                         BEGIN
2026-02-14T13:01:56.1570723Z                             FOR r IN (
2026-02-14T13:01:56.1570823Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1570903Z                                 FROM pg_views
2026-02-14T13:01:56.1571164Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1571240Z                             )
2026-02-14T13:01:56.1571310Z                             LOOP
2026-02-14T13:01:56.1571629Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1571709Z                             END LOOP;
2026-02-14T13:01:56.1571778Z                         END $$;
2026-02-14T13:01:56.1571842Z                     """)
2026-02-14T13:01:56.1571918Z                     # Drop tables
2026-02-14T13:01:56.1571993Z                     cur.execute("""
2026-02-14T13:01:56.1572060Z                         DO $$
2026-02-14T13:01:56.1572128Z                         DECLARE
2026-02-14T13:01:56.1572207Z                             r RECORD;
2026-02-14T13:01:56.1572271Z                         BEGIN
2026-02-14T13:01:56.1572340Z                             FOR r IN (
2026-02-14T13:01:56.1572446Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1572527Z                                 FROM pg_tables
2026-02-14T13:01:56.1572652Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1572721Z                             )
2026-02-14T13:01:56.1572790Z                             LOOP
2026-02-14T13:01:56.1573217Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1573293Z                             END LOOP;
2026-02-14T13:01:56.1573365Z                         END $$;
2026-02-14T13:01:56.1573429Z                     """)
2026-02-14T13:01:56.1573613Z                 except psycopg2.Error:
2026-02-14T13:01:56.1573794Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1573862Z                     pass
2026-02-14T13:01:56.1573920Z     
2026-02-14T13:01:56.1574094Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1574203Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1574281Z                 if init_dir.exists():
2026-02-14T13:01:56.1574385Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1574489Z                     for script_path in scripts:
2026-02-14T13:01:56.1574624Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1574702Z                             sql = f.read()
2026-02-14T13:01:56.1574907Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1575053Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1575131Z                             statements = []
2026-02-14T13:01:56.1575191Z     
2026-02-14T13:01:56.1575370Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1575446Z                             do_blocks = []
2026-02-14T13:01:56.1575549Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1575612Z     
2026-02-14T13:01:56.1575710Z                             def replace_do_block(match):
2026-02-14T13:01:56.1575800Z                                 block = match.group(0)
2026-02-14T13:01:56.1575928Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1576031Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1576119Z                                 return placeholder
2026-02-14T13:01:56.1576179Z     
2026-02-14T13:01:56.1576295Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1576393Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1576475Z                                                     ^^
2026-02-14T13:01:56.1576711Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1576779Z                             )
2026-02-14T13:01:56.1576887Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1576892Z 
2026-02-14T13:01:56.1576992Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1577212Z _ ERROR at setup of TestCampaignDeletion.test_delete_campaign_removes_etl_metrics _
2026-02-14T13:01:56.1577216Z 
2026-02-14T13:01:56.1577508Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1577513Z 
2026-02-14T13:01:56.1577601Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1577709Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1577779Z         """
2026-02-14T13:01:56.1577914Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1577972Z     
2026-02-14T13:01:56.1578106Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1578230Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1578290Z         """
2026-02-14T13:01:56.1578383Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1578511Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1578571Z     
2026-02-14T13:01:56.1578674Z         # Parse connection string to get database name
2026-02-14T13:01:56.1579012Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1579073Z     
2026-02-14T13:01:56.1579259Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1579494Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1579638Z     
2026-02-14T13:01:56.1579781Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1579889Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1579972Z         if len(parts) >= 4:
2026-02-14T13:01:56.1580090Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1580152Z         else:
2026-02-14T13:01:56.1580259Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1580317Z     
2026-02-14T13:01:56.1580412Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1580649Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1580716Z         import time
2026-02-14T13:01:56.1580774Z     
2026-02-14T13:01:56.1580845Z         max_retries = 5
2026-02-14T13:01:56.1580917Z         retry_delay = 2
2026-02-14T13:01:56.1580977Z     
2026-02-14T13:01:56.1581343Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1581419Z             try:
2026-02-14T13:01:56.1581522Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1581618Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1581699Z                 conn.autocommit = True
2026-02-14T13:01:56.1581770Z                 try:
2026-02-14T13:01:56.1581850Z                     cur = conn.cursor()
2026-02-14T13:01:56.1582035Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1582123Z                     if not cur.fetchone():
2026-02-14T13:01:56.1582278Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1582397Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1582474Z                     cur.close()
2026-02-14T13:01:56.1582541Z                 finally:
2026-02-14T13:01:56.1582617Z                     conn.close()
2026-02-14T13:01:56.1582687Z                 break  # Success
2026-02-14T13:01:56.1582886Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1582977Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1583048Z                     print(
2026-02-14T13:01:56.1583271Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1583335Z                     )
2026-02-14T13:01:56.1583418Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1583491Z                 else:
2026-02-14T13:01:56.1583694Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1583881Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1583949Z                     pass
2026-02-14T13:01:56.1584068Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1584148Z                 break  # Already exists
2026-02-14T13:01:56.1584207Z     
2026-02-14T13:01:56.1584424Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1584607Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1584741Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1584803Z     
2026-02-14T13:01:56.1584878Z         close_all_pools()
2026-02-14T13:01:56.1584936Z     
2026-02-14T13:01:56.1585054Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1585226Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1585497Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1585583Z             conn.autocommit = True
2026-02-14T13:01:56.1585670Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1585863Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1586055Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1586133Z                 cur.execute(
2026-02-14T13:01:56.1586199Z                     """
2026-02-14T13:01:56.1586298Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1586379Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1586481Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1586570Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1586636Z                     """
2026-02-14T13:01:56.1586712Z                 )
2026-02-14T13:01:56.1586774Z     
2026-02-14T13:01:56.1586965Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1587149Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1587222Z                 try:
2026-02-14T13:01:56.1587345Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1587423Z                     cur.execute("""
2026-02-14T13:01:56.1587498Z                         DO $$
2026-02-14T13:01:56.1587565Z                         DECLARE
2026-02-14T13:01:56.1587638Z                             r RECORD;
2026-02-14T13:01:56.1587710Z                         BEGIN
2026-02-14T13:01:56.1587782Z                             FOR r IN (
2026-02-14T13:01:56.1587880Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1587962Z                                 FROM pg_views
2026-02-14T13:01:56.1588095Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1588162Z                             )
2026-02-14T13:01:56.1588231Z                             LOOP
2026-02-14T13:01:56.1588549Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1588626Z                             END LOOP;
2026-02-14T13:01:56.1588693Z                         END $$;
2026-02-14T13:01:56.1588761Z                     """)
2026-02-14T13:01:56.1588832Z                     # Drop tables
2026-02-14T13:01:56.1588905Z                     cur.execute("""
2026-02-14T13:01:56.1588970Z                         DO $$
2026-02-14T13:01:56.1589040Z                         DECLARE
2026-02-14T13:01:56.1589109Z                             r RECORD;
2026-02-14T13:01:56.1589174Z                         BEGIN
2026-02-14T13:01:56.1589249Z                             FOR r IN (
2026-02-14T13:01:56.1589348Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1589434Z                                 FROM pg_tables
2026-02-14T13:01:56.1589563Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1589628Z                             )
2026-02-14T13:01:56.1589696Z                             LOOP
2026-02-14T13:01:56.1590015Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1590093Z                             END LOOP;
2026-02-14T13:01:56.1590159Z                         END $$;
2026-02-14T13:01:56.1590224Z                     """)
2026-02-14T13:01:56.1590312Z                 except psycopg2.Error:
2026-02-14T13:01:56.1590486Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1590553Z                     pass
2026-02-14T13:01:56.1590617Z     
2026-02-14T13:01:56.1590785Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1590977Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1591174Z                 if init_dir.exists():
2026-02-14T13:01:56.1591290Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1591379Z                     for script_path in scripts:
2026-02-14T13:01:56.1591618Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1591703Z                             sql = f.read()
2026-02-14T13:01:56.1591908Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1592040Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1592123Z                             statements = []
2026-02-14T13:01:56.1592181Z     
2026-02-14T13:01:56.1592361Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1592439Z                             do_blocks = []
2026-02-14T13:01:56.1592548Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1592607Z     
2026-02-14T13:01:56.1592703Z                             def replace_do_block(match):
2026-02-14T13:01:56.1592798Z                                 block = match.group(0)
2026-02-14T13:01:56.1592927Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1593026Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1593122Z                                 return placeholder
2026-02-14T13:01:56.1593180Z     
2026-02-14T13:01:56.1593289Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1593387Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1593474Z                                                     ^^
2026-02-14T13:01:56.1593660Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1593731Z                             )
2026-02-14T13:01:56.1593848Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1593854Z 
2026-02-14T13:01:56.1593956Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1594179Z _ ERROR at setup of TestCampaignDeletion.test_delete_campaign_comprehensive_cleanup _
2026-02-14T13:01:56.1594188Z 
2026-02-14T13:01:56.1594497Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1594502Z 
2026-02-14T13:01:56.1594597Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1594702Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1594764Z         """
2026-02-14T13:01:56.1594908Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1594967Z     
2026-02-14T13:01:56.1595098Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1595225Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1595291Z         """
2026-02-14T13:01:56.1595388Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1595511Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1595579Z     
2026-02-14T13:01:56.1595687Z         # Parse connection string to get database name
2026-02-14T13:01:56.1595935Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1595994Z     
2026-02-14T13:01:56.1596183Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1596409Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1596469Z     
2026-02-14T13:01:56.1596622Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1596730Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1596806Z         if len(parts) >= 4:
2026-02-14T13:01:56.1597057Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1597124Z         else:
2026-02-14T13:01:56.1597226Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1597284Z     
2026-02-14T13:01:56.1597385Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1597691Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1597759Z         import time
2026-02-14T13:01:56.1597827Z     
2026-02-14T13:01:56.1597896Z         max_retries = 5
2026-02-14T13:01:56.1597964Z         retry_delay = 2
2026-02-14T13:01:56.1598027Z     
2026-02-14T13:01:56.1598113Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1598174Z             try:
2026-02-14T13:01:56.1598272Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1598371Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1598451Z                 conn.autocommit = True
2026-02-14T13:01:56.1598514Z                 try:
2026-02-14T13:01:56.1598599Z                     cur = conn.cursor()
2026-02-14T13:01:56.1598785Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1598864Z                     if not cur.fetchone():
2026-02-14T13:01:56.1599020Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1599143Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1599214Z                     cur.close()
2026-02-14T13:01:56.1599280Z                 finally:
2026-02-14T13:01:56.1599358Z                     conn.close()
2026-02-14T13:01:56.1599429Z                 break  # Success
2026-02-14T13:01:56.1599618Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1599712Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1599781Z                     print(
2026-02-14T13:01:56.1600006Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1600070Z                     )
2026-02-14T13:01:56.1600157Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1600223Z                 else:
2026-02-14T13:01:56.1600428Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1600618Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1600686Z                     pass
2026-02-14T13:01:56.1600800Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1600885Z                 break  # Already exists
2026-02-14T13:01:56.1600943Z     
2026-02-14T13:01:56.1601308Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1601495Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1601633Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1601696Z     
2026-02-14T13:01:56.1601770Z         close_all_pools()
2026-02-14T13:01:56.1601834Z     
2026-02-14T13:01:56.1601951Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1602115Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1602266Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1602345Z             conn.autocommit = True
2026-02-14T13:01:56.1602424Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1602617Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1602717Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1602789Z                 cur.execute(
2026-02-14T13:01:56.1602855Z                     """
2026-02-14T13:01:56.1602959Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1603040Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1603253Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1603352Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1603417Z                     """
2026-02-14T13:01:56.1603478Z                 )
2026-02-14T13:01:56.1603636Z     
2026-02-14T13:01:56.1603830Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1604014Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1604079Z                 try:
2026-02-14T13:01:56.1604201Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1604275Z                     cur.execute("""
2026-02-14T13:01:56.1604345Z                         DO $$
2026-02-14T13:01:56.1604420Z                         DECLARE
2026-02-14T13:01:56.1604493Z                             r RECORD;
2026-02-14T13:01:56.1604560Z                         BEGIN
2026-02-14T13:01:56.1604636Z                             FOR r IN (
2026-02-14T13:01:56.1604746Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1604829Z                                 FROM pg_views
2026-02-14T13:01:56.1604955Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1605031Z                             )
2026-02-14T13:01:56.1605100Z                             LOOP
2026-02-14T13:01:56.1605413Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1605493Z                             END LOOP;
2026-02-14T13:01:56.1605561Z                         END $$;
2026-02-14T13:01:56.1605626Z                     """)
2026-02-14T13:01:56.1605700Z                     # Drop tables
2026-02-14T13:01:56.1605779Z                     cur.execute("""
2026-02-14T13:01:56.1605850Z                         DO $$
2026-02-14T13:01:56.1605916Z                         DECLARE
2026-02-14T13:01:56.1605995Z                             r RECORD;
2026-02-14T13:01:56.1606060Z                         BEGIN
2026-02-14T13:01:56.1606133Z                             FOR r IN (
2026-02-14T13:01:56.1606233Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1606327Z                                 FROM pg_tables
2026-02-14T13:01:56.1606452Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1606518Z                             )
2026-02-14T13:01:56.1606594Z                             LOOP
2026-02-14T13:01:56.1606909Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1606981Z                             END LOOP;
2026-02-14T13:01:56.1607053Z                         END $$;
2026-02-14T13:01:56.1607118Z                     """)
2026-02-14T13:01:56.1607202Z                 except psycopg2.Error:
2026-02-14T13:01:56.1607377Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1607451Z                     pass
2026-02-14T13:01:56.1607508Z     
2026-02-14T13:01:56.1607677Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1607793Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1607868Z                 if init_dir.exists():
2026-02-14T13:01:56.1607974Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1608068Z                     for script_path in scripts:
2026-02-14T13:01:56.1608194Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1608269Z                             sql = f.read()
2026-02-14T13:01:56.1608478Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1608731Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1608814Z                             statements = []
2026-02-14T13:01:56.1608872Z     
2026-02-14T13:01:56.1609060Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1609215Z                             do_blocks = []
2026-02-14T13:01:56.1609317Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1609379Z     
2026-02-14T13:01:56.1609476Z                             def replace_do_block(match):
2026-02-14T13:01:56.1609565Z                                 block = match.group(0)
2026-02-14T13:01:56.1609696Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1609792Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1609877Z                                 return placeholder
2026-02-14T13:01:56.1609935Z     
2026-02-14T13:01:56.1610050Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1610150Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1610230Z                                                     ^^
2026-02-14T13:01:56.1610417Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1610487Z                             )
2026-02-14T13:01:56.1610594Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1610600Z 
2026-02-14T13:01:56.1610706Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1610919Z _ ERROR at setup of TestCampaignDeletion.test_new_campaign_does_not_show_old_jobs _
2026-02-14T13:01:56.1610924Z 
2026-02-14T13:01:56.1611328Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1611334Z 
2026-02-14T13:01:56.1611421Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1611525Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1611593Z         """
2026-02-14T13:01:56.1611730Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1611788Z     
2026-02-14T13:01:56.1611925Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1612050Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1612113Z         """
2026-02-14T13:01:56.1612215Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1612339Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1612399Z     
2026-02-14T13:01:56.1612505Z         # Parse connection string to get database name
2026-02-14T13:01:56.1612753Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1612812Z     
2026-02-14T13:01:56.1612997Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1613231Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1613293Z     
2026-02-14T13:01:56.1613436Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1613550Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1613625Z         if len(parts) >= 4:
2026-02-14T13:01:56.1613745Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1613806Z         else:
2026-02-14T13:01:56.1613912Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1613970Z     
2026-02-14T13:01:56.1614065Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1614298Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1614366Z         import time
2026-02-14T13:01:56.1614425Z     
2026-02-14T13:01:56.1614495Z         max_retries = 5
2026-02-14T13:01:56.1614573Z         retry_delay = 2
2026-02-14T13:01:56.1614632Z     
2026-02-14T13:01:56.1614718Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1614924Z             try:
2026-02-14T13:01:56.1615034Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1615130Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1615214Z                 conn.autocommit = True
2026-02-14T13:01:56.1615378Z                 try:
2026-02-14T13:01:56.1615463Z                     cur = conn.cursor()
2026-02-14T13:01:56.1615648Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1615735Z                     if not cur.fetchone():
2026-02-14T13:01:56.1615889Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1616005Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1616083Z                     cur.close()
2026-02-14T13:01:56.1616149Z                 finally:
2026-02-14T13:01:56.1616221Z                     conn.close()
2026-02-14T13:01:56.1616301Z                 break  # Success
2026-02-14T13:01:56.1616498Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1616587Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1616656Z                     print(
2026-02-14T13:01:56.1616887Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1616953Z                     )
2026-02-14T13:01:56.1617040Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1617112Z                 else:
2026-02-14T13:01:56.1617317Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1617500Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1617574Z                     pass
2026-02-14T13:01:56.1617687Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1617766Z                 break  # Already exists
2026-02-14T13:01:56.1617827Z     
2026-02-14T13:01:56.1618050Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1618235Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1618371Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1618435Z     
2026-02-14T13:01:56.1618508Z         close_all_pools()
2026-02-14T13:01:56.1618565Z     
2026-02-14T13:01:56.1618687Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1618848Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1618988Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1619067Z             conn.autocommit = True
2026-02-14T13:01:56.1619152Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1619344Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1619440Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1619519Z                 cur.execute(
2026-02-14T13:01:56.1619583Z                     """
2026-02-14T13:01:56.1619680Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1619767Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1619861Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1619950Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1620015Z                     """
2026-02-14T13:01:56.1620080Z                 )
2026-02-14T13:01:56.1620138Z     
2026-02-14T13:01:56.1620328Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1620516Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1620579Z                 try:
2026-02-14T13:01:56.1620695Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1620858Z                     cur.execute("""
2026-02-14T13:01:56.1620930Z                         DO $$
2026-02-14T13:01:56.1620997Z                         DECLARE
2026-02-14T13:01:56.1621313Z                             r RECORD;
2026-02-14T13:01:56.1621537Z                         BEGIN
2026-02-14T13:01:56.1621616Z                             FOR r IN (
2026-02-14T13:01:56.1621727Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1621818Z                                 FROM pg_views
2026-02-14T13:01:56.1621952Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1622021Z                             )
2026-02-14T13:01:56.1622093Z                             LOOP
2026-02-14T13:01:56.1622424Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1622501Z                             END LOOP;
2026-02-14T13:01:56.1622575Z                         END $$;
2026-02-14T13:01:56.1622646Z                     """)
2026-02-14T13:01:56.1622720Z                     # Drop tables
2026-02-14T13:01:56.1622795Z                     cur.execute("""
2026-02-14T13:01:56.1622870Z                         DO $$
2026-02-14T13:01:56.1622940Z                         DECLARE
2026-02-14T13:01:56.1623010Z                             r RECORD;
2026-02-14T13:01:56.1623076Z                         BEGIN
2026-02-14T13:01:56.1623154Z                             FOR r IN (
2026-02-14T13:01:56.1623259Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1623345Z                                 FROM pg_tables
2026-02-14T13:01:56.1623481Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1623548Z                             )
2026-02-14T13:01:56.1623618Z                             LOOP
2026-02-14T13:01:56.1623947Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1624018Z                             END LOOP;
2026-02-14T13:01:56.1624087Z                         END $$;
2026-02-14T13:01:56.1624153Z                     """)
2026-02-14T13:01:56.1624247Z                 except psycopg2.Error:
2026-02-14T13:01:56.1624427Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1624499Z                     pass
2026-02-14T13:01:56.1624562Z     
2026-02-14T13:01:56.1624739Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1624853Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1624936Z                 if init_dir.exists():
2026-02-14T13:01:56.1625044Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1625137Z                     for script_path in scripts:
2026-02-14T13:01:56.1625265Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1625348Z                             sql = f.read()
2026-02-14T13:01:56.1625560Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1625696Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1625782Z                             statements = []
2026-02-14T13:01:56.1625841Z     
2026-02-14T13:01:56.1626023Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1626105Z                             do_blocks = []
2026-02-14T13:01:56.1626209Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1626268Z     
2026-02-14T13:01:56.1626366Z                             def replace_do_block(match):
2026-02-14T13:01:56.1626465Z                                 block = match.group(0)
2026-02-14T13:01:56.1626723Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1626826Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1626923Z                                 return placeholder
2026-02-14T13:01:56.1626982Z     
2026-02-14T13:01:56.1627169Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1627279Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1627366Z                                                     ^^
2026-02-14T13:01:56.1627557Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1627626Z                             )
2026-02-14T13:01:56.1627743Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1627748Z 
2026-02-14T13:01:56.1627848Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1628080Z _ ERROR at setup of TestCampaignDeletion.test_job_queries_only_show_existing_campaigns _
2026-02-14T13:01:56.1628093Z 
2026-02-14T13:01:56.1628383Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1628388Z 
2026-02-14T13:01:56.1628486Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1628594Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1628662Z         """
2026-02-14T13:01:56.1628803Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1628862Z     
2026-02-14T13:01:56.1628996Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1629127Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1629189Z         """
2026-02-14T13:01:56.1629284Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1629409Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1629472Z     
2026-02-14T13:01:56.1629578Z         # Parse connection string to get database name
2026-02-14T13:01:56.1629825Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1629888Z     
2026-02-14T13:01:56.1630073Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1630304Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1630370Z     
2026-02-14T13:01:56.1630517Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1630630Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1630704Z         if len(parts) >= 4:
2026-02-14T13:01:56.1630829Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1630892Z         else:
2026-02-14T13:01:56.1630992Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1631285Z     
2026-02-14T13:01:56.1631402Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1631637Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1631705Z         import time
2026-02-14T13:01:56.1631777Z     
2026-02-14T13:01:56.1631846Z         max_retries = 5
2026-02-14T13:01:56.1631913Z         retry_delay = 2
2026-02-14T13:01:56.1631979Z     
2026-02-14T13:01:56.1632066Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1632127Z             try:
2026-02-14T13:01:56.1632228Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1632328Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1632409Z                 conn.autocommit = True
2026-02-14T13:01:56.1632473Z                 try:
2026-02-14T13:01:56.1632556Z                     cur = conn.cursor()
2026-02-14T13:01:56.1632743Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1632833Z                     if not cur.fetchone():
2026-02-14T13:01:56.1633124Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1633250Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1633322Z                     cur.close()
2026-02-14T13:01:56.1633389Z                 finally:
2026-02-14T13:01:56.1633573Z                     conn.close()
2026-02-14T13:01:56.1633645Z                 break  # Success
2026-02-14T13:01:56.1633839Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1633939Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1634009Z                     print(
2026-02-14T13:01:56.1634236Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1634306Z                     )
2026-02-14T13:01:56.1634390Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1634454Z                 else:
2026-02-14T13:01:56.1634665Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1634860Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1634929Z                     pass
2026-02-14T13:01:56.1635045Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1635134Z                 break  # Already exists
2026-02-14T13:01:56.1635192Z     
2026-02-14T13:01:56.1635407Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1635597Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1635733Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1635791Z     
2026-02-14T13:01:56.1635863Z         close_all_pools()
2026-02-14T13:01:56.1635928Z     
2026-02-14T13:01:56.1636045Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1636211Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1636361Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1636444Z             conn.autocommit = True
2026-02-14T13:01:56.1636524Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1636726Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1636822Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1636895Z                 cur.execute(
2026-02-14T13:01:56.1636960Z                     """
2026-02-14T13:01:56.1637065Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1637146Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1637240Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1637338Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1637404Z                     """
2026-02-14T13:01:56.1637466Z                 )
2026-02-14T13:01:56.1637530Z     
2026-02-14T13:01:56.1637723Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1637908Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1637973Z                 try:
2026-02-14T13:01:56.1638103Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1638185Z                     cur.execute("""
2026-02-14T13:01:56.1638257Z                         DO $$
2026-02-14T13:01:56.1638335Z                         DECLARE
2026-02-14T13:01:56.1638411Z                             r RECORD;
2026-02-14T13:01:56.1638479Z                         BEGIN
2026-02-14T13:01:56.1638558Z                             FOR r IN (
2026-02-14T13:01:56.1638657Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1638738Z                                 FROM pg_views
2026-02-14T13:01:56.1638864Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1639019Z                             )
2026-02-14T13:01:56.1639091Z                             LOOP
2026-02-14T13:01:56.1639405Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1639559Z                             END LOOP;
2026-02-14T13:01:56.1639626Z                         END $$;
2026-02-14T13:01:56.1639691Z                     """)
2026-02-14T13:01:56.1639773Z                     # Drop tables
2026-02-14T13:01:56.1639846Z                     cur.execute("""
2026-02-14T13:01:56.1639912Z                         DO $$
2026-02-14T13:01:56.1639978Z                         DECLARE
2026-02-14T13:01:56.1640052Z                             r RECORD;
2026-02-14T13:01:56.1640116Z                         BEGIN
2026-02-14T13:01:56.1640187Z                             FOR r IN (
2026-02-14T13:01:56.1640290Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1640376Z                                 FROM pg_tables
2026-02-14T13:01:56.1640502Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1640566Z                             )
2026-02-14T13:01:56.1640640Z                             LOOP
2026-02-14T13:01:56.1640958Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1641146Z                             END LOOP;
2026-02-14T13:01:56.1641223Z                         END $$;
2026-02-14T13:01:56.1641289Z                     """)
2026-02-14T13:01:56.1641372Z                 except psycopg2.Error:
2026-02-14T13:01:56.1641553Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1641620Z                     pass
2026-02-14T13:01:56.1641677Z     
2026-02-14T13:01:56.1641846Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1641964Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1642040Z                 if init_dir.exists():
2026-02-14T13:01:56.1642146Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1642241Z                     for script_path in scripts:
2026-02-14T13:01:56.1642369Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1642446Z                             sql = f.read()
2026-02-14T13:01:56.1642657Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1642788Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1642869Z                             statements = []
2026-02-14T13:01:56.1642935Z     
2026-02-14T13:01:56.1643113Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1643190Z                             do_blocks = []
2026-02-14T13:01:56.1643294Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1643358Z     
2026-02-14T13:01:56.1643456Z                             def replace_do_block(match):
2026-02-14T13:01:56.1643548Z                                 block = match.group(0)
2026-02-14T13:01:56.1643684Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1643779Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1643869Z                                 return placeholder
2026-02-14T13:01:56.1643933Z     
2026-02-14T13:01:56.1644045Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1644141Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1644223Z                                                     ^^
2026-02-14T13:01:56.1644415Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1644596Z                             )
2026-02-14T13:01:56.1644711Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1644716Z 
2026-02-14T13:01:56.1644823Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1645071Z _ ERROR at setup of TestCompanyEnrichmentFlow.test_companies_identified_from_staging_jobs _
2026-02-14T13:01:56.1645176Z 
2026-02-14T13:01:56.1645479Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1645484Z 
2026-02-14T13:01:56.1645575Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1645687Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1645749Z         """
2026-02-14T13:01:56.1645883Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1645942Z     
2026-02-14T13:01:56.1646080Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1646203Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1646265Z         """
2026-02-14T13:01:56.1646373Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1646507Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1646565Z     
2026-02-14T13:01:56.1646676Z         # Parse connection string to get database name
2026-02-14T13:01:56.1646924Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1646982Z     
2026-02-14T13:01:56.1647169Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1647407Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1647466Z     
2026-02-14T13:01:56.1647611Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1647729Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1647805Z         if len(parts) >= 4:
2026-02-14T13:01:56.1647928Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1647996Z         else:
2026-02-14T13:01:56.1648098Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1648158Z     
2026-02-14T13:01:56.1648253Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1648493Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1648560Z         import time
2026-02-14T13:01:56.1648619Z     
2026-02-14T13:01:56.1648695Z         max_retries = 5
2026-02-14T13:01:56.1648763Z         retry_delay = 2
2026-02-14T13:01:56.1648823Z     
2026-02-14T13:01:56.1648910Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1648979Z             try:
2026-02-14T13:01:56.1649081Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1649177Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1649267Z                 conn.autocommit = True
2026-02-14T13:01:56.1649330Z                 try:
2026-02-14T13:01:56.1649412Z                     cur = conn.cursor()
2026-02-14T13:01:56.1649605Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1649684Z                     if not cur.fetchone():
2026-02-14T13:01:56.1649840Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1649957Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1650034Z                     cur.close()
2026-02-14T13:01:56.1650101Z                 finally:
2026-02-14T13:01:56.1650173Z                     conn.close()
2026-02-14T13:01:56.1650249Z                 break  # Success
2026-02-14T13:01:56.1650436Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1650526Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1650602Z                     print(
2026-02-14T13:01:56.1650903Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1650972Z                     )
2026-02-14T13:01:56.1651258Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1651357Z                 else:
2026-02-14T13:01:56.1651701Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1651885Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1651961Z                     pass
2026-02-14T13:01:56.1652079Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1652160Z                 break  # Already exists
2026-02-14T13:01:56.1652224Z     
2026-02-14T13:01:56.1652441Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1652626Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1652767Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1652834Z     
2026-02-14T13:01:56.1652909Z         close_all_pools()
2026-02-14T13:01:56.1652969Z     
2026-02-14T13:01:56.1653095Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1653269Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1653414Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1653501Z             conn.autocommit = True
2026-02-14T13:01:56.1653583Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1653776Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1653869Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1653948Z                 cur.execute(
2026-02-14T13:01:56.1654015Z                     """
2026-02-14T13:01:56.1654114Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1654203Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1654299Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1654391Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1654458Z                     """
2026-02-14T13:01:56.1654529Z                 )
2026-02-14T13:01:56.1654589Z     
2026-02-14T13:01:56.1654780Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1654971Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1655036Z                 try:
2026-02-14T13:01:56.1655157Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1655239Z                     cur.execute("""
2026-02-14T13:01:56.1655309Z                         DO $$
2026-02-14T13:01:56.1655377Z                         DECLARE
2026-02-14T13:01:56.1655451Z                             r RECORD;
2026-02-14T13:01:56.1655525Z                         BEGIN
2026-02-14T13:01:56.1655601Z                             FOR r IN (
2026-02-14T13:01:56.1655702Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1655788Z                                 FROM pg_views
2026-02-14T13:01:56.1655917Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1655986Z                             )
2026-02-14T13:01:56.1656062Z                             LOOP
2026-02-14T13:01:56.1656377Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1656450Z                             END LOOP;
2026-02-14T13:01:56.1656518Z                         END $$;
2026-02-14T13:01:56.1656588Z                     """)
2026-02-14T13:01:56.1656661Z                     # Drop tables
2026-02-14T13:01:56.1656735Z                     cur.execute("""
2026-02-14T13:01:56.1656807Z                         DO $$
2026-02-14T13:01:56.1657031Z                         DECLARE
2026-02-14T13:01:56.1657105Z                             r RECORD;
2026-02-14T13:01:56.1657177Z                         BEGIN
2026-02-14T13:01:56.1657249Z                             FOR r IN (
2026-02-14T13:01:56.1657350Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1657510Z                                 FROM pg_tables
2026-02-14T13:01:56.1657642Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1657710Z                             )
2026-02-14T13:01:56.1657779Z                             LOOP
2026-02-14T13:01:56.1658108Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1675462Z                             END LOOP;
2026-02-14T13:01:56.1675588Z                         END $$;
2026-02-14T13:01:56.1675662Z                     """)
2026-02-14T13:01:56.1675763Z                 except psycopg2.Error:
2026-02-14T13:01:56.1675979Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1676052Z                     pass
2026-02-14T13:01:56.1676116Z     
2026-02-14T13:01:56.1676303Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1676423Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1676510Z                 if init_dir.exists():
2026-02-14T13:01:56.1676660Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1676753Z                     for script_path in scripts:
2026-02-14T13:01:56.1676880Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1676962Z                             sql = f.read()
2026-02-14T13:01:56.1677176Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1677312Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1677398Z                             statements = []
2026-02-14T13:01:56.1677457Z     
2026-02-14T13:01:56.1677644Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1677730Z                             do_blocks = []
2026-02-14T13:01:56.1677835Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1677894Z     
2026-02-14T13:01:56.1677995Z                             def replace_do_block(match):
2026-02-14T13:01:56.1678099Z                                 block = match.group(0)
2026-02-14T13:01:56.1678235Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1678334Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1678429Z                                 return placeholder
2026-02-14T13:01:56.1678488Z     
2026-02-14T13:01:56.1678606Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1678713Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1678797Z                                                     ^^
2026-02-14T13:01:56.1678996Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1679078Z                             )
2026-02-14T13:01:56.1679188Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1679195Z 
2026-02-14T13:01:56.1679301Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1679522Z _ ERROR at setup of TestCompanyEnrichmentFlow.test_company_extracted_to_raw_layer _
2026-02-14T13:01:56.1679533Z 
2026-02-14T13:01:56.1679867Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1679873Z 
2026-02-14T13:01:56.1679977Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1680086Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1680150Z         """
2026-02-14T13:01:56.1680475Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1680540Z     
2026-02-14T13:01:56.1680679Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1680816Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1680985Z         """
2026-02-14T13:01:56.1681211Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1681341Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1681410Z     
2026-02-14T13:01:56.1681519Z         # Parse connection string to get database name
2026-02-14T13:01:56.1681768Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1681833Z     
2026-02-14T13:01:56.1682021Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1682259Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1682324Z     
2026-02-14T13:01:56.1682476Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1682592Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1682674Z         if len(parts) >= 4:
2026-02-14T13:01:56.1682806Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1682870Z         else:
2026-02-14T13:01:56.1682979Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1683047Z     
2026-02-14T13:01:56.1683147Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1683384Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1683453Z         import time
2026-02-14T13:01:56.1683517Z     
2026-02-14T13:01:56.1683592Z         max_retries = 5
2026-02-14T13:01:56.1683661Z         retry_delay = 2
2026-02-14T13:01:56.1683725Z     
2026-02-14T13:01:56.1683817Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1683879Z             try:
2026-02-14T13:01:56.1683983Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1684085Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1684171Z                 conn.autocommit = True
2026-02-14T13:01:56.1684237Z                 try:
2026-02-14T13:01:56.1684323Z                     cur = conn.cursor()
2026-02-14T13:01:56.1684517Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1684600Z                     if not cur.fetchone():
2026-02-14T13:01:56.1684753Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1684872Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1684942Z                     cur.close()
2026-02-14T13:01:56.1685007Z                 finally:
2026-02-14T13:01:56.1685088Z                     conn.close()
2026-02-14T13:01:56.1685160Z                 break  # Success
2026-02-14T13:01:56.1685350Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1685442Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1685513Z                     print(
2026-02-14T13:01:56.1685737Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1685805Z                     )
2026-02-14T13:01:56.1685889Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1685950Z                 else:
2026-02-14T13:01:56.1686157Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1686345Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1686412Z                     pass
2026-02-14T13:01:56.1686526Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1686738Z                 break  # Already exists
2026-02-14T13:01:56.1686797Z     
2026-02-14T13:01:56.1687017Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1687207Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1687444Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1687504Z     
2026-02-14T13:01:56.1687579Z         close_all_pools()
2026-02-14T13:01:56.1687646Z     
2026-02-14T13:01:56.1687766Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1687934Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1688083Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1688163Z             conn.autocommit = True
2026-02-14T13:01:56.1688244Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1688447Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1688540Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1688621Z                 cur.execute(
2026-02-14T13:01:56.1688687Z                     """
2026-02-14T13:01:56.1688792Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1688876Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1688972Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1689070Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1689139Z                     """
2026-02-14T13:01:56.1689200Z                 )
2026-02-14T13:01:56.1689264Z     
2026-02-14T13:01:56.1689454Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1689637Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1689703Z                 try:
2026-02-14T13:01:56.1689835Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1689911Z                     cur.execute("""
2026-02-14T13:01:56.1689985Z                         DO $$
2026-02-14T13:01:56.1690062Z                         DECLARE
2026-02-14T13:01:56.1690137Z                             r RECORD;
2026-02-14T13:01:56.1690208Z                         BEGIN
2026-02-14T13:01:56.1690282Z                             FOR r IN (
2026-02-14T13:01:56.1690394Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1690479Z                                 FROM pg_views
2026-02-14T13:01:56.1690608Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1690682Z                             )
2026-02-14T13:01:56.1690754Z                             LOOP
2026-02-14T13:01:56.1691283Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1691407Z                             END LOOP;
2026-02-14T13:01:56.1691480Z                         END $$;
2026-02-14T13:01:56.1691547Z                     """)
2026-02-14T13:01:56.1691628Z                     # Drop tables
2026-02-14T13:01:56.1691704Z                     cur.execute("""
2026-02-14T13:01:56.1691775Z                         DO $$
2026-02-14T13:01:56.1691840Z                         DECLARE
2026-02-14T13:01:56.1691913Z                             r RECORD;
2026-02-14T13:01:56.1691977Z                         BEGIN
2026-02-14T13:01:56.1692045Z                             FOR r IN (
2026-02-14T13:01:56.1692153Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1692239Z                                 FROM pg_tables
2026-02-14T13:01:56.1692368Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1692438Z                             )
2026-02-14T13:01:56.1692513Z                             LOOP
2026-02-14T13:01:56.1692990Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1693067Z                             END LOOP;
2026-02-14T13:01:56.1693140Z                         END $$;
2026-02-14T13:01:56.1693307Z                     """)
2026-02-14T13:01:56.1693392Z                 except psycopg2.Error:
2026-02-14T13:01:56.1693578Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1693647Z                     pass
2026-02-14T13:01:56.1693708Z     
2026-02-14T13:01:56.1693881Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1694001Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1694079Z                 if init_dir.exists():
2026-02-14T13:01:56.1694186Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1694285Z                     for script_path in scripts:
2026-02-14T13:01:56.1694417Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1694494Z                             sql = f.read()
2026-02-14T13:01:56.1694711Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1694849Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1694926Z                             statements = []
2026-02-14T13:01:56.1694986Z     
2026-02-14T13:01:56.1695174Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1695250Z                             do_blocks = []
2026-02-14T13:01:56.1695355Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1695419Z     
2026-02-14T13:01:56.1695519Z                             def replace_do_block(match):
2026-02-14T13:01:56.1695611Z                                 block = match.group(0)
2026-02-14T13:01:56.1695748Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1695845Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1695933Z                                 return placeholder
2026-02-14T13:01:56.1695995Z     
2026-02-14T13:01:56.1696111Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1696212Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1696293Z                                                     ^^
2026-02-14T13:01:56.1696488Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1696557Z                             )
2026-02-14T13:01:56.1696666Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1696672Z 
2026-02-14T13:01:56.1696780Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1696987Z __ ERROR at setup of TestCompanyEnrichmentFlow.test_enrichment_queue_updated ___
2026-02-14T13:01:56.1696995Z 
2026-02-14T13:01:56.1697292Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1697297Z 
2026-02-14T13:01:56.1697393Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1697501Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1697569Z         """
2026-02-14T13:01:56.1697713Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1697771Z     
2026-02-14T13:01:56.1697917Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1698047Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1698109Z         """
2026-02-14T13:01:56.1698213Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1698342Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1698403Z     
2026-02-14T13:01:56.1698514Z         # Parse connection string to get database name
2026-02-14T13:01:56.1698857Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1698920Z     
2026-02-14T13:01:56.1699112Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1703190Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1703257Z     
2026-02-14T13:01:56.1703423Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1703550Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1703632Z         if len(parts) >= 4:
2026-02-14T13:01:56.1703757Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1703828Z         else:
2026-02-14T13:01:56.1703934Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1703993Z     
2026-02-14T13:01:56.1704092Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1704340Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1704408Z         import time
2026-02-14T13:01:56.1704468Z     
2026-02-14T13:01:56.1704544Z         max_retries = 5
2026-02-14T13:01:56.1704610Z         retry_delay = 2
2026-02-14T13:01:56.1704673Z     
2026-02-14T13:01:56.1704772Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1704835Z             try:
2026-02-14T13:01:56.1704940Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1705041Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1705124Z                 conn.autocommit = True
2026-02-14T13:01:56.1705186Z                 try:
2026-02-14T13:01:56.1705263Z                     cur = conn.cursor()
2026-02-14T13:01:56.1705461Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1705540Z                     if not cur.fetchone():
2026-02-14T13:01:56.1705697Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1705823Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1705898Z                     cur.close()
2026-02-14T13:01:56.1705970Z                 finally:
2026-02-14T13:01:56.1706054Z                     conn.close()
2026-02-14T13:01:56.1706124Z                 break  # Success
2026-02-14T13:01:56.1706317Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1706410Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1706499Z                     print(
2026-02-14T13:01:56.1706726Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1706791Z                     )
2026-02-14T13:01:56.1706882Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1706946Z                 else:
2026-02-14T13:01:56.1707160Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1707354Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1707423Z                     pass
2026-02-14T13:01:56.1707545Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1707630Z                 break  # Already exists
2026-02-14T13:01:56.1707696Z     
2026-02-14T13:01:56.1707923Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1708114Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1708256Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1708315Z     
2026-02-14T13:01:56.1708388Z         close_all_pools()
2026-02-14T13:01:56.1708451Z     
2026-02-14T13:01:56.1708573Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1708740Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1709023Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1709115Z             conn.autocommit = True
2026-02-14T13:01:56.1709195Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1709495Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1709593Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1709667Z                 cur.execute(
2026-02-14T13:01:56.1709731Z                     """
2026-02-14T13:01:56.1709836Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1709916Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1710013Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1710106Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1710176Z                     """
2026-02-14T13:01:56.1710239Z                 )
2026-02-14T13:01:56.1710297Z     
2026-02-14T13:01:56.1710492Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1710674Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1710738Z                 try:
2026-02-14T13:01:56.1710866Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1710941Z                     cur.execute("""
2026-02-14T13:01:56.1711010Z                         DO $$
2026-02-14T13:01:56.1711221Z                         DECLARE
2026-02-14T13:01:56.1711303Z                             r RECORD;
2026-02-14T13:01:56.1711367Z                         BEGIN
2026-02-14T13:01:56.1711439Z                             FOR r IN (
2026-02-14T13:01:56.1711545Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1711627Z                                 FROM pg_views
2026-02-14T13:01:56.1711753Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1711831Z                             )
2026-02-14T13:01:56.1711902Z                             LOOP
2026-02-14T13:01:56.1712220Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1712296Z                             END LOOP;
2026-02-14T13:01:56.1712368Z                         END $$;
2026-02-14T13:01:56.1712434Z                     """)
2026-02-14T13:01:56.1712505Z                     # Drop tables
2026-02-14T13:01:56.1712582Z                     cur.execute("""
2026-02-14T13:01:56.1712647Z                         DO $$
2026-02-14T13:01:56.1712711Z                         DECLARE
2026-02-14T13:01:56.1712780Z                             r RECORD;
2026-02-14T13:01:56.1712851Z                         BEGIN
2026-02-14T13:01:56.1712922Z                             FOR r IN (
2026-02-14T13:01:56.1713022Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1713114Z                                 FROM pg_tables
2026-02-14T13:01:56.1713241Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1713306Z                             )
2026-02-14T13:01:56.1713379Z                             LOOP
2026-02-14T13:01:56.1713698Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1713769Z                             END LOOP;
2026-02-14T13:01:56.1713836Z                         END $$;
2026-02-14T13:01:56.1713908Z                     """)
2026-02-14T13:01:56.1713989Z                 except psycopg2.Error:
2026-02-14T13:01:56.1714162Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1714235Z                     pass
2026-02-14T13:01:56.1714295Z     
2026-02-14T13:01:56.1714467Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1714698Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1714783Z                 if init_dir.exists():
2026-02-14T13:01:56.1714888Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1715115Z                     for script_path in scripts:
2026-02-14T13:01:56.1715247Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1715325Z                             sql = f.read()
2026-02-14T13:01:56.1715533Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1715671Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1715749Z                             statements = []
2026-02-14T13:01:56.1715807Z     
2026-02-14T13:01:56.1715988Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1716063Z                             do_blocks = []
2026-02-14T13:01:56.1716169Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1716228Z     
2026-02-14T13:01:56.1716336Z                             def replace_do_block(match):
2026-02-14T13:01:56.1716437Z                                 block = match.group(0)
2026-02-14T13:01:56.1716568Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1716671Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1716761Z                                 return placeholder
2026-02-14T13:01:56.1716821Z     
2026-02-14T13:01:56.1716944Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1717044Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1717129Z                                                     ^^
2026-02-14T13:01:56.1717334Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1717406Z                             )
2026-02-14T13:01:56.1717517Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1717524Z 
2026-02-14T13:01:56.1717628Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1717867Z _ ERROR at setup of TestCompanyEnrichmentFlow.test_normalize_companies_to_staging _
2026-02-14T13:01:56.1717872Z 
2026-02-14T13:01:56.1718173Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1718179Z 
2026-02-14T13:01:56.1718271Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1718380Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1718450Z         """
2026-02-14T13:01:56.1718590Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1718652Z     
2026-02-14T13:01:56.1718794Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1718924Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1718985Z         """
2026-02-14T13:01:56.1719086Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1719220Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1719279Z     
2026-02-14T13:01:56.1719388Z         # Parse connection string to get database name
2026-02-14T13:01:56.1719644Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1719700Z     
2026-02-14T13:01:56.1719888Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1720123Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1720180Z     
2026-02-14T13:01:56.1720323Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1720434Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1720515Z         if len(parts) >= 4:
2026-02-14T13:01:56.1720723Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1720789Z         else:
2026-02-14T13:01:56.1720896Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1720954Z     
2026-02-14T13:01:56.1721184Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1721537Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1721612Z         import time
2026-02-14T13:01:56.1721671Z     
2026-02-14T13:01:56.1721740Z         max_retries = 5
2026-02-14T13:01:56.1721814Z         retry_delay = 2
2026-02-14T13:01:56.1721871Z     
2026-02-14T13:01:56.1721958Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1722025Z             try:
2026-02-14T13:01:56.1722126Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1722222Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1722303Z                 conn.autocommit = True
2026-02-14T13:01:56.1722378Z                 try:
2026-02-14T13:01:56.1722456Z                     cur = conn.cursor()
2026-02-14T13:01:56.1722647Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1722733Z                     if not cur.fetchone():
2026-02-14T13:01:56.1722889Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1723009Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1723087Z                     cur.close()
2026-02-14T13:01:56.1723155Z                 finally:
2026-02-14T13:01:56.1723228Z                     conn.close()
2026-02-14T13:01:56.1723297Z                 break  # Success
2026-02-14T13:01:56.1723493Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1723584Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1723655Z                     print(
2026-02-14T13:01:56.1723884Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1723950Z                     )
2026-02-14T13:01:56.1724034Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1724098Z                 else:
2026-02-14T13:01:56.1724313Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1724499Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1724568Z                     pass
2026-02-14T13:01:56.1724693Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1724771Z                 break  # Already exists
2026-02-14T13:01:56.1724829Z     
2026-02-14T13:01:56.1725052Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1725237Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1725373Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1725443Z     
2026-02-14T13:01:56.1725517Z         close_all_pools()
2026-02-14T13:01:56.1725575Z     
2026-02-14T13:01:56.1725691Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1725862Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1726002Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1726085Z             conn.autocommit = True
2026-02-14T13:01:56.1726166Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1726362Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1726456Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1726529Z                 cur.execute(
2026-02-14T13:01:56.1726602Z                     """
2026-02-14T13:01:56.1726699Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1726901Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1727009Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1727099Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1727164Z                     """
2026-02-14T13:01:56.1727309Z                 )
2026-02-14T13:01:56.1727369Z     
2026-02-14T13:01:56.1727558Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1727741Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1727813Z                 try:
2026-02-14T13:01:56.1727933Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1728010Z                     cur.execute("""
2026-02-14T13:01:56.1728090Z                         DO $$
2026-02-14T13:01:56.1728158Z                         DECLARE
2026-02-14T13:01:56.1728233Z                             r RECORD;
2026-02-14T13:01:56.1728307Z                         BEGIN
2026-02-14T13:01:56.1728391Z                             FOR r IN (
2026-02-14T13:01:56.1728499Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1728583Z                                 FROM pg_views
2026-02-14T13:01:56.1728726Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1728800Z                             )
2026-02-14T13:01:56.1728874Z                             LOOP
2026-02-14T13:01:56.1729202Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1729278Z                             END LOOP;
2026-02-14T13:01:56.1729346Z                         END $$;
2026-02-14T13:01:56.1729420Z                     """)
2026-02-14T13:01:56.1729495Z                     # Drop tables
2026-02-14T13:01:56.1729570Z                     cur.execute("""
2026-02-14T13:01:56.1729637Z                         DO $$
2026-02-14T13:01:56.1729712Z                         DECLARE
2026-02-14T13:01:56.1729784Z                             r RECORD;
2026-02-14T13:01:56.1729850Z                         BEGIN
2026-02-14T13:01:56.1729930Z                             FOR r IN (
2026-02-14T13:01:56.1730036Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1730121Z                                 FROM pg_tables
2026-02-14T13:01:56.1730249Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1730320Z                             )
2026-02-14T13:01:56.1730391Z                             LOOP
2026-02-14T13:01:56.1730705Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1730784Z                             END LOOP;
2026-02-14T13:01:56.1730851Z                         END $$;
2026-02-14T13:01:56.1730915Z                     """)
2026-02-14T13:01:56.1731005Z                 except psycopg2.Error:
2026-02-14T13:01:56.1731435Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1731506Z                     pass
2026-02-14T13:01:56.1731566Z     
2026-02-14T13:01:56.1731751Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1731867Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1731942Z                 if init_dir.exists():
2026-02-14T13:01:56.1732055Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1732146Z                     for script_path in scripts:
2026-02-14T13:01:56.1732273Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1732354Z                             sql = f.read()
2026-02-14T13:01:56.1732563Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1732856Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1732951Z                             statements = []
2026-02-14T13:01:56.1733010Z     
2026-02-14T13:01:56.1733199Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1733390Z                             do_blocks = []
2026-02-14T13:01:56.1733500Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1733559Z     
2026-02-14T13:01:56.1733658Z                             def replace_do_block(match):
2026-02-14T13:01:56.1733756Z                                 block = match.group(0)
2026-02-14T13:01:56.1733889Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1733986Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1734082Z                                 return placeholder
2026-02-14T13:01:56.1734141Z     
2026-02-14T13:01:56.1734254Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1734354Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1734442Z                                                     ^^
2026-02-14T13:01:56.1734631Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1734707Z                             )
2026-02-14T13:01:56.1734822Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1734828Z 
2026-02-14T13:01:56.1734928Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1735156Z _ ERROR at setup of TestCompanyEnrichmentFlow.test_companies_in_marts_dim_companies _
2026-02-14T13:01:56.1735161Z 
2026-02-14T13:01:56.1735459Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1735465Z 
2026-02-14T13:01:56.1735565Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1735679Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1735743Z         """
2026-02-14T13:01:56.1735891Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1735957Z     
2026-02-14T13:01:56.1736095Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1736226Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1736296Z         """
2026-02-14T13:01:56.1736392Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1736521Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1736588Z     
2026-02-14T13:01:56.1736699Z         # Parse connection string to get database name
2026-02-14T13:01:56.1736950Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1737010Z     
2026-02-14T13:01:56.1737207Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1737439Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1737499Z     
2026-02-14T13:01:56.1737656Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1737771Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1737857Z         if len(parts) >= 4:
2026-02-14T13:01:56.1737988Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1738051Z         else:
2026-02-14T13:01:56.1738154Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1738213Z     
2026-02-14T13:01:56.1738315Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1738547Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1738614Z         import time
2026-02-14T13:01:56.1738678Z     
2026-02-14T13:01:56.1738749Z         max_retries = 5
2026-02-14T13:01:56.1738818Z         retry_delay = 2
2026-02-14T13:01:56.1738877Z     
2026-02-14T13:01:56.1739061Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1739127Z             try:
2026-02-14T13:01:56.1739230Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1739329Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1739487Z                 conn.autocommit = True
2026-02-14T13:01:56.1739555Z                 try:
2026-02-14T13:01:56.1739631Z                     cur = conn.cursor()
2026-02-14T13:01:56.1739827Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1739909Z                     if not cur.fetchone():
2026-02-14T13:01:56.1740063Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1740190Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1740264Z                     cur.close()
2026-02-14T13:01:56.1740333Z                 finally:
2026-02-14T13:01:56.1740413Z                     conn.close()
2026-02-14T13:01:56.1740488Z                 break  # Success
2026-02-14T13:01:56.1740682Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1740781Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1740856Z                     print(
2026-02-14T13:01:56.1741452Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1741582Z                     )
2026-02-14T13:01:56.1741700Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1741770Z                 else:
2026-02-14T13:01:56.1741990Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1742192Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1742264Z                     pass
2026-02-14T13:01:56.1742384Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1742479Z                 break  # Already exists
2026-02-14T13:01:56.1742539Z     
2026-02-14T13:01:56.1742760Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1742953Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1743092Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1743151Z     
2026-02-14T13:01:56.1743226Z         close_all_pools()
2026-02-14T13:01:56.1743292Z     
2026-02-14T13:01:56.1743411Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1743580Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1743731Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1743812Z             conn.autocommit = True
2026-02-14T13:01:56.1743892Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1744100Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1744194Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1744269Z                 cur.execute(
2026-02-14T13:01:56.1744337Z                     """
2026-02-14T13:01:56.1744442Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1744528Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1744626Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1744724Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1744790Z                     """
2026-02-14T13:01:56.1744850Z                 )
2026-02-14T13:01:56.1744909Z     
2026-02-14T13:01:56.1745102Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1745286Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1745360Z                 try:
2026-02-14T13:01:56.1745632Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1745716Z                     cur.execute("""
2026-02-14T13:01:56.1745787Z                         DO $$
2026-02-14T13:01:56.1745865Z                         DECLARE
2026-02-14T13:01:56.1745941Z                             r RECORD;
2026-02-14T13:01:56.1746116Z                         BEGIN
2026-02-14T13:01:56.1746190Z                             FOR r IN (
2026-02-14T13:01:56.1746301Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1746383Z                                 FROM pg_views
2026-02-14T13:01:56.1746515Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1746597Z                             )
2026-02-14T13:01:56.1746668Z                             LOOP
2026-02-14T13:01:56.1746983Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1747070Z                             END LOOP;
2026-02-14T13:01:56.1747145Z                         END $$;
2026-02-14T13:01:56.1747213Z                     """)
2026-02-14T13:01:56.1747286Z                     # Drop tables
2026-02-14T13:01:56.1747364Z                     cur.execute("""
2026-02-14T13:01:56.1747434Z                         DO $$
2026-02-14T13:01:56.1747500Z                         DECLARE
2026-02-14T13:01:56.1747575Z                             r RECORD;
2026-02-14T13:01:56.1747640Z                         BEGIN
2026-02-14T13:01:56.1747711Z                             FOR r IN (
2026-02-14T13:01:56.1747819Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1747906Z                                 FROM pg_tables
2026-02-14T13:01:56.1748033Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1748099Z                             )
2026-02-14T13:01:56.1748173Z                             LOOP
2026-02-14T13:01:56.1748493Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1748565Z                             END LOOP;
2026-02-14T13:01:56.1748638Z                         END $$;
2026-02-14T13:01:56.1748707Z                     """)
2026-02-14T13:01:56.1748792Z                 except psycopg2.Error:
2026-02-14T13:01:56.1748974Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1749042Z                     pass
2026-02-14T13:01:56.1749102Z     
2026-02-14T13:01:56.1749274Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1749391Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1749467Z                 if init_dir.exists():
2026-02-14T13:01:56.1749573Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1749668Z                     for script_path in scripts:
2026-02-14T13:01:56.1749795Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1749871Z                             sql = f.read()
2026-02-14T13:01:56.1750086Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1750222Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1750300Z                             statements = []
2026-02-14T13:01:56.1750360Z     
2026-02-14T13:01:56.1750545Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1750623Z                             do_blocks = []
2026-02-14T13:01:56.1750727Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1750792Z     
2026-02-14T13:01:56.1750892Z                             def replace_do_block(match):
2026-02-14T13:01:56.1750984Z                                 block = match.group(0)
2026-02-14T13:01:56.1751382Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1751493Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1751582Z                                 return placeholder
2026-02-14T13:01:56.1751738Z     
2026-02-14T13:01:56.1751853Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1751951Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1752033Z                                                     ^^
2026-02-14T13:01:56.1752228Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1752297Z                             )
2026-02-14T13:01:56.1752405Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1752412Z 
2026-02-14T13:01:56.1752519Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1752747Z _ ERROR at setup of TestCompanyEnrichmentFlow.test_complete_company_enrichment_flow _
2026-02-14T13:01:56.1752755Z 
2026-02-14T13:01:56.1753071Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1753076Z 
2026-02-14T13:01:56.1753173Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1753296Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1753359Z         """
2026-02-14T13:01:56.1753498Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1753557Z     
2026-02-14T13:01:56.1753695Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1753819Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1753881Z         """
2026-02-14T13:01:56.1753988Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1754113Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1754172Z     
2026-02-14T13:01:56.1754283Z         # Parse connection string to get database name
2026-02-14T13:01:56.1754541Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1754603Z     
2026-02-14T13:01:56.1754792Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1755039Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1755101Z     
2026-02-14T13:01:56.1755244Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1755358Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1755440Z         if len(parts) >= 4:
2026-02-14T13:01:56.1755559Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1755623Z         else:
2026-02-14T13:01:56.1755731Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1755790Z     
2026-02-14T13:01:56.1755888Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1756129Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1756200Z         import time
2026-02-14T13:01:56.1756259Z     
2026-02-14T13:01:56.1756338Z         max_retries = 5
2026-02-14T13:01:56.1756406Z         retry_delay = 2
2026-02-14T13:01:56.1756474Z     
2026-02-14T13:01:56.1756560Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1756633Z             try:
2026-02-14T13:01:56.1756733Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1756830Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1756917Z                 conn.autocommit = True
2026-02-14T13:01:56.1756981Z                 try:
2026-02-14T13:01:56.1757067Z                     cur = conn.cursor()
2026-02-14T13:01:56.1757256Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1757344Z                     if not cur.fetchone():
2026-02-14T13:01:56.1757590Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1757711Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1757788Z                     cur.close()
2026-02-14T13:01:56.1757855Z                 finally:
2026-02-14T13:01:56.1758003Z                     conn.close()
2026-02-14T13:01:56.1758078Z                 break  # Success
2026-02-14T13:01:56.1758265Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1758354Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1758427Z                     print(
2026-02-14T13:01:56.1758652Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1758716Z                     )
2026-02-14T13:01:56.1758798Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1758867Z                 else:
2026-02-14T13:01:56.1759073Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1759257Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1759330Z                     pass
2026-02-14T13:01:56.1759442Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1759523Z                 break  # Already exists
2026-02-14T13:01:56.1759581Z     
2026-02-14T13:01:56.1759801Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1759996Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1760132Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1760194Z     
2026-02-14T13:01:56.1760274Z         close_all_pools()
2026-02-14T13:01:56.1760334Z     
2026-02-14T13:01:56.1760452Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1760624Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1760765Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1760847Z             conn.autocommit = True
2026-02-14T13:01:56.1760928Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1761242Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1761335Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1761410Z                 cur.execute(
2026-02-14T13:01:56.1761482Z                     """
2026-02-14T13:01:56.1761581Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1761661Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1761762Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1761854Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1761923Z                     """
2026-02-14T13:01:56.1761984Z                 )
2026-02-14T13:01:56.1762048Z     
2026-02-14T13:01:56.1762240Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1762424Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1762496Z                 try:
2026-02-14T13:01:56.1762616Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1762690Z                     cur.execute("""
2026-02-14T13:01:56.1762764Z                         DO $$
2026-02-14T13:01:56.1762834Z                         DECLARE
2026-02-14T13:01:56.1762907Z                             r RECORD;
2026-02-14T13:01:56.1762974Z                         BEGIN
2026-02-14T13:01:56.1763052Z                             FOR r IN (
2026-02-14T13:01:56.1763151Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1763231Z                                 FROM pg_views
2026-02-14T13:01:56.1763367Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1763586Z                             )
2026-02-14T13:01:56.1763659Z                             LOOP
2026-02-14T13:01:56.1763976Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1764155Z                             END LOOP;
2026-02-14T13:01:56.1764220Z                         END $$;
2026-02-14T13:01:56.1764285Z                     """)
2026-02-14T13:01:56.1764361Z                     # Drop tables
2026-02-14T13:01:56.1764433Z                     cur.execute("""
2026-02-14T13:01:56.1764498Z                         DO $$
2026-02-14T13:01:56.1764567Z                         DECLARE
2026-02-14T13:01:56.1764636Z                             r RECORD;
2026-02-14T13:01:56.1764703Z                         BEGIN
2026-02-14T13:01:56.1764778Z                             FOR r IN (
2026-02-14T13:01:56.1764882Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1764966Z                                 FROM pg_tables
2026-02-14T13:01:56.1765090Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1765160Z                             )
2026-02-14T13:01:56.1765228Z                             LOOP
2026-02-14T13:01:56.1765551Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1765628Z                             END LOOP;
2026-02-14T13:01:56.1765695Z                         END $$;
2026-02-14T13:01:56.1765759Z                     """)
2026-02-14T13:01:56.1765844Z                 except psycopg2.Error:
2026-02-14T13:01:56.1766023Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1766091Z                     pass
2026-02-14T13:01:56.1766150Z     
2026-02-14T13:01:56.1766326Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1766438Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1766514Z                 if init_dir.exists():
2026-02-14T13:01:56.1766625Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1766718Z                     for script_path in scripts:
2026-02-14T13:01:56.1766844Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1766919Z                             sql = f.read()
2026-02-14T13:01:56.1767139Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1767270Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1767349Z                             statements = []
2026-02-14T13:01:56.1767412Z     
2026-02-14T13:01:56.1767592Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1767667Z                             do_blocks = []
2026-02-14T13:01:56.1767779Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1767838Z     
2026-02-14T13:01:56.1767935Z                             def replace_do_block(match):
2026-02-14T13:01:56.1768028Z                                 block = match.group(0)
2026-02-14T13:01:56.1768165Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1768262Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1768350Z                                 return placeholder
2026-02-14T13:01:56.1768413Z     
2026-02-14T13:01:56.1768526Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1768627Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1768718Z                                                     ^^
2026-02-14T13:01:56.1768908Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1769064Z                             )
2026-02-14T13:01:56.1769183Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1769188Z 
2026-02-14T13:01:56.1769290Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1769564Z ____ ERROR at setup of TestCooldownLogic.test_cooldown_after_successful_dag ____
2026-02-14T13:01:56.1769569Z 
2026-02-14T13:01:56.1769862Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1769867Z 
2026-02-14T13:01:56.1769959Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1770073Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1770134Z         """
2026-02-14T13:01:56.1770274Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1770338Z     
2026-02-14T13:01:56.1770470Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1770598Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1770669Z         """
2026-02-14T13:01:56.1770764Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1770891Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1770949Z     
2026-02-14T13:01:56.1771236Z         # Parse connection string to get database name
2026-02-14T13:01:56.1771538Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1771598Z     
2026-02-14T13:01:56.1771792Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1772020Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1772079Z     
2026-02-14T13:01:56.1772228Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1772338Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1772414Z         if len(parts) >= 4:
2026-02-14T13:01:56.1772541Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1772611Z         else:
2026-02-14T13:01:56.1772711Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1772774Z     
2026-02-14T13:01:56.1772876Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1773112Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1773179Z         import time
2026-02-14T13:01:56.1773238Z     
2026-02-14T13:01:56.1773312Z         max_retries = 5
2026-02-14T13:01:56.1773381Z         retry_delay = 2
2026-02-14T13:01:56.1773438Z     
2026-02-14T13:01:56.1773530Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1773594Z             try:
2026-02-14T13:01:56.1773697Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1773792Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1773877Z                 conn.autocommit = True
2026-02-14T13:01:56.1773943Z                 try:
2026-02-14T13:01:56.1774020Z                     cur = conn.cursor()
2026-02-14T13:01:56.1774215Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1774295Z                     if not cur.fetchone():
2026-02-14T13:01:56.1774450Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1774572Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1774644Z                     cur.close()
2026-02-14T13:01:56.1774712Z                 finally:
2026-02-14T13:01:56.1774785Z                     conn.close()
2026-02-14T13:01:56.1774865Z                 break  # Success
2026-02-14T13:01:56.1775058Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1775152Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1775229Z                     print(
2026-02-14T13:01:56.1775590Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1775663Z                     )
2026-02-14T13:01:56.1775754Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1775818Z                 else:
2026-02-14T13:01:56.1776127Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1776313Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1776388Z                     pass
2026-02-14T13:01:56.1776505Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1776633Z                 break  # Already exists
2026-02-14T13:01:56.1776700Z     
2026-02-14T13:01:56.1776917Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1777101Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1777245Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1777304Z     
2026-02-14T13:01:56.1777376Z         close_all_pools()
2026-02-14T13:01:56.1777434Z     
2026-02-14T13:01:56.1777556Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1777726Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1777869Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1777955Z             conn.autocommit = True
2026-02-14T13:01:56.1778037Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1778231Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1778327Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1778401Z                 cur.execute(
2026-02-14T13:01:56.1778466Z                     """
2026-02-14T13:01:56.1778566Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1778656Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1778752Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1778843Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1778913Z                     """
2026-02-14T13:01:56.1778978Z                 )
2026-02-14T13:01:56.1779038Z     
2026-02-14T13:01:56.1779232Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1779415Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1779480Z                 try:
2026-02-14T13:01:56.1779597Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1779679Z                     cur.execute("""
2026-02-14T13:01:56.1779749Z                         DO $$
2026-02-14T13:01:56.1779817Z                         DECLARE
2026-02-14T13:01:56.1779896Z                             r RECORD;
2026-02-14T13:01:56.1779963Z                         BEGIN
2026-02-14T13:01:56.1780041Z                             FOR r IN (
2026-02-14T13:01:56.1780144Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1780232Z                                 FROM pg_views
2026-02-14T13:01:56.1780362Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1780435Z                             )
2026-02-14T13:01:56.1780511Z                             LOOP
2026-02-14T13:01:56.1780826Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1780902Z                             END LOOP;
2026-02-14T13:01:56.1780979Z                         END $$;
2026-02-14T13:01:56.1781298Z                     """)
2026-02-14T13:01:56.1781432Z                     # Drop tables
2026-02-14T13:01:56.1781544Z                     cur.execute("""
2026-02-14T13:01:56.1781620Z                         DO $$
2026-02-14T13:01:56.1781830Z                         DECLARE
2026-02-14T13:01:56.1781906Z                             r RECORD;
2026-02-14T13:01:56.1781977Z                         BEGIN
2026-02-14T13:01:56.1782050Z                             FOR r IN (
2026-02-14T13:01:56.1782155Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1782347Z                                 FROM pg_tables
2026-02-14T13:01:56.1782475Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1782541Z                             )
2026-02-14T13:01:56.1782613Z                             LOOP
2026-02-14T13:01:56.1782941Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1783013Z                             END LOOP;
2026-02-14T13:01:56.1783080Z                         END $$;
2026-02-14T13:01:56.1783153Z                     """)
2026-02-14T13:01:56.1783238Z                 except psycopg2.Error:
2026-02-14T13:01:56.1783416Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1783495Z                     pass
2026-02-14T13:01:56.1783554Z     
2026-02-14T13:01:56.1783727Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1783843Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1783925Z                 if init_dir.exists():
2026-02-14T13:01:56.1784030Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1784121Z                     for script_path in scripts:
2026-02-14T13:01:56.1784254Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1784330Z                             sql = f.read()
2026-02-14T13:01:56.1784539Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1784679Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1784759Z                             statements = []
2026-02-14T13:01:56.1784817Z     
2026-02-14T13:01:56.1784993Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1785076Z                             do_blocks = []
2026-02-14T13:01:56.1785178Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1785236Z     
2026-02-14T13:01:56.1785338Z                             def replace_do_block(match):
2026-02-14T13:01:56.1785429Z                                 block = match.group(0)
2026-02-14T13:01:56.1785556Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1785655Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1785742Z                                 return placeholder
2026-02-14T13:01:56.1785800Z     
2026-02-14T13:01:56.1785918Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1786023Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1786105Z                                                     ^^
2026-02-14T13:01:56.1786294Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1786372Z                             )
2026-02-14T13:01:56.1786478Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1786484Z 
2026-02-14T13:01:56.1786585Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1786793Z ______ ERROR at setup of TestCooldownLogic.test_cooldown_after_failed_dag ______
2026-02-14T13:01:56.1786798Z 
2026-02-14T13:01:56.1787094Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1787099Z 
2026-02-14T13:01:56.1787188Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1787294Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1787362Z         """
2026-02-14T13:01:56.1787591Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1787653Z     
2026-02-14T13:01:56.1787788Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1787920Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1788057Z         """
2026-02-14T13:01:56.1788151Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1788280Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1788340Z     
2026-02-14T13:01:56.1788445Z         # Parse connection string to get database name
2026-02-14T13:01:56.1788697Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1788756Z     
2026-02-14T13:01:56.1788940Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1789171Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1789238Z     
2026-02-14T13:01:56.1789382Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1789492Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1789577Z         if len(parts) >= 4:
2026-02-14T13:01:56.1789696Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1789759Z         else:
2026-02-14T13:01:56.1789866Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1789924Z     
2026-02-14T13:01:56.1790020Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1790248Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1790325Z         import time
2026-02-14T13:01:56.1790383Z     
2026-02-14T13:01:56.1790453Z         max_retries = 5
2026-02-14T13:01:56.1790532Z         retry_delay = 2
2026-02-14T13:01:56.1790590Z     
2026-02-14T13:01:56.1790678Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1790743Z             try:
2026-02-14T13:01:56.1790849Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1790944Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1791241Z                 conn.autocommit = True
2026-02-14T13:01:56.1791347Z                 try:
2026-02-14T13:01:56.1791426Z                     cur = conn.cursor()
2026-02-14T13:01:56.1791617Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1791698Z                     if not cur.fetchone():
2026-02-14T13:01:56.1791855Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1791972Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1792045Z                     cur.close()
2026-02-14T13:01:56.1792122Z                 finally:
2026-02-14T13:01:56.1792195Z                     conn.close()
2026-02-14T13:01:56.1792268Z                 break  # Success
2026-02-14T13:01:56.1792464Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1792555Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1792631Z                     print(
2026-02-14T13:01:56.1792853Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1792926Z                     )
2026-02-14T13:01:56.1793009Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1793072Z                 else:
2026-02-14T13:01:56.1793286Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1793469Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1793537Z                     pass
2026-02-14T13:01:56.1793666Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1793869Z                 break  # Already exists
2026-02-14T13:01:56.1793932Z     
2026-02-14T13:01:56.1794159Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1794349Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1794583Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1794644Z     
2026-02-14T13:01:56.1794726Z         close_all_pools()
2026-02-14T13:01:56.1794785Z     
2026-02-14T13:01:56.1794903Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1795074Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1795224Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1795310Z             conn.autocommit = True
2026-02-14T13:01:56.1795390Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1795596Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1795689Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1795764Z                 cur.execute(
2026-02-14T13:01:56.1795837Z                     """
2026-02-14T13:01:56.1795933Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1796019Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1796120Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1796214Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1796281Z                     """
2026-02-14T13:01:56.1796341Z                 )
2026-02-14T13:01:56.1796404Z     
2026-02-14T13:01:56.1796595Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1796779Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1796847Z                 try:
2026-02-14T13:01:56.1796965Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1797040Z                     cur.execute("""
2026-02-14T13:01:56.1797114Z                         DO $$
2026-02-14T13:01:56.1797182Z                         DECLARE
2026-02-14T13:01:56.1797256Z                             r RECORD;
2026-02-14T13:01:56.1797326Z                         BEGIN
2026-02-14T13:01:56.1797403Z                             FOR r IN (
2026-02-14T13:01:56.1797501Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1797582Z                                 FROM pg_views
2026-02-14T13:01:56.1797715Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1797784Z                             )
2026-02-14T13:01:56.1797854Z                             LOOP
2026-02-14T13:01:56.1798174Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1798248Z                             END LOOP;
2026-02-14T13:01:56.1798318Z                         END $$;
2026-02-14T13:01:56.1798383Z                     """)
2026-02-14T13:01:56.1798465Z                     # Drop tables
2026-02-14T13:01:56.1798538Z                     cur.execute("""
2026-02-14T13:01:56.1798608Z                         DO $$
2026-02-14T13:01:56.1798679Z                         DECLARE
2026-02-14T13:01:56.1798747Z                             r RECORD;
2026-02-14T13:01:56.1798812Z                         BEGIN
2026-02-14T13:01:56.1798883Z                             FOR r IN (
2026-02-14T13:01:56.1798987Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1799069Z                                 FROM pg_tables
2026-02-14T13:01:56.1799197Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1799268Z                             )
2026-02-14T13:01:56.1799337Z                             LOOP
2026-02-14T13:01:56.1799734Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1799815Z                             END LOOP;
2026-02-14T13:01:56.1799882Z                         END $$;
2026-02-14T13:01:56.1800020Z                     """)
2026-02-14T13:01:56.1800103Z                 except psycopg2.Error:
2026-02-14T13:01:56.1800283Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1800353Z                     pass
2026-02-14T13:01:56.1800411Z     
2026-02-14T13:01:56.1800590Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1800698Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1800774Z                 if init_dir.exists():
2026-02-14T13:01:56.1800884Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1800975Z                     for script_path in scripts:
2026-02-14T13:01:56.1801233Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1801312Z                             sql = f.read()
2026-02-14T13:01:56.1801524Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1801657Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1801736Z                             statements = []
2026-02-14T13:01:56.1801802Z     
2026-02-14T13:01:56.1801981Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1802057Z                             do_blocks = []
2026-02-14T13:01:56.1802164Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1802223Z     
2026-02-14T13:01:56.1802321Z                             def replace_do_block(match):
2026-02-14T13:01:56.1802418Z                                 block = match.group(0)
2026-02-14T13:01:56.1802549Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1802645Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1802735Z                                 return placeholder
2026-02-14T13:01:56.1802802Z     
2026-02-14T13:01:56.1802910Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1803009Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1803095Z                                                     ^^
2026-02-14T13:01:56.1803283Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1803350Z                             )
2026-02-14T13:01:56.1803463Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1803468Z 
2026-02-14T13:01:56.1803572Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1803770Z ____ ERROR at setup of TestCooldownLogic.test_no_cooldown_before_first_run _____
2026-02-14T13:01:56.1803778Z 
2026-02-14T13:01:56.1804069Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1804074Z 
2026-02-14T13:01:56.1804162Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1804280Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1804348Z         """
2026-02-14T13:01:56.1804486Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1804549Z     
2026-02-14T13:01:56.1804682Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1804806Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1804874Z         """
2026-02-14T13:01:56.1804969Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1805095Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1805154Z     
2026-02-14T13:01:56.1805270Z         # Parse connection string to get database name
2026-02-14T13:01:56.1805639Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1805703Z     
2026-02-14T13:01:56.1805904Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1806234Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1806293Z     
2026-02-14T13:01:56.1806448Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1806558Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1806635Z         if len(parts) >= 4:
2026-02-14T13:01:56.1806754Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1806826Z         else:
2026-02-14T13:01:56.1806927Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1806986Z     
2026-02-14T13:01:56.1807087Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1807319Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1807385Z         import time
2026-02-14T13:01:56.1807442Z     
2026-02-14T13:01:56.1807516Z         max_retries = 5
2026-02-14T13:01:56.1807584Z         retry_delay = 2
2026-02-14T13:01:56.1807649Z     
2026-02-14T13:01:56.1807742Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1807804Z             try:
2026-02-14T13:01:56.1807901Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1808001Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1808082Z                 conn.autocommit = True
2026-02-14T13:01:56.1808145Z                 try:
2026-02-14T13:01:56.1808224Z                     cur = conn.cursor()
2026-02-14T13:01:56.1808418Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1808499Z                     if not cur.fetchone():
2026-02-14T13:01:56.1808655Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1808777Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1808849Z                     cur.close()
2026-02-14T13:01:56.1808916Z                 finally:
2026-02-14T13:01:56.1808995Z                     conn.close()
2026-02-14T13:01:56.1809066Z                 break  # Success
2026-02-14T13:01:56.1809255Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1809346Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1809419Z                     print(
2026-02-14T13:01:56.1809637Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1809702Z                     )
2026-02-14T13:01:56.1809789Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1809854Z                 else:
2026-02-14T13:01:56.1810059Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1810249Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1810317Z                     pass
2026-02-14T13:01:56.1810431Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1810511Z                 break  # Already exists
2026-02-14T13:01:56.1810577Z     
2026-02-14T13:01:56.1810794Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1810975Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1811370Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1811445Z     
2026-02-14T13:01:56.1811520Z         close_all_pools()
2026-02-14T13:01:56.1811580Z     
2026-02-14T13:01:56.1811705Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1812042Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1812190Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1812279Z             conn.autocommit = True
2026-02-14T13:01:56.1812359Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1812658Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1812754Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1812827Z                 cur.execute(
2026-02-14T13:01:56.1812892Z                     """
2026-02-14T13:01:56.1812988Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1813075Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1813172Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1813263Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1813335Z                     """
2026-02-14T13:01:56.1813399Z                 )
2026-02-14T13:01:56.1813458Z     
2026-02-14T13:01:56.1813657Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1813841Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1813907Z                 try:
2026-02-14T13:01:56.1814026Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1814106Z                     cur.execute("""
2026-02-14T13:01:56.1814175Z                         DO $$
2026-02-14T13:01:56.1814243Z                         DECLARE
2026-02-14T13:01:56.1814326Z                             r RECORD;
2026-02-14T13:01:56.1814392Z                         BEGIN
2026-02-14T13:01:56.1814465Z                             FOR r IN (
2026-02-14T13:01:56.1814570Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1814653Z                                 FROM pg_views
2026-02-14T13:01:56.1814781Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1814850Z                             )
2026-02-14T13:01:56.1814925Z                             LOOP
2026-02-14T13:01:56.1815237Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1815313Z                             END LOOP;
2026-02-14T13:01:56.1815387Z                         END $$;
2026-02-14T13:01:56.1815453Z                     """)
2026-02-14T13:01:56.1815526Z                     # Drop tables
2026-02-14T13:01:56.1815603Z                     cur.execute("""
2026-02-14T13:01:56.1815670Z                         DO $$
2026-02-14T13:01:56.1815736Z                         DECLARE
2026-02-14T13:01:56.1815807Z                             r RECORD;
2026-02-14T13:01:56.1815882Z                         BEGIN
2026-02-14T13:01:56.1815953Z                             FOR r IN (
2026-02-14T13:01:56.1816056Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1816149Z                                 FROM pg_tables
2026-02-14T13:01:56.1816275Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1816341Z                             )
2026-02-14T13:01:56.1816410Z                             LOOP
2026-02-14T13:01:56.1816733Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1816805Z                             END LOOP;
2026-02-14T13:01:56.1816879Z                         END $$;
2026-02-14T13:01:56.1816954Z                     """)
2026-02-14T13:01:56.1817036Z                 except psycopg2.Error:
2026-02-14T13:01:56.1817210Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1817285Z                     pass
2026-02-14T13:01:56.1817344Z     
2026-02-14T13:01:56.1817515Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1817717Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1817804Z                 if init_dir.exists():
2026-02-14T13:01:56.1817909Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1818076Z                     for script_path in scripts:
2026-02-14T13:01:56.1818207Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1818283Z                             sql = f.read()
2026-02-14T13:01:56.1818488Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1818627Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1818706Z                             statements = []
2026-02-14T13:01:56.1818764Z     
2026-02-14T13:01:56.1818943Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1819021Z                             do_blocks = []
2026-02-14T13:01:56.1819125Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1819184Z     
2026-02-14T13:01:56.1819287Z                             def replace_do_block(match):
2026-02-14T13:01:56.1819377Z                                 block = match.group(0)
2026-02-14T13:01:56.1819507Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1819609Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1819696Z                                 return placeholder
2026-02-14T13:01:56.1819753Z     
2026-02-14T13:01:56.1819869Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1819967Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1820050Z                                                     ^^
2026-02-14T13:01:56.1820234Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1820313Z                             )
2026-02-14T13:01:56.1820421Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1820427Z 
2026-02-14T13:01:56.1820530Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1820740Z ___ ERROR at setup of TestCooldownLogic.test_cooldown_expires_after_one_hour ___
2026-02-14T13:01:56.1820745Z 
2026-02-14T13:01:56.1821308Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1821321Z 
2026-02-14T13:01:56.1821482Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1821651Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1821750Z         """
2026-02-14T13:01:56.1821957Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1822051Z     
2026-02-14T13:01:56.1822283Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1822430Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1822502Z         """
2026-02-14T13:01:56.1822599Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1822730Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1822792Z     
2026-02-14T13:01:56.1822898Z         # Parse connection string to get database name
2026-02-14T13:01:56.1823152Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1823210Z     
2026-02-14T13:01:56.1823398Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1823625Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1823689Z     
2026-02-14T13:01:56.1823835Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1823949Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1824032Z         if len(parts) >= 4:
2026-02-14T13:01:56.1824319Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1824388Z         else:
2026-02-14T13:01:56.1824498Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1824558Z     
2026-02-14T13:01:56.1824659Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1824992Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1825066Z         import time
2026-02-14T13:01:56.1825125Z     
2026-02-14T13:01:56.1825196Z         max_retries = 5
2026-02-14T13:01:56.1825270Z         retry_delay = 2
2026-02-14T13:01:56.1825327Z     
2026-02-14T13:01:56.1825413Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1825476Z             try:
2026-02-14T13:01:56.1825586Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1825682Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1825764Z                 conn.autocommit = True
2026-02-14T13:01:56.1825840Z                 try:
2026-02-14T13:01:56.1825918Z                     cur = conn.cursor()
2026-02-14T13:01:56.1826110Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1826208Z                     if not cur.fetchone():
2026-02-14T13:01:56.1826371Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1826490Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1826563Z                     cur.close()
2026-02-14T13:01:56.1826636Z                 finally:
2026-02-14T13:01:56.1826709Z                     conn.close()
2026-02-14T13:01:56.1826780Z                 break  # Success
2026-02-14T13:01:56.1826984Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1827078Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1827148Z                     print(
2026-02-14T13:01:56.1827379Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1827445Z                     )
2026-02-14T13:01:56.1827529Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1827595Z                 else:
2026-02-14T13:01:56.1827810Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1827993Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1828061Z                     pass
2026-02-14T13:01:56.1828181Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1828258Z                 break  # Already exists
2026-02-14T13:01:56.1828317Z     
2026-02-14T13:01:56.1828542Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1828726Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1828861Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1828920Z     
2026-02-14T13:01:56.1829001Z         close_all_pools()
2026-02-14T13:01:56.1829061Z     
2026-02-14T13:01:56.1829182Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1829356Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1829498Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1829582Z             conn.autocommit = True
2026-02-14T13:01:56.1829662Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1829860Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1829952Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1830024Z                 cur.execute(
2026-02-14T13:01:56.1830096Z                     """
2026-02-14T13:01:56.1830193Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1830356Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1830460Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1830550Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1830617Z                     """
2026-02-14T13:01:56.1830753Z                 )
2026-02-14T13:01:56.1830819Z     
2026-02-14T13:01:56.1831012Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1831454Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1831529Z                 try:
2026-02-14T13:01:56.1831650Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1831728Z                     cur.execute("""
2026-02-14T13:01:56.1831803Z                         DO $$
2026-02-14T13:01:56.1831870Z                         DECLARE
2026-02-14T13:01:56.1831942Z                             r RECORD;
2026-02-14T13:01:56.1832008Z                         BEGIN
2026-02-14T13:01:56.1832093Z                             FOR r IN (
2026-02-14T13:01:56.1832194Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1832276Z                                 FROM pg_views
2026-02-14T13:01:56.1832412Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1832485Z                             )
2026-02-14T13:01:56.1832554Z                             LOOP
2026-02-14T13:01:56.1832880Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1832960Z                             END LOOP;
2026-02-14T13:01:56.1833031Z                         END $$;
2026-02-14T13:01:56.1833096Z                     """)
2026-02-14T13:01:56.1833175Z                     # Drop tables
2026-02-14T13:01:56.1833248Z                     cur.execute("""
2026-02-14T13:01:56.1833315Z                         DO $$
2026-02-14T13:01:56.1833390Z                         DECLARE
2026-02-14T13:01:56.1833459Z                             r RECORD;
2026-02-14T13:01:56.1833525Z                         BEGIN
2026-02-14T13:01:56.1833600Z                             FOR r IN (
2026-02-14T13:01:56.1833707Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1833794Z                                 FROM pg_tables
2026-02-14T13:01:56.1833920Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1833992Z                             )
2026-02-14T13:01:56.1834062Z                             LOOP
2026-02-14T13:01:56.1834375Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1834454Z                             END LOOP;
2026-02-14T13:01:56.1834521Z                         END $$;
2026-02-14T13:01:56.1834588Z                     """)
2026-02-14T13:01:56.1834671Z                 except psycopg2.Error:
2026-02-14T13:01:56.1834855Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1834926Z                     pass
2026-02-14T13:01:56.1834985Z     
2026-02-14T13:01:56.1835162Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1835275Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1835352Z                 if init_dir.exists():
2026-02-14T13:01:56.1835463Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1835554Z                     for script_path in scripts:
2026-02-14T13:01:56.1835677Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1835759Z                             sql = f.read()
2026-02-14T13:01:56.1835965Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1836215Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1836301Z                             statements = []
2026-02-14T13:01:56.1836367Z     
2026-02-14T13:01:56.1836551Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1836727Z                             do_blocks = []
2026-02-14T13:01:56.1836837Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1836896Z     
2026-02-14T13:01:56.1836993Z                             def replace_do_block(match):
2026-02-14T13:01:56.1837090Z                                 block = match.group(0)
2026-02-14T13:01:56.1837216Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1837311Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1837410Z                                 return placeholder
2026-02-14T13:01:56.1837475Z     
2026-02-14T13:01:56.1837591Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1837690Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1837780Z                                                     ^^
2026-02-14T13:01:56.1837972Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1838046Z                             )
2026-02-14T13:01:56.1838162Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1838168Z 
2026-02-14T13:01:56.1838270Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1838494Z _ ERROR at setup of TestCooldownLogic.test_multiple_campaigns_independent_cooldown _
2026-02-14T13:01:56.1838499Z 
2026-02-14T13:01:56.1838800Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1838805Z 
2026-02-14T13:01:56.1838897Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1839011Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1839072Z         """
2026-02-14T13:01:56.1839213Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1839277Z     
2026-02-14T13:01:56.1839413Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1839538Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1839610Z         """
2026-02-14T13:01:56.1839706Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1839832Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1839891Z     
2026-02-14T13:01:56.1840013Z         # Parse connection string to get database name
2026-02-14T13:01:56.1840265Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1840326Z     
2026-02-14T13:01:56.1840520Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1840754Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1840815Z     
2026-02-14T13:01:56.1840973Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1841219Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1841303Z         if len(parts) >= 4:
2026-02-14T13:01:56.1841427Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1841497Z         else:
2026-02-14T13:01:56.1841601Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1841659Z     
2026-02-14T13:01:56.1841759Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1841990Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1842056Z         import time
2026-02-14T13:01:56.1842121Z     
2026-02-14T13:01:56.1842189Z         max_retries = 5
2026-02-14T13:01:56.1842259Z         retry_delay = 2
2026-02-14T13:01:56.1842316Z     
2026-02-14T13:01:56.1842532Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1842599Z             try:
2026-02-14T13:01:56.1842704Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1842803Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1842986Z                 conn.autocommit = True
2026-02-14T13:01:56.1843050Z                 try:
2026-02-14T13:01:56.1843129Z                     cur = conn.cursor()
2026-02-14T13:01:56.1843326Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1843406Z                     if not cur.fetchone():
2026-02-14T13:01:56.1843559Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1843686Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1843760Z                     cur.close()
2026-02-14T13:01:56.1843829Z                 finally:
2026-02-14T13:01:56.1843909Z                     conn.close()
2026-02-14T13:01:56.1843983Z                 break  # Success
2026-02-14T13:01:56.1844175Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1844265Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1844344Z                     print(
2026-02-14T13:01:56.1844568Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1844633Z                     )
2026-02-14T13:01:56.1844724Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1844789Z                 else:
2026-02-14T13:01:56.1844993Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1845183Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1845252Z                     pass
2026-02-14T13:01:56.1845367Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1845449Z                 break  # Already exists
2026-02-14T13:01:56.1845513Z     
2026-02-14T13:01:56.1845735Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1845918Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1846061Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1846121Z     
2026-02-14T13:01:56.1846195Z         close_all_pools()
2026-02-14T13:01:56.1846258Z     
2026-02-14T13:01:56.1846377Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1846546Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1846691Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1846782Z             conn.autocommit = True
2026-02-14T13:01:56.1846865Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1847062Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1847158Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1847230Z                 cur.execute(
2026-02-14T13:01:56.1847296Z                     """
2026-02-14T13:01:56.1847399Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1847485Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1847583Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1847673Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1847746Z                     """
2026-02-14T13:01:56.1847807Z                 )
2026-02-14T13:01:56.1847866Z     
2026-02-14T13:01:56.1848061Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1848245Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1848311Z                 try:
2026-02-14T13:01:56.1848522Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1848612Z                     cur.execute("""
2026-02-14T13:01:56.1848681Z                         DO $$
2026-02-14T13:01:56.1848751Z                         DECLARE
2026-02-14T13:01:56.1848829Z                             r RECORD;
2026-02-14T13:01:56.1848974Z                         BEGIN
2026-02-14T13:01:56.1849051Z                             FOR r IN (
2026-02-14T13:01:56.1849157Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1849239Z                                 FROM pg_views
2026-02-14T13:01:56.1849379Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1849446Z                             )
2026-02-14T13:01:56.1849525Z                             LOOP
2026-02-14T13:01:56.1849839Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1849913Z                             END LOOP;
2026-02-14T13:01:56.1849992Z                         END $$;
2026-02-14T13:01:56.1850058Z                     """)
2026-02-14T13:01:56.1850134Z                     # Drop tables
2026-02-14T13:01:56.1850216Z                     cur.execute("""
2026-02-14T13:01:56.1850287Z                         DO $$
2026-02-14T13:01:56.1850354Z                         DECLARE
2026-02-14T13:01:56.1850425Z                             r RECORD;
2026-02-14T13:01:56.1850499Z                         BEGIN
2026-02-14T13:01:56.1850573Z                             FOR r IN (
2026-02-14T13:01:56.1850675Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1850765Z                                 FROM pg_tables
2026-02-14T13:01:56.1850893Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1850960Z                             )
2026-02-14T13:01:56.1851219Z                             LOOP
2026-02-14T13:01:56.1851602Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1851678Z                             END LOOP;
2026-02-14T13:01:56.1851749Z                         END $$;
2026-02-14T13:01:56.1851833Z                     """)
2026-02-14T13:01:56.1851920Z                 except psycopg2.Error:
2026-02-14T13:01:56.1852098Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1852173Z                     pass
2026-02-14T13:01:56.1852231Z     
2026-02-14T13:01:56.1852407Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1852527Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1852605Z                 if init_dir.exists():
2026-02-14T13:01:56.1852712Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1852801Z                     for script_path in scripts:
2026-02-14T13:01:56.1852939Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1853018Z                             sql = f.read()
2026-02-14T13:01:56.1853225Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1853368Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1853448Z                             statements = []
2026-02-14T13:01:56.1853507Z     
2026-02-14T13:01:56.1853691Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1853766Z                             do_blocks = []
2026-02-14T13:01:56.1853869Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1853928Z     
2026-02-14T13:01:56.1854033Z                             def replace_do_block(match):
2026-02-14T13:01:56.1854125Z                                 block = match.group(0)
2026-02-14T13:01:56.1854373Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1854482Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1854570Z                                 return placeholder
2026-02-14T13:01:56.1854769Z     
2026-02-14T13:01:56.1854888Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1854989Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1855071Z                                                     ^^
2026-02-14T13:01:56.1855261Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1855338Z                             )
2026-02-14T13:01:56.1855447Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1855453Z 
2026-02-14T13:01:56.1855553Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1855770Z _ ERROR at setup of TestCooldownLogic.test_concurrent_dag_triggers_same_campaign _
2026-02-14T13:01:56.1855778Z 
2026-02-14T13:01:56.1856072Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1856077Z 
2026-02-14T13:01:56.1856169Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1856274Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1856344Z         """
2026-02-14T13:01:56.1856483Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1856547Z     
2026-02-14T13:01:56.1856681Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1856813Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1856875Z         """
2026-02-14T13:01:56.1856972Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1857104Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1857164Z     
2026-02-14T13:01:56.1929181Z         # Parse connection string to get database name
2026-02-14T13:01:56.1929640Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1929714Z     
2026-02-14T13:01:56.1929930Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1930184Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1930249Z     
2026-02-14T13:01:56.1930410Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1930531Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1930621Z         if len(parts) >= 4:
2026-02-14T13:01:56.1930752Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1930818Z         else:
2026-02-14T13:01:56.1930927Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1930997Z     
2026-02-14T13:01:56.1931545Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1931800Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1931885Z         import time
2026-02-14T13:01:56.1931945Z     
2026-02-14T13:01:56.1932018Z         max_retries = 5
2026-02-14T13:01:56.1932088Z         retry_delay = 2
2026-02-14T13:01:56.1932159Z     
2026-02-14T13:01:56.1932250Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1932314Z             try:
2026-02-14T13:01:56.1932428Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1932527Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1932610Z                 conn.autocommit = True
2026-02-14T13:01:56.1932687Z                 try:
2026-02-14T13:01:56.1932769Z                     cur = conn.cursor()
2026-02-14T13:01:56.1932965Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1933049Z                     if not cur.fetchone():
2026-02-14T13:01:56.1933530Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1933660Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1933735Z                     cur.close()
2026-02-14T13:01:56.1933813Z                 finally:
2026-02-14T13:01:56.1934019Z                     conn.close()
2026-02-14T13:01:56.1934089Z                 break  # Success
2026-02-14T13:01:56.1934295Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1934392Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1934463Z                     print(
2026-02-14T13:01:56.1934693Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1934768Z                     )
2026-02-14T13:01:56.1934852Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1934914Z                 else:
2026-02-14T13:01:56.1935137Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1935329Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1935401Z                     pass
2026-02-14T13:01:56.1935533Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1935618Z                 break  # Already exists
2026-02-14T13:01:56.1935677Z     
2026-02-14T13:01:56.1935908Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1936116Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1936257Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1936318Z     
2026-02-14T13:01:56.1936400Z         close_all_pools()
2026-02-14T13:01:56.1936458Z     
2026-02-14T13:01:56.1936580Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1936756Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1936906Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1936989Z             conn.autocommit = True
2026-02-14T13:01:56.1937073Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1937283Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1937379Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1937455Z                 cur.execute(
2026-02-14T13:01:56.1937528Z                     """
2026-02-14T13:01:56.1937629Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1937711Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1937809Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1937909Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1937976Z                     """
2026-02-14T13:01:56.1938036Z                 )
2026-02-14T13:01:56.1938102Z     
2026-02-14T13:01:56.1938298Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1938486Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1938556Z                 try:
2026-02-14T13:01:56.1938680Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1938759Z                     cur.execute("""
2026-02-14T13:01:56.1938829Z                         DO $$
2026-02-14T13:01:56.1938905Z                         DECLARE
2026-02-14T13:01:56.1938980Z                             r RECORD;
2026-02-14T13:01:56.1939046Z                         BEGIN
2026-02-14T13:01:56.1939126Z                             FOR r IN (
2026-02-14T13:01:56.1939230Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1939316Z                                 FROM pg_views
2026-02-14T13:01:56.1939458Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1939615Z                             )
2026-02-14T13:01:56.1939689Z                             LOOP
2026-02-14T13:01:56.1940012Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1940170Z                             END LOOP;
2026-02-14T13:01:56.1940237Z                         END $$;
2026-02-14T13:01:56.1940302Z                     """)
2026-02-14T13:01:56.1940380Z                     # Drop tables
2026-02-14T13:01:56.1940454Z                     cur.execute("""
2026-02-14T13:01:56.1940521Z                         DO $$
2026-02-14T13:01:56.1940592Z                         DECLARE
2026-02-14T13:01:56.1940663Z                             r RECORD;
2026-02-14T13:01:56.1940728Z                         BEGIN
2026-02-14T13:01:56.1940802Z                             FOR r IN (
2026-02-14T13:01:56.1940912Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1940998Z                                 FROM pg_tables
2026-02-14T13:01:56.1941261Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1941337Z                             )
2026-02-14T13:01:56.1941411Z                             LOOP
2026-02-14T13:01:56.1941734Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1941812Z                             END LOOP;
2026-02-14T13:01:56.1941879Z                         END $$;
2026-02-14T13:01:56.1941944Z                     """)
2026-02-14T13:01:56.1942028Z                 except psycopg2.Error:
2026-02-14T13:01:56.1942214Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1942282Z                     pass
2026-02-14T13:01:56.1942340Z     
2026-02-14T13:01:56.1942518Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1942633Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1942712Z                 if init_dir.exists():
2026-02-14T13:01:56.1942817Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1942919Z                     for script_path in scripts:
2026-02-14T13:01:56.1943049Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1943126Z                             sql = f.read()
2026-02-14T13:01:56.1943341Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1943471Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1943551Z                             statements = []
2026-02-14T13:01:56.1943617Z     
2026-02-14T13:01:56.1943795Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1943873Z                             do_blocks = []
2026-02-14T13:01:56.1943982Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1944041Z     
2026-02-14T13:01:56.1944140Z                             def replace_do_block(match):
2026-02-14T13:01:56.1944234Z                                 block = match.group(0)
2026-02-14T13:01:56.1944376Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1944477Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1944566Z                                 return placeholder
2026-02-14T13:01:56.1944629Z     
2026-02-14T13:01:56.1944738Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1944840Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1944932Z                                                     ^^
2026-02-14T13:01:56.1945122Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1945319Z                             )
2026-02-14T13:01:56.1945436Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1945453Z 
2026-02-14T13:01:56.1945558Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1945865Z _____ ERROR at setup of TestCooldownLogic.test_dag_completion_with_no_jobs _____
2026-02-14T13:01:56.1945871Z 
2026-02-14T13:01:56.1946316Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1946322Z 
2026-02-14T13:01:56.1946419Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1946542Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1946605Z         """
2026-02-14T13:01:56.1946753Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1946820Z     
2026-02-14T13:01:56.1946960Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1947097Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1947162Z         """
2026-02-14T13:01:56.1947264Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1947395Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1947458Z     
2026-02-14T13:01:56.1947578Z         # Parse connection string to get database name
2026-02-14T13:01:56.1947831Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1947892Z     
2026-02-14T13:01:56.1948087Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1948317Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1948376Z     
2026-02-14T13:01:56.1948522Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1948642Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1948719Z         if len(parts) >= 4:
2026-02-14T13:01:56.1948842Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1948912Z         else:
2026-02-14T13:01:56.1949015Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1949074Z     
2026-02-14T13:01:56.1949180Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1949413Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1949481Z         import time
2026-02-14T13:01:56.1949540Z     
2026-02-14T13:01:56.1949617Z         max_retries = 5
2026-02-14T13:01:56.1949686Z         retry_delay = 2
2026-02-14T13:01:56.1949743Z     
2026-02-14T13:01:56.1949838Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1949901Z             try:
2026-02-14T13:01:56.1950004Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1950101Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1950191Z                 conn.autocommit = True
2026-02-14T13:01:56.1950260Z                 try:
2026-02-14T13:01:56.1950341Z                     cur = conn.cursor()
2026-02-14T13:01:56.1950543Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1950625Z                     if not cur.fetchone():
2026-02-14T13:01:56.1950782Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1950906Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1950980Z                     cur.close()
2026-02-14T13:01:56.1951272Z                 finally:
2026-02-14T13:01:56.1951393Z                     conn.close()
2026-02-14T13:01:56.1951483Z                 break  # Success
2026-02-14T13:01:56.1951685Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1951781Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1951859Z                     print(
2026-02-14T13:01:56.1952210Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1952283Z                     )
2026-02-14T13:01:56.1952380Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1952446Z                 else:
2026-02-14T13:01:56.1952760Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1952947Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1953028Z                     pass
2026-02-14T13:01:56.1953150Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1953233Z                 break  # Already exists
2026-02-14T13:01:56.1953300Z     
2026-02-14T13:01:56.1953522Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1953710Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1953856Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1953917Z     
2026-02-14T13:01:56.1953992Z         close_all_pools()
2026-02-14T13:01:56.1954051Z     
2026-02-14T13:01:56.1954178Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1954346Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1954492Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1954581Z             conn.autocommit = True
2026-02-14T13:01:56.1954663Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1954859Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1954959Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1955033Z                 cur.execute(
2026-02-14T13:01:56.1955100Z                     """
2026-02-14T13:01:56.1955201Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1955297Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1955396Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1955491Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1955563Z                     """
2026-02-14T13:01:56.1955632Z                 )
2026-02-14T13:01:56.1955690Z     
2026-02-14T13:01:56.1955882Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1956069Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1956135Z                 try:
2026-02-14T13:01:56.1956252Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1956336Z                     cur.execute("""
2026-02-14T13:01:56.1956408Z                         DO $$
2026-02-14T13:01:56.1956478Z                         DECLARE
2026-02-14T13:01:56.1956559Z                             r RECORD;
2026-02-14T13:01:56.1956628Z                         BEGIN
2026-02-14T13:01:56.1956705Z                             FOR r IN (
2026-02-14T13:01:56.1956808Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1956896Z                                 FROM pg_views
2026-02-14T13:01:56.1957026Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1957105Z                             )
2026-02-14T13:01:56.1957186Z                             LOOP
2026-02-14T13:01:56.1957503Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1957582Z                             END LOOP;
2026-02-14T13:01:56.1957650Z                         END $$;
2026-02-14T13:01:56.1957716Z                     """)
2026-02-14T13:01:56.1957789Z                     # Drop tables
2026-02-14T13:01:56.1957870Z                     cur.execute("""
2026-02-14T13:01:56.1957937Z                         DO $$
2026-02-14T13:01:56.1958140Z                         DECLARE
2026-02-14T13:01:56.1958217Z                             r RECORD;
2026-02-14T13:01:56.1958288Z                         BEGIN
2026-02-14T13:01:56.1958360Z                             FOR r IN (
2026-02-14T13:01:56.1958462Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1958629Z                                 FROM pg_tables
2026-02-14T13:01:56.1958753Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1958818Z                             )
2026-02-14T13:01:56.1958898Z                             LOOP
2026-02-14T13:01:56.1959212Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1959284Z                             END LOOP;
2026-02-14T13:01:56.1959359Z                         END $$;
2026-02-14T13:01:56.1959424Z                     """)
2026-02-14T13:01:56.1959514Z                 except psycopg2.Error:
2026-02-14T13:01:56.1959691Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1959770Z                     pass
2026-02-14T13:01:56.1959828Z     
2026-02-14T13:01:56.1960000Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1960122Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1960199Z                 if init_dir.exists():
2026-02-14T13:01:56.1960303Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1960401Z                     for script_path in scripts:
2026-02-14T13:01:56.1960530Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1960608Z                             sql = f.read()
2026-02-14T13:01:56.1960821Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1960958Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1961245Z                             statements = []
2026-02-14T13:01:56.1961354Z     
2026-02-14T13:01:56.1961650Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1961740Z                             do_blocks = []
2026-02-14T13:01:56.1961849Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1961916Z     
2026-02-14T13:01:56.1962016Z                             def replace_do_block(match):
2026-02-14T13:01:56.1962107Z                                 block = match.group(0)
2026-02-14T13:01:56.1962243Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1962340Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1962427Z                                 return placeholder
2026-02-14T13:01:56.1962485Z     
2026-02-14T13:01:56.1962603Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1962703Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1962784Z                                                     ^^
2026-02-14T13:01:56.1962980Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1963052Z                             )
2026-02-14T13:01:56.1963161Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1963167Z 
2026-02-14T13:01:56.1963274Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1963476Z ___ ERROR at setup of TestCooldownLogic.test_page_refresh_preserves_cooldown ___
2026-02-14T13:01:56.1963481Z 
2026-02-14T13:01:56.1963809Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1963815Z 
2026-02-14T13:01:56.1963909Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1964016Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1964088Z         """
2026-02-14T13:01:56.1964413Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1964481Z     
2026-02-14T13:01:56.1964628Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1964756Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1964918Z         """
2026-02-14T13:01:56.1965021Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1965148Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1965206Z     
2026-02-14T13:01:56.1965315Z         # Parse connection string to get database name
2026-02-14T13:01:56.1965568Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1965628Z     
2026-02-14T13:01:56.1965815Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1966053Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1966122Z     
2026-02-14T13:01:56.1966271Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1966390Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1966470Z         if len(parts) >= 4:
2026-02-14T13:01:56.1966590Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1966653Z         else:
2026-02-14T13:01:56.1966760Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1966819Z     
2026-02-14T13:01:56.1966916Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1967160Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1967227Z         import time
2026-02-14T13:01:56.1967285Z     
2026-02-14T13:01:56.1967356Z         max_retries = 5
2026-02-14T13:01:56.1967431Z         retry_delay = 2
2026-02-14T13:01:56.1967490Z     
2026-02-14T13:01:56.1967581Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1967651Z             try:
2026-02-14T13:01:56.1967754Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1967849Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1967943Z                 conn.autocommit = True
2026-02-14T13:01:56.1968009Z                 try:
2026-02-14T13:01:56.1968088Z                     cur = conn.cursor()
2026-02-14T13:01:56.1968277Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1968369Z                     if not cur.fetchone():
2026-02-14T13:01:56.1968521Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1968640Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1968720Z                     cur.close()
2026-02-14T13:01:56.1968788Z                 finally:
2026-02-14T13:01:56.1968864Z                     conn.close()
2026-02-14T13:01:56.1968946Z                 break  # Success
2026-02-14T13:01:56.1969139Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1969231Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.1969302Z                     print(
2026-02-14T13:01:56.1969535Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.1969602Z                     )
2026-02-14T13:01:56.1969686Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.1969758Z                 else:
2026-02-14T13:01:56.1969963Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.1970147Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.1970223Z                     pass
2026-02-14T13:01:56.1970339Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.1970506Z                 break  # Already exists
2026-02-14T13:01:56.1970569Z     
2026-02-14T13:01:56.1970798Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.1970980Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.1971514Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.1971580Z     
2026-02-14T13:01:56.1971658Z         close_all_pools()
2026-02-14T13:01:56.1971719Z     
2026-02-14T13:01:56.1971841Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.1972015Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.1972158Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.1972244Z             conn.autocommit = True
2026-02-14T13:01:56.1972334Z             with conn.cursor() as cur:
2026-02-14T13:01:56.1972535Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.1972633Z                 # EXCEPT our current connection
2026-02-14T13:01:56.1972713Z                 cur.execute(
2026-02-14T13:01:56.1972781Z                     """
2026-02-14T13:01:56.1972882Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.1972966Z                     FROM pg_stat_activity
2026-02-14T13:01:56.1973075Z                     WHERE datname = current_database()
2026-02-14T13:01:56.1973170Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.1973234Z                     """
2026-02-14T13:01:56.1973306Z                 )
2026-02-14T13:01:56.1973364Z     
2026-02-14T13:01:56.1973555Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.1973744Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.1973807Z                 try:
2026-02-14T13:01:56.1973929Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.1974005Z                     cur.execute("""
2026-02-14T13:01:56.1974080Z                         DO $$
2026-02-14T13:01:56.1974148Z                         DECLARE
2026-02-14T13:01:56.1974222Z                             r RECORD;
2026-02-14T13:01:56.1974302Z                         BEGIN
2026-02-14T13:01:56.1974376Z                             FOR r IN (
2026-02-14T13:01:56.1974479Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.1974566Z                                 FROM pg_views
2026-02-14T13:01:56.1974697Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1974765Z                             )
2026-02-14T13:01:56.1974838Z                             LOOP
2026-02-14T13:01:56.1975163Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.1975235Z                             END LOOP;
2026-02-14T13:01:56.1975308Z                         END $$;
2026-02-14T13:01:56.1975384Z                     """)
2026-02-14T13:01:56.1975457Z                     # Drop tables
2026-02-14T13:01:56.1975546Z                     cur.execute("""
2026-02-14T13:01:56.1975619Z                         DO $$
2026-02-14T13:01:56.1975694Z                         DECLARE
2026-02-14T13:01:56.1975767Z                             r RECORD;
2026-02-14T13:01:56.1975833Z                         BEGIN
2026-02-14T13:01:56.1975906Z                             FOR r IN (
2026-02-14T13:01:56.1976018Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.1976102Z                                 FROM pg_tables
2026-02-14T13:01:56.1976233Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.1976306Z                             )
2026-02-14T13:01:56.1976377Z                             LOOP
2026-02-14T13:01:56.1976869Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.1976953Z                             END LOOP;
2026-02-14T13:01:56.1977021Z                         END $$;
2026-02-14T13:01:56.1977184Z                     """)
2026-02-14T13:01:56.1977269Z                 except psycopg2.Error:
2026-02-14T13:01:56.1977453Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.1977522Z                     pass
2026-02-14T13:01:56.1977580Z     
2026-02-14T13:01:56.1977762Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.1977875Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.1977953Z                 if init_dir.exists():
2026-02-14T13:01:56.1978067Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.1978160Z                     for script_path in scripts:
2026-02-14T13:01:56.1978290Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.1978367Z                             sql = f.read()
2026-02-14T13:01:56.1978583Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.1979062Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.1979380Z                             statements = []
2026-02-14T13:01:56.1979603Z     
2026-02-14T13:01:56.1979874Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.1980236Z                             do_blocks = []
2026-02-14T13:01:56.1980499Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.1980752Z     
2026-02-14T13:01:56.1980930Z                             def replace_do_block(match):
2026-02-14T13:01:56.1981488Z                                 block = match.group(0)
2026-02-14T13:01:56.1981803Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.1982133Z                                 do_blocks.append(block)
2026-02-14T13:01:56.1982404Z                                 return placeholder
2026-02-14T13:01:56.1982638Z     
2026-02-14T13:01:56.1982946Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.1983396Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.1983670Z                                                     ^^
2026-02-14T13:01:56.1984025Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.1984489Z                             )
2026-02-14T13:01:56.1984734Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.1984977Z 
2026-02-14T13:01:56.1985081Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.1985463Z ____ ERROR at setup of TestCooldownLogic.test_force_start_bypasses_cooldown ____
2026-02-14T13:01:56.1985769Z 
2026-02-14T13:01:56.1986115Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.1986358Z 
2026-02-14T13:01:56.1986453Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.1986724Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.1986982Z         """
2026-02-14T13:01:56.1987214Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.1987495Z     
2026-02-14T13:01:56.1987717Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.1988061Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.1988342Z         """
2026-02-14T13:01:56.1988524Z         # Read schema and table creation scripts
2026-02-14T13:01:56.1988833Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.1989100Z     
2026-02-14T13:01:56.1989292Z         # Parse connection string to get database name
2026-02-14T13:01:56.1989869Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.1990269Z     
2026-02-14T13:01:56.1990536Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.1991439Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.1991838Z     
2026-02-14T13:01:56.1992057Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.1992400Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.1992669Z         if len(parts) >= 4:
2026-02-14T13:01:56.1992914Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.1993182Z         else:
2026-02-14T13:01:56.1993370Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.1993612Z     
2026-02-14T13:01:56.1993782Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.1994200Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.1994586Z         import time
2026-02-14T13:01:56.1994753Z     
2026-02-14T13:01:56.1994899Z         max_retries = 5
2026-02-14T13:01:56.1995087Z         retry_delay = 2
2026-02-14T13:01:56.1995263Z     
2026-02-14T13:01:56.1995425Z         for attempt in range(max_retries):
2026-02-14T13:01:56.1995658Z             try:
2026-02-14T13:01:56.1995856Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.1996150Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.1996407Z                 conn.autocommit = True
2026-02-14T13:01:56.1996633Z                 try:
2026-02-14T13:01:56.1996812Z                     cur = conn.cursor()
2026-02-14T13:01:56.1997160Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.1997533Z                     if not cur.fetchone():
2026-02-14T13:01:56.1997844Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.1998213Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.1998489Z                     cur.close()
2026-02-14T13:01:56.1998696Z                 finally:
2026-02-14T13:01:56.1998888Z                     conn.close()
2026-02-14T13:01:56.1999095Z                 break  # Success
2026-02-14T13:01:56.1999421Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.1999790Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2000033Z                     print(
2026-02-14T13:01:56.2000374Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2000763Z                     )
2026-02-14T13:01:56.2000949Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2001476Z                 else:
2026-02-14T13:01:56.2001798Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2002285Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2002640Z                     pass
2026-02-14T13:01:56.2002872Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2003164Z                 break  # Already exists
2026-02-14T13:01:56.2003377Z     
2026-02-14T13:01:56.2003686Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2004180Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2004592Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2004868Z     
2026-02-14T13:01:56.2005018Z         close_all_pools()
2026-02-14T13:01:56.2005209Z     
2026-02-14T13:01:56.2005401Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2005769Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2006308Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2006627Z             conn.autocommit = True
2026-02-14T13:01:56.2006858Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2007315Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2007699Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2007944Z                 cur.execute(
2026-02-14T13:01:56.2008139Z                     """
2026-02-14T13:01:56.2008344Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2008610Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2008865Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2009138Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2009373Z                     """
2026-02-14T13:01:56.2009547Z                 )
2026-02-14T13:01:56.2009708Z     
2026-02-14T13:01:56.2009978Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2010453Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2010795Z                 try:
2026-02-14T13:01:56.2011186Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2011476Z                     cur.execute("""
2026-02-14T13:01:56.2011701Z                         DO $$
2026-02-14T13:01:56.2011899Z                         DECLARE
2026-02-14T13:01:56.2012101Z                             r RECORD;
2026-02-14T13:01:56.2012319Z                         BEGIN
2026-02-14T13:01:56.2012516Z                             FOR r IN (
2026-02-14T13:01:56.2012768Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2013038Z                                 FROM pg_views
2026-02-14T13:01:56.2013332Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2013623Z                             )
2026-02-14T13:01:56.2013823Z                             LOOP
2026-02-14T13:01:56.2014272Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2014748Z                             END LOOP;
2026-02-14T13:01:56.2014970Z                         END $$;
2026-02-14T13:01:56.2015161Z                     """)
2026-02-14T13:01:56.2015353Z                     # Drop tables
2026-02-14T13:01:56.2015562Z                     cur.execute("""
2026-02-14T13:01:56.2015779Z                         DO $$
2026-02-14T13:01:56.2015966Z                         DECLARE
2026-02-14T13:01:56.2016166Z                             r RECORD;
2026-02-14T13:01:56.2016380Z                         BEGIN
2026-02-14T13:01:56.2016574Z                             FOR r IN (
2026-02-14T13:01:56.2016826Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2017099Z                                 FROM pg_tables
2026-02-14T13:01:56.2017392Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2017680Z                             )
2026-02-14T13:01:56.2017878Z                             LOOP
2026-02-14T13:01:56.2018328Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2018807Z                             END LOOP;
2026-02-14T13:01:56.2019018Z                         END $$;
2026-02-14T13:01:56.2019203Z                     """)
2026-02-14T13:01:56.2019404Z                 except psycopg2.Error:
2026-02-14T13:01:56.2019727Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2020069Z                     pass
2026-02-14T13:01:56.2020238Z     
2026-02-14T13:01:56.2020494Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2021004Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2021582Z                 if init_dir.exists():
2026-02-14T13:01:56.2021844Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2022257Z                     for script_path in scripts:
2026-02-14T13:01:56.2022555Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2022844Z                             sql = f.read()
2026-02-14T13:01:56.2023206Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2023644Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2023947Z                             statements = []
2026-02-14T13:01:56.2024169Z     
2026-02-14T13:01:56.2024425Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2024783Z                             do_blocks = []
2026-02-14T13:01:56.2025040Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2025290Z     
2026-02-14T13:01:56.2025463Z                             def replace_do_block(match):
2026-02-14T13:01:56.2025746Z                                 block = match.group(0)
2026-02-14T13:01:56.2026055Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2026373Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2026642Z                                 return placeholder
2026-02-14T13:01:56.2026867Z     
2026-02-14T13:01:56.2027059Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2027363Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2027633Z                                                     ^^
2026-02-14T13:01:56.2027991Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2028344Z                             )
2026-02-14T13:01:56.2028579Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2028778Z 
2026-02-14T13:01:56.2028882Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2029286Z ___ ERROR at setup of TestCooldownLogic.test_cooldown_calculation_edge_cases ___
2026-02-14T13:01:56.2029587Z 
2026-02-14T13:01:56.2029943Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2030172Z 
2026-02-14T13:01:56.2030270Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2030536Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2030790Z         """
2026-02-14T13:01:56.2031016Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2031569Z     
2026-02-14T13:01:56.2031784Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2032135Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2032413Z         """
2026-02-14T13:01:56.2032597Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2032906Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2033173Z     
2026-02-14T13:01:56.2033359Z         # Parse connection string to get database name
2026-02-14T13:01:56.2033793Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2034189Z     
2026-02-14T13:01:56.2034450Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2034953Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2035339Z     
2026-02-14T13:01:56.2035552Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2035888Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2036149Z         if len(parts) >= 4:
2026-02-14T13:01:56.2036528Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2036798Z         else:
2026-02-14T13:01:56.2036997Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2037242Z     
2026-02-14T13:01:56.2037418Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2037940Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2038457Z         import time
2026-02-14T13:01:56.2038713Z     
2026-02-14T13:01:56.2038944Z         max_retries = 5
2026-02-14T13:01:56.2039270Z         retry_delay = 2
2026-02-14T13:01:56.2039449Z     
2026-02-14T13:01:56.2039620Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2040106Z             try:
2026-02-14T13:01:56.2040312Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2040645Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2040907Z                 conn.autocommit = True
2026-02-14T13:01:56.2041393Z                 try:
2026-02-14T13:01:56.2041579Z                     cur = conn.cursor()
2026-02-14T13:01:56.2041929Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2042290Z                     if not cur.fetchone():
2026-02-14T13:01:56.2042608Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2042978Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2043259Z                     cur.close()
2026-02-14T13:01:56.2043464Z                 finally:
2026-02-14T13:01:56.2043652Z                     conn.close()
2026-02-14T13:01:56.2043862Z                 break  # Success
2026-02-14T13:01:56.2044186Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2044562Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2044803Z                     print(
2026-02-14T13:01:56.2045156Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2045541Z                     )
2026-02-14T13:01:56.2045732Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2045966Z                 else:
2026-02-14T13:01:56.2046281Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2046766Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2047114Z                     pass
2026-02-14T13:01:56.2047347Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2047629Z                 break  # Already exists
2026-02-14T13:01:56.2047839Z     
2026-02-14T13:01:56.2048141Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2048638Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2049054Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2049330Z     
2026-02-14T13:01:56.2049484Z         close_all_pools()
2026-02-14T13:01:56.2049660Z     
2026-02-14T13:01:56.2049857Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2050227Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2050623Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2050931Z             conn.autocommit = True
2026-02-14T13:01:56.2051380Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2051741Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2052126Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2052374Z                 cur.execute(
2026-02-14T13:01:56.2052573Z                     """
2026-02-14T13:01:56.2052781Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2053245Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2053519Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2053797Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2054035Z                     """
2026-02-14T13:01:56.2054318Z                 )
2026-02-14T13:01:56.2054470Z     
2026-02-14T13:01:56.2054744Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2055216Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2055560Z                 try:
2026-02-14T13:01:56.2055787Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2056071Z                     cur.execute("""
2026-02-14T13:01:56.2056292Z                         DO $$
2026-02-14T13:01:56.2056489Z                         DECLARE
2026-02-14T13:01:56.2056696Z                             r RECORD;
2026-02-14T13:01:56.2056909Z                         BEGIN
2026-02-14T13:01:56.2057113Z                             FOR r IN (
2026-02-14T13:01:56.2057377Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2057646Z                                 FROM pg_views
2026-02-14T13:01:56.2057945Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2058238Z                             )
2026-02-14T13:01:56.2058438Z                             LOOP
2026-02-14T13:01:56.2058882Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2059357Z                             END LOOP;
2026-02-14T13:01:56.2059578Z                         END $$;
2026-02-14T13:01:56.2059771Z                     """)
2026-02-14T13:01:56.2059965Z                     # Drop tables
2026-02-14T13:01:56.2060174Z                     cur.execute("""
2026-02-14T13:01:56.2060391Z                         DO $$
2026-02-14T13:01:56.2060586Z                         DECLARE
2026-02-14T13:01:56.2060789Z                             r RECORD;
2026-02-14T13:01:56.2060999Z                         BEGIN
2026-02-14T13:01:56.2061338Z                             FOR r IN (
2026-02-14T13:01:56.2061596Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2061869Z                                 FROM pg_tables
2026-02-14T13:01:56.2062159Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2062444Z                             )
2026-02-14T13:01:56.2062640Z                             LOOP
2026-02-14T13:01:56.2063083Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2063565Z                             END LOOP;
2026-02-14T13:01:56.2063780Z                         END $$;
2026-02-14T13:01:56.2063968Z                     """)
2026-02-14T13:01:56.2064174Z                 except psycopg2.Error:
2026-02-14T13:01:56.2064503Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2064848Z                     pass
2026-02-14T13:01:56.2065019Z     
2026-02-14T13:01:56.2065279Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2065660Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2065937Z                 if init_dir.exists():
2026-02-14T13:01:56.2066193Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2066473Z                     for script_path in scripts:
2026-02-14T13:01:56.2066766Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2067056Z                             sql = f.read()
2026-02-14T13:01:56.2067429Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2067999Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2068318Z                             statements = []
2026-02-14T13:01:56.2068537Z     
2026-02-14T13:01:56.2068791Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2069250Z                             do_blocks = []
2026-02-14T13:01:56.2069502Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2069755Z     
2026-02-14T13:01:56.2069930Z                             def replace_do_block(match):
2026-02-14T13:01:56.2070208Z                                 block = match.group(0)
2026-02-14T13:01:56.2070512Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2070837Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2071356Z                                 return placeholder
2026-02-14T13:01:56.2071593Z     
2026-02-14T13:01:56.2071792Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2072089Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2072362Z                                                     ^^
2026-02-14T13:01:56.2072712Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2073078Z                             )
2026-02-14T13:01:56.2073313Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2073513Z 
2026-02-14T13:01:56.2073614Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2073993Z _____ ERROR at setup of TestCooldownLogic.test_status_derived_from_metrics _____
2026-02-14T13:01:56.2074290Z 
2026-02-14T13:01:56.2074651Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2074883Z 
2026-02-14T13:01:56.2074980Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2075244Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2075495Z         """
2026-02-14T13:01:56.2075720Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2076009Z     
2026-02-14T13:01:56.2076216Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2076564Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2076868Z         """
2026-02-14T13:01:56.2077053Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2077358Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2077628Z     
2026-02-14T13:01:56.2077817Z         # Parse connection string to get database name
2026-02-14T13:01:56.2078247Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2078643Z     
2026-02-14T13:01:56.2078896Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2079410Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2079797Z     
2026-02-14T13:01:56.2080013Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2080354Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2080620Z         if len(parts) >= 4:
2026-02-14T13:01:56.2080873Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2081246Z         else:
2026-02-14T13:01:56.2081445Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2081686Z     
2026-02-14T13:01:56.2081862Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2082277Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2082663Z         import time
2026-02-14T13:01:56.2082827Z     
2026-02-14T13:01:56.2082970Z         max_retries = 5
2026-02-14T13:01:56.2083155Z         retry_delay = 2
2026-02-14T13:01:56.2083321Z     
2026-02-14T13:01:56.2083620Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2083853Z             try:
2026-02-14T13:01:56.2084054Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2084330Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2084696Z                 conn.autocommit = True
2026-02-14T13:01:56.2084917Z                 try:
2026-02-14T13:01:56.2085094Z                     cur = conn.cursor()
2026-02-14T13:01:56.2085440Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2085806Z                     if not cur.fetchone():
2026-02-14T13:01:56.2086123Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2086490Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2086770Z                     cur.close()
2026-02-14T13:01:56.2086969Z                 finally:
2026-02-14T13:01:56.2087154Z                     conn.close()
2026-02-14T13:01:56.2087377Z                 break  # Success
2026-02-14T13:01:56.2087698Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2088088Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2088324Z                     print(
2026-02-14T13:01:56.2088674Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2089056Z                     )
2026-02-14T13:01:56.2089251Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2089483Z                 else:
2026-02-14T13:01:56.2089793Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2090285Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2090630Z                     pass
2026-02-14T13:01:56.2090864Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2091367Z                 break  # Already exists
2026-02-14T13:01:56.2091591Z     
2026-02-14T13:01:56.2091895Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2092383Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2092804Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2093079Z     
2026-02-14T13:01:56.2093232Z         close_all_pools()
2026-02-14T13:01:56.2093409Z     
2026-02-14T13:01:56.2093606Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2093967Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2094369Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2094676Z             conn.autocommit = True
2026-02-14T13:01:56.2094904Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2095363Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2095964Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2096218Z                 cur.execute(
2026-02-14T13:01:56.2096407Z                     """
2026-02-14T13:01:56.2096619Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2096892Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2097145Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2097418Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2097652Z                     """
2026-02-14T13:01:56.2097830Z                 )
2026-02-14T13:01:56.2097983Z     
2026-02-14T13:01:56.2098253Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2098717Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2099068Z                 try:
2026-02-14T13:01:56.2099291Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2099726Z                     cur.execute("""
2026-02-14T13:01:56.2099953Z                         DO $$
2026-02-14T13:01:56.2100149Z                         DECLARE
2026-02-14T13:01:56.2100354Z                             r RECORD;
2026-02-14T13:01:56.2100676Z                         BEGIN
2026-02-14T13:01:56.2100878Z                             FOR r IN (
2026-02-14T13:01:56.2101385Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2101668Z                                 FROM pg_views
2026-02-14T13:01:56.2101961Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2102250Z                             )
2026-02-14T13:01:56.2102449Z                             LOOP
2026-02-14T13:01:56.2103009Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2103804Z                             END LOOP;
2026-02-14T13:01:56.2104096Z                         END $$;
2026-02-14T13:01:56.2104451Z                     """)
2026-02-14T13:01:56.2104804Z                     # Drop tables
2026-02-14T13:01:56.2105091Z                     cur.execute("""
2026-02-14T13:01:56.2105435Z                         DO $$
2026-02-14T13:01:56.2105730Z                         DECLARE
2026-02-14T13:01:56.2106060Z                             r RECORD;
2026-02-14T13:01:56.2106373Z                         BEGIN
2026-02-14T13:01:56.2106714Z                             FOR r IN (
2026-02-14T13:01:56.2107054Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2107451Z                                 FROM pg_tables
2026-02-14T13:01:56.2107884Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2108263Z                             )
2026-02-14T13:01:56.2108602Z                             LOOP
2026-02-14T13:01:56.2109107Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2109764Z                             END LOOP;
2026-02-14T13:01:56.2110093Z                         END $$;
2026-02-14T13:01:56.2110338Z                     """)
2026-02-14T13:01:56.2110728Z                 except psycopg2.Error:
2026-02-14T13:01:56.2111522Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2112038Z                     pass
2026-02-14T13:01:56.2112384Z     
2026-02-14T13:01:56.2112757Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2113206Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2113651Z                 if init_dir.exists():
2026-02-14T13:01:56.2114059Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2114418Z                     for script_path in scripts:
2026-02-14T13:01:56.2114886Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2115251Z                             sql = f.read()
2026-02-14T13:01:56.2115728Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2116327Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2116739Z                             statements = []
2026-02-14T13:01:56.2117070Z     
2026-02-14T13:01:56.2117433Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2117911Z                             do_blocks = []
2026-02-14T13:01:56.2118236Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2118626Z     
2026-02-14T13:01:56.2118969Z                             def replace_do_block(match):
2026-02-14T13:01:56.2119312Z                                 block = match.group(0)
2026-02-14T13:01:56.2119904Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2120330Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2120720Z                                 return placeholder
2026-02-14T13:01:56.2121005Z     
2026-02-14T13:01:56.2121746Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2122178Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2122508Z                                                     ^^
2026-02-14T13:01:56.2123057Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2123493Z                             )
2026-02-14T13:01:56.2123879Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2124166Z 
2026-02-14T13:01:56.2124364Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2124821Z _ ERROR at setup of TestCooldownLogic.test_concurrent_triggers_different_users _
2026-02-14T13:01:56.2125162Z 
2026-02-14T13:01:56.2125559Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2125949Z 
2026-02-14T13:01:56.2126081Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2126462Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2126802Z         """
2026-02-14T13:01:56.2127212Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2127568Z     
2026-02-14T13:01:56.2127877Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2128352Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2128740Z         """
2026-02-14T13:01:56.2129027Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2129499Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2129884Z     
2026-02-14T13:01:56.2130145Z         # Parse connection string to get database name
2026-02-14T13:01:56.2130766Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2131539Z     
2026-02-14T13:01:56.2131955Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2132589Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2133111Z     
2026-02-14T13:01:56.2133441Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2133908Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2134309Z         if len(parts) >= 4:
2026-02-14T13:01:56.2134663Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2135075Z         else:
2026-02-14T13:01:56.2135366Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2135720Z     
2026-02-14T13:01:56.2136047Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2136551Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2137088Z         import time
2026-02-14T13:01:56.2137304Z     
2026-02-14T13:01:56.2137634Z         max_retries = 5
2026-02-14T13:01:56.2137739Z         retry_delay = 2
2026-02-14T13:01:56.2137840Z     
2026-02-14T13:01:56.2138007Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2138090Z             try:
2026-02-14T13:01:56.2138277Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2138473Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2138624Z                 conn.autocommit = True
2026-02-14T13:01:56.2138729Z                 try:
2026-02-14T13:01:56.2138845Z                     cur = conn.cursor()
2026-02-14T13:01:56.2139098Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2139263Z                     if not cur.fetchone():
2026-02-14T13:01:56.2139609Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2139815Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2139926Z                     cur.close()
2026-02-14T13:01:56.2140031Z                 finally:
2026-02-14T13:01:56.2140271Z                     conn.close()
2026-02-14T13:01:56.2140439Z                 break  # Success
2026-02-14T13:01:56.2140720Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2140888Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2140996Z                     print(
2026-02-14T13:01:56.2141396Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2141499Z                     )
2026-02-14T13:01:56.2141703Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2141824Z                 else:
2026-02-14T13:01:56.2142068Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2142329Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2142434Z                     pass
2026-02-14T13:01:56.2142586Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2142776Z                 break  # Already exists
2026-02-14T13:01:56.2142922Z     
2026-02-14T13:01:56.2143178Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2143438Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2143608Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2143702Z     
2026-02-14T13:01:56.2143795Z         close_all_pools()
2026-02-14T13:01:56.2143992Z     
2026-02-14T13:01:56.2144151Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2144351Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2144573Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2144695Z             conn.autocommit = True
2026-02-14T13:01:56.2144794Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2145163Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2145292Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2145403Z                 cur.execute(
2026-02-14T13:01:56.2145505Z                     """
2026-02-14T13:01:56.2145679Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2145778Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2145961Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2146147Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2146248Z                     """
2026-02-14T13:01:56.2146345Z                 )
2026-02-14T13:01:56.2146477Z     
2026-02-14T13:01:56.2146689Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2146992Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2147153Z                 try:
2026-02-14T13:01:56.2147312Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2147424Z                     cur.execute("""
2026-02-14T13:01:56.2147529Z                         DO $$
2026-02-14T13:01:56.2147662Z                         DECLARE
2026-02-14T13:01:56.2147818Z                             r RECORD;
2026-02-14T13:01:56.2147938Z                         BEGIN
2026-02-14T13:01:56.2148087Z                             FOR r IN (
2026-02-14T13:01:56.2148225Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2148343Z                                 FROM pg_views
2026-02-14T13:01:56.2148564Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2148845Z                             )
2026-02-14T13:01:56.2148978Z                             LOOP
2026-02-14T13:01:56.2149334Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2149614Z                             END LOOP;
2026-02-14T13:01:56.2149718Z                         END $$;
2026-02-14T13:01:56.2149820Z                     """)
2026-02-14T13:01:56.2150013Z                     # Drop tables
2026-02-14T13:01:56.2150144Z                     cur.execute("""
2026-02-14T13:01:56.2150246Z                         DO $$
2026-02-14T13:01:56.2150456Z                         DECLARE
2026-02-14T13:01:56.2150563Z                             r RECORD;
2026-02-14T13:01:56.2150664Z                         BEGIN
2026-02-14T13:01:56.2150753Z                             FOR r IN (
2026-02-14T13:01:56.2151003Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2151487Z                                 FROM pg_tables
2026-02-14T13:01:56.2151733Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2151883Z                             )
2026-02-14T13:01:56.2151989Z                             LOOP
2026-02-14T13:01:56.2152334Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2152579Z                             END LOOP;
2026-02-14T13:01:56.2152684Z                         END $$;
2026-02-14T13:01:56.2152785Z                     """)
2026-02-14T13:01:56.2152982Z                 except psycopg2.Error:
2026-02-14T13:01:56.2153199Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2153287Z                     pass
2026-02-14T13:01:56.2153442Z     
2026-02-14T13:01:56.2153711Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2153866Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2153980Z                 if init_dir.exists():
2026-02-14T13:01:56.2154160Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2154273Z                     for script_path in scripts:
2026-02-14T13:01:56.2154485Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2154656Z                             sql = f.read()
2026-02-14T13:01:56.2154984Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2155153Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2155306Z                             statements = []
2026-02-14T13:01:56.2155384Z     
2026-02-14T13:01:56.2155655Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2155785Z                             do_blocks = []
2026-02-14T13:01:56.2155969Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2156064Z     
2026-02-14T13:01:56.2156199Z                             def replace_do_block(match):
2026-02-14T13:01:56.2156350Z                                 block = match.group(0)
2026-02-14T13:01:56.2156564Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2156715Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2156909Z                                 return placeholder
2026-02-14T13:01:56.2157004Z     
2026-02-14T13:01:56.2157152Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2157286Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2157472Z                                                     ^^
2026-02-14T13:01:56.2157715Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2157957Z                             )
2026-02-14T13:01:56.2158149Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2158156Z 
2026-02-14T13:01:56.2158294Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2158628Z ____ ERROR at setup of TestCooldownLogic.test_cooldown_with_timezone_issues ____
2026-02-14T13:01:56.2158634Z 
2026-02-14T13:01:56.2159072Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2159079Z 
2026-02-14T13:01:56.2159302Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2159446Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2159544Z         """
2026-02-14T13:01:56.2159759Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2159836Z     
2026-02-14T13:01:56.2160055Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2160235Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2160371Z         """
2026-02-14T13:01:56.2160510Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2160675Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2160771Z     
2026-02-14T13:01:56.2160981Z         # Parse connection string to get database name
2026-02-14T13:01:56.2172932Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2173019Z     
2026-02-14T13:01:56.2173234Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2173483Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2173542Z     
2026-02-14T13:01:56.2173696Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2173820Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2173901Z         if len(parts) >= 4:
2026-02-14T13:01:56.2174034Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2174099Z         else:
2026-02-14T13:01:56.2174208Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2174265Z     
2026-02-14T13:01:56.2174361Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2174602Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2174669Z         import time
2026-02-14T13:01:56.2174728Z     
2026-02-14T13:01:56.2174807Z         max_retries = 5
2026-02-14T13:01:56.2174874Z         retry_delay = 2
2026-02-14T13:01:56.2174935Z     
2026-02-14T13:01:56.2175026Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2175096Z             try:
2026-02-14T13:01:56.2175204Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2175301Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2175392Z                 conn.autocommit = True
2026-02-14T13:01:56.2175455Z                 try:
2026-02-14T13:01:56.2175537Z                     cur = conn.cursor()
2026-02-14T13:01:56.2175730Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2175819Z                     if not cur.fetchone():
2026-02-14T13:01:56.2175975Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2176092Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2176174Z                     cur.close()
2026-02-14T13:01:56.2176244Z                 finally:
2026-02-14T13:01:56.2176316Z                     conn.close()
2026-02-14T13:01:56.2176393Z                 break  # Success
2026-02-14T13:01:56.2176585Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2176728Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2176799Z                     print(
2026-02-14T13:01:56.2177263Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2177338Z                     )
2026-02-14T13:01:56.2177424Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2177497Z                 else:
2026-02-14T13:01:56.2177817Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2178004Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2178081Z                     pass
2026-02-14T13:01:56.2178202Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2178283Z                 break  # Already exists
2026-02-14T13:01:56.2178342Z     
2026-02-14T13:01:56.2178576Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2178764Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2178904Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2178970Z     
2026-02-14T13:01:56.2179043Z         close_all_pools()
2026-02-14T13:01:56.2179102Z     
2026-02-14T13:01:56.2179229Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2179405Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2179557Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2179640Z             conn.autocommit = True
2026-02-14T13:01:56.2179728Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2179926Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2180019Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2180100Z                 cur.execute(
2026-02-14T13:01:56.2180167Z                     """
2026-02-14T13:01:56.2180265Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2180353Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2180454Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2180547Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2180614Z                     """
2026-02-14T13:01:56.2180681Z                 )
2026-02-14T13:01:56.2180742Z     
2026-02-14T13:01:56.2180939Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2181411Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2181484Z                 try:
2026-02-14T13:01:56.2181607Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2181684Z                     cur.execute("""
2026-02-14T13:01:56.2181762Z                         DO $$
2026-02-14T13:01:56.2181830Z                         DECLARE
2026-02-14T13:01:56.2181903Z                             r RECORD;
2026-02-14T13:01:56.2181975Z                         BEGIN
2026-02-14T13:01:56.2182055Z                             FOR r IN (
2026-02-14T13:01:56.2182158Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2182249Z                                 FROM pg_views
2026-02-14T13:01:56.2182379Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2182448Z                             )
2026-02-14T13:01:56.2182518Z                             LOOP
2026-02-14T13:01:56.2182842Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2182914Z                             END LOOP;
2026-02-14T13:01:56.2182981Z                         END $$;
2026-02-14T13:01:56.2183054Z                     """)
2026-02-14T13:01:56.2183124Z                     # Drop tables
2026-02-14T13:01:56.2183196Z                     cur.execute("""
2026-02-14T13:01:56.2183268Z                         DO $$
2026-02-14T13:01:56.2183460Z                         DECLARE
2026-02-14T13:01:56.2183536Z                             r RECORD;
2026-02-14T13:01:56.2183601Z                         BEGIN
2026-02-14T13:01:56.2183679Z                             FOR r IN (
2026-02-14T13:01:56.2183782Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2183972Z                                 FROM pg_tables
2026-02-14T13:01:56.2184106Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2184174Z                             )
2026-02-14T13:01:56.2184242Z                             LOOP
2026-02-14T13:01:56.2184565Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2184640Z                             END LOOP;
2026-02-14T13:01:56.2184705Z                         END $$;
2026-02-14T13:01:56.2184770Z                     """)
2026-02-14T13:01:56.2184859Z                 except psycopg2.Error:
2026-02-14T13:01:56.2185044Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2185113Z                     pass
2026-02-14T13:01:56.2185178Z     
2026-02-14T13:01:56.2185354Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2185468Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2185551Z                 if init_dir.exists():
2026-02-14T13:01:56.2185657Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2185747Z                     for script_path in scripts:
2026-02-14T13:01:56.2185873Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2185958Z                             sql = f.read()
2026-02-14T13:01:56.2186165Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2186299Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2186386Z                             statements = []
2026-02-14T13:01:56.2186444Z     
2026-02-14T13:01:56.2186623Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2186708Z                             do_blocks = []
2026-02-14T13:01:56.2186810Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2186867Z     
2026-02-14T13:01:56.2186964Z                             def replace_do_block(match):
2026-02-14T13:01:56.2187062Z                                 block = match.group(0)
2026-02-14T13:01:56.2187190Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2187287Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2187381Z                                 return placeholder
2026-02-14T13:01:56.2187438Z     
2026-02-14T13:01:56.2187548Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2187658Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2187742Z                                                     ^^
2026-02-14T13:01:56.2187929Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2188001Z                             )
2026-02-14T13:01:56.2188117Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2188125Z 
2026-02-14T13:01:56.2188227Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2188424Z ____ ERROR at setup of TestCooldownLogic.test_cooldown_reset_on_force_start ____
2026-02-14T13:01:56.2188430Z 
2026-02-14T13:01:56.2188782Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2188787Z 
2026-02-14T13:01:56.2188890Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2188998Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2189062Z         """
2026-02-14T13:01:56.2189314Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2189375Z     
2026-02-14T13:01:56.2189513Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2189640Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2189784Z         """
2026-02-14T13:01:56.2189879Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2190007Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2190078Z     
2026-02-14T13:01:56.2190185Z         # Parse connection string to get database name
2026-02-14T13:01:56.2190435Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2190502Z     
2026-02-14T13:01:56.2190688Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2190919Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2190977Z     
2026-02-14T13:01:56.2191433Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2191606Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2191695Z         if len(parts) >= 4:
2026-02-14T13:01:56.2191826Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2191891Z         else:
2026-02-14T13:01:56.2191992Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2192058Z     
2026-02-14T13:01:56.2192153Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2192387Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2192452Z         import time
2026-02-14T13:01:56.2192516Z     
2026-02-14T13:01:56.2192585Z         max_retries = 5
2026-02-14T13:01:56.2192653Z         retry_delay = 2
2026-02-14T13:01:56.2192716Z     
2026-02-14T13:01:56.2192806Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2192869Z             try:
2026-02-14T13:01:56.2192971Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2193076Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2193163Z                 conn.autocommit = True
2026-02-14T13:01:56.2193227Z                 try:
2026-02-14T13:01:56.2193310Z                     cur = conn.cursor()
2026-02-14T13:01:56.2193498Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2193579Z                     if not cur.fetchone():
2026-02-14T13:01:56.2193736Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2193852Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2193928Z                     cur.close()
2026-02-14T13:01:56.2193994Z                 finally:
2026-02-14T13:01:56.2194074Z                     conn.close()
2026-02-14T13:01:56.2194147Z                 break  # Success
2026-02-14T13:01:56.2194335Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2194431Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2194502Z                     print(
2026-02-14T13:01:56.2194722Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2194793Z                     )
2026-02-14T13:01:56.2194879Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2194944Z                 else:
2026-02-14T13:01:56.2195148Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2195337Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2195408Z                     pass
2026-02-14T13:01:56.2195522Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2195608Z                 break  # Already exists
2026-02-14T13:01:56.2195800Z     
2026-02-14T13:01:56.2196026Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2196218Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2196455Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2196512Z     
2026-02-14T13:01:56.2196585Z         close_all_pools()
2026-02-14T13:01:56.2196650Z     
2026-02-14T13:01:56.2196766Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2196930Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2197079Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2197159Z             conn.autocommit = True
2026-02-14T13:01:56.2197238Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2197439Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2197537Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2197610Z                 cur.execute(
2026-02-14T13:01:56.2197675Z                     """
2026-02-14T13:01:56.2197779Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2197865Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2197961Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2198058Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2198122Z                     """
2026-02-14T13:01:56.2198183Z                 )
2026-02-14T13:01:56.2198239Z     
2026-02-14T13:01:56.2198436Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2198621Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2198685Z                 try:
2026-02-14T13:01:56.2198809Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2198889Z                     cur.execute("""
2026-02-14T13:01:56.2198958Z                         DO $$
2026-02-14T13:01:56.2199032Z                         DECLARE
2026-02-14T13:01:56.2199105Z                             r RECORD;
2026-02-14T13:01:56.2199175Z                         BEGIN
2026-02-14T13:01:56.2199251Z                             FOR r IN (
2026-02-14T13:01:56.2199357Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2199446Z                                 FROM pg_views
2026-02-14T13:01:56.2199573Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2199638Z                             )
2026-02-14T13:01:56.2199714Z                             LOOP
2026-02-14T13:01:56.2200022Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2200093Z                             END LOOP;
2026-02-14T13:01:56.2200163Z                         END $$;
2026-02-14T13:01:56.2200230Z                     """)
2026-02-14T13:01:56.2200300Z                     # Drop tables
2026-02-14T13:01:56.2200371Z                     cur.execute("""
2026-02-14T13:01:56.2200444Z                         DO $$
2026-02-14T13:01:56.2200508Z                         DECLARE
2026-02-14T13:01:56.2200577Z                             r RECORD;
2026-02-14T13:01:56.2200640Z                         BEGIN
2026-02-14T13:01:56.2200716Z                             FOR r IN (
2026-02-14T13:01:56.2200815Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2200896Z                                 FROM pg_tables
2026-02-14T13:01:56.2201239Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2201308Z                             )
2026-02-14T13:01:56.2201377Z                             LOOP
2026-02-14T13:01:56.2201832Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2201908Z                             END LOOP;
2026-02-14T13:01:56.2201976Z                         END $$;
2026-02-14T13:01:56.2202041Z                     """)
2026-02-14T13:01:56.2202228Z                 except psycopg2.Error:
2026-02-14T13:01:56.2202400Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2202467Z                     pass
2026-02-14T13:01:56.2202530Z     
2026-02-14T13:01:56.2202699Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2202809Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2202891Z                 if init_dir.exists():
2026-02-14T13:01:56.2202993Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2203083Z                     for script_path in scripts:
2026-02-14T13:01:56.2203209Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2203291Z                             sql = f.read()
2026-02-14T13:01:56.2203498Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2203633Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2203725Z                             statements = []
2026-02-14T13:01:56.2203781Z     
2026-02-14T13:01:56.2203956Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2204036Z                             do_blocks = []
2026-02-14T13:01:56.2204137Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2204193Z     
2026-02-14T13:01:56.2204297Z                             def replace_do_block(match):
2026-02-14T13:01:56.2204390Z                                 block = match.group(0)
2026-02-14T13:01:56.2204524Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2204623Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2204717Z                                 return placeholder
2026-02-14T13:01:56.2204774Z     
2026-02-14T13:01:56.2204884Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2204988Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2205069Z                                                     ^^
2026-02-14T13:01:56.2205258Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2205328Z                             )
2026-02-14T13:01:56.2205435Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2205441Z 
2026-02-14T13:01:56.2205540Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2205751Z _ ERROR at setup of TestTriggerLogicEdgeCases.test_invalid_campaign_id_handling _
2026-02-14T13:01:56.2205765Z 
2026-02-14T13:01:56.2206058Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2206062Z 
2026-02-14T13:01:56.2206160Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2206267Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2206332Z         """
2026-02-14T13:01:56.2206476Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2206534Z     
2026-02-14T13:01:56.2206670Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2206798Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2206857Z         """
2026-02-14T13:01:56.2206952Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2207077Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2207141Z     
2026-02-14T13:01:56.2207249Z         # Parse connection string to get database name
2026-02-14T13:01:56.2207582Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2207648Z     
2026-02-14T13:01:56.2207835Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2208138Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2208201Z     
2026-02-14T13:01:56.2208346Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2208456Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2208530Z         if len(parts) >= 4:
2026-02-14T13:01:56.2208654Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2208718Z         else:
2026-02-14T13:01:56.2208817Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2208881Z     
2026-02-14T13:01:56.2208978Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2209210Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2209282Z         import time
2026-02-14T13:01:56.2209339Z     
2026-02-14T13:01:56.2209407Z         max_retries = 5
2026-02-14T13:01:56.2209475Z         retry_delay = 2
2026-02-14T13:01:56.2209541Z     
2026-02-14T13:01:56.2209631Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2209692Z             try:
2026-02-14T13:01:56.2209801Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2209895Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2209976Z                 conn.autocommit = True
2026-02-14T13:01:56.2210041Z                 try:
2026-02-14T13:01:56.2210124Z                     cur = conn.cursor()
2026-02-14T13:01:56.2210315Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2210395Z                     if not cur.fetchone():
2026-02-14T13:01:56.2210560Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2210682Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2210756Z                     cur.close()
2026-02-14T13:01:56.2210828Z                 finally:
2026-02-14T13:01:56.2210905Z                     conn.close()
2026-02-14T13:01:56.2210975Z                 break  # Success
2026-02-14T13:01:56.2211426Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2211536Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2211608Z                     print(
2026-02-14T13:01:56.2211838Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2211907Z                     )
2026-02-14T13:01:56.2211992Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2212058Z                 else:
2026-02-14T13:01:56.2212277Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2212463Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2212532Z                     pass
2026-02-14T13:01:56.2212651Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2212741Z                 break  # Already exists
2026-02-14T13:01:56.2212798Z     
2026-02-14T13:01:56.2213017Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2213211Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2213343Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2213401Z     
2026-02-14T13:01:56.2213479Z         close_all_pools()
2026-02-14T13:01:56.2213537Z     
2026-02-14T13:01:56.2213655Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2213818Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2214095Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2214180Z             conn.autocommit = True
2026-02-14T13:01:56.2214261Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2214562Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2214654Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2214727Z                 cur.execute(
2026-02-14T13:01:56.2214791Z                     """
2026-02-14T13:01:56.2214894Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2214975Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2215071Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2215166Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2215229Z                     """
2026-02-14T13:01:56.2215288Z                 )
2026-02-14T13:01:56.2215349Z     
2026-02-14T13:01:56.2215540Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2215722Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2215784Z                 try:
2026-02-14T13:01:56.2215910Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2215984Z                     cur.execute("""
2026-02-14T13:01:56.2216055Z                         DO $$
2026-02-14T13:01:56.2216129Z                         DECLARE
2026-02-14T13:01:56.2216201Z                             r RECORD;
2026-02-14T13:01:56.2216266Z                         BEGIN
2026-02-14T13:01:56.2216343Z                             FOR r IN (
2026-02-14T13:01:56.2216446Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2216526Z                                 FROM pg_views
2026-02-14T13:01:56.2216654Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2216729Z                             )
2026-02-14T13:01:56.2216798Z                             LOOP
2026-02-14T13:01:56.2217109Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2217197Z                             END LOOP;
2026-02-14T13:01:56.2217272Z                         END $$;
2026-02-14T13:01:56.2217337Z                     """)
2026-02-14T13:01:56.2217408Z                     # Drop tables
2026-02-14T13:01:56.2217487Z                     cur.execute("""
2026-02-14T13:01:56.2217553Z                         DO $$
2026-02-14T13:01:56.2217619Z                         DECLARE
2026-02-14T13:01:56.2217688Z                             r RECORD;
2026-02-14T13:01:56.2217759Z                         BEGIN
2026-02-14T13:01:56.2217829Z                             FOR r IN (
2026-02-14T13:01:56.2217929Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2218019Z                                 FROM pg_tables
2026-02-14T13:01:56.2218143Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2218208Z                             )
2026-02-14T13:01:56.2218284Z                             LOOP
2026-02-14T13:01:56.2218600Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2218671Z                             END LOOP;
2026-02-14T13:01:56.2218737Z                         END $$;
2026-02-14T13:01:56.2218809Z                     """)
2026-02-14T13:01:56.2218891Z                 except psycopg2.Error:
2026-02-14T13:01:56.2219065Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2219138Z                     pass
2026-02-14T13:01:56.2219196Z     
2026-02-14T13:01:56.2219362Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2219562Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2219640Z                 if init_dir.exists():
2026-02-14T13:01:56.2219742Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2219830Z                     for script_path in scripts:
2026-02-14T13:01:56.2220081Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2220157Z                             sql = f.read()
2026-02-14T13:01:56.2220363Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2220496Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2220574Z                             statements = []
2026-02-14T13:01:56.2220631Z     
2026-02-14T13:01:56.2220811Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2220885Z                             do_blocks = []
2026-02-14T13:01:56.2220988Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2221166Z     
2026-02-14T13:01:56.2221269Z                             def replace_do_block(match):
2026-02-14T13:01:56.2221361Z                                 block = match.group(0)
2026-02-14T13:01:56.2221492Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2221595Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2221684Z                                 return placeholder
2026-02-14T13:01:56.2221741Z     
2026-02-14T13:01:56.2221854Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2221949Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2222028Z                                                     ^^
2026-02-14T13:01:56.2222215Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2222292Z                             )
2026-02-14T13:01:56.2222396Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2222401Z 
2026-02-14T13:01:56.2222499Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2222705Z _ ERROR at setup of TestTriggerLogicEdgeCases.test_missing_dag_run_id_handling _
2026-02-14T13:01:56.2222713Z 
2026-02-14T13:01:56.2222998Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2223003Z 
2026-02-14T13:01:56.2223089Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2223191Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2223256Z         """
2026-02-14T13:01:56.2223388Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2223445Z     
2026-02-14T13:01:56.2223574Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2223702Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2223760Z         """
2026-02-14T13:01:56.2223859Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2223988Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2224045Z     
2026-02-14T13:01:56.2224148Z         # Parse connection string to get database name
2026-02-14T13:01:56.2224396Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2224453Z     
2026-02-14T13:01:56.2224637Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2224861Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2224926Z     
2026-02-14T13:01:56.2225066Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2225172Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2225252Z         if len(parts) >= 4:
2026-02-14T13:01:56.2225593Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2225661Z         else:
2026-02-14T13:01:56.2225766Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2225822Z     
2026-02-14T13:01:56.2225918Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2226242Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2226314Z         import time
2026-02-14T13:01:56.2226373Z     
2026-02-14T13:01:56.2226443Z         max_retries = 5
2026-02-14T13:01:56.2226517Z         retry_delay = 2
2026-02-14T13:01:56.2226573Z     
2026-02-14T13:01:56.2226657Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2226720Z             try:
2026-02-14T13:01:56.2226824Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2226915Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2226995Z                 conn.autocommit = True
2026-02-14T13:01:56.2227063Z                 try:
2026-02-14T13:01:56.2227142Z                     cur = conn.cursor()
2026-02-14T13:01:56.2227330Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2227413Z                     if not cur.fetchone():
2026-02-14T13:01:56.2227565Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2227682Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2227751Z                     cur.close()
2026-02-14T13:01:56.2227824Z                 finally:
2026-02-14T13:01:56.2227895Z                     conn.close()
2026-02-14T13:01:56.2227966Z                 break  # Success
2026-02-14T13:01:56.2228161Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2228255Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2228325Z                     print(
2026-02-14T13:01:56.2228555Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2228620Z                     )
2026-02-14T13:01:56.2228707Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2228770Z                 else:
2026-02-14T13:01:56.2228985Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2229167Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2229236Z                     pass
2026-02-14T13:01:56.2229370Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2229447Z                 break  # Already exists
2026-02-14T13:01:56.2229508Z     
2026-02-14T13:01:56.2229728Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2229906Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2230042Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2230100Z     
2026-02-14T13:01:56.2230180Z         close_all_pools()
2026-02-14T13:01:56.2230237Z     
2026-02-14T13:01:56.2230355Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2230528Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2230667Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2230745Z             conn.autocommit = True
2026-02-14T13:01:56.2230828Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2231019Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2231408Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2231535Z                 cur.execute(
2026-02-14T13:01:56.2231606Z                     """
2026-02-14T13:01:56.2231705Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2231783Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2232011Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2232106Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2232169Z                     """
2026-02-14T13:01:56.2232237Z                 )
2026-02-14T13:01:56.2232395Z     
2026-02-14T13:01:56.2232586Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2232768Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2232836Z                 try:
2026-02-14T13:01:56.2232952Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2233030Z                     cur.execute("""
2026-02-14T13:01:56.2233103Z                         DO $$
2026-02-14T13:01:56.2233170Z                         DECLARE
2026-02-14T13:01:56.2233240Z                             r RECORD;
2026-02-14T13:01:56.2233306Z                         BEGIN
2026-02-14T13:01:56.2233387Z                             FOR r IN (
2026-02-14T13:01:56.2233486Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2233565Z                                 FROM pg_views
2026-02-14T13:01:56.2233696Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2233764Z                             )
2026-02-14T13:01:56.2233834Z                             LOOP
2026-02-14T13:01:56.2234157Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2234230Z                             END LOOP;
2026-02-14T13:01:56.2234297Z                         END $$;
2026-02-14T13:01:56.2234362Z                     """)
2026-02-14T13:01:56.2234438Z                     # Drop tables
2026-02-14T13:01:56.2234509Z                     cur.execute("""
2026-02-14T13:01:56.2234572Z                         DO $$
2026-02-14T13:01:56.2234644Z                         DECLARE
2026-02-14T13:01:56.2234715Z                             r RECORD;
2026-02-14T13:01:56.2234779Z                         BEGIN
2026-02-14T13:01:56.2234857Z                             FOR r IN (
2026-02-14T13:01:56.2234956Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2235044Z                                 FROM pg_tables
2026-02-14T13:01:56.2235168Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2235239Z                             )
2026-02-14T13:01:56.2235306Z                             LOOP
2026-02-14T13:01:56.2235621Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2235697Z                             END LOOP;
2026-02-14T13:01:56.2235764Z                         END $$;
2026-02-14T13:01:56.2235828Z                     """)
2026-02-14T13:01:56.2235916Z                 except psycopg2.Error:
2026-02-14T13:01:56.2236093Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2236161Z                     pass
2026-02-14T13:01:56.2236217Z     
2026-02-14T13:01:56.2236391Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2236505Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2236579Z                 if init_dir.exists():
2026-02-14T13:01:56.2236686Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2236774Z                     for script_path in scripts:
2026-02-14T13:01:56.2236898Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2236978Z                             sql = f.read()
2026-02-14T13:01:56.2237183Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2237397Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2237478Z                             statements = []
2026-02-14T13:01:56.2237541Z     
2026-02-14T13:01:56.2237719Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2237888Z                             do_blocks = []
2026-02-14T13:01:56.2237995Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2238051Z     
2026-02-14T13:01:56.2238145Z                             def replace_do_block(match):
2026-02-14T13:01:56.2238238Z                                 block = match.group(0)
2026-02-14T13:01:56.2238362Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2238456Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2238542Z                                 return placeholder
2026-02-14T13:01:56.2238607Z     
2026-02-14T13:01:56.2238713Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2238812Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2238898Z                                                     ^^
2026-02-14T13:01:56.2239083Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2239153Z                             )
2026-02-14T13:01:56.2239267Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2239274Z 
2026-02-14T13:01:56.2239375Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2239618Z _ ERROR at setup of TestTriggerLogicEdgeCases.test_concurrent_status_check_race_condition _
2026-02-14T13:01:56.2239623Z 
2026-02-14T13:01:56.2239923Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2239928Z 
2026-02-14T13:01:56.2240024Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2240129Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2240191Z         """
2026-02-14T13:01:56.2240327Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2240393Z     
2026-02-14T13:01:56.2240523Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2240647Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2240719Z         """
2026-02-14T13:01:56.2240814Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2240937Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2240997Z     
2026-02-14T13:01:56.2241277Z         # Parse connection string to get database name
2026-02-14T13:01:56.2241523Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2241582Z     
2026-02-14T13:01:56.2241773Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2242003Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2242062Z     
2026-02-14T13:01:56.2242207Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2242316Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2242396Z         if len(parts) >= 4:
2026-02-14T13:01:56.2242515Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2242581Z         else:
2026-02-14T13:01:56.2242678Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2242735Z     
2026-02-14T13:01:56.2242835Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2243059Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2243125Z         import time
2026-02-14T13:01:56.2243188Z     
2026-02-14T13:01:56.2243255Z         max_retries = 5
2026-02-14T13:01:56.2243320Z         retry_delay = 2
2026-02-14T13:01:56.2243378Z     
2026-02-14T13:01:56.2243591Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2243657Z             try:
2026-02-14T13:01:56.2243755Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2243854Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2244036Z                 conn.autocommit = True
2026-02-14T13:01:56.2244100Z                 try:
2026-02-14T13:01:56.2244177Z                     cur = conn.cursor()
2026-02-14T13:01:56.2244372Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2244451Z                     if not cur.fetchone():
2026-02-14T13:01:56.2244604Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2244725Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2244798Z                     cur.close()
2026-02-14T13:01:56.2244864Z                 finally:
2026-02-14T13:01:56.2244941Z                     conn.close()
2026-02-14T13:01:56.2245014Z                 break  # Success
2026-02-14T13:01:56.2245200Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2245288Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2245364Z                     print(
2026-02-14T13:01:56.2245579Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2245645Z                     )
2026-02-14T13:01:56.2245733Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2245796Z                 else:
2026-02-14T13:01:56.2245998Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2246188Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2246256Z                     pass
2026-02-14T13:01:56.2246372Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2246451Z                 break  # Already exists
2026-02-14T13:01:56.2246513Z     
2026-02-14T13:01:56.2246728Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2246906Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2247047Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2247103Z     
2026-02-14T13:01:56.2247175Z         close_all_pools()
2026-02-14T13:01:56.2247237Z     
2026-02-14T13:01:56.2247352Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2247513Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2247653Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2247741Z             conn.autocommit = True
2026-02-14T13:01:56.2247819Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2248014Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2248110Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2248182Z                 cur.execute(
2026-02-14T13:01:56.2248245Z                     """
2026-02-14T13:01:56.2248347Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2248429Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2248524Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2248610Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2248681Z                     """
2026-02-14T13:01:56.2248741Z                 )
2026-02-14T13:01:56.2248797Z     
2026-02-14T13:01:56.2248988Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2249171Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2249234Z                 try:
2026-02-14T13:01:56.2249452Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2249528Z                     cur.execute("""
2026-02-14T13:01:56.2249597Z                         DO $$
2026-02-14T13:01:56.2249662Z                         DECLARE
2026-02-14T13:01:56.2249739Z                             r RECORD;
2026-02-14T13:01:56.2249881Z                         BEGIN
2026-02-14T13:01:56.2249954Z                             FOR r IN (
2026-02-14T13:01:56.2250059Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2250139Z                                 FROM pg_views
2026-02-14T13:01:56.2250267Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2250333Z                             )
2026-02-14T13:01:56.2250409Z                             LOOP
2026-02-14T13:01:56.2250719Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2250790Z                             END LOOP;
2026-02-14T13:01:56.2250867Z                         END $$;
2026-02-14T13:01:56.2250932Z                     """)
2026-02-14T13:01:56.2251006Z                     # Drop tables
2026-02-14T13:01:56.2251266Z                     cur.execute("""
2026-02-14T13:01:56.2251368Z                         DO $$
2026-02-14T13:01:56.2251437Z                         DECLARE
2026-02-14T13:01:56.2251508Z                             r RECORD;
2026-02-14T13:01:56.2251582Z                         BEGIN
2026-02-14T13:01:56.2251653Z                             FOR r IN (
2026-02-14T13:01:56.2251751Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2251839Z                                 FROM pg_tables
2026-02-14T13:01:56.2251964Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2252028Z                             )
2026-02-14T13:01:56.2252102Z                             LOOP
2026-02-14T13:01:56.2252418Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2252489Z                             END LOOP;
2026-02-14T13:01:56.2252555Z                         END $$;
2026-02-14T13:01:56.2252631Z                     """)
2026-02-14T13:01:56.2252713Z                 except psycopg2.Error:
2026-02-14T13:01:56.2252884Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2252958Z                     pass
2026-02-14T13:01:56.2253015Z     
2026-02-14T13:01:56.2253181Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2253293Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2253367Z                 if init_dir.exists():
2026-02-14T13:01:56.2253470Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2253556Z                     for script_path in scripts:
2026-02-14T13:01:56.2253687Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2253762Z                             sql = f.read()
2026-02-14T13:01:56.2253966Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2254107Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2254182Z                             statements = []
2026-02-14T13:01:56.2254240Z     
2026-02-14T13:01:56.2254423Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2254496Z                             do_blocks = []
2026-02-14T13:01:56.2254598Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2254654Z     
2026-02-14T13:01:56.2254756Z                             def replace_do_block(match):
2026-02-14T13:01:56.2254844Z                                 block = match.group(0)
2026-02-14T13:01:56.2255091Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2255196Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2255282Z                                 return placeholder
2026-02-14T13:01:56.2255439Z     
2026-02-14T13:01:56.2255551Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2255647Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2255728Z                                                     ^^
2026-02-14T13:01:56.2255912Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2255984Z                             )
2026-02-14T13:01:56.2256090Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2256096Z 
2026-02-14T13:01:56.2256195Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2256419Z _ ERROR at setup of TestTriggerLogicEdgeCases.test_airflow_api_timeout_simulation _
2026-02-14T13:01:56.2256427Z 
2026-02-14T13:01:56.2256715Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2256721Z 
2026-02-14T13:01:56.2256808Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2256912Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2256980Z         """
2026-02-14T13:01:56.2257116Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2257172Z     
2026-02-14T13:01:56.2257307Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2257431Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2257489Z         """
2026-02-14T13:01:56.2257582Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2257718Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2257775Z     
2026-02-14T13:01:56.2257882Z         # Parse connection string to get database name
2026-02-14T13:01:56.2258129Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2258186Z     
2026-02-14T13:01:56.2258368Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2258602Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2258659Z     
2026-02-14T13:01:56.2258800Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2258906Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2258985Z         if len(parts) >= 4:
2026-02-14T13:01:56.2259103Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2259163Z         else:
2026-02-14T13:01:56.2259269Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2259326Z     
2026-02-14T13:01:56.2259421Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2259650Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2259721Z         import time
2026-02-14T13:01:56.2259779Z     
2026-02-14T13:01:56.2259846Z         max_retries = 5
2026-02-14T13:01:56.2259919Z         retry_delay = 2
2026-02-14T13:01:56.2259979Z     
2026-02-14T13:01:56.2260066Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2260126Z             try:
2026-02-14T13:01:56.2260230Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2260323Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2260402Z                 conn.autocommit = True
2026-02-14T13:01:56.2260470Z                 try:
2026-02-14T13:01:56.2260546Z                     cur = conn.cursor()
2026-02-14T13:01:56.2260740Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2260825Z                     if not cur.fetchone():
2026-02-14T13:01:56.2261298Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2261486Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2261568Z                     cur.close()
2026-02-14T13:01:56.2261637Z                 finally:
2026-02-14T13:01:56.2261822Z                     conn.close()
2026-02-14T13:01:56.2261894Z                 break  # Success
2026-02-14T13:01:56.2262098Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2262191Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2262260Z                     print(
2026-02-14T13:01:56.2262488Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2262553Z                     )
2026-02-14T13:01:56.2262639Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2262703Z                 else:
2026-02-14T13:01:56.2262920Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2263104Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2263172Z                     pass
2026-02-14T13:01:56.2263296Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2263378Z                 break  # Already exists
2026-02-14T13:01:56.2263436Z     
2026-02-14T13:01:56.2263667Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2263852Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2263984Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2264040Z     
2026-02-14T13:01:56.2264119Z         close_all_pools()
2026-02-14T13:01:56.2264178Z     
2026-02-14T13:01:56.2264296Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2264469Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2264608Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2264687Z             conn.autocommit = True
2026-02-14T13:01:56.2264768Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2264963Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2265053Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2265124Z                 cur.execute(
2026-02-14T13:01:56.2265193Z                     """
2026-02-14T13:01:56.2265291Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2265368Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2265467Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2265554Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2265616Z                     """
2026-02-14T13:01:56.2265681Z                 )
2026-02-14T13:01:56.2265737Z     
2026-02-14T13:01:56.2265932Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2266113Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2266183Z                 try:
2026-02-14T13:01:56.2266301Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2266374Z                     cur.execute("""
2026-02-14T13:01:56.2266450Z                         DO $$
2026-02-14T13:01:56.2266516Z                         DECLARE
2026-02-14T13:01:56.2266587Z                             r RECORD;
2026-02-14T13:01:56.2266657Z                         BEGIN
2026-02-14T13:01:56.2266729Z                             FOR r IN (
2026-02-14T13:01:56.2266828Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2266910Z                                 FROM pg_views
2026-02-14T13:01:56.2267041Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2267205Z                             )
2026-02-14T13:01:56.2267277Z                             LOOP
2026-02-14T13:01:56.2267605Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2267794Z                             END LOOP;
2026-02-14T13:01:56.2267860Z                         END $$;
2026-02-14T13:01:56.2267934Z                     """)
2026-02-14T13:01:56.2268005Z                     # Drop tables
2026-02-14T13:01:56.2268077Z                     cur.execute("""
2026-02-14T13:01:56.2268143Z                         DO $$
2026-02-14T13:01:56.2268213Z                         DECLARE
2026-02-14T13:01:56.2268282Z                             r RECORD;
2026-02-14T13:01:56.2268350Z                         BEGIN
2026-02-14T13:01:56.2268425Z                             FOR r IN (
2026-02-14T13:01:56.2268523Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2268608Z                                 FROM pg_tables
2026-02-14T13:01:56.2268730Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2268804Z                             )
2026-02-14T13:01:56.2268871Z                             LOOP
2026-02-14T13:01:56.2269188Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2269269Z                             END LOOP;
2026-02-14T13:01:56.2269334Z                         END $$;
2026-02-14T13:01:56.2269398Z                     """)
2026-02-14T13:01:56.2269484Z                 except psycopg2.Error:
2026-02-14T13:01:56.2269658Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2269726Z                     pass
2026-02-14T13:01:56.2269783Z     
2026-02-14T13:01:56.2269957Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2270071Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2270146Z                 if init_dir.exists():
2026-02-14T13:01:56.2270258Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2270351Z                     for script_path in scripts:
2026-02-14T13:01:56.2270476Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2270560Z                             sql = f.read()
2026-02-14T13:01:56.2270766Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2270895Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2270982Z                             statements = []
2026-02-14T13:01:56.2271244Z     
2026-02-14T13:01:56.2271527Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2271607Z                             do_blocks = []
2026-02-14T13:01:56.2271720Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2271780Z     
2026-02-14T13:01:56.2271875Z                             def replace_do_block(match):
2026-02-14T13:01:56.2271972Z                                 block = match.group(0)
2026-02-14T13:01:56.2272103Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2272200Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2272294Z                                 return placeholder
2026-02-14T13:01:56.2272352Z     
2026-02-14T13:01:56.2272460Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2272556Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2272644Z                                                     ^^
2026-02-14T13:01:56.2272829Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2273030Z                             )
2026-02-14T13:01:56.2273156Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2273162Z 
2026-02-14T13:01:56.2273264Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2273595Z _ ERROR at setup of TestTriggerLogicEdgeCases.test_airflow_connection_error_simulation _
2026-02-14T13:01:56.2273601Z 
2026-02-14T13:01:56.2273902Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2273907Z 
2026-02-14T13:01:56.2274002Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2274107Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2274167Z         """
2026-02-14T13:01:56.2274302Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2274366Z     
2026-02-14T13:01:56.2274497Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2274619Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2274687Z         """
2026-02-14T13:01:56.2274781Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2274905Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2274967Z     
2026-02-14T13:01:56.2275072Z         # Parse connection string to get database name
2026-02-14T13:01:56.2275319Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2275376Z     
2026-02-14T13:01:56.2275565Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2275789Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2275846Z     
2026-02-14T13:01:56.2275992Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2276097Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2276170Z         if len(parts) >= 4:
2026-02-14T13:01:56.2276293Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2276356Z         else:
2026-02-14T13:01:56.2276457Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2276513Z     
2026-02-14T13:01:56.2276610Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2276879Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2276946Z         import time
2026-02-14T13:01:56.2277007Z     
2026-02-14T13:01:56.2277075Z         max_retries = 5
2026-02-14T13:01:56.2277143Z         retry_delay = 2
2026-02-14T13:01:56.2277201Z     
2026-02-14T13:01:56.2277291Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2277352Z             try:
2026-02-14T13:01:56.2277450Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2277550Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2277628Z                 conn.autocommit = True
2026-02-14T13:01:56.2277694Z                 try:
2026-02-14T13:01:56.2277769Z                     cur = conn.cursor()
2026-02-14T13:01:56.2277963Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2278043Z                     if not cur.fetchone():
2026-02-14T13:01:56.2278196Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2278316Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2278386Z                     cur.close()
2026-02-14T13:01:56.2278452Z                 finally:
2026-02-14T13:01:56.2278530Z                     conn.close()
2026-02-14T13:01:56.2278601Z                 break  # Success
2026-02-14T13:01:56.2278787Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2278875Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2278949Z                     print(
2026-02-14T13:01:56.2279284Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2279350Z                     )
2026-02-14T13:01:56.2279438Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2279500Z                 else:
2026-02-14T13:01:56.2279783Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2279971Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2280037Z                     pass
2026-02-14T13:01:56.2280154Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2280236Z                 break  # Already exists
2026-02-14T13:01:56.2280294Z     
2026-02-14T13:01:56.2280506Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2280687Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2280825Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2280883Z     
2026-02-14T13:01:56.2280954Z         close_all_pools()
2026-02-14T13:01:56.2281015Z     
2026-02-14T13:01:56.2281415Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2281590Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2281727Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2281812Z             conn.autocommit = True
2026-02-14T13:01:56.2281891Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2282082Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2282179Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2282250Z                 cur.execute(
2026-02-14T13:01:56.2282313Z                     """
2026-02-14T13:01:56.2282412Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2282495Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2282588Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2282676Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2282747Z                     """
2026-02-14T13:01:56.2282809Z                 )
2026-02-14T13:01:56.2282869Z     
2026-02-14T13:01:56.2283062Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2283242Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2283305Z                 try:
2026-02-14T13:01:56.2283426Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2283501Z                     cur.execute("""
2026-02-14T13:01:56.2283571Z                         DO $$
2026-02-14T13:01:56.2283637Z                         DECLARE
2026-02-14T13:01:56.2283715Z                             r RECORD;
2026-02-14T13:01:56.2283782Z                         BEGIN
2026-02-14T13:01:56.2283856Z                             FOR r IN (
2026-02-14T13:01:56.2283961Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2284041Z                                 FROM pg_views
2026-02-14T13:01:56.2284166Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2284245Z                             )
2026-02-14T13:01:56.2284314Z                             LOOP
2026-02-14T13:01:56.2284621Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2284694Z                             END LOOP;
2026-02-14T13:01:56.2284773Z                         END $$;
2026-02-14T13:01:56.2284836Z                     """)
2026-02-14T13:01:56.2284908Z                     # Drop tables
2026-02-14T13:01:56.2284988Z                     cur.execute("""
2026-02-14T13:01:56.2285053Z                         DO $$
2026-02-14T13:01:56.2285232Z                         DECLARE
2026-02-14T13:01:56.2285305Z                             r RECORD;
2026-02-14T13:01:56.2285377Z                         BEGIN
2026-02-14T13:01:56.2285446Z                             FOR r IN (
2026-02-14T13:01:56.2285544Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2285731Z                                 FROM pg_tables
2026-02-14T13:01:56.2285854Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2285918Z                             )
2026-02-14T13:01:56.2285992Z                             LOOP
2026-02-14T13:01:56.2286302Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2286371Z                             END LOOP;
2026-02-14T13:01:56.2286435Z                         END $$;
2026-02-14T13:01:56.2286503Z                     """)
2026-02-14T13:01:56.2286586Z                 except psycopg2.Error:
2026-02-14T13:01:56.2286757Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2286833Z                     pass
2026-02-14T13:01:56.2286889Z     
2026-02-14T13:01:56.2287056Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2287173Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2287247Z                 if init_dir.exists():
2026-02-14T13:01:56.2287348Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2287435Z                     for script_path in scripts:
2026-02-14T13:01:56.2287563Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2287639Z                             sql = f.read()
2026-02-14T13:01:56.2287841Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2287977Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2288054Z                             statements = []
2026-02-14T13:01:56.2288110Z     
2026-02-14T13:01:56.2288289Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2288366Z                             do_blocks = []
2026-02-14T13:01:56.2288465Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2288527Z     
2026-02-14T13:01:56.2288623Z                             def replace_do_block(match):
2026-02-14T13:01:56.2288712Z                                 block = match.group(0)
2026-02-14T13:01:56.2288834Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2288938Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2289023Z                                 return placeholder
2026-02-14T13:01:56.2289080Z     
2026-02-14T13:01:56.2289198Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2289294Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2289373Z                                                     ^^
2026-02-14T13:01:56.2289564Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2289632Z                             )
2026-02-14T13:01:56.2289737Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2289743Z 
2026-02-14T13:01:56.2289841Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2290045Z _____ ERROR at setup of TestTriggerLogicEdgeCases.test_response_validation _____
2026-02-14T13:01:56.2290050Z 
2026-02-14T13:01:56.2290333Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2290338Z 
2026-02-14T13:01:56.2290424Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2290527Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2290593Z         """
2026-02-14T13:01:56.2290825Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2290885Z     
2026-02-14T13:01:56.2291022Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2291553Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2291615Z         """
2026-02-14T13:01:56.2291711Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2291843Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2291900Z     
2026-02-14T13:01:56.2292006Z         # Parse connection string to get database name
2026-02-14T13:01:56.2292256Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2292314Z     
2026-02-14T13:01:56.2292499Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2292735Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2292793Z     
2026-02-14T13:01:56.2292935Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2293043Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2293129Z         if len(parts) >= 4:
2026-02-14T13:01:56.2293247Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2293307Z         else:
2026-02-14T13:01:56.2293414Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2293471Z     
2026-02-14T13:01:56.2293565Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2293796Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2293865Z         import time
2026-02-14T13:01:56.2293922Z     
2026-02-14T13:01:56.2293992Z         max_retries = 5
2026-02-14T13:01:56.2294064Z         retry_delay = 2
2026-02-14T13:01:56.2294120Z     
2026-02-14T13:01:56.2294207Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2294274Z             try:
2026-02-14T13:01:56.2294375Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2294469Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2294552Z                 conn.autocommit = True
2026-02-14T13:01:56.2294622Z                 try:
2026-02-14T13:01:56.2294700Z                     cur = conn.cursor()
2026-02-14T13:01:56.2294891Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2294978Z                     if not cur.fetchone():
2026-02-14T13:01:56.2295130Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2295246Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2295322Z                     cur.close()
2026-02-14T13:01:56.2295389Z                 finally:
2026-02-14T13:01:56.2295463Z                     conn.close()
2026-02-14T13:01:56.2295538Z                 break  # Success
2026-02-14T13:01:56.2295733Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2295832Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2295907Z                     print(
2026-02-14T13:01:56.2296145Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2296209Z                     )
2026-02-14T13:01:56.2296295Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2296358Z                 else:
2026-02-14T13:01:56.2296574Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2296758Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2296825Z                     pass
2026-02-14T13:01:56.2296950Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2297151Z                 break  # Already exists
2026-02-14T13:01:56.2297211Z     
2026-02-14T13:01:56.2297440Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2297622Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2297829Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2297891Z     
2026-02-14T13:01:56.2297962Z         close_all_pools()
2026-02-14T13:01:56.2298023Z     
2026-02-14T13:01:56.2298139Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2298306Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2298446Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2298525Z             conn.autocommit = True
2026-02-14T13:01:56.2298607Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2298802Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2298893Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2298966Z                 cur.execute(
2026-02-14T13:01:56.2299034Z                     """
2026-02-14T13:01:56.2299130Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2299211Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2299311Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2299399Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2299461Z                     """
2026-02-14T13:01:56.2299526Z                 )
2026-02-14T13:01:56.2299584Z     
2026-02-14T13:01:56.2299772Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2299952Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2300020Z                 try:
2026-02-14T13:01:56.2300139Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2300213Z                     cur.execute("""
2026-02-14T13:01:56.2300287Z                         DO $$
2026-02-14T13:01:56.2300353Z                         DECLARE
2026-02-14T13:01:56.2300425Z                             r RECORD;
2026-02-14T13:01:56.2300504Z                         BEGIN
2026-02-14T13:01:56.2300574Z                             FOR r IN (
2026-02-14T13:01:56.2300673Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2300755Z                                 FROM pg_views
2026-02-14T13:01:56.2300889Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2300954Z                             )
2026-02-14T13:01:56.2301021Z                             LOOP
2026-02-14T13:01:56.2301469Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2301540Z                             END LOOP;
2026-02-14T13:01:56.2301610Z                         END $$;
2026-02-14T13:01:56.2301679Z                     """)
2026-02-14T13:01:56.2301750Z                     # Drop tables
2026-02-14T13:01:56.2301822Z                     cur.execute("""
2026-02-14T13:01:56.2301891Z                         DO $$
2026-02-14T13:01:56.2301964Z                         DECLARE
2026-02-14T13:01:56.2302032Z                             r RECORD;
2026-02-14T13:01:56.2302097Z                         BEGIN
2026-02-14T13:01:56.2302172Z                             FOR r IN (
2026-02-14T13:01:56.2302270Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2302350Z                                 FROM pg_tables
2026-02-14T13:01:56.2302471Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2302539Z                             )
2026-02-14T13:01:56.2302607Z                             LOOP
2026-02-14T13:01:56.2303042Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2303122Z                             END LOOP;
2026-02-14T13:01:56.2303186Z                         END $$;
2026-02-14T13:01:56.2303350Z                     """)
2026-02-14T13:01:56.2303439Z                 except psycopg2.Error:
2026-02-14T13:01:56.2303614Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2303682Z                     pass
2026-02-14T13:01:56.2303738Z     
2026-02-14T13:01:56.2303911Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2304021Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2304095Z                 if init_dir.exists():
2026-02-14T13:01:56.2304204Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2304294Z                     for script_path in scripts:
2026-02-14T13:01:56.2304419Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2304500Z                             sql = f.read()
2026-02-14T13:01:56.2304709Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2304842Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2304933Z                             statements = []
2026-02-14T13:01:56.2304992Z     
2026-02-14T13:01:56.2305168Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2305246Z                             do_blocks = []
2026-02-14T13:01:56.2305353Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2305410Z     
2026-02-14T13:01:56.2305506Z                             def replace_do_block(match):
2026-02-14T13:01:56.2305605Z                                 block = match.group(0)
2026-02-14T13:01:56.2305733Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2305829Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2305922Z                                 return placeholder
2026-02-14T13:01:56.2305986Z     
2026-02-14T13:01:56.2306099Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2306200Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2306294Z                                                     ^^
2026-02-14T13:01:56.2306488Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2306560Z                             )
2026-02-14T13:01:56.2306684Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2306689Z 
2026-02-14T13:01:56.2306795Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2307014Z _ ERROR at setup of TestTriggerLogicEdgeCases.test_campaign_ownership_validation _
2026-02-14T13:01:56.2307022Z 
2026-02-14T13:01:56.2307315Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2307320Z 
2026-02-14T13:01:56.2307416Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2307524Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2307584Z         """
2026-02-14T13:01:56.2307721Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2307783Z     
2026-02-14T13:01:56.2307912Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2308037Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2308100Z         """
2026-02-14T13:01:56.2308193Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2308318Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2308379Z     
2026-02-14T13:01:56.2308487Z         # Parse connection string to get database name
2026-02-14T13:01:56.2308820Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2308881Z     
2026-02-14T13:01:56.2309073Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2309385Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2309441Z     
2026-02-14T13:01:56.2309593Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2309704Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2309777Z         if len(parts) >= 4:
2026-02-14T13:01:56.2309902Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2309962Z         else:
2026-02-14T13:01:56.2310063Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2310120Z     
2026-02-14T13:01:56.2310224Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2310457Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2310522Z         import time
2026-02-14T13:01:56.2310588Z     
2026-02-14T13:01:56.2310656Z         max_retries = 5
2026-02-14T13:01:56.2310723Z         retry_delay = 2
2026-02-14T13:01:56.2310784Z     
2026-02-14T13:01:56.2310877Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2310938Z             try:
2026-02-14T13:01:56.2311265Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2311459Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2311555Z                 conn.autocommit = True
2026-02-14T13:01:56.2311620Z                 try:
2026-02-14T13:01:56.2311698Z                     cur = conn.cursor()
2026-02-14T13:01:56.2311895Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2311974Z                     if not cur.fetchone():
2026-02-14T13:01:56.2312134Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2312258Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2312329Z                     cur.close()
2026-02-14T13:01:56.2312397Z                 finally:
2026-02-14T13:01:56.2312479Z                     conn.close()
2026-02-14T13:01:56.2312551Z                 break  # Success
2026-02-14T13:01:56.2312740Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2312837Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2312906Z                     print(
2026-02-14T13:01:56.2313124Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2313187Z                     )
2026-02-14T13:01:56.2313277Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2313342Z                 else:
2026-02-14T13:01:56.2313549Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2313736Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2313805Z                     pass
2026-02-14T13:01:56.2313920Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2314006Z                 break  # Already exists
2026-02-14T13:01:56.2314065Z     
2026-02-14T13:01:56.2314279Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2314462Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2314601Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2314659Z     
2026-02-14T13:01:56.2314731Z         close_all_pools()
2026-02-14T13:01:56.2314796Z     
2026-02-14T13:01:56.2314912Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2315244Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2315398Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2315479Z             conn.autocommit = True
2026-02-14T13:01:56.2315558Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2315849Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2315949Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2316021Z                 cur.execute(
2026-02-14T13:01:56.2316085Z                     """
2026-02-14T13:01:56.2316186Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2316265Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2316361Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2316451Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2316519Z                     """
2026-02-14T13:01:56.2316579Z                 )
2026-02-14T13:01:56.2316636Z     
2026-02-14T13:01:56.2316835Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2317018Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2317084Z                 try:
2026-02-14T13:01:56.2317211Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2317287Z                     cur.execute("""
2026-02-14T13:01:56.2317358Z                         DO $$
2026-02-14T13:01:56.2317426Z                         DECLARE
2026-02-14T13:01:56.2317505Z                             r RECORD;
2026-02-14T13:01:56.2317576Z                         BEGIN
2026-02-14T13:01:56.2317651Z                             FOR r IN (
2026-02-14T13:01:56.2317757Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2317838Z                                 FROM pg_views
2026-02-14T13:01:56.2317965Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2318039Z                             )
2026-02-14T13:01:56.2318111Z                             LOOP
2026-02-14T13:01:56.2318423Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2318500Z                             END LOOP;
2026-02-14T13:01:56.2318574Z                         END $$;
2026-02-14T13:01:56.2318640Z                     """)
2026-02-14T13:01:56.2318711Z                     # Drop tables
2026-02-14T13:01:56.2318790Z                     cur.execute("""
2026-02-14T13:01:56.2318854Z                         DO $$
2026-02-14T13:01:56.2318920Z                         DECLARE
2026-02-14T13:01:56.2318994Z                             r RECORD;
2026-02-14T13:01:56.2319058Z                         BEGIN
2026-02-14T13:01:56.2319129Z                             FOR r IN (
2026-02-14T13:01:56.2319230Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2319322Z                                 FROM pg_tables
2026-02-14T13:01:56.2319446Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2319511Z                             )
2026-02-14T13:01:56.2319583Z                             LOOP
2026-02-14T13:01:56.2319903Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2319973Z                             END LOOP;
2026-02-14T13:01:56.2320043Z                         END $$;
2026-02-14T13:01:56.2320106Z                     """)
2026-02-14T13:01:56.2320186Z                 except psycopg2.Error:
2026-02-14T13:01:56.2320359Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2320431Z                     pass
2026-02-14T13:01:56.2320488Z     
2026-02-14T13:01:56.2320658Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2320874Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2320952Z                 if init_dir.exists():
2026-02-14T13:01:56.2321187Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2321394Z                     for script_path in scripts:
2026-02-14T13:01:56.2321524Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2321600Z                             sql = f.read()
2026-02-14T13:01:56.2321803Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2321937Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2322017Z                             statements = []
2026-02-14T13:01:56.2322073Z     
2026-02-14T13:01:56.2322252Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2322326Z                             do_blocks = []
2026-02-14T13:01:56.2322431Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2322494Z     
2026-02-14T13:01:56.2322588Z                             def replace_do_block(match):
2026-02-14T13:01:56.2322679Z                                 block = match.group(0)
2026-02-14T13:01:56.2322810Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2322912Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2323000Z                                 return placeholder
2026-02-14T13:01:56.2323056Z     
2026-02-14T13:01:56.2323171Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2323269Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2323353Z                                                     ^^
2026-02-14T13:01:56.2323543Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2323612Z                             )
2026-02-14T13:01:56.2323719Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2323726Z 
2026-02-14T13:01:56.2323827Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2324066Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_success _
2026-02-14T13:01:56.2324071Z 
2026-02-14T13:01:56.2324367Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2324371Z 
2026-02-14T13:01:56.2324459Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2324563Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2324628Z         """
2026-02-14T13:01:56.2324764Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2324822Z     
2026-02-14T13:01:56.2324960Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2325082Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2325147Z         """
2026-02-14T13:01:56.2325241Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2325368Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2325426Z     
2026-02-14T13:01:56.2325535Z         # Parse connection string to get database name
2026-02-14T13:01:56.2325785Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2325843Z     
2026-02-14T13:01:56.2326027Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2326264Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2326322Z     
2026-02-14T13:01:56.2326463Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2326572Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2326652Z         if len(parts) >= 4:
2026-02-14T13:01:56.2326897Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2326963Z         else:
2026-02-14T13:01:56.2327068Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2327125Z     
2026-02-14T13:01:56.2327220Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2327530Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2327598Z         import time
2026-02-14T13:01:56.2327660Z     
2026-02-14T13:01:56.2327729Z         max_retries = 5
2026-02-14T13:01:56.2327805Z         retry_delay = 2
2026-02-14T13:01:56.2327862Z     
2026-02-14T13:01:56.2327948Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2328016Z             try:
2026-02-14T13:01:56.2328115Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2328214Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2328292Z                 conn.autocommit = True
2026-02-14T13:01:56.2328365Z                 try:
2026-02-14T13:01:56.2328443Z                     cur = conn.cursor()
2026-02-14T13:01:56.2328631Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2328721Z                     if not cur.fetchone():
2026-02-14T13:01:56.2328878Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2328993Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2329072Z                     cur.close()
2026-02-14T13:01:56.2329140Z                 finally:
2026-02-14T13:01:56.2329212Z                     conn.close()
2026-02-14T13:01:56.2329283Z                 break  # Success
2026-02-14T13:01:56.2329477Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2329565Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2329635Z                     print(
2026-02-14T13:01:56.2329860Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2329925Z                     )
2026-02-14T13:01:56.2330007Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2330076Z                 else:
2026-02-14T13:01:56.2330278Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2330455Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2330522Z                     pass
2026-02-14T13:01:56.2330640Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2330719Z                 break  # Already exists
2026-02-14T13:01:56.2330776Z     
2026-02-14T13:01:56.2330996Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2331431Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2331574Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2331638Z     
2026-02-14T13:01:56.2331711Z         close_all_pools()
2026-02-14T13:01:56.2331769Z     
2026-02-14T13:01:56.2331885Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2332057Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2332198Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2332277Z             conn.autocommit = True
2026-02-14T13:01:56.2332360Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2332551Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2332640Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2332720Z                 cur.execute(
2026-02-14T13:01:56.2332785Z                     """
2026-02-14T13:01:56.2332880Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2333091Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2333198Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2333286Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2333352Z                     """
2026-02-14T13:01:56.2333517Z                 )
2026-02-14T13:01:56.2333573Z     
2026-02-14T13:01:56.2333761Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2333946Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2334016Z                 try:
2026-02-14T13:01:56.2334134Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2334209Z                     cur.execute("""
2026-02-14T13:01:56.2334284Z                         DO $$
2026-02-14T13:01:56.2334352Z                         DECLARE
2026-02-14T13:01:56.2334425Z                             r RECORD;
2026-02-14T13:01:56.2334495Z                         BEGIN
2026-02-14T13:01:56.2334573Z                             FOR r IN (
2026-02-14T13:01:56.2334672Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2334750Z                                 FROM pg_views
2026-02-14T13:01:56.2334888Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2334954Z                             )
2026-02-14T13:01:56.2335023Z                             LOOP
2026-02-14T13:01:56.2335348Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2335421Z                             END LOOP;
2026-02-14T13:01:56.2335490Z                         END $$;
2026-02-14T13:01:56.2335560Z                     """)
2026-02-14T13:01:56.2335632Z                     # Drop tables
2026-02-14T13:01:56.2335705Z                     cur.execute("""
2026-02-14T13:01:56.2335770Z                         DO $$
2026-02-14T13:01:56.2335844Z                         DECLARE
2026-02-14T13:01:56.2335915Z                             r RECORD;
2026-02-14T13:01:56.2335984Z                         BEGIN
2026-02-14T13:01:56.2336066Z                             FOR r IN (
2026-02-14T13:01:56.2336170Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2336257Z                                 FROM pg_tables
2026-02-14T13:01:56.2336388Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2336455Z                             )
2026-02-14T13:01:56.2336524Z                             LOOP
2026-02-14T13:01:56.2336837Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2336913Z                             END LOOP;
2026-02-14T13:01:56.2336979Z                         END $$;
2026-02-14T13:01:56.2337043Z                     """)
2026-02-14T13:01:56.2337134Z                 except psycopg2.Error:
2026-02-14T13:01:56.2337306Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2337373Z                     pass
2026-02-14T13:01:56.2337437Z     
2026-02-14T13:01:56.2337612Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2337722Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2337799Z                 if init_dir.exists():
2026-02-14T13:01:56.2337909Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2337999Z                     for script_path in scripts:
2026-02-14T13:01:56.2338125Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2338208Z                             sql = f.read()
2026-02-14T13:01:56.2338413Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2338627Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2338715Z                             statements = []
2026-02-14T13:01:56.2338772Z     
2026-02-14T13:01:56.2338947Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2339098Z                             do_blocks = []
2026-02-14T13:01:56.2339207Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2339264Z     
2026-02-14T13:01:56.2339361Z                             def replace_do_block(match):
2026-02-14T13:01:56.2339460Z                                 block = match.group(0)
2026-02-14T13:01:56.2339587Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2339684Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2339775Z                                 return placeholder
2026-02-14T13:01:56.2339834Z     
2026-02-14T13:01:56.2339946Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2340044Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2340134Z                                                     ^^
2026-02-14T13:01:56.2340320Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2340391Z                             )
2026-02-14T13:01:56.2340504Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2340510Z 
2026-02-14T13:01:56.2340612Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2340869Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_with_comments _
2026-02-14T13:01:56.2340874Z 
2026-02-14T13:01:56.2341389Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2341397Z 
2026-02-14T13:01:56.2341495Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2341603Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2341667Z         """
2026-02-14T13:01:56.2341805Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2341867Z     
2026-02-14T13:01:56.2342001Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2342134Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2342197Z         """
2026-02-14T13:01:56.2342292Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2342416Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2342477Z     
2026-02-14T13:01:56.2342582Z         # Parse connection string to get database name
2026-02-14T13:01:56.2342823Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2342880Z     
2026-02-14T13:01:56.2343070Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2343302Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2343360Z     
2026-02-14T13:01:56.2343508Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2343615Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2343692Z         if len(parts) >= 4:
2026-02-14T13:01:56.2343815Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2343876Z         else:
2026-02-14T13:01:56.2343975Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2344032Z     
2026-02-14T13:01:56.2344131Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2344357Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2344424Z         import time
2026-02-14T13:01:56.2344487Z     
2026-02-14T13:01:56.2344556Z         max_retries = 5
2026-02-14T13:01:56.2344625Z         retry_delay = 2
2026-02-14T13:01:56.2344681Z     
2026-02-14T13:01:56.2344893Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2344958Z             try:
2026-02-14T13:01:56.2345057Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2345157Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2345336Z                 conn.autocommit = True
2026-02-14T13:01:56.2345400Z                 try:
2026-02-14T13:01:56.2345485Z                     cur = conn.cursor()
2026-02-14T13:01:56.2345673Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2345751Z                     if not cur.fetchone():
2026-02-14T13:01:56.2345904Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2346027Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2346098Z                     cur.close()
2026-02-14T13:01:56.2346165Z                 finally:
2026-02-14T13:01:56.2346243Z                     conn.close()
2026-02-14T13:01:56.2346317Z                 break  # Success
2026-02-14T13:01:56.2346505Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2346601Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2346675Z                     print(
2026-02-14T13:01:56.2346893Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2346960Z                     )
2026-02-14T13:01:56.2347047Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2347110Z                 else:
2026-02-14T13:01:56.2347310Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2347496Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2347567Z                     pass
2026-02-14T13:01:56.2347682Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2347769Z                 break  # Already exists
2026-02-14T13:01:56.2347827Z     
2026-02-14T13:01:56.2348051Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2348231Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2348371Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2348430Z     
2026-02-14T13:01:56.2348502Z         close_all_pools()
2026-02-14T13:01:56.2348564Z     
2026-02-14T13:01:56.2348679Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2348844Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2348988Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2349067Z             conn.autocommit = True
2026-02-14T13:01:56.2349145Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2349338Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2349566Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2349675Z                 cur.execute(
2026-02-14T13:01:56.2349779Z                     """
2026-02-14T13:01:56.2349992Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2350107Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2350239Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2359010Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2359117Z                     """
2026-02-14T13:01:56.2359181Z                 )
2026-02-14T13:01:56.2359238Z     
2026-02-14T13:01:56.2359461Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2359676Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2359745Z                 try:
2026-02-14T13:01:56.2360053Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2360149Z                     cur.execute("""
2026-02-14T13:01:56.2360225Z                         DO $$
2026-02-14T13:01:56.2360294Z                         DECLARE
2026-02-14T13:01:56.2360370Z                             r RECORD;
2026-02-14T13:01:56.2360559Z                         BEGIN
2026-02-14T13:01:56.2360635Z                             FOR r IN (
2026-02-14T13:01:56.2360743Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2360841Z                                 FROM pg_views
2026-02-14T13:01:56.2360977Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2361526Z                             )
2026-02-14T13:01:56.2361616Z                             LOOP
2026-02-14T13:01:56.2361944Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2362027Z                             END LOOP;
2026-02-14T13:01:56.2362100Z                         END $$;
2026-02-14T13:01:56.2362177Z                     """)
2026-02-14T13:01:56.2362252Z                     # Drop tables
2026-02-14T13:01:56.2362327Z                     cur.execute("""
2026-02-14T13:01:56.2362406Z                         DO $$
2026-02-14T13:01:56.2362473Z                         DECLARE
2026-02-14T13:01:56.2362545Z                             r RECORD;
2026-02-14T13:01:56.2362619Z                         BEGIN
2026-02-14T13:01:56.2362693Z                             FOR r IN (
2026-02-14T13:01:56.2362801Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2362886Z                                 FROM pg_tables
2026-02-14T13:01:56.2363024Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2363090Z                             )
2026-02-14T13:01:56.2363159Z                             LOOP
2026-02-14T13:01:56.2363496Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2363571Z                             END LOOP;
2026-02-14T13:01:56.2363638Z                         END $$;
2026-02-14T13:01:56.2363712Z                     """)
2026-02-14T13:01:56.2363796Z                 except psycopg2.Error:
2026-02-14T13:01:56.2363978Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2364048Z                     pass
2026-02-14T13:01:56.2364113Z     
2026-02-14T13:01:56.2364290Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2364408Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2364490Z                 if init_dir.exists():
2026-02-14T13:01:56.2364596Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2364688Z                     for script_path in scripts:
2026-02-14T13:01:56.2364823Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2364900Z                             sql = f.read()
2026-02-14T13:01:56.2365110Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2365247Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2365333Z                             statements = []
2026-02-14T13:01:56.2365393Z     
2026-02-14T13:01:56.2365584Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2365668Z                             do_blocks = []
2026-02-14T13:01:56.2365771Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2365829Z     
2026-02-14T13:01:56.2365937Z                             def replace_do_block(match):
2026-02-14T13:01:56.2366033Z                                 block = match.group(0)
2026-02-14T13:01:56.2366284Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2366388Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2366485Z                                 return placeholder
2026-02-14T13:01:56.2366645Z     
2026-02-14T13:01:56.2366757Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2366864Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2366952Z                                                     ^^
2026-02-14T13:01:56.2367142Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2367218Z                             )
2026-02-14T13:01:56.2367327Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2367334Z 
2026-02-14T13:01:56.2367437Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2367720Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_missing_resume_id _
2026-02-14T13:01:56.2367726Z 
2026-02-14T13:01:56.2368064Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2368077Z 
2026-02-14T13:01:56.2368173Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2368291Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2368355Z         """
2026-02-14T13:01:56.2368507Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2368568Z     
2026-02-14T13:01:56.2368710Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2368848Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2368911Z         """
2026-02-14T13:01:56.2369008Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2369138Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2369205Z     
2026-02-14T13:01:56.2369316Z         # Parse connection string to get database name
2026-02-14T13:01:56.2369580Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2369645Z     
2026-02-14T13:01:56.2369838Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2370082Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2370146Z     
2026-02-14T13:01:56.2370294Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2370405Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2370485Z         if len(parts) >= 4:
2026-02-14T13:01:56.2370618Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2370682Z         else:
2026-02-14T13:01:56.2370784Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2370849Z     
2026-02-14T13:01:56.2370948Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2371475Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2371557Z         import time
2026-02-14T13:01:56.2371618Z     
2026-02-14T13:01:56.2371690Z         max_retries = 5
2026-02-14T13:01:56.2371763Z         retry_delay = 2
2026-02-14T13:01:56.2371832Z     
2026-02-14T13:01:56.2371922Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2371986Z             try:
2026-02-14T13:01:56.2372096Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2372191Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2372273Z                 conn.autocommit = True
2026-02-14T13:01:56.2372339Z                 try:
2026-02-14T13:01:56.2372424Z                     cur = conn.cursor()
2026-02-14T13:01:56.2372623Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2372705Z                     if not cur.fetchone():
2026-02-14T13:01:56.2372998Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2373124Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2373199Z                     cur.close()
2026-02-14T13:01:56.2373384Z                 finally:
2026-02-14T13:01:56.2373459Z                     conn.close()
2026-02-14T13:01:56.2373531Z                 break  # Success
2026-02-14T13:01:56.2373730Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2373828Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2373899Z                     print(
2026-02-14T13:01:56.2374125Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2374194Z                     )
2026-02-14T13:01:56.2374277Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2374341Z                 else:
2026-02-14T13:01:56.2374563Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2374751Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2374822Z                     pass
2026-02-14T13:01:56.2374948Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2375032Z                 break  # Already exists
2026-02-14T13:01:56.2375091Z     
2026-02-14T13:01:56.2375315Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2375510Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2375650Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2375709Z     
2026-02-14T13:01:56.2375788Z         close_all_pools()
2026-02-14T13:01:56.2375847Z     
2026-02-14T13:01:56.2375966Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2376135Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2376289Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2376369Z             conn.autocommit = True
2026-02-14T13:01:56.2376448Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2376655Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2376784Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2376860Z                 cur.execute(
2026-02-14T13:01:56.2376929Z                     """
2026-02-14T13:01:56.2377027Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2377107Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2377206Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2377300Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2377364Z                     """
2026-02-14T13:01:56.2377423Z                 )
2026-02-14T13:01:56.2377491Z     
2026-02-14T13:01:56.2377686Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2377873Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2377948Z                 try:
2026-02-14T13:01:56.2378069Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2378146Z                     cur.execute("""
2026-02-14T13:01:56.2378216Z                         DO $$
2026-02-14T13:01:56.2378292Z                         DECLARE
2026-02-14T13:01:56.2378366Z                             r RECORD;
2026-02-14T13:01:56.2378433Z                         BEGIN
2026-02-14T13:01:56.2378513Z                             FOR r IN (
2026-02-14T13:01:56.2378614Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2378696Z                                 FROM pg_views
2026-02-14T13:01:56.2378926Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2379001Z                             )
2026-02-14T13:01:56.2379071Z                             LOOP
2026-02-14T13:01:56.2379397Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2379551Z                             END LOOP;
2026-02-14T13:01:56.2379618Z                         END $$;
2026-02-14T13:01:56.2379682Z                     """)
2026-02-14T13:01:56.2379761Z                     # Drop tables
2026-02-14T13:01:56.2379834Z                     cur.execute("""
2026-02-14T13:01:56.2379899Z                         DO $$
2026-02-14T13:01:56.2379966Z                         DECLARE
2026-02-14T13:01:56.2380042Z                             r RECORD;
2026-02-14T13:01:56.2380107Z                         BEGIN
2026-02-14T13:01:56.2380177Z                             FOR r IN (
2026-02-14T13:01:56.2380283Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2380368Z                                 FROM pg_tables
2026-02-14T13:01:56.2380496Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2380567Z                             )
2026-02-14T13:01:56.2380642Z                             LOOP
2026-02-14T13:01:56.2380965Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2381169Z                             END LOOP;
2026-02-14T13:01:56.2381247Z                         END $$;
2026-02-14T13:01:56.2381312Z                     """)
2026-02-14T13:01:56.2381397Z                 except psycopg2.Error:
2026-02-14T13:01:56.2381578Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2381646Z                     pass
2026-02-14T13:01:56.2381704Z     
2026-02-14T13:01:56.2381887Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2381999Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2382079Z                 if init_dir.exists():
2026-02-14T13:01:56.2382185Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2382286Z                     for script_path in scripts:
2026-02-14T13:01:56.2382414Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2382491Z                             sql = f.read()
2026-02-14T13:01:56.2382707Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2382840Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2382920Z                             statements = []
2026-02-14T13:01:56.2382985Z     
2026-02-14T13:01:56.2383166Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2383245Z                             do_blocks = []
2026-02-14T13:01:56.2383350Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2383416Z     
2026-02-14T13:01:56.2383515Z                             def replace_do_block(match):
2026-02-14T13:01:56.2383614Z                                 block = match.group(0)
2026-02-14T13:01:56.2383749Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2383846Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2383935Z                                 return placeholder
2026-02-14T13:01:56.2383998Z     
2026-02-14T13:01:56.2384107Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2384206Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2384288Z                                                     ^^
2026-02-14T13:01:56.2384615Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2384686Z                             )
2026-02-14T13:01:56.2384796Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2384801Z 
2026-02-14T13:01:56.2384908Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2385277Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_invalid_resume_id _
2026-02-14T13:01:56.2385282Z 
2026-02-14T13:01:56.2385576Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2385581Z 
2026-02-14T13:01:56.2385674Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2385794Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2385857Z         """
2026-02-14T13:01:56.2385997Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2386064Z     
2026-02-14T13:01:56.2386202Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2386334Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2386398Z         """
2026-02-14T13:01:56.2386502Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2386625Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2386692Z     
2026-02-14T13:01:56.2386807Z         # Parse connection string to get database name
2026-02-14T13:01:56.2387054Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2387113Z     
2026-02-14T13:01:56.2387305Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2387535Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2387594Z     
2026-02-14T13:01:56.2387750Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2387860Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2387935Z         if len(parts) >= 4:
2026-02-14T13:01:56.2388062Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2388126Z         else:
2026-02-14T13:01:56.2388229Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2388291Z     
2026-02-14T13:01:56.2388394Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2388624Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2388691Z         import time
2026-02-14T13:01:56.2388758Z     
2026-02-14T13:01:56.2388828Z         max_retries = 5
2026-02-14T13:01:56.2388897Z         retry_delay = 2
2026-02-14T13:01:56.2388955Z     
2026-02-14T13:01:56.2389051Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2389115Z             try:
2026-02-14T13:01:56.2389222Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2389326Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2389413Z                 conn.autocommit = True
2026-02-14T13:01:56.2389480Z                 try:
2026-02-14T13:01:56.2389568Z                     cur = conn.cursor()
2026-02-14T13:01:56.2389762Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2389849Z                     if not cur.fetchone():
2026-02-14T13:01:56.2390005Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2390130Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2390203Z                     cur.close()
2026-02-14T13:01:56.2390274Z                 finally:
2026-02-14T13:01:56.2390356Z                     conn.close()
2026-02-14T13:01:56.2390427Z                 break  # Success
2026-02-14T13:01:56.2390623Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2390723Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2390793Z                     print(
2026-02-14T13:01:56.2391237Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2391313Z                     )
2026-02-14T13:01:56.2391406Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2391575Z                 else:
2026-02-14T13:01:56.2391784Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2391976Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2392045Z                     pass
2026-02-14T13:01:56.2392164Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2392249Z                 break  # Already exists
2026-02-14T13:01:56.2392308Z     
2026-02-14T13:01:56.2392525Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2392710Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2392858Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2392916Z     
2026-02-14T13:01:56.2392989Z         close_all_pools()
2026-02-14T13:01:56.2393051Z     
2026-02-14T13:01:56.2393168Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2393338Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2393485Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2393566Z             conn.autocommit = True
2026-02-14T13:01:56.2393645Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2393840Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2393937Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2394012Z                 cur.execute(
2026-02-14T13:01:56.2394081Z                     """
2026-02-14T13:01:56.2394188Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2394272Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2394370Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2394466Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2394534Z                     """
2026-02-14T13:01:56.2394595Z                 )
2026-02-14T13:01:56.2394653Z     
2026-02-14T13:01:56.2394849Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2395032Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2395097Z                 try:
2026-02-14T13:01:56.2395225Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2395302Z                     cur.execute("""
2026-02-14T13:01:56.2395371Z                         DO $$
2026-02-14T13:01:56.2395440Z                         DECLARE
2026-02-14T13:01:56.2395520Z                             r RECORD;
2026-02-14T13:01:56.2395590Z                         BEGIN
2026-02-14T13:01:56.2395663Z                             FOR r IN (
2026-02-14T13:01:56.2395774Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2395859Z                                 FROM pg_views
2026-02-14T13:01:56.2395991Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2396065Z                             )
2026-02-14T13:01:56.2396138Z                             LOOP
2026-02-14T13:01:56.2396450Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2396532Z                             END LOOP;
2026-02-14T13:01:56.2396602Z                         END $$;
2026-02-14T13:01:56.2396671Z                     """)
2026-02-14T13:01:56.2396743Z                     # Drop tables
2026-02-14T13:01:56.2396823Z                     cur.execute("""
2026-02-14T13:01:56.2397038Z                         DO $$
2026-02-14T13:01:56.2397109Z                         DECLARE
2026-02-14T13:01:56.2397188Z                             r RECORD;
2026-02-14T13:01:56.2397254Z                         BEGIN
2026-02-14T13:01:56.2397329Z                             FOR r IN (
2026-02-14T13:01:56.2397508Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2397598Z                                 FROM pg_tables
2026-02-14T13:01:56.2397725Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2397791Z                             )
2026-02-14T13:01:56.2397869Z                             LOOP
2026-02-14T13:01:56.2398185Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2398257Z                             END LOOP;
2026-02-14T13:01:56.2398330Z                         END $$;
2026-02-14T13:01:56.2398396Z                     """)
2026-02-14T13:01:56.2398483Z                 except psycopg2.Error:
2026-02-14T13:01:56.2398658Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2398733Z                     pass
2026-02-14T13:01:56.2398794Z     
2026-02-14T13:01:56.2398965Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2399082Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2399159Z                 if init_dir.exists():
2026-02-14T13:01:56.2399267Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2399366Z                     for script_path in scripts:
2026-02-14T13:01:56.2399492Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2399569Z                             sql = f.read()
2026-02-14T13:01:56.2399777Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2399918Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2399997Z                             statements = []
2026-02-14T13:01:56.2400057Z     
2026-02-14T13:01:56.2400243Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2400323Z                             do_blocks = []
2026-02-14T13:01:56.2400426Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2400491Z     
2026-02-14T13:01:56.2400591Z                             def replace_do_block(match):
2026-02-14T13:01:56.2400684Z                                 block = match.group(0)
2026-02-14T13:01:56.2400813Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2400917Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2401005Z                                 return placeholder
2026-02-14T13:01:56.2401175Z     
2026-02-14T13:01:56.2401299Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2401398Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2401481Z                                                     ^^
2026-02-14T13:01:56.2401678Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2401748Z                             )
2026-02-14T13:01:56.2401857Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2401862Z 
2026-02-14T13:01:56.2401969Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2402204Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_not_json _
2026-02-14T13:01:56.2402209Z 
2026-02-14T13:01:56.2402493Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2402498Z 
2026-02-14T13:01:56.2402586Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2402805Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2402876Z         """
2026-02-14T13:01:56.2403013Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2403071Z     
2026-02-14T13:01:56.2403208Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2403437Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2403498Z         """
2026-02-14T13:01:56.2403593Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2403725Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2403784Z     
2026-02-14T13:01:56.2403891Z         # Parse connection string to get database name
2026-02-14T13:01:56.2404144Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2404202Z     
2026-02-14T13:01:56.2404389Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2404626Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2404684Z     
2026-02-14T13:01:56.2404836Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2404948Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2405033Z         if len(parts) >= 4:
2026-02-14T13:01:56.2405153Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2405216Z         else:
2026-02-14T13:01:56.2405317Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2405382Z     
2026-02-14T13:01:56.2405476Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2405704Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2405777Z         import time
2026-02-14T13:01:56.2405836Z     
2026-02-14T13:01:56.2405906Z         max_retries = 5
2026-02-14T13:01:56.2405975Z         retry_delay = 2
2026-02-14T13:01:56.2406044Z     
2026-02-14T13:01:56.2406130Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2406193Z             try:
2026-02-14T13:01:56.2406299Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2406395Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2406480Z                 conn.autocommit = True
2026-02-14T13:01:56.2406546Z                 try:
2026-02-14T13:01:56.2406634Z                     cur = conn.cursor()
2026-02-14T13:01:56.2406823Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2406903Z                     if not cur.fetchone():
2026-02-14T13:01:56.2407060Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2407176Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2407248Z                     cur.close()
2026-02-14T13:01:56.2407322Z                 finally:
2026-02-14T13:01:56.2407397Z                     conn.close()
2026-02-14T13:01:56.2407468Z                 break  # Success
2026-02-14T13:01:56.2407656Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2407760Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2407832Z                     print(
2026-02-14T13:01:56.2408055Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2408125Z                     )
2026-02-14T13:01:56.2408207Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2408271Z                 else:
2026-02-14T13:01:56.2408479Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2408660Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2408727Z                     pass
2026-02-14T13:01:56.2408934Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2409014Z                 break  # Already exists
2026-02-14T13:01:56.2409072Z     
2026-02-14T13:01:56.2409288Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2409555Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2409689Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2409747Z     
2026-02-14T13:01:56.2409826Z         close_all_pools()
2026-02-14T13:01:56.2409885Z     
2026-02-14T13:01:56.2410001Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2410167Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2410311Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2410394Z             conn.autocommit = True
2026-02-14T13:01:56.2410475Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2410675Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2410768Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2410841Z                 cur.execute(
2026-02-14T13:01:56.2410910Z                     """
2026-02-14T13:01:56.2411011Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2411315Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2411434Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2411531Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2411599Z                     """
2026-02-14T13:01:56.2411659Z                 )
2026-02-14T13:01:56.2411722Z     
2026-02-14T13:01:56.2411912Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2412096Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2412166Z                 try:
2026-02-14T13:01:56.2412286Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2412364Z                     cur.execute("""
2026-02-14T13:01:56.2412435Z                         DO $$
2026-02-14T13:01:56.2412510Z                         DECLARE
2026-02-14T13:01:56.2412588Z                             r RECORD;
2026-02-14T13:01:56.2412655Z                         BEGIN
2026-02-14T13:01:56.2412736Z                             FOR r IN (
2026-02-14T13:01:56.2412835Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2412917Z                                 FROM pg_views
2026-02-14T13:01:56.2413053Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2413121Z                             )
2026-02-14T13:01:56.2413191Z                             LOOP
2026-02-14T13:01:56.2413501Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2413585Z                             END LOOP;
2026-02-14T13:01:56.2413653Z                         END $$;
2026-02-14T13:01:56.2413719Z                     """)
2026-02-14T13:01:56.2413797Z                     # Drop tables
2026-02-14T13:01:56.2413875Z                     cur.execute("""
2026-02-14T13:01:56.2413941Z                         DO $$
2026-02-14T13:01:56.2414010Z                         DECLARE
2026-02-14T13:01:56.2414085Z                             r RECORD;
2026-02-14T13:01:56.2414151Z                         BEGIN
2026-02-14T13:01:56.2414223Z                             FOR r IN (
2026-02-14T13:01:56.2414326Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2414409Z                                 FROM pg_tables
2026-02-14T13:01:56.2414535Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2414607Z                             )
2026-02-14T13:01:56.2414675Z                             LOOP
2026-02-14T13:01:56.2415118Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2415202Z                             END LOOP;
2026-02-14T13:01:56.2415370Z                         END $$;
2026-02-14T13:01:56.2415438Z                     """)
2026-02-14T13:01:56.2415522Z                 except psycopg2.Error:
2026-02-14T13:01:56.2415705Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2415773Z                     pass
2026-02-14T13:01:56.2415833Z     
2026-02-14T13:01:56.2416012Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2416122Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2416198Z                 if init_dir.exists():
2026-02-14T13:01:56.2416301Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2416403Z                     for script_path in scripts:
2026-02-14T13:01:56.2416528Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2416607Z                             sql = f.read()
2026-02-14T13:01:56.2416819Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2416953Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2417033Z                             statements = []
2026-02-14T13:01:56.2417099Z     
2026-02-14T13:01:56.2417275Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2417351Z                             do_blocks = []
2026-02-14T13:01:56.2417460Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2417522Z     
2026-02-14T13:01:56.2417620Z                             def replace_do_block(match):
2026-02-14T13:01:56.2417715Z                                 block = match.group(0)
2026-02-14T13:01:56.2417848Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2417954Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2418043Z                                 return placeholder
2026-02-14T13:01:56.2418109Z     
2026-02-14T13:01:56.2418220Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2418316Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2418403Z                                                     ^^
2026-02-14T13:01:56.2418589Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2418655Z                             )
2026-02-14T13:01:56.2418761Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2418766Z 
2026-02-14T13:01:56.2418873Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2419139Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_generation_error _
2026-02-14T13:01:56.2419145Z 
2026-02-14T13:01:56.2419432Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2419437Z 
2026-02-14T13:01:56.2419528Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2419638Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2419700Z         """
2026-02-14T13:01:56.2419832Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2419894Z     
2026-02-14T13:01:56.2420026Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2420146Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2420206Z         """
2026-02-14T13:01:56.2420303Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2420425Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2420483Z     
2026-02-14T13:01:56.2420680Z         # Parse connection string to get database name
2026-02-14T13:01:56.2420924Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2420987Z     
2026-02-14T13:01:56.2421421Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2421779Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2421838Z     
2026-02-14T13:01:56.2421986Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2422103Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2422179Z         if len(parts) >= 4:
2026-02-14T13:01:56.2422300Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2422366Z         else:
2026-02-14T13:01:56.2422467Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2422525Z     
2026-02-14T13:01:56.2422630Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2422859Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2422928Z         import time
2026-02-14T13:01:56.2422987Z     
2026-02-14T13:01:56.2423066Z         max_retries = 5
2026-02-14T13:01:56.2423139Z         retry_delay = 2
2026-02-14T13:01:56.2423197Z     
2026-02-14T13:01:56.2423289Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2423351Z             try:
2026-02-14T13:01:56.2423451Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2423546Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2423633Z                 conn.autocommit = True
2026-02-14T13:01:56.2423697Z                 try:
2026-02-14T13:01:56.2423779Z                     cur = conn.cursor()
2026-02-14T13:01:56.2423969Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2424053Z                     if not cur.fetchone():
2026-02-14T13:01:56.2424204Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2424325Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2424396Z                     cur.close()
2026-02-14T13:01:56.2424467Z                 finally:
2026-02-14T13:01:56.2424539Z                     conn.close()
2026-02-14T13:01:56.2424619Z                 break  # Success
2026-02-14T13:01:56.2424806Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2424896Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2424973Z                     print(
2026-02-14T13:01:56.2425187Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2425252Z                     )
2026-02-14T13:01:56.2425342Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2425407Z                 else:
2026-02-14T13:01:56.2425612Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2425794Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2425870Z                     pass
2026-02-14T13:01:56.2425985Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2426063Z                 break  # Already exists
2026-02-14T13:01:56.2426126Z     
2026-02-14T13:01:56.2426345Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2426526Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2426663Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2426722Z     
2026-02-14T13:01:56.2426797Z         close_all_pools()
2026-02-14T13:01:56.2426855Z     
2026-02-14T13:01:56.2426978Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2427256Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2427402Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2427494Z             conn.autocommit = True
2026-02-14T13:01:56.2427653Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2427848Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2427951Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2428024Z                 cur.execute(
2026-02-14T13:01:56.2428088Z                     """
2026-02-14T13:01:56.2428184Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2428273Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2428369Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2428459Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2428530Z                     """
2026-02-14T13:01:56.2428595Z                 )
2026-02-14T13:01:56.2428655Z     
2026-02-14T13:01:56.2428843Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2429033Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2429103Z                 try:
2026-02-14T13:01:56.2429222Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2429304Z                     cur.execute("""
2026-02-14T13:01:56.2429374Z                         DO $$
2026-02-14T13:01:56.2429443Z                         DECLARE
2026-02-14T13:01:56.2429519Z                             r RECORD;
2026-02-14T13:01:56.2429586Z                         BEGIN
2026-02-14T13:01:56.2429659Z                             FOR r IN (
2026-02-14T13:01:56.2429757Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2429844Z                                 FROM pg_views
2026-02-14T13:01:56.2429977Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2430044Z                             )
2026-02-14T13:01:56.2430119Z                             LOOP
2026-02-14T13:01:56.2430431Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2430507Z                             END LOOP;
2026-02-14T13:01:56.2430578Z                         END $$;
2026-02-14T13:01:56.2430644Z                     """)
2026-02-14T13:01:56.2430717Z                     # Drop tables
2026-02-14T13:01:56.2430790Z                     cur.execute("""
2026-02-14T13:01:56.2430862Z                         DO $$
2026-02-14T13:01:56.2430927Z                         DECLARE
2026-02-14T13:01:56.2430996Z                             r RECORD;
2026-02-14T13:01:56.2431185Z                         BEGIN
2026-02-14T13:01:56.2431258Z                             FOR r IN (
2026-02-14T13:01:56.2431361Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2431444Z                                 FROM pg_tables
2026-02-14T13:01:56.2431574Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2431643Z                             )
2026-02-14T13:01:56.2431712Z                             LOOP
2026-02-14T13:01:56.2432030Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2432101Z                             END LOOP;
2026-02-14T13:01:56.2432168Z                         END $$;
2026-02-14T13:01:56.2432239Z                     """)
2026-02-14T13:01:56.2432321Z                 except psycopg2.Error:
2026-02-14T13:01:56.2432492Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2432566Z                     pass
2026-02-14T13:01:56.2432626Z     
2026-02-14T13:01:56.2432913Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2433030Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2433112Z                 if init_dir.exists():
2026-02-14T13:01:56.2433215Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2433413Z                     for script_path in scripts:
2026-02-14T13:01:56.2433543Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2433619Z                             sql = f.read()
2026-02-14T13:01:56.2433827Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2433962Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2434041Z                             statements = []
2026-02-14T13:01:56.2434100Z     
2026-02-14T13:01:56.2434275Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2434363Z                             do_blocks = []
2026-02-14T13:01:56.2434467Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2434525Z     
2026-02-14T13:01:56.2434627Z                             def replace_do_block(match):
2026-02-14T13:01:56.2434729Z                                 block = match.group(0)
2026-02-14T13:01:56.2434863Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2434967Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2435057Z                                 return placeholder
2026-02-14T13:01:56.2435115Z     
2026-02-14T13:01:56.2435224Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2435330Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2435413Z                                                     ^^
2026-02-14T13:01:56.2435606Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2435680Z                             )
2026-02-14T13:01:56.2435788Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2435792Z 
2026-02-14T13:01:56.2435897Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2436173Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_validation_error _
2026-02-14T13:01:56.2436179Z 
2026-02-14T13:01:56.2436471Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2436476Z 
2026-02-14T13:01:56.2436566Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2436676Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2436737Z         """
2026-02-14T13:01:56.2436877Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2436939Z     
2026-02-14T13:01:56.2437071Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2437204Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2437265Z         """
2026-02-14T13:01:56.2437361Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2437497Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2437562Z     
2026-02-14T13:01:56.2437669Z         # Parse connection string to get database name
2026-02-14T13:01:56.2437919Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2437986Z     
2026-02-14T13:01:56.2438171Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2438398Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2438466Z     
2026-02-14T13:01:56.2438610Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2438718Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2438890Z         if len(parts) >= 4:
2026-02-14T13:01:56.2439012Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2439078Z         else:
2026-02-14T13:01:56.2439179Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2439322Z     
2026-02-14T13:01:56.2439420Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2439648Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2439722Z         import time
2026-02-14T13:01:56.2439781Z     
2026-02-14T13:01:56.2439850Z         max_retries = 5
2026-02-14T13:01:56.2439919Z         retry_delay = 2
2026-02-14T13:01:56.2439985Z     
2026-02-14T13:01:56.2440073Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2440135Z             try:
2026-02-14T13:01:56.2440245Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2440340Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2440427Z                 conn.autocommit = True
2026-02-14T13:01:56.2440497Z                 try:
2026-02-14T13:01:56.2440575Z                     cur = conn.cursor()
2026-02-14T13:01:56.2440762Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2440845Z                     if not cur.fetchone():
2026-02-14T13:01:56.2441001Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2441245Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2441317Z                     cur.close()
2026-02-14T13:01:56.2441389Z                 finally:
2026-02-14T13:01:56.2441462Z                     conn.close()
2026-02-14T13:01:56.2441534Z                 break  # Success
2026-02-14T13:01:56.2441727Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2441818Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2441890Z                     print(
2026-02-14T13:01:56.2442110Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2442180Z                     )
2026-02-14T13:01:56.2442262Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2442330Z                 else:
2026-02-14T13:01:56.2442541Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2442722Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2442790Z                     pass
2026-02-14T13:01:56.2442909Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2442987Z                 break  # Already exists
2026-02-14T13:01:56.2443046Z     
2026-02-14T13:01:56.2443269Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2443463Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2443594Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2443652Z     
2026-02-14T13:01:56.2443730Z         close_all_pools()
2026-02-14T13:01:56.2443789Z     
2026-02-14T13:01:56.2443908Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2444076Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2444217Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2444298Z             conn.autocommit = True
2026-02-14T13:01:56.2444377Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2444579Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2444671Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2444744Z                 cur.execute(
2026-02-14T13:01:56.2444818Z                     """
2026-02-14T13:01:56.2445075Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2445159Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2445262Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2445352Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2445516Z                     """
2026-02-14T13:01:56.2445577Z                 )
2026-02-14T13:01:56.2445641Z     
2026-02-14T13:01:56.2445830Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2446012Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2446082Z                 try:
2026-02-14T13:01:56.2446200Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2446276Z                     cur.execute("""
2026-02-14T13:01:56.2446346Z                         DO $$
2026-02-14T13:01:56.2446418Z                         DECLARE
2026-02-14T13:01:56.2446494Z                             r RECORD;
2026-02-14T13:01:56.2446562Z                         BEGIN
2026-02-14T13:01:56.2446639Z                             FOR r IN (
2026-02-14T13:01:56.2446746Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2446833Z                                 FROM pg_views
2026-02-14T13:01:56.2446967Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2447033Z                             )
2026-02-14T13:01:56.2447103Z                             LOOP
2026-02-14T13:01:56.2447418Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2447500Z                             END LOOP;
2026-02-14T13:01:56.2447568Z                         END $$;
2026-02-14T13:01:56.2447633Z                     """)
2026-02-14T13:01:56.2447714Z                     # Drop tables
2026-02-14T13:01:56.2447787Z                     cur.execute("""
2026-02-14T13:01:56.2447856Z                         DO $$
2026-02-14T13:01:56.2447927Z                         DECLARE
2026-02-14T13:01:56.2447997Z                             r RECORD;
2026-02-14T13:01:56.2448064Z                         BEGIN
2026-02-14T13:01:56.2448138Z                             FOR r IN (
2026-02-14T13:01:56.2448243Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2448326Z                                 FROM pg_tables
2026-02-14T13:01:56.2448457Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2448531Z                             )
2026-02-14T13:01:56.2448601Z                             LOOP
2026-02-14T13:01:56.2448920Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2448998Z                             END LOOP;
2026-02-14T13:01:56.2449067Z                         END $$;
2026-02-14T13:01:56.2449136Z                     """)
2026-02-14T13:01:56.2449221Z                 except psycopg2.Error:
2026-02-14T13:01:56.2449401Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2449468Z                     pass
2026-02-14T13:01:56.2449530Z     
2026-02-14T13:01:56.2449706Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2449818Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2449895Z                 if init_dir.exists():
2026-02-14T13:01:56.2450007Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2450100Z                     for script_path in scripts:
2026-02-14T13:01:56.2450227Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2450303Z                             sql = f.read()
2026-02-14T13:01:56.2450597Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2450734Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2450813Z                             statements = []
2026-02-14T13:01:56.2450878Z     
2026-02-14T13:01:56.2451361Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2451446Z                             do_blocks = []
2026-02-14T13:01:56.2451556Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2451616Z     
2026-02-14T13:01:56.2451713Z                             def replace_do_block(match):
2026-02-14T13:01:56.2451808Z                                 block = match.group(0)
2026-02-14T13:01:56.2451942Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2452041Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2452130Z                                 return placeholder
2026-02-14T13:01:56.2452197Z     
2026-02-14T13:01:56.2452305Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2452406Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2452492Z                                                     ^^
2026-02-14T13:01:56.2452683Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2452754Z                             )
2026-02-14T13:01:56.2452861Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2452873Z 
2026-02-14T13:01:56.2452973Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2453232Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_requires_login _
2026-02-14T13:01:56.2453237Z 
2026-02-14T13:01:56.2453532Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2453537Z 
2026-02-14T13:01:56.2453626Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2453738Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2453800Z         """
2026-02-14T13:01:56.2453934Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2453999Z     
2026-02-14T13:01:56.2454135Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2454259Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2454320Z         """
2026-02-14T13:01:56.2454421Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2454546Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2454605Z     
2026-02-14T13:01:56.2454717Z         # Parse connection string to get database name
2026-02-14T13:01:56.2454959Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2455018Z     
2026-02-14T13:01:56.2455209Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2455441Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2455501Z     
2026-02-14T13:01:56.2455646Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2455766Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2455844Z         if len(parts) >= 4:
2026-02-14T13:01:56.2455961Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2456029Z         else:
2026-02-14T13:01:56.2456130Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2456189Z     
2026-02-14T13:01:56.2456291Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2456520Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2456588Z         import time
2026-02-14T13:01:56.2456648Z     
2026-02-14T13:01:56.2456724Z         max_retries = 5
2026-02-14T13:01:56.2456914Z         retry_delay = 2
2026-02-14T13:01:56.2456976Z     
2026-02-14T13:01:56.2457070Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2457133Z             try:
2026-02-14T13:01:56.2457234Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2457444Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2457532Z                 conn.autocommit = True
2026-02-14T13:01:56.2457596Z                 try:
2026-02-14T13:01:56.2457674Z                     cur = conn.cursor()
2026-02-14T13:01:56.2457870Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2457953Z                     if not cur.fetchone():
2026-02-14T13:01:56.2458105Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2458237Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2458310Z                     cur.close()
2026-02-14T13:01:56.2458382Z                 finally:
2026-02-14T13:01:56.2458456Z                     conn.close()
2026-02-14T13:01:56.2458536Z                 break  # Success
2026-02-14T13:01:56.2458728Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2458825Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2458902Z                     print(
2026-02-14T13:01:56.2459123Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2459189Z                     )
2026-02-14T13:01:56.2459278Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2459342Z                 else:
2026-02-14T13:01:56.2459546Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2459728Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2459809Z                     pass
2026-02-14T13:01:56.2459928Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2460007Z                 break  # Already exists
2026-02-14T13:01:56.2460075Z     
2026-02-14T13:01:56.2460293Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2460479Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2460621Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2460681Z     
2026-02-14T13:01:56.2460758Z         close_all_pools()
2026-02-14T13:01:56.2460816Z     
2026-02-14T13:01:56.2460941Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2461235Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2461380Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2461471Z             conn.autocommit = True
2026-02-14T13:01:56.2461552Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2461751Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2461849Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2461921Z                 cur.execute(
2026-02-14T13:01:56.2461992Z                     """
2026-02-14T13:01:56.2462090Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2462178Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2462279Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2462373Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2462447Z                     """
2026-02-14T13:01:56.2462509Z                 )
2026-02-14T13:01:56.2462569Z     
2026-02-14T13:01:56.2462761Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2462954Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2463144Z                 try:
2026-02-14T13:01:56.2463268Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2463349Z                     cur.execute("""
2026-02-14T13:01:56.2463419Z                         DO $$
2026-02-14T13:01:56.2463591Z                         DECLARE
2026-02-14T13:01:56.2463671Z                             r RECORD;
2026-02-14T13:01:56.2463738Z                         BEGIN
2026-02-14T13:01:56.2463810Z                             FOR r IN (
2026-02-14T13:01:56.2463913Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2464006Z                                 FROM pg_views
2026-02-14T13:01:56.2464138Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2464204Z                             )
2026-02-14T13:01:56.2464285Z                             LOOP
2026-02-14T13:01:56.2464602Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2464676Z                             END LOOP;
2026-02-14T13:01:56.2464749Z                         END $$;
2026-02-14T13:01:56.2464815Z                     """)
2026-02-14T13:01:56.2464887Z                     # Drop tables
2026-02-14T13:01:56.2464964Z                     cur.execute("""
2026-02-14T13:01:56.2465037Z                         DO $$
2026-02-14T13:01:56.2465104Z                         DECLARE
2026-02-14T13:01:56.2465173Z                             r RECORD;
2026-02-14T13:01:56.2465244Z                         BEGIN
2026-02-14T13:01:56.2465315Z                             FOR r IN (
2026-02-14T13:01:56.2465419Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2465506Z                                 FROM pg_tables
2026-02-14T13:01:56.2465634Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2465699Z                             )
2026-02-14T13:01:56.2465774Z                             LOOP
2026-02-14T13:01:56.2466094Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2466165Z                             END LOOP;
2026-02-14T13:01:56.2466236Z                         END $$;
2026-02-14T13:01:56.2466306Z                     """)
2026-02-14T13:01:56.2466389Z                 except psycopg2.Error:
2026-02-14T13:01:56.2466565Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2466640Z                     pass
2026-02-14T13:01:56.2466700Z     
2026-02-14T13:01:56.2466872Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2466982Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2467064Z                 if init_dir.exists():
2026-02-14T13:01:56.2467172Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2467266Z                     for script_path in scripts:
2026-02-14T13:01:56.2467399Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2467477Z                             sql = f.read()
2026-02-14T13:01:56.2467686Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2467825Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2467904Z                             statements = []
2026-02-14T13:01:56.2467963Z     
2026-02-14T13:01:56.2468148Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2468233Z                             do_blocks = []
2026-02-14T13:01:56.2468341Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2468399Z     
2026-02-14T13:01:56.2468501Z                             def replace_do_block(match):
2026-02-14T13:01:56.2468678Z                                 block = match.group(0)
2026-02-14T13:01:56.2468808Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2468910Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2469073Z                                 return placeholder
2026-02-14T13:01:56.2469131Z     
2026-02-14T13:01:56.2469242Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2469346Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2469428Z                                                     ^^
2026-02-14T13:01:56.2469615Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2469688Z                             )
2026-02-14T13:01:56.2469797Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2469802Z 
2026-02-14T13:01:56.2469902Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2470184Z _ ERROR at setup of TestCoverLetterGenerationRoute.test_generate_cover_letter_general_exception _
2026-02-14T13:01:56.2470189Z 
2026-02-14T13:01:56.2470474Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2470483Z 
2026-02-14T13:01:56.2470573Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2470678Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2470745Z         """
2026-02-14T13:01:56.2470881Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2470940Z     
2026-02-14T13:01:56.2471180Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2471320Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2471381Z         """
2026-02-14T13:01:56.2471478Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2471609Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2471672Z     
2026-02-14T13:01:56.2471781Z         # Parse connection string to get database name
2026-02-14T13:01:56.2472028Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2472094Z     
2026-02-14T13:01:56.2472283Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2472508Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2472574Z     
2026-02-14T13:01:56.2472718Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2472828Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2472913Z         if len(parts) >= 4:
2026-02-14T13:01:56.2473032Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2473095Z         else:
2026-02-14T13:01:56.2473195Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2473260Z     
2026-02-14T13:01:56.2473359Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2473586Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2473661Z         import time
2026-02-14T13:01:56.2473722Z     
2026-02-14T13:01:56.2473793Z         max_retries = 5
2026-02-14T13:01:56.2473866Z         retry_delay = 2
2026-02-14T13:01:56.2473925Z     
2026-02-14T13:01:56.2474010Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2474072Z             try:
2026-02-14T13:01:56.2474178Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2474274Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2474354Z                 conn.autocommit = True
2026-02-14T13:01:56.2474423Z                 try:
2026-02-14T13:01:56.2474504Z                     cur = conn.cursor()
2026-02-14T13:01:56.2474693Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2474895Z                     if not cur.fetchone():
2026-02-14T13:01:56.2475056Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2475174Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2475345Z                     cur.close()
2026-02-14T13:01:56.2475418Z                 finally:
2026-02-14T13:01:56.2475490Z                     conn.close()
2026-02-14T13:01:56.2475559Z                 break  # Success
2026-02-14T13:01:56.2475753Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2475845Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2475915Z                     print(
2026-02-14T13:01:56.2476131Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2476200Z                     )
2026-02-14T13:01:56.2476283Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2476350Z                 else:
2026-02-14T13:01:56.2476560Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2476787Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2476861Z                     pass
2026-02-14T13:01:56.2476980Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2477058Z                 break  # Already exists
2026-02-14T13:01:56.2477117Z     
2026-02-14T13:01:56.2477333Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2477522Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2477652Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2477711Z     
2026-02-14T13:01:56.2477789Z         close_all_pools()
2026-02-14T13:01:56.2477848Z     
2026-02-14T13:01:56.2477969Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2478142Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2478283Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2478366Z             conn.autocommit = True
2026-02-14T13:01:56.2478445Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2478643Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2478733Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2478806Z                 cur.execute(
2026-02-14T13:01:56.2478876Z                     """
2026-02-14T13:01:56.2478973Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2479052Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2479151Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2479244Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2479312Z                     """
2026-02-14T13:01:56.2479373Z                 )
2026-02-14T13:01:56.2479437Z     
2026-02-14T13:01:56.2479625Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2479809Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2479884Z                 try:
2026-02-14T13:01:56.2480003Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2480081Z                     cur.execute("""
2026-02-14T13:01:56.2480156Z                         DO $$
2026-02-14T13:01:56.2480224Z                         DECLARE
2026-02-14T13:01:56.2480297Z                             r RECORD;
2026-02-14T13:01:56.2480364Z                         BEGIN
2026-02-14T13:01:56.2480444Z                             FOR r IN (
2026-02-14T13:01:56.2480544Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2480626Z                                 FROM pg_views
2026-02-14T13:01:56.2480844Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2480913Z                             )
2026-02-14T13:01:56.2480983Z                             LOOP
2026-02-14T13:01:56.2481417Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2481616Z                             END LOOP;
2026-02-14T13:01:56.2481685Z                         END $$;
2026-02-14T13:01:56.2481751Z                     """)
2026-02-14T13:01:56.2481831Z                     # Drop tables
2026-02-14T13:01:56.2481906Z                     cur.execute("""
2026-02-14T13:01:56.2481975Z                         DO $$
2026-02-14T13:01:56.2482046Z                         DECLARE
2026-02-14T13:01:56.2482119Z                             r RECORD;
2026-02-14T13:01:56.2482187Z                         BEGIN
2026-02-14T13:01:56.2482259Z                             FOR r IN (
2026-02-14T13:01:56.2482376Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2482465Z                                 FROM pg_tables
2026-02-14T13:01:56.2482594Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2482672Z                             )
2026-02-14T13:01:56.2482743Z                             LOOP
2026-02-14T13:01:56.2483063Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2483146Z                             END LOOP;
2026-02-14T13:01:56.2483216Z                         END $$;
2026-02-14T13:01:56.2483282Z                     """)
2026-02-14T13:01:56.2483367Z                 except psycopg2.Error:
2026-02-14T13:01:56.2483552Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2483621Z                     pass
2026-02-14T13:01:56.2483680Z     
2026-02-14T13:01:56.2483864Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2483976Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2484054Z                 if init_dir.exists():
2026-02-14T13:01:56.2484168Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2484260Z                     for script_path in scripts:
2026-02-14T13:01:56.2484389Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2484467Z                             sql = f.read()
2026-02-14T13:01:56.2484678Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2484810Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2484888Z                             statements = []
2026-02-14T13:01:56.2484953Z     
2026-02-14T13:01:56.2485135Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2485212Z                             do_blocks = []
2026-02-14T13:01:56.2485318Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2485378Z     
2026-02-14T13:01:56.2485478Z                             def replace_do_block(match):
2026-02-14T13:01:56.2485569Z                                 block = match.group(0)
2026-02-14T13:01:56.2485703Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2485799Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2485886Z                                 return placeholder
2026-02-14T13:01:56.2485950Z     
2026-02-14T13:01:56.2486058Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2486156Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2486240Z                                                     ^^
2026-02-14T13:01:56.2486565Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2486636Z                             )
2026-02-14T13:01:56.2486750Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2486872Z 
2026-02-14T13:01:56.2486979Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2487156Z _____________ ERROR at setup of test_dag_end_to_end_full_pipeline ______________
2026-02-14T13:01:56.2487161Z 
2026-02-14T13:01:56.2487447Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2487452Z 
2026-02-14T13:01:56.2487541Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2487653Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2487714Z         """
2026-02-14T13:01:56.2487849Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2487916Z     
2026-02-14T13:01:56.2488047Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2488185Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2488251Z         """
2026-02-14T13:01:56.2488344Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2488473Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2488535Z     
2026-02-14T13:01:56.2488647Z         # Parse connection string to get database name
2026-02-14T13:01:56.2488893Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2488956Z     
2026-02-14T13:01:56.2489146Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2489375Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2489433Z     
2026-02-14T13:01:56.2489583Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2489695Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2489770Z         if len(parts) >= 4:
2026-02-14T13:01:56.2489890Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2489958Z         else:
2026-02-14T13:01:56.2490057Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2490119Z     
2026-02-14T13:01:56.2490220Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2490450Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2490517Z         import time
2026-02-14T13:01:56.2490576Z     
2026-02-14T13:01:56.2490650Z         max_retries = 5
2026-02-14T13:01:56.2490718Z         retry_delay = 2
2026-02-14T13:01:56.2490776Z     
2026-02-14T13:01:56.2490865Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2490930Z             try:
2026-02-14T13:01:56.2491207Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2491390Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2491485Z                 conn.autocommit = True
2026-02-14T13:01:56.2491552Z                 try:
2026-02-14T13:01:56.2491631Z                     cur = conn.cursor()
2026-02-14T13:01:56.2491828Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2491913Z                     if not cur.fetchone():
2026-02-14T13:01:56.2492063Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2492183Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2492254Z                     cur.close()
2026-02-14T13:01:56.2492321Z                 finally:
2026-02-14T13:01:56.2492393Z                     conn.close()
2026-02-14T13:01:56.2492473Z                 break  # Success
2026-02-14T13:01:56.2492664Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2492754Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2492965Z                     print(
2026-02-14T13:01:56.2493191Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2493262Z                     )
2026-02-14T13:01:56.2493455Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2493521Z                 else:
2026-02-14T13:01:56.2493725Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2493909Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2493985Z                     pass
2026-02-14T13:01:56.2494097Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2494175Z                 break  # Already exists
2026-02-14T13:01:56.2494241Z     
2026-02-14T13:01:56.2494457Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2494644Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2494786Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2494845Z     
2026-02-14T13:01:56.2494918Z         close_all_pools()
2026-02-14T13:01:56.2494981Z     
2026-02-14T13:01:56.2495110Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2495274Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2495415Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2495503Z             conn.autocommit = True
2026-02-14T13:01:56.2495583Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2495774Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2495874Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2495948Z                 cur.execute(
2026-02-14T13:01:56.2496014Z                     """
2026-02-14T13:01:56.2496113Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2496199Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2496298Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2496387Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2496463Z                     """
2026-02-14T13:01:56.2496524Z                 )
2026-02-14T13:01:56.2496583Z     
2026-02-14T13:01:56.2496779Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2496964Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2497030Z                 try:
2026-02-14T13:01:56.2497147Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2497227Z                     cur.execute("""
2026-02-14T13:01:56.2497299Z                         DO $$
2026-02-14T13:01:56.2497366Z                         DECLARE
2026-02-14T13:01:56.2497447Z                             r RECORD;
2026-02-14T13:01:56.2497515Z                         BEGIN
2026-02-14T13:01:56.2497585Z                             FOR r IN (
2026-02-14T13:01:56.2497685Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2497775Z                                 FROM pg_views
2026-02-14T13:01:56.2497903Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2497969Z                             )
2026-02-14T13:01:56.2498046Z                             LOOP
2026-02-14T13:01:56.2498362Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2498436Z                             END LOOP;
2026-02-14T13:01:56.2498512Z                         END $$;
2026-02-14T13:01:56.2498576Z                     """)
2026-02-14T13:01:56.2498647Z                     # Drop tables
2026-02-14T13:01:56.2498817Z                     cur.execute("""
2026-02-14T13:01:56.2498893Z                         DO $$
2026-02-14T13:01:56.2498959Z                         DECLARE
2026-02-14T13:01:56.2499027Z                             r RECORD;
2026-02-14T13:01:56.2499099Z                         BEGIN
2026-02-14T13:01:56.2499246Z                             FOR r IN (
2026-02-14T13:01:56.2499346Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2499434Z                                 FROM pg_tables
2026-02-14T13:01:56.2499558Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2499625Z                             )
2026-02-14T13:01:56.2499696Z                             LOOP
2026-02-14T13:01:56.2500012Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2500084Z                             END LOOP;
2026-02-14T13:01:56.2500152Z                         END $$;
2026-02-14T13:01:56.2500227Z                     """)
2026-02-14T13:01:56.2500311Z                 except psycopg2.Error:
2026-02-14T13:01:56.2500484Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2500564Z                     pass
2026-02-14T13:01:56.2500623Z     
2026-02-14T13:01:56.2500792Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2500904Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2500987Z                 if init_dir.exists():
2026-02-14T13:01:56.2501336Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2501436Z                     for script_path in scripts:
2026-02-14T13:01:56.2501568Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2501646Z                             sql = f.read()
2026-02-14T13:01:56.2501855Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2501993Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2502074Z                             statements = []
2026-02-14T13:01:56.2502136Z     
2026-02-14T13:01:56.2502314Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2502400Z                             do_blocks = []
2026-02-14T13:01:56.2502502Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2502561Z     
2026-02-14T13:01:56.2502667Z                             def replace_do_block(match):
2026-02-14T13:01:56.2502759Z                                 block = match.group(0)
2026-02-14T13:01:56.2502887Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2502991Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2503079Z                                 return placeholder
2026-02-14T13:01:56.2503140Z     
2026-02-14T13:01:56.2503247Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2503354Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2503437Z                                                     ^^
2026-02-14T13:01:56.2503627Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2503702Z                             )
2026-02-14T13:01:56.2503809Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2503814Z 
2026-02-14T13:01:56.2503917Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2504215Z _ ERROR at setup of TestDataPreservation.test_fact_jobs_preserves_all_campaigns_on_single_campaign_dag _
2026-02-14T13:01:56.2504220Z 
2026-02-14T13:01:56.2504514Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2504520Z 
2026-02-14T13:01:56.2504755Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2504869Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2504936Z         """
2026-02-14T13:01:56.2505078Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2505241Z     
2026-02-14T13:01:56.2505377Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2505509Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2505570Z         """
2026-02-14T13:01:56.2505669Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2505804Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2505863Z     
2026-02-14T13:01:56.2505970Z         # Parse connection string to get database name
2026-02-14T13:01:56.2506222Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2506281Z     
2026-02-14T13:01:56.2506471Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2506699Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2506765Z     
2026-02-14T13:01:56.2506909Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2507024Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2507105Z         if len(parts) >= 4:
2026-02-14T13:01:56.2507225Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2507289Z         else:
2026-02-14T13:01:56.2507393Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2507452Z     
2026-02-14T13:01:56.2507549Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2507777Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2507850Z         import time
2026-02-14T13:01:56.2507907Z     
2026-02-14T13:01:56.2507976Z         max_retries = 5
2026-02-14T13:01:56.2508053Z         retry_delay = 2
2026-02-14T13:01:56.2508111Z     
2026-02-14T13:01:56.2508196Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2508261Z             try:
2026-02-14T13:01:56.2508368Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2508469Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2508550Z                 conn.autocommit = True
2026-02-14T13:01:56.2508620Z                 try:
2026-02-14T13:01:56.2508700Z                     cur = conn.cursor()
2026-02-14T13:01:56.2508892Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2508981Z                     if not cur.fetchone():
2026-02-14T13:01:56.2509135Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2509250Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2509321Z                     cur.close()
2026-02-14T13:01:56.2509396Z                 finally:
2026-02-14T13:01:56.2509469Z                     conn.close()
2026-02-14T13:01:56.2509541Z                 break  # Success
2026-02-14T13:01:56.2509738Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2509834Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2509905Z                     print(
2026-02-14T13:01:56.2510128Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2510194Z                     )
2026-02-14T13:01:56.2510277Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2510341Z                 else:
2026-02-14T13:01:56.2510550Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2510732Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2510801Z                     pass
2026-02-14T13:01:56.2511019Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2511247Z                 break  # Already exists
2026-02-14T13:01:56.2511306Z     
2026-02-14T13:01:56.2511524Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2511833Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2511968Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2512027Z     
2026-02-14T13:01:56.2512107Z         close_all_pools()
2026-02-14T13:01:56.2512167Z     
2026-02-14T13:01:56.2512286Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2512452Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2512594Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2512674Z             conn.autocommit = True
2026-02-14T13:01:56.2512756Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2512954Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2513048Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2513126Z                 cur.execute(
2026-02-14T13:01:56.2513197Z                     """
2026-02-14T13:01:56.2513295Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2513375Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2513476Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2513566Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2513630Z                     """
2026-02-14T13:01:56.2513693Z                 )
2026-02-14T13:01:56.2513760Z     
2026-02-14T13:01:56.2513949Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2514133Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2514207Z                 try:
2026-02-14T13:01:56.2514325Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2514401Z                     cur.execute("""
2026-02-14T13:01:56.2514476Z                         DO $$
2026-02-14T13:01:56.2514548Z                         DECLARE
2026-02-14T13:01:56.2514621Z                             r RECORD;
2026-02-14T13:01:56.2514688Z                         BEGIN
2026-02-14T13:01:56.2514766Z                             FOR r IN (
2026-02-14T13:01:56.2514867Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2514948Z                                 FROM pg_views
2026-02-14T13:01:56.2515081Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2515147Z                             )
2026-02-14T13:01:56.2515217Z                             LOOP
2026-02-14T13:01:56.2515539Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2515613Z                             END LOOP;
2026-02-14T13:01:56.2515682Z                         END $$;
2026-02-14T13:01:56.2515747Z                     """)
2026-02-14T13:01:56.2515830Z                     # Drop tables
2026-02-14T13:01:56.2515907Z                     cur.execute("""
2026-02-14T13:01:56.2515974Z                         DO $$
2026-02-14T13:01:56.2516051Z                         DECLARE
2026-02-14T13:01:56.2516122Z                             r RECORD;
2026-02-14T13:01:56.2516189Z                         BEGIN
2026-02-14T13:01:56.2516261Z                             FOR r IN (
2026-02-14T13:01:56.2516371Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2516453Z                                 FROM pg_tables
2026-02-14T13:01:56.2516579Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2516655Z                             )
2026-02-14T13:01:56.2516847Z                             LOOP
2026-02-14T13:01:56.2517166Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2517323Z                             END LOOP;
2026-02-14T13:01:56.2517391Z                         END $$;
2026-02-14T13:01:56.2517456Z                     """)
2026-02-14T13:01:56.2517539Z                 except psycopg2.Error:
2026-02-14T13:01:56.2517720Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2517789Z                     pass
2026-02-14T13:01:56.2517848Z     
2026-02-14T13:01:56.2518026Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2518133Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2518210Z                 if init_dir.exists():
2026-02-14T13:01:56.2518322Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2518414Z                     for script_path in scripts:
2026-02-14T13:01:56.2518538Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2518615Z                             sql = f.read()
2026-02-14T13:01:56.2518832Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2518965Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2519044Z                             statements = []
2026-02-14T13:01:56.2519106Z     
2026-02-14T13:01:56.2519281Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2519361Z                             do_blocks = []
2026-02-14T13:01:56.2519468Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2519527Z     
2026-02-14T13:01:56.2519626Z                             def replace_do_block(match):
2026-02-14T13:01:56.2519723Z                                 block = match.group(0)
2026-02-14T13:01:56.2519848Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2519947Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2520041Z                                 return placeholder
2026-02-14T13:01:56.2520104Z     
2026-02-14T13:01:56.2520213Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2520310Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2520394Z                                                     ^^
2026-02-14T13:01:56.2520579Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2520646Z                             )
2026-02-14T13:01:56.2520757Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2520762Z 
2026-02-14T13:01:56.2520864Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2521226Z _ ERROR at setup of TestDataPreservation.test_staging_incremental_preserves_other_campaigns _
2026-02-14T13:01:56.2521232Z 
2026-02-14T13:01:56.2521508Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2521517Z 
2026-02-14T13:01:56.2521605Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2521717Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2521778Z         """
2026-02-14T13:01:56.2521912Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2521976Z     
2026-02-14T13:01:56.2522109Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2522232Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2522298Z         """
2026-02-14T13:01:56.2522393Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2522520Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2522702Z     
2026-02-14T13:01:56.2522819Z         # Parse connection string to get database name
2026-02-14T13:01:56.2523061Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2523219Z     
2026-02-14T13:01:56.2523410Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2523640Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2523700Z     
2026-02-14T13:01:56.2523847Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2523956Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2524031Z         if len(parts) >= 4:
2026-02-14T13:01:56.2524148Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2524217Z         else:
2026-02-14T13:01:56.2524315Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2524377Z     
2026-02-14T13:01:56.2524479Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2524705Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2524772Z         import time
2026-02-14T13:01:56.2524840Z     
2026-02-14T13:01:56.2524911Z         max_retries = 5
2026-02-14T13:01:56.2524980Z         retry_delay = 2
2026-02-14T13:01:56.2525040Z     
2026-02-14T13:01:56.2525135Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2525198Z             try:
2026-02-14T13:01:56.2525298Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2525399Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2525479Z                 conn.autocommit = True
2026-02-14T13:01:56.2525544Z                 try:
2026-02-14T13:01:56.2525624Z                     cur = conn.cursor()
2026-02-14T13:01:56.2525819Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2525900Z                     if not cur.fetchone():
2026-02-14T13:01:56.2526051Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2526175Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2526250Z                     cur.close()
2026-02-14T13:01:56.2526318Z                 finally:
2026-02-14T13:01:56.2526396Z                     conn.close()
2026-02-14T13:01:56.2526467Z                 break  # Success
2026-02-14T13:01:56.2526655Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2526747Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2526824Z                     print(
2026-02-14T13:01:56.2527041Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2527105Z                     )
2026-02-14T13:01:56.2527199Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2527265Z                 else:
2026-02-14T13:01:56.2527471Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2527661Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2527734Z                     pass
2026-02-14T13:01:56.2527847Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2527926Z                 break  # Already exists
2026-02-14T13:01:56.2527991Z     
2026-02-14T13:01:56.2528214Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2528395Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2528536Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2528595Z     
2026-02-14T13:01:56.2528673Z         close_all_pools()
2026-02-14T13:01:56.2528739Z     
2026-02-14T13:01:56.2528954Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2529123Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2529264Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2529425Z             conn.autocommit = True
2026-02-14T13:01:56.2529503Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2529696Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2529794Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2529865Z                 cur.execute(
2026-02-14T13:01:56.2529929Z                     """
2026-02-14T13:01:56.2530024Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2530110Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2530205Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2530295Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2530368Z                     """
2026-02-14T13:01:56.2530429Z                 )
2026-02-14T13:01:56.2530487Z     
2026-02-14T13:01:56.2530679Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2530866Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2530929Z                 try:
2026-02-14T13:01:56.2531226Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2531360Z                     cur.execute("""
2026-02-14T13:01:56.2531433Z                         DO $$
2026-02-14T13:01:56.2531504Z                         DECLARE
2026-02-14T13:01:56.2531583Z                             r RECORD;
2026-02-14T13:01:56.2531650Z                         BEGIN
2026-02-14T13:01:56.2531724Z                             FOR r IN (
2026-02-14T13:01:56.2531828Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2531914Z                                 FROM pg_views
2026-02-14T13:01:56.2532041Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2532107Z                             )
2026-02-14T13:01:56.2532183Z                             LOOP
2026-02-14T13:01:56.2532499Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2532572Z                             END LOOP;
2026-02-14T13:01:56.2532645Z                         END $$;
2026-02-14T13:01:56.2532710Z                     """)
2026-02-14T13:01:56.2532785Z                     # Drop tables
2026-02-14T13:01:56.2532864Z                     cur.execute("""
2026-02-14T13:01:56.2532931Z                         DO $$
2026-02-14T13:01:56.2532998Z                         DECLARE
2026-02-14T13:01:56.2533068Z                             r RECORD;
2026-02-14T13:01:56.2533140Z                         BEGIN
2026-02-14T13:01:56.2533214Z                             FOR r IN (
2026-02-14T13:01:56.2533316Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2533403Z                                 FROM pg_tables
2026-02-14T13:01:56.2533529Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2533599Z                             )
2026-02-14T13:01:56.2533669Z                             LOOP
2026-02-14T13:01:56.2533987Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2534059Z                             END LOOP;
2026-02-14T13:01:56.2534127Z                         END $$;
2026-02-14T13:01:56.2534198Z                     """)
2026-02-14T13:01:56.2534281Z                 except psycopg2.Error:
2026-02-14T13:01:56.2534452Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2534526Z                     pass
2026-02-14T13:01:56.2534735Z     
2026-02-14T13:01:56.2534908Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2535022Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2535243Z                 if init_dir.exists():
2026-02-14T13:01:56.2535349Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2535439Z                     for script_path in scripts:
2026-02-14T13:01:56.2535568Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2535645Z                             sql = f.read()
2026-02-14T13:01:56.2535852Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2535991Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2536072Z                             statements = []
2026-02-14T13:01:56.2536131Z     
2026-02-14T13:01:56.2536316Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2536392Z                             do_blocks = []
2026-02-14T13:01:56.2536495Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2536558Z     
2026-02-14T13:01:56.2536661Z                             def replace_do_block(match):
2026-02-14T13:01:56.2536751Z                                 block = match.group(0)
2026-02-14T13:01:56.2536878Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2536981Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2537068Z                                 return placeholder
2026-02-14T13:01:56.2537126Z     
2026-02-14T13:01:56.2537254Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2542018Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2542148Z                                                     ^^
2026-02-14T13:01:56.2542370Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2542454Z                             )
2026-02-14T13:01:56.2542573Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2542583Z 
2026-02-14T13:01:56.2542691Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2542996Z _ ERROR at setup of TestDataPreservation.test_incremental_materialization_processes_only_new_records _
2026-02-14T13:01:56.2543001Z 
2026-02-14T13:01:56.2543348Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2543354Z 
2026-02-14T13:01:56.2543449Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2543559Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2543628Z         """
2026-02-14T13:01:56.2543774Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2543835Z     
2026-02-14T13:01:56.2543977Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2544115Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2544176Z         """
2026-02-14T13:01:56.2544271Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2544412Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2544473Z     
2026-02-14T13:01:56.2544588Z         # Parse connection string to get database name
2026-02-14T13:01:56.2544847Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2544908Z     
2026-02-14T13:01:56.2545099Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2545333Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2545398Z     
2026-02-14T13:01:56.2545543Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2545815Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2545907Z         if len(parts) >= 4:
2026-02-14T13:01:56.2546032Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2546095Z         else:
2026-02-14T13:01:56.2546312Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2546374Z     
2026-02-14T13:01:56.2546472Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2546705Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2546778Z         import time
2026-02-14T13:01:56.2546837Z     
2026-02-14T13:01:56.2546908Z         max_retries = 5
2026-02-14T13:01:56.2546982Z         retry_delay = 2
2026-02-14T13:01:56.2547041Z     
2026-02-14T13:01:56.2547129Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2547191Z             try:
2026-02-14T13:01:56.2547303Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2547406Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2547488Z                 conn.autocommit = True
2026-02-14T13:01:56.2547559Z                 try:
2026-02-14T13:01:56.2547638Z                     cur = conn.cursor()
2026-02-14T13:01:56.2547843Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2547931Z                     if not cur.fetchone():
2026-02-14T13:01:56.2548089Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2548208Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2548281Z                     cur.close()
2026-02-14T13:01:56.2548358Z                 finally:
2026-02-14T13:01:56.2548433Z                     conn.close()
2026-02-14T13:01:56.2548507Z                 break  # Success
2026-02-14T13:01:56.2548710Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2548810Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2548881Z                     print(
2026-02-14T13:01:56.2549114Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2549184Z                     )
2026-02-14T13:01:56.2549269Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2549334Z                 else:
2026-02-14T13:01:56.2549546Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2549733Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2549804Z                     pass
2026-02-14T13:01:56.2549931Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2550012Z                 break  # Already exists
2026-02-14T13:01:56.2550070Z     
2026-02-14T13:01:56.2550299Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2550489Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2550626Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2550684Z     
2026-02-14T13:01:56.2550766Z         close_all_pools()
2026-02-14T13:01:56.2550823Z     
2026-02-14T13:01:56.2550941Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2551247Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2551395Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2551477Z             conn.autocommit = True
2026-02-14T13:01:56.2551557Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2551758Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2551850Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2551922Z                 cur.execute(
2026-02-14T13:01:56.2552112Z                     """
2026-02-14T13:01:56.2552217Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2552299Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2552403Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2552593Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2552658Z                     """
2026-02-14T13:01:56.2552719Z                 )
2026-02-14T13:01:56.2552785Z     
2026-02-14T13:01:56.2552978Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2553160Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2553232Z                 try:
2026-02-14T13:01:56.2553351Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2553431Z                     cur.execute("""
2026-02-14T13:01:56.2553508Z                         DO $$
2026-02-14T13:01:56.2553582Z                         DECLARE
2026-02-14T13:01:56.2553656Z                             r RECORD;
2026-02-14T13:01:56.2553724Z                         BEGIN
2026-02-14T13:01:56.2553805Z                             FOR r IN (
2026-02-14T13:01:56.2553911Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2553994Z                                 FROM pg_views
2026-02-14T13:01:56.2554132Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2554202Z                             )
2026-02-14T13:01:56.2554275Z                             LOOP
2026-02-14T13:01:56.2554596Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2554670Z                             END LOOP;
2026-02-14T13:01:56.2554738Z                         END $$;
2026-02-14T13:01:56.2554803Z                     """)
2026-02-14T13:01:56.2554885Z                     # Drop tables
2026-02-14T13:01:56.2554958Z                     cur.execute("""
2026-02-14T13:01:56.2555027Z                         DO $$
2026-02-14T13:01:56.2555098Z                         DECLARE
2026-02-14T13:01:56.2555168Z                             r RECORD;
2026-02-14T13:01:56.2555238Z                         BEGIN
2026-02-14T13:01:56.2555314Z                             FOR r IN (
2026-02-14T13:01:56.2555421Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2555506Z                                 FROM pg_tables
2026-02-14T13:01:56.2555633Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2555706Z                             )
2026-02-14T13:01:56.2555775Z                             LOOP
2026-02-14T13:01:56.2556087Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2556166Z                             END LOOP;
2026-02-14T13:01:56.2556236Z                         END $$;
2026-02-14T13:01:56.2556302Z                     """)
2026-02-14T13:01:56.2556385Z                 except psycopg2.Error:
2026-02-14T13:01:56.2556563Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2556634Z                     pass
2026-02-14T13:01:56.2556692Z     
2026-02-14T13:01:56.2556873Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2556981Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2557057Z                 if init_dir.exists():
2026-02-14T13:01:56.2557170Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2557260Z                     for script_path in scripts:
2026-02-14T13:01:56.2557385Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2557469Z                             sql = f.read()
2026-02-14T13:01:56.2557770Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2557906Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2557985Z                             statements = []
2026-02-14T13:01:56.2558126Z     
2026-02-14T13:01:56.2558305Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2558380Z                             do_blocks = []
2026-02-14T13:01:56.2558490Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2558548Z     
2026-02-14T13:01:56.2558646Z                             def replace_do_block(match):
2026-02-14T13:01:56.2558742Z                                 block = match.group(0)
2026-02-14T13:01:56.2558868Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2558963Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2559053Z                                 return placeholder
2026-02-14T13:01:56.2559116Z     
2026-02-14T13:01:56.2559225Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2559323Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2559416Z                                                     ^^
2026-02-14T13:01:56.2559601Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2559669Z                             )
2026-02-14T13:01:56.2559785Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2559791Z 
2026-02-14T13:01:56.2559891Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2560138Z _ ERROR at setup of TestDataPreservation.test_fact_jobs_incremental_without_campaign_filter _
2026-02-14T13:01:56.2560144Z 
2026-02-14T13:01:56.2560434Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2560440Z 
2026-02-14T13:01:56.2560535Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2560650Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2560713Z         """
2026-02-14T13:01:56.2560853Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2560922Z     
2026-02-14T13:01:56.2561196Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2561328Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2561394Z         """
2026-02-14T13:01:56.2561491Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2561618Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2561677Z     
2026-02-14T13:01:56.2561794Z         # Parse connection string to get database name
2026-02-14T13:01:56.2562045Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2562107Z     
2026-02-14T13:01:56.2562304Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2562534Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2562593Z     
2026-02-14T13:01:56.2562745Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2562857Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2562935Z         if len(parts) >= 4:
2026-02-14T13:01:56.2563056Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2563125Z         else:
2026-02-14T13:01:56.2563225Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2563285Z     
2026-02-14T13:01:56.2563389Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2563619Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2563687Z         import time
2026-02-14T13:01:56.2563752Z     
2026-02-14T13:01:56.2563947Z         max_retries = 5
2026-02-14T13:01:56.2564021Z         retry_delay = 2
2026-02-14T13:01:56.2564080Z     
2026-02-14T13:01:56.2564173Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2564237Z             try:
2026-02-14T13:01:56.2564463Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2564565Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2564649Z                 conn.autocommit = True
2026-02-14T13:01:56.2564714Z                 try:
2026-02-14T13:01:56.2564796Z                     cur = conn.cursor()
2026-02-14T13:01:56.2564994Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2565077Z                     if not cur.fetchone():
2026-02-14T13:01:56.2565232Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2565360Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2565437Z                     cur.close()
2026-02-14T13:01:56.2565507Z                 finally:
2026-02-14T13:01:56.2565593Z                     conn.close()
2026-02-14T13:01:56.2565665Z                 break  # Success
2026-02-14T13:01:56.2565862Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2565954Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2566033Z                     print(
2026-02-14T13:01:56.2566255Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2566324Z                     )
2026-02-14T13:01:56.2566417Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2566483Z                 else:
2026-02-14T13:01:56.2566688Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2566877Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2566949Z                     pass
2026-02-14T13:01:56.2567065Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2567146Z                 break  # Already exists
2026-02-14T13:01:56.2567214Z     
2026-02-14T13:01:56.2567435Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2567618Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2567760Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2567819Z     
2026-02-14T13:01:56.2567895Z         close_all_pools()
2026-02-14T13:01:56.2567959Z     
2026-02-14T13:01:56.2568078Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2568243Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2568389Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2568483Z             conn.autocommit = True
2026-02-14T13:01:56.2568565Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2568759Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2568857Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2568935Z                 cur.execute(
2026-02-14T13:01:56.2569000Z                     """
2026-02-14T13:01:56.2569104Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2569183Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2569281Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2569382Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2569447Z                     """
2026-02-14T13:01:56.2569508Z                 )
2026-02-14T13:01:56.2569572Z     
2026-02-14T13:01:56.2569761Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2570037Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2570104Z                 try:
2026-02-14T13:01:56.2570227Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2570305Z                     cur.execute("""
2026-02-14T13:01:56.2570451Z                         DO $$
2026-02-14T13:01:56.2570526Z                         DECLARE
2026-02-14T13:01:56.2570599Z                             r RECORD;
2026-02-14T13:01:56.2570666Z                         BEGIN
2026-02-14T13:01:56.2570746Z                             FOR r IN (
2026-02-14T13:01:56.2570849Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2570931Z                                 FROM pg_views
2026-02-14T13:01:56.2571258Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2571393Z                             )
2026-02-14T13:01:56.2571475Z                             LOOP
2026-02-14T13:01:56.2571797Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2571881Z                             END LOOP;
2026-02-14T13:01:56.2571949Z                         END $$;
2026-02-14T13:01:56.2572019Z                     """)
2026-02-14T13:01:56.2572098Z                     # Drop tables
2026-02-14T13:01:56.2572173Z                     cur.execute("""
2026-02-14T13:01:56.2572240Z                         DO $$
2026-02-14T13:01:56.2572307Z                         DECLARE
2026-02-14T13:01:56.2572385Z                             r RECORD;
2026-02-14T13:01:56.2572452Z                         BEGIN
2026-02-14T13:01:56.2572524Z                             FOR r IN (
2026-02-14T13:01:56.2572630Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2572713Z                                 FROM pg_tables
2026-02-14T13:01:56.2572841Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2572910Z                             )
2026-02-14T13:01:56.2572987Z                             LOOP
2026-02-14T13:01:56.2573300Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2573376Z                             END LOOP;
2026-02-14T13:01:56.2573450Z                         END $$;
2026-02-14T13:01:56.2573514Z                     """)
2026-02-14T13:01:56.2573597Z                 except psycopg2.Error:
2026-02-14T13:01:56.2573778Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2573845Z                     pass
2026-02-14T13:01:56.2573904Z     
2026-02-14T13:01:56.2574078Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2574194Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2574271Z                 if init_dir.exists():
2026-02-14T13:01:56.2574378Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2574475Z                     for script_path in scripts:
2026-02-14T13:01:56.2574605Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2574684Z                             sql = f.read()
2026-02-14T13:01:56.2574893Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2575023Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2575101Z                             statements = []
2026-02-14T13:01:56.2575166Z     
2026-02-14T13:01:56.2575343Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2575420Z                             do_blocks = []
2026-02-14T13:01:56.2575521Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2575585Z     
2026-02-14T13:01:56.2575805Z                             def replace_do_block(match):
2026-02-14T13:01:56.2575903Z                                 block = match.group(0)
2026-02-14T13:01:56.2576037Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2576235Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2576323Z                                 return placeholder
2026-02-14T13:01:56.2576386Z     
2026-02-14T13:01:56.2576495Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2576591Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2576674Z                                                     ^^
2026-02-14T13:01:56.2576900Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2576969Z                             )
2026-02-14T13:01:56.2577077Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2577082Z 
2026-02-14T13:01:56.2577194Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2577426Z _ ERROR at setup of TestDataPreservation.test_ranking_upsert_preserves_other_campaigns _
2026-02-14T13:01:56.2577431Z 
2026-02-14T13:01:56.2577722Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2577730Z 
2026-02-14T13:01:56.2577818Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2577925Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2577987Z         """
2026-02-14T13:01:56.2578126Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2578186Z     
2026-02-14T13:01:56.2578323Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2578453Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2578514Z         """
2026-02-14T13:01:56.2578616Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2578746Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2578804Z     
2026-02-14T13:01:56.2578919Z         # Parse connection string to get database name
2026-02-14T13:01:56.2579166Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2579228Z     
2026-02-14T13:01:56.2579413Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2579651Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2579709Z     
2026-02-14T13:01:56.2579852Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2579967Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2580045Z         if len(parts) >= 4:
2026-02-14T13:01:56.2580165Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2580234Z         else:
2026-02-14T13:01:56.2580338Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2580397Z     
2026-02-14T13:01:56.2580494Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2580727Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2580799Z         import time
2026-02-14T13:01:56.2580860Z     
2026-02-14T13:01:56.2580935Z         max_retries = 5
2026-02-14T13:01:56.2581004Z         retry_delay = 2
2026-02-14T13:01:56.2581233Z     
2026-02-14T13:01:56.2581365Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2581437Z             try:
2026-02-14T13:01:56.2581544Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2581643Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2581731Z                 conn.autocommit = True
2026-02-14T13:01:56.2581796Z                 try:
2026-02-14T13:01:56.2581877Z                     cur = conn.cursor()
2026-02-14T13:01:56.2582202Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2582289Z                     if not cur.fetchone():
2026-02-14T13:01:56.2582443Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2582666Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2582746Z                     cur.close()
2026-02-14T13:01:56.2582814Z                 finally:
2026-02-14T13:01:56.2582889Z                     conn.close()
2026-02-14T13:01:56.2582966Z                 break  # Success
2026-02-14T13:01:56.2583156Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2583246Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2583326Z                     print(
2026-02-14T13:01:56.2583545Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2583613Z                     )
2026-02-14T13:01:56.2583699Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2583770Z                 else:
2026-02-14T13:01:56.2583976Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2584158Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2584237Z                     pass
2026-02-14T13:01:56.2584355Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2584434Z                 break  # Already exists
2026-02-14T13:01:56.2584499Z     
2026-02-14T13:01:56.2584716Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2584899Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2585030Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2585095Z     
2026-02-14T13:01:56.2585173Z         close_all_pools()
2026-02-14T13:01:56.2585229Z     
2026-02-14T13:01:56.2585354Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2585520Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2585660Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2585752Z             conn.autocommit = True
2026-02-14T13:01:56.2585830Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2586021Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2586112Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2586192Z                 cur.execute(
2026-02-14T13:01:56.2586257Z                     """
2026-02-14T13:01:56.2586355Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2586441Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2586538Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2586631Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2586696Z                     """
2026-02-14T13:01:56.2586763Z                 )
2026-02-14T13:01:56.2586820Z     
2026-02-14T13:01:56.2587008Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2587197Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2587273Z                 try:
2026-02-14T13:01:56.2587389Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2587466Z                     cur.execute("""
2026-02-14T13:01:56.2587543Z                         DO $$
2026-02-14T13:01:56.2587610Z                         DECLARE
2026-02-14T13:01:56.2587684Z                             r RECORD;
2026-02-14T13:01:56.2587751Z                         BEGIN
2026-02-14T13:01:56.2587830Z                             FOR r IN (
2026-02-14T13:01:56.2587931Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2588150Z                                 FROM pg_views
2026-02-14T13:01:56.2588288Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2588356Z                             )
2026-02-14T13:01:56.2588508Z                             LOOP
2026-02-14T13:01:56.2588830Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2588904Z                             END LOOP;
2026-02-14T13:01:56.2588975Z                         END $$;
2026-02-14T13:01:56.2589043Z                     """)
2026-02-14T13:01:56.2589123Z                     # Drop tables
2026-02-14T13:01:56.2589196Z                     cur.execute("""
2026-02-14T13:01:56.2589262Z                         DO $$
2026-02-14T13:01:56.2589336Z                         DECLARE
2026-02-14T13:01:56.2589403Z                             r RECORD;
2026-02-14T13:01:56.2589469Z                         BEGIN
2026-02-14T13:01:56.2589549Z                             FOR r IN (
2026-02-14T13:01:56.2589650Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2589734Z                                 FROM pg_tables
2026-02-14T13:01:56.2589863Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2589934Z                             )
2026-02-14T13:01:56.2590002Z                             LOOP
2026-02-14T13:01:56.2590316Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2590395Z                             END LOOP;
2026-02-14T13:01:56.2590462Z                         END $$;
2026-02-14T13:01:56.2590527Z                     """)
2026-02-14T13:01:56.2590617Z                 except psycopg2.Error:
2026-02-14T13:01:56.2590793Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2590864Z                     pass
2026-02-14T13:01:56.2590922Z     
2026-02-14T13:01:56.2591240Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2591352Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2591436Z                 if init_dir.exists():
2026-02-14T13:01:56.2591546Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2591636Z                     for script_path in scripts:
2026-02-14T13:01:56.2591762Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2591842Z                             sql = f.read()
2026-02-14T13:01:56.2592046Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2592177Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2592255Z                             statements = []
2026-02-14T13:01:56.2592319Z     
2026-02-14T13:01:56.2592502Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2592577Z                             do_blocks = []
2026-02-14T13:01:56.2592682Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2592744Z     
2026-02-14T13:01:56.2592840Z                             def replace_do_block(match):
2026-02-14T13:01:56.2592937Z                                 block = match.group(0)
2026-02-14T13:01:56.2593063Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2593160Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2593248Z                                 return placeholder
2026-02-14T13:01:56.2593316Z     
2026-02-14T13:01:56.2593424Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2593519Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2593727Z                                                     ^^
2026-02-14T13:01:56.2593916Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2593983Z                             )
2026-02-14T13:01:56.2594414Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2594419Z 
2026-02-14T13:01:56.2594521Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2594752Z _ ERROR at setup of TestDataPreservation.test_ranking_upsert_updates_existing_rankings _
2026-02-14T13:01:56.2594757Z 
2026-02-14T13:01:56.2595061Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2595067Z 
2026-02-14T13:01:56.2595162Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2595268Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2595330Z         """
2026-02-14T13:01:56.2595466Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2595529Z     
2026-02-14T13:01:56.2595666Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2595793Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2595860Z         """
2026-02-14T13:01:56.2595955Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2596084Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2596142Z     
2026-02-14T13:01:56.2596258Z         # Parse connection string to get database name
2026-02-14T13:01:56.2596503Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2596561Z     
2026-02-14T13:01:56.2596755Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2596983Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2597041Z     
2026-02-14T13:01:56.2597197Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2597312Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2597391Z         if len(parts) >= 4:
2026-02-14T13:01:56.2597513Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2597585Z         else:
2026-02-14T13:01:56.2597688Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2597745Z     
2026-02-14T13:01:56.2597849Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2598079Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2598145Z         import time
2026-02-14T13:01:56.2598208Z     
2026-02-14T13:01:56.2598277Z         max_retries = 5
2026-02-14T13:01:56.2598345Z         retry_delay = 2
2026-02-14T13:01:56.2598404Z     
2026-02-14T13:01:56.2598496Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2598558Z             try:
2026-02-14T13:01:56.2598667Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2598768Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2598851Z                 conn.autocommit = True
2026-02-14T13:01:56.2598914Z                 try:
2026-02-14T13:01:56.2598992Z                     cur = conn.cursor()
2026-02-14T13:01:56.2599191Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2599274Z                     if not cur.fetchone():
2026-02-14T13:01:56.2599424Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2599548Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2599622Z                     cur.close()
2026-02-14T13:01:56.2599689Z                 finally:
2026-02-14T13:01:56.2599768Z                     conn.close()
2026-02-14T13:01:56.2599840Z                 break  # Success
2026-02-14T13:01:56.2600029Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2600212Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2600292Z                     print(
2026-02-14T13:01:56.2600512Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2600651Z                     )
2026-02-14T13:01:56.2600743Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2600808Z                 else:
2026-02-14T13:01:56.2601016Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2601332Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2601402Z                     pass
2026-02-14T13:01:56.2601518Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2601599Z                 break  # Already exists
2026-02-14T13:01:56.2601662Z     
2026-02-14T13:01:56.2601886Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2602073Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2602211Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2602275Z     
2026-02-14T13:01:56.2602347Z         close_all_pools()
2026-02-14T13:01:56.2602409Z     
2026-02-14T13:01:56.2602524Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2602688Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2602829Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2602916Z             conn.autocommit = True
2026-02-14T13:01:56.2602994Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2603186Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2603284Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2603357Z                 cur.execute(
2026-02-14T13:01:56.2603424Z                     """
2026-02-14T13:01:56.2603526Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2603609Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2603704Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2603799Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2603869Z                     """
2026-02-14T13:01:56.2603930Z                 )
2026-02-14T13:01:56.2603988Z     
2026-02-14T13:01:56.2604180Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2604363Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2604427Z                 try:
2026-02-14T13:01:56.2604550Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2604625Z                     cur.execute("""
2026-02-14T13:01:56.2604695Z                         DO $$
2026-02-14T13:01:56.2604765Z                         DECLARE
2026-02-14T13:01:56.2604844Z                             r RECORD;
2026-02-14T13:01:56.2604910Z                         BEGIN
2026-02-14T13:01:56.2604982Z                             FOR r IN (
2026-02-14T13:01:56.2605091Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2605175Z                                 FROM pg_views
2026-02-14T13:01:56.2605304Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2605369Z                             )
2026-02-14T13:01:56.2605444Z                             LOOP
2026-02-14T13:01:56.2605754Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2605826Z                             END LOOP;
2026-02-14T13:01:56.2605900Z                         END $$;
2026-02-14T13:01:56.2605966Z                     """)
2026-02-14T13:01:56.2606184Z                     # Drop tables
2026-02-14T13:01:56.2606266Z                     cur.execute("""
2026-02-14T13:01:56.2606334Z                         DO $$
2026-02-14T13:01:56.2606400Z                         DECLARE
2026-02-14T13:01:56.2606472Z                             r RECORD;
2026-02-14T13:01:56.2606644Z                         BEGIN
2026-02-14T13:01:56.2606715Z                             FOR r IN (
2026-02-14T13:01:56.2606818Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2606908Z                                 FROM pg_tables
2026-02-14T13:01:56.2607035Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2607101Z                             )
2026-02-14T13:01:56.2607176Z                             LOOP
2026-02-14T13:01:56.2607491Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2607566Z                             END LOOP;
2026-02-14T13:01:56.2607633Z                         END $$;
2026-02-14T13:01:56.2607704Z                     """)
2026-02-14T13:01:56.2607786Z                 except psycopg2.Error:
2026-02-14T13:01:56.2607959Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2608038Z                     pass
2026-02-14T13:01:56.2608096Z     
2026-02-14T13:01:56.2608267Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2608382Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2608459Z                 if init_dir.exists():
2026-02-14T13:01:56.2608565Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2608656Z                     for script_path in scripts:
2026-02-14T13:01:56.2608786Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2608864Z                             sql = f.read()
2026-02-14T13:01:56.2609071Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2609214Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2609298Z                             statements = []
2026-02-14T13:01:56.2609357Z     
2026-02-14T13:01:56.2609543Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2609619Z                             do_blocks = []
2026-02-14T13:01:56.2609721Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2609783Z     
2026-02-14T13:01:56.2609887Z                             def replace_do_block(match):
2026-02-14T13:01:56.2609978Z                                 block = match.group(0)
2026-02-14T13:01:56.2610106Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2610212Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2610304Z                                 return placeholder
2026-02-14T13:01:56.2610362Z     
2026-02-14T13:01:56.2610477Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2610576Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2610662Z                                                     ^^
2026-02-14T13:01:56.2610855Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2610922Z                             )
2026-02-14T13:01:56.2611258Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2611269Z 
2026-02-14T13:01:56.2611422Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2611680Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_resume_linked_to_multiple_jobs _
2026-02-14T13:01:56.2611685Z 
2026-02-14T13:01:56.2611985Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2612143Z 
2026-02-14T13:01:56.2612244Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2612353Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2612420Z         """
2026-02-14T13:01:56.2612556Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2612727Z     
2026-02-14T13:01:56.2612867Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2612994Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2613055Z         """
2026-02-14T13:01:56.2613149Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2613283Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2613341Z     
2026-02-14T13:01:56.2613449Z         # Parse connection string to get database name
2026-02-14T13:01:56.2613698Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2613756Z     
2026-02-14T13:01:56.2613941Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2614172Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2614236Z     
2026-02-14T13:01:56.2614378Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2614490Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2614569Z         if len(parts) >= 4:
2026-02-14T13:01:56.2614689Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2614750Z         else:
2026-02-14T13:01:56.2614858Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2614916Z     
2026-02-14T13:01:56.2615013Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2615241Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2615313Z         import time
2026-02-14T13:01:56.2615373Z     
2026-02-14T13:01:56.2615442Z         max_retries = 5
2026-02-14T13:01:56.2615518Z         retry_delay = 2
2026-02-14T13:01:56.2615575Z     
2026-02-14T13:01:56.2615662Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2615732Z             try:
2026-02-14T13:01:56.2615833Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2615928Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2616010Z                 conn.autocommit = True
2026-02-14T13:01:56.2616080Z                 try:
2026-02-14T13:01:56.2616158Z                     cur = conn.cursor()
2026-02-14T13:01:56.2616345Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2616431Z                     if not cur.fetchone():
2026-02-14T13:01:56.2616581Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2616699Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2616783Z                     cur.close()
2026-02-14T13:01:56.2616852Z                 finally:
2026-02-14T13:01:56.2616925Z                     conn.close()
2026-02-14T13:01:56.2616995Z                 break  # Success
2026-02-14T13:01:56.2617193Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2617283Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2617353Z                     print(
2026-02-14T13:01:56.2617573Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2617637Z                     )
2026-02-14T13:01:56.2617722Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2617787Z                 else:
2026-02-14T13:01:56.2617995Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2618263Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2618336Z                     pass
2026-02-14T13:01:56.2618463Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2618542Z                 break  # Already exists
2026-02-14T13:01:56.2618600Z     
2026-02-14T13:01:56.2618895Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2619075Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2619207Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2619272Z     
2026-02-14T13:01:56.2619346Z         close_all_pools()
2026-02-14T13:01:56.2619404Z     
2026-02-14T13:01:56.2619521Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2619689Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2619829Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2619914Z             conn.autocommit = True
2026-02-14T13:01:56.2620002Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2620195Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2620287Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2620365Z                 cur.execute(
2026-02-14T13:01:56.2620440Z                     """
2026-02-14T13:01:56.2620538Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2620618Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2620720Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2620810Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2620878Z                     """
2026-02-14T13:01:56.2620947Z                 )
2026-02-14T13:01:56.2621005Z     
2026-02-14T13:01:56.2621334Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2621525Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2621597Z                 try:
2026-02-14T13:01:56.2621713Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2621788Z                     cur.execute("""
2026-02-14T13:01:56.2621872Z                         DO $$
2026-02-14T13:01:56.2621940Z                         DECLARE
2026-02-14T13:01:56.2622015Z                             r RECORD;
2026-02-14T13:01:56.2622088Z                         BEGIN
2026-02-14T13:01:56.2622165Z                             FOR r IN (
2026-02-14T13:01:56.2622269Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2622351Z                                 FROM pg_views
2026-02-14T13:01:56.2622486Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2622552Z                             )
2026-02-14T13:01:56.2622623Z                             LOOP
2026-02-14T13:01:56.2622941Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2623015Z                             END LOOP;
2026-02-14T13:01:56.2623084Z                         END $$;
2026-02-14T13:01:56.2623159Z                     """)
2026-02-14T13:01:56.2623231Z                     # Drop tables
2026-02-14T13:01:56.2623304Z                     cur.execute("""
2026-02-14T13:01:56.2623369Z                         DO $$
2026-02-14T13:01:56.2623440Z                         DECLARE
2026-02-14T13:01:56.2623510Z                             r RECORD;
2026-02-14T13:01:56.2623575Z                         BEGIN
2026-02-14T13:01:56.2623653Z                             FOR r IN (
2026-02-14T13:01:56.2623754Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2623836Z                                 FROM pg_tables
2026-02-14T13:01:56.2624074Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2624148Z                             )
2026-02-14T13:01:56.2624218Z                             LOOP
2026-02-14T13:01:56.2624530Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2624711Z                             END LOOP;
2026-02-14T13:01:56.2624778Z                         END $$;
2026-02-14T13:01:56.2624843Z                     """)
2026-02-14T13:01:56.2624932Z                 except psycopg2.Error:
2026-02-14T13:01:56.2625105Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2625172Z                     pass
2026-02-14T13:01:56.2625230Z     
2026-02-14T13:01:56.2625409Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2625517Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2625593Z                 if init_dir.exists():
2026-02-14T13:01:56.2625705Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2625794Z                     for script_path in scripts:
2026-02-14T13:01:56.2625919Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2626002Z                             sql = f.read()
2026-02-14T13:01:56.2626208Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2626338Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2626421Z                             statements = []
2026-02-14T13:01:56.2626479Z     
2026-02-14T13:01:56.2626656Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2626732Z                             do_blocks = []
2026-02-14T13:01:56.2626840Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2626900Z     
2026-02-14T13:01:56.2627000Z                             def replace_do_block(match):
2026-02-14T13:01:56.2627096Z                                 block = match.group(0)
2026-02-14T13:01:56.2627222Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2627323Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2627416Z                                 return placeholder
2026-02-14T13:01:56.2627474Z     
2026-02-14T13:01:56.2627583Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2627681Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2627769Z                                                     ^^
2026-02-14T13:01:56.2627954Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2628021Z                             )
2026-02-14T13:01:56.2628132Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2628140Z 
2026-02-14T13:01:56.2628240Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2628482Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_delete_resume_linked_to_jobs _
2026-02-14T13:01:56.2628487Z 
2026-02-14T13:01:56.2628772Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2628777Z 
2026-02-14T13:01:56.2628870Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2628977Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2629037Z         """
2026-02-14T13:01:56.2629170Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2629235Z     
2026-02-14T13:01:56.2629367Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2629488Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2629552Z         """
2026-02-14T13:01:56.2629647Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2629871Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2629937Z     
2026-02-14T13:01:56.2630043Z         # Parse connection string to get database name
2026-02-14T13:01:56.2630282Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2630421Z     
2026-02-14T13:01:56.2630611Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2630837Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2630897Z     
2026-02-14T13:01:56.2631177Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2631292Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2631366Z         if len(parts) >= 4:
2026-02-14T13:01:56.2631489Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2631553Z         else:
2026-02-14T13:01:56.2631655Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2631714Z     
2026-02-14T13:01:56.2631823Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2632053Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2632129Z         import time
2026-02-14T13:01:56.2632194Z     
2026-02-14T13:01:56.2632263Z         max_retries = 5
2026-02-14T13:01:56.2632333Z         retry_delay = 2
2026-02-14T13:01:56.2632392Z     
2026-02-14T13:01:56.2632487Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2632551Z             try:
2026-02-14T13:01:56.2632651Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2632752Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2632833Z                 conn.autocommit = True
2026-02-14T13:01:56.2632898Z                 try:
2026-02-14T13:01:56.2632976Z                     cur = conn.cursor()
2026-02-14T13:01:56.2633172Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2633252Z                     if not cur.fetchone():
2026-02-14T13:01:56.2633404Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2633536Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2633607Z                     cur.close()
2026-02-14T13:01:56.2633675Z                 finally:
2026-02-14T13:01:56.2633755Z                     conn.close()
2026-02-14T13:01:56.2633828Z                 break  # Success
2026-02-14T13:01:56.2634020Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2634119Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2634188Z                     print(
2026-02-14T13:01:56.2634406Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2634471Z                     )
2026-02-14T13:01:56.2634562Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2634626Z                 else:
2026-02-14T13:01:56.2634826Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2635017Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2635090Z                     pass
2026-02-14T13:01:56.2635204Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2635286Z                 break  # Already exists
2026-02-14T13:01:56.2635343Z     
2026-02-14T13:01:56.2635558Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2635743Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2635883Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2635941Z     
2026-02-14T13:01:56.2636013Z         close_all_pools()
2026-02-14T13:01:56.2636238Z     
2026-02-14T13:01:56.2636364Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2636530Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2636773Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2636862Z             conn.autocommit = True
2026-02-14T13:01:56.2636942Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2637134Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2637234Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2637308Z                 cur.execute(
2026-02-14T13:01:56.2637376Z                     """
2026-02-14T13:01:56.2637478Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2637558Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2637653Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2637746Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2637818Z                     """
2026-02-14T13:01:56.2637878Z                 )
2026-02-14T13:01:56.2637935Z     
2026-02-14T13:01:56.2638130Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2638320Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2638393Z                 try:
2026-02-14T13:01:56.2638515Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2638590Z                     cur.execute("""
2026-02-14T13:01:56.2638660Z                         DO $$
2026-02-14T13:01:56.2638729Z                         DECLARE
2026-02-14T13:01:56.2638807Z                             r RECORD;
2026-02-14T13:01:56.2638874Z                         BEGIN
2026-02-14T13:01:56.2638946Z                             FOR r IN (
2026-02-14T13:01:56.2639058Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2639139Z                                 FROM pg_views
2026-02-14T13:01:56.2639269Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2639342Z                             )
2026-02-14T13:01:56.2639416Z                             LOOP
2026-02-14T13:01:56.2639727Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2639802Z                             END LOOP;
2026-02-14T13:01:56.2639875Z                         END $$;
2026-02-14T13:01:56.2639941Z                     """)
2026-02-14T13:01:56.2640014Z                     # Drop tables
2026-02-14T13:01:56.2640091Z                     cur.execute("""
2026-02-14T13:01:56.2640158Z                         DO $$
2026-02-14T13:01:56.2640224Z                         DECLARE
2026-02-14T13:01:56.2640296Z                             r RECORD;
2026-02-14T13:01:56.2640372Z                         BEGIN
2026-02-14T13:01:56.2640444Z                             FOR r IN (
2026-02-14T13:01:56.2640542Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2640633Z                                 FROM pg_tables
2026-02-14T13:01:56.2640760Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2640832Z                             )
2026-02-14T13:01:56.2640909Z                             LOOP
2026-02-14T13:01:56.2641342Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2641416Z                             END LOOP;
2026-02-14T13:01:56.2641489Z                         END $$;
2026-02-14T13:01:56.2641554Z                     """)
2026-02-14T13:01:56.2641635Z                 except psycopg2.Error:
2026-02-14T13:01:56.2641808Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2642000Z                     pass
2026-02-14T13:01:56.2642064Z     
2026-02-14T13:01:56.2642234Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2642349Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2642526Z                 if init_dir.exists():
2026-02-14T13:01:56.2642632Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2642723Z                     for script_path in scripts:
2026-02-14T13:01:56.2642857Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2642935Z                             sql = f.read()
2026-02-14T13:01:56.2643140Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2643278Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2643358Z                             statements = []
2026-02-14T13:01:56.2643419Z     
2026-02-14T13:01:56.2643604Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2643683Z                             do_blocks = []
2026-02-14T13:01:56.2643786Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2643855Z     
2026-02-14T13:01:56.2643953Z                             def replace_do_block(match):
2026-02-14T13:01:56.2644044Z                                 block = match.group(0)
2026-02-14T13:01:56.2644171Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2644274Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2644363Z                                 return placeholder
2026-02-14T13:01:56.2644421Z     
2026-02-14T13:01:56.2644537Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2644635Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2644720Z                                                     ^^
2026-02-14T13:01:56.2644912Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2644983Z                             )
2026-02-14T13:01:56.2645094Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2645098Z 
2026-02-14T13:01:56.2645197Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2645473Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_cover_letter_same_name_different_jobs _
2026-02-14T13:01:56.2645478Z 
2026-02-14T13:01:56.2645763Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2645768Z 
2026-02-14T13:01:56.2645855Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2645959Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2646025Z         """
2026-02-14T13:01:56.2646157Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2646218Z     
2026-02-14T13:01:56.2646354Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2646475Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2646536Z         """
2026-02-14T13:01:56.2646634Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2646764Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2646822Z     
2026-02-14T13:01:56.2646928Z         # Parse connection string to get database name
2026-02-14T13:01:56.2647172Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2647229Z     
2026-02-14T13:01:56.2647416Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2647643Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2647701Z     
2026-02-14T13:01:56.2647932Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2648043Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2648123Z         if len(parts) >= 4:
2026-02-14T13:01:56.2648248Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2648393Z         else:
2026-02-14T13:01:56.2648499Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2648557Z     
2026-02-14T13:01:56.2648652Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2648881Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2648948Z         import time
2026-02-14T13:01:56.2649006Z     
2026-02-14T13:01:56.2649074Z         max_retries = 5
2026-02-14T13:01:56.2649149Z         retry_delay = 2
2026-02-14T13:01:56.2649206Z     
2026-02-14T13:01:56.2649291Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2649358Z             try:
2026-02-14T13:01:56.2649462Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2649556Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2649637Z                 conn.autocommit = True
2026-02-14T13:01:56.2649705Z                 try:
2026-02-14T13:01:56.2649786Z                     cur = conn.cursor()
2026-02-14T13:01:56.2649970Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2650058Z                     if not cur.fetchone():
2026-02-14T13:01:56.2650210Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2650326Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2650403Z                     cur.close()
2026-02-14T13:01:56.2650471Z                 finally:
2026-02-14T13:01:56.2650545Z                     conn.close()
2026-02-14T13:01:56.2650615Z                 break  # Success
2026-02-14T13:01:56.2650816Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2650908Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2650979Z                     print(
2026-02-14T13:01:56.2651462Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2651535Z                     )
2026-02-14T13:01:56.2651622Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2651693Z                 else:
2026-02-14T13:01:56.2651896Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2652077Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2652147Z                     pass
2026-02-14T13:01:56.2652272Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2652350Z                 break  # Already exists
2026-02-14T13:01:56.2652409Z     
2026-02-14T13:01:56.2652636Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2652818Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2652950Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2653018Z     
2026-02-14T13:01:56.2653091Z         close_all_pools()
2026-02-14T13:01:56.2653150Z     
2026-02-14T13:01:56.2653265Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2653432Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2653570Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2653650Z             conn.autocommit = True
2026-02-14T13:01:56.2653736Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2653927Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2654018Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2654242Z                 cur.execute(
2026-02-14T13:01:56.2654312Z                     """
2026-02-14T13:01:56.2654408Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2654493Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2654696Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2654789Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2654856Z                     """
2026-02-14T13:01:56.2654927Z                 )
2026-02-14T13:01:56.2654986Z     
2026-02-14T13:01:56.2655172Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2655357Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2655429Z                 try:
2026-02-14T13:01:56.2655546Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2655620Z                     cur.execute("""
2026-02-14T13:01:56.2655698Z                         DO $$
2026-02-14T13:01:56.2655767Z                         DECLARE
2026-02-14T13:01:56.2655840Z                             r RECORD;
2026-02-14T13:01:56.2655913Z                         BEGIN
2026-02-14T13:01:56.2655987Z                             FOR r IN (
2026-02-14T13:01:56.2656092Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2656173Z                                 FROM pg_views
2026-02-14T13:01:56.2656308Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2656373Z                             )
2026-02-14T13:01:56.2656443Z                             LOOP
2026-02-14T13:01:56.2656760Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2656833Z                             END LOOP;
2026-02-14T13:01:56.2656903Z                         END $$;
2026-02-14T13:01:56.2656975Z                     """)
2026-02-14T13:01:56.2657050Z                     # Drop tables
2026-02-14T13:01:56.2657124Z                     cur.execute("""
2026-02-14T13:01:56.2657191Z                         DO $$
2026-02-14T13:01:56.2657264Z                         DECLARE
2026-02-14T13:01:56.2657337Z                             r RECORD;
2026-02-14T13:01:56.2657403Z                         BEGIN
2026-02-14T13:01:56.2657481Z                             FOR r IN (
2026-02-14T13:01:56.2657582Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2657665Z                                 FROM pg_tables
2026-02-14T13:01:56.2657796Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2657862Z                             )
2026-02-14T13:01:56.2657932Z                             LOOP
2026-02-14T13:01:56.2658249Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2658328Z                             END LOOP;
2026-02-14T13:01:56.2658395Z                         END $$;
2026-02-14T13:01:56.2658460Z                     """)
2026-02-14T13:01:56.2658547Z                 except psycopg2.Error:
2026-02-14T13:01:56.2658720Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2658787Z                     pass
2026-02-14T13:01:56.2658844Z     
2026-02-14T13:01:56.2659018Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2659129Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2659204Z                 if init_dir.exists():
2026-02-14T13:01:56.2659312Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2659401Z                     for script_path in scripts:
2026-02-14T13:01:56.2659524Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2659696Z                             sql = f.read()
2026-02-14T13:01:56.2659905Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2660035Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2660190Z                             statements = []
2026-02-14T13:01:56.2660250Z     
2026-02-14T13:01:56.2660429Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2660505Z                             do_blocks = []
2026-02-14T13:01:56.2660611Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2660669Z     
2026-02-14T13:01:56.2660765Z                             def replace_do_block(match):
2026-02-14T13:01:56.2660865Z                                 block = match.group(0)
2026-02-14T13:01:56.2660991Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2661343Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2661448Z                                 return placeholder
2026-02-14T13:01:56.2661508Z     
2026-02-14T13:01:56.2661619Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2661721Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2661810Z                                                     ^^
2026-02-14T13:01:56.2661993Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2662060Z                             )
2026-02-14T13:01:56.2662173Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2662179Z 
2026-02-14T13:01:56.2662278Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2662568Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_switch_from_inline_text_to_cover_letter_id _
2026-02-14T13:01:56.2662573Z 
2026-02-14T13:01:56.2662879Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2662884Z 
2026-02-14T13:01:56.2662980Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2663088Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2663151Z         """
2026-02-14T13:01:56.2663292Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2663358Z     
2026-02-14T13:01:56.2663488Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2663613Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2663680Z         """
2026-02-14T13:01:56.2663773Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2663898Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2663962Z     
2026-02-14T13:01:56.2664070Z         # Parse connection string to get database name
2026-02-14T13:01:56.2664312Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2664373Z     
2026-02-14T13:01:56.2664564Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2664796Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2664858Z     
2026-02-14T13:01:56.2665008Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2665116Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2665192Z         if len(parts) >= 4:
2026-02-14T13:01:56.2665318Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2665381Z         else:
2026-02-14T13:01:56.2665482Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2665542Z     
2026-02-14T13:01:56.2665644Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2665872Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2666124Z         import time
2026-02-14T13:01:56.2666198Z     
2026-02-14T13:01:56.2666272Z         max_retries = 5
2026-02-14T13:01:56.2666342Z         retry_delay = 2
2026-02-14T13:01:56.2666400Z     
2026-02-14T13:01:56.2666497Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2666688Z             try:
2026-02-14T13:01:56.2666789Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2666890Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2666970Z                 conn.autocommit = True
2026-02-14T13:01:56.2667035Z                 try:
2026-02-14T13:01:56.2667117Z                     cur = conn.cursor()
2026-02-14T13:01:56.2667306Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2667386Z                     if not cur.fetchone():
2026-02-14T13:01:56.2667538Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2667662Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2667733Z                     cur.close()
2026-02-14T13:01:56.2667801Z                 finally:
2026-02-14T13:01:56.2667878Z                     conn.close()
2026-02-14T13:01:56.2667953Z                 break  # Success
2026-02-14T13:01:56.2668142Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2668236Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2668305Z                     print(
2026-02-14T13:01:56.2668521Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2668586Z                     )
2026-02-14T13:01:56.2668675Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2668738Z                 else:
2026-02-14T13:01:56.2668942Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2669130Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2669199Z                     pass
2026-02-14T13:01:56.2669316Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2669401Z                 break  # Already exists
2026-02-14T13:01:56.2669463Z     
2026-02-14T13:01:56.2669677Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2669862Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2669998Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2670056Z     
2026-02-14T13:01:56.2670129Z         close_all_pools()
2026-02-14T13:01:56.2670199Z     
2026-02-14T13:01:56.2670315Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2670477Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2670624Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2670705Z             conn.autocommit = True
2026-02-14T13:01:56.2670783Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2670973Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2671199Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2671276Z                 cur.execute(
2026-02-14T13:01:56.2671340Z                     """
2026-02-14T13:01:56.2671441Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2671520Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2671614Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2671708Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2671773Z                     """
2026-02-14T13:01:56.2671834Z                 )
2026-02-14T13:01:56.2671891Z     
2026-02-14T13:01:56.2672082Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2672377Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2672444Z                 try:
2026-02-14T13:01:56.2672566Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2672743Z                     cur.execute("""
2026-02-14T13:01:56.2672812Z                         DO $$
2026-02-14T13:01:56.2672882Z                         DECLARE
2026-02-14T13:01:56.2672961Z                             r RECORD;
2026-02-14T13:01:56.2673028Z                         BEGIN
2026-02-14T13:01:56.2673100Z                             FOR r IN (
2026-02-14T13:01:56.2673205Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2673286Z                                 FROM pg_views
2026-02-14T13:01:56.2673414Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2673483Z                             )
2026-02-14T13:01:56.2673560Z                             LOOP
2026-02-14T13:01:56.2673870Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2673944Z                             END LOOP;
2026-02-14T13:01:56.2674023Z                         END $$;
2026-02-14T13:01:56.2674087Z                     """)
2026-02-14T13:01:56.2674161Z                     # Drop tables
2026-02-14T13:01:56.2674241Z                     cur.execute("""
2026-02-14T13:01:56.2674307Z                         DO $$
2026-02-14T13:01:56.2674376Z                         DECLARE
2026-02-14T13:01:56.2674452Z                             r RECORD;
2026-02-14T13:01:56.2674517Z                         BEGIN
2026-02-14T13:01:56.2674587Z                             FOR r IN (
2026-02-14T13:01:56.2674686Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2674773Z                                 FROM pg_tables
2026-02-14T13:01:56.2674900Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2674966Z                             )
2026-02-14T13:01:56.2675043Z                             LOOP
2026-02-14T13:01:56.2675359Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2675436Z                             END LOOP;
2026-02-14T13:01:56.2675508Z                         END $$;
2026-02-14T13:01:56.2675578Z                     """)
2026-02-14T13:01:56.2675662Z                 except psycopg2.Error:
2026-02-14T13:01:56.2675834Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2675909Z                     pass
2026-02-14T13:01:56.2675968Z     
2026-02-14T13:01:56.2676137Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2676253Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2676333Z                 if init_dir.exists():
2026-02-14T13:01:56.2676438Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2676535Z                     for script_path in scripts:
2026-02-14T13:01:56.2676662Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2676774Z                             sql = f.read()
2026-02-14T13:01:56.2676981Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2677119Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2677200Z                             statements = []
2026-02-14T13:01:56.2677258Z     
2026-02-14T13:01:56.2677441Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2677516Z                             do_blocks = []
2026-02-14T13:01:56.2677618Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2677795Z     
2026-02-14T13:01:56.2677896Z                             def replace_do_block(match):
2026-02-14T13:01:56.2677990Z                                 block = match.group(0)
2026-02-14T13:01:56.2678118Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2678349Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2678438Z                                 return placeholder
2026-02-14T13:01:56.2678494Z     
2026-02-14T13:01:56.2678607Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2678706Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2678788Z                                                     ^^
2026-02-14T13:01:56.2678976Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2679043Z                             )
2026-02-14T13:01:56.2679151Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2679156Z 
2026-02-14T13:01:56.2679261Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2679549Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_switch_from_cover_letter_id_to_inline_text _
2026-02-14T13:01:56.2679557Z 
2026-02-14T13:01:56.2679838Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2679843Z 
2026-02-14T13:01:56.2679932Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2680037Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2680103Z         """
2026-02-14T13:01:56.2680238Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2680297Z     
2026-02-14T13:01:56.2680432Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2680555Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2680615Z         """
2026-02-14T13:01:56.2680710Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2680843Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2680902Z     
2026-02-14T13:01:56.2681008Z         # Parse connection string to get database name
2026-02-14T13:01:56.2681366Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2681427Z     
2026-02-14T13:01:56.2681611Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2681842Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2681901Z     
2026-02-14T13:01:56.2682044Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2682150Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2682231Z         if len(parts) >= 4:
2026-02-14T13:01:56.2682350Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2682416Z         else:
2026-02-14T13:01:56.2682520Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2682578Z     
2026-02-14T13:01:56.2682675Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2682907Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2682976Z         import time
2026-02-14T13:01:56.2683034Z     
2026-02-14T13:01:56.2683103Z         max_retries = 5
2026-02-14T13:01:56.2683176Z         retry_delay = 2
2026-02-14T13:01:56.2683235Z     
2026-02-14T13:01:56.2683323Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2683392Z             try:
2026-02-14T13:01:56.2683492Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2683587Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2683668Z                 conn.autocommit = True
2026-02-14T13:01:56.2683738Z                 try:
2026-02-14T13:01:56.2683949Z                     cur = conn.cursor()
2026-02-14T13:01:56.2684141Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2684226Z                     if not cur.fetchone():
2026-02-14T13:01:56.2684377Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2684596Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2684673Z                     cur.close()
2026-02-14T13:01:56.2684740Z                 finally:
2026-02-14T13:01:56.2684813Z                     conn.close()
2026-02-14T13:01:56.2684882Z                 break  # Success
2026-02-14T13:01:56.2685080Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2685171Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2685241Z                     print(
2026-02-14T13:01:56.2685461Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2685531Z                     )
2026-02-14T13:01:56.2685613Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2685682Z                 else:
2026-02-14T13:01:56.2685889Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2686073Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2686143Z                     pass
2026-02-14T13:01:56.2686265Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2686343Z                 break  # Already exists
2026-02-14T13:01:56.2686401Z     
2026-02-14T13:01:56.2686624Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2686804Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2686935Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2687000Z     
2026-02-14T13:01:56.2687076Z         close_all_pools()
2026-02-14T13:01:56.2687135Z     
2026-02-14T13:01:56.2687250Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2687421Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2687567Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2687650Z             conn.autocommit = True
2026-02-14T13:01:56.2687736Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2687930Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2688021Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2688102Z                 cur.execute(
2026-02-14T13:01:56.2688169Z                     """
2026-02-14T13:01:56.2688266Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2688346Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2688455Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2688549Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2688615Z                     """
2026-02-14T13:01:56.2688685Z                 )
2026-02-14T13:01:56.2688744Z     
2026-02-14T13:01:56.2688938Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2689128Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2689194Z                 try:
2026-02-14T13:01:56.2689313Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2689389Z                     cur.execute("""
2026-02-14T13:01:56.2689464Z                         DO $$
2026-02-14T13:01:56.2689534Z                         DECLARE
2026-02-14T13:01:56.2689606Z                             r RECORD;
2026-02-14T13:01:56.2689679Z                         BEGIN
2026-02-14T13:01:56.2689752Z                             FOR r IN (
2026-02-14T13:01:56.2689942Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2690028Z                                 FROM pg_views
2026-02-14T13:01:56.2690162Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2690302Z                             )
2026-02-14T13:01:56.2690371Z                             LOOP
2026-02-14T13:01:56.2690690Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2690762Z                             END LOOP;
2026-02-14T13:01:56.2690830Z                         END $$;
2026-02-14T13:01:56.2690898Z                     """)
2026-02-14T13:01:56.2690971Z                     # Drop tables
2026-02-14T13:01:56.2691208Z                     cur.execute("""
2026-02-14T13:01:56.2691330Z                         DO $$
2026-02-14T13:01:56.2691417Z                         DECLARE
2026-02-14T13:01:56.2691495Z                             r RECORD;
2026-02-14T13:01:56.2691562Z                         BEGIN
2026-02-14T13:01:56.2691639Z                             FOR r IN (
2026-02-14T13:01:56.2691740Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2691827Z                                 FROM pg_tables
2026-02-14T13:01:56.2691957Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2692023Z                             )
2026-02-14T13:01:56.2692092Z                             LOOP
2026-02-14T13:01:56.2692406Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2692481Z                             END LOOP;
2026-02-14T13:01:56.2692546Z                         END $$;
2026-02-14T13:01:56.2692610Z                     """)
2026-02-14T13:01:56.2692698Z                 except psycopg2.Error:
2026-02-14T13:01:56.2692876Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2692945Z                     pass
2026-02-14T13:01:56.2693009Z     
2026-02-14T13:01:56.2693182Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2693295Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2693371Z                 if init_dir.exists():
2026-02-14T13:01:56.2693482Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2693571Z                     for script_path in scripts:
2026-02-14T13:01:56.2693696Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2693778Z                             sql = f.read()
2026-02-14T13:01:56.2693983Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2694116Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2694206Z                             statements = []
2026-02-14T13:01:56.2694265Z     
2026-02-14T13:01:56.2694441Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2694518Z                             do_blocks = []
2026-02-14T13:01:56.2694629Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2694688Z     
2026-02-14T13:01:56.2694785Z                             def replace_do_block(match):
2026-02-14T13:01:56.2694883Z                                 block = match.group(0)
2026-02-14T13:01:56.2695010Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2695106Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2695199Z                                 return placeholder
2026-02-14T13:01:56.2695260Z     
2026-02-14T13:01:56.2695369Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2695588Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2695682Z                                                     ^^
2026-02-14T13:01:56.2695868Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2696039Z                             )
2026-02-14T13:01:56.2696153Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2696158Z 
2026-02-14T13:01:56.2696260Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2696518Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_concurrent_updates_same_document _
2026-02-14T13:01:56.2696525Z 
2026-02-14T13:01:56.2696813Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2696818Z 
2026-02-14T13:01:56.2696913Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2697019Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2697080Z         """
2026-02-14T13:01:56.2697223Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2697281Z     
2026-02-14T13:01:56.2697413Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2697535Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2697603Z         """
2026-02-14T13:01:56.2697697Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2697822Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2697889Z     
2026-02-14T13:01:56.2697998Z         # Parse connection string to get database name
2026-02-14T13:01:56.2698241Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2698301Z     
2026-02-14T13:01:56.2698493Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2698720Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2698779Z     
2026-02-14T13:01:56.2698931Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2699040Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2699115Z         if len(parts) >= 4:
2026-02-14T13:01:56.2699240Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2699303Z         else:
2026-02-14T13:01:56.2699402Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2699461Z     
2026-02-14T13:01:56.2699562Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2699788Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2699854Z         import time
2026-02-14T13:01:56.2699919Z     
2026-02-14T13:01:56.2699989Z         max_retries = 5
2026-02-14T13:01:56.2700061Z         retry_delay = 2
2026-02-14T13:01:56.2700126Z     
2026-02-14T13:01:56.2700213Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2700278Z             try:
2026-02-14T13:01:56.2700381Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2700483Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2700561Z                 conn.autocommit = True
2026-02-14T13:01:56.2700629Z                 try:
2026-02-14T13:01:56.2700711Z                     cur = conn.cursor()
2026-02-14T13:01:56.2700896Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2700976Z                     if not cur.fetchone():
2026-02-14T13:01:56.2701259Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2701385Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2701455Z                     cur.close()
2026-02-14T13:01:56.2701520Z                 finally:
2026-02-14T13:01:56.2701597Z                     conn.close()
2026-02-14T13:01:56.2701668Z                 break  # Success
2026-02-14T13:01:56.2701983Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2702084Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2702156Z                     print(
2026-02-14T13:01:56.2702372Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2702550Z                     )
2026-02-14T13:01:56.2702639Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2702703Z                 else:
2026-02-14T13:01:56.2702907Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2703093Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2703162Z                     pass
2026-02-14T13:01:56.2703277Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2703362Z                 break  # Already exists
2026-02-14T13:01:56.2703419Z     
2026-02-14T13:01:56.2703637Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2703818Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2703956Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2704020Z     
2026-02-14T13:01:56.2704094Z         close_all_pools()
2026-02-14T13:01:56.2704156Z     
2026-02-14T13:01:56.2704274Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2704436Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2704583Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2704664Z             conn.autocommit = True
2026-02-14T13:01:56.2704743Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2704936Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2705035Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2705108Z                 cur.execute(
2026-02-14T13:01:56.2705174Z                     """
2026-02-14T13:01:56.2705278Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2705361Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2705458Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2705554Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2705619Z                     """
2026-02-14T13:01:56.2705681Z                 )
2026-02-14T13:01:56.2705739Z     
2026-02-14T13:01:56.2705936Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2706118Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2706184Z                 try:
2026-02-14T13:01:56.2706309Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2706387Z                     cur.execute("""
2026-02-14T13:01:56.2706456Z                         DO $$
2026-02-14T13:01:56.2706530Z                         DECLARE
2026-02-14T13:01:56.2706604Z                             r RECORD;
2026-02-14T13:01:56.2706671Z                         BEGIN
2026-02-14T13:01:56.2706747Z                             FOR r IN (
2026-02-14T13:01:56.2706852Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2706934Z                                 FROM pg_views
2026-02-14T13:01:56.2707064Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2707137Z                             )
2026-02-14T13:01:56.2707207Z                             LOOP
2026-02-14T13:01:56.2707518Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2707598Z                             END LOOP;
2026-02-14T13:01:56.2707666Z                         END $$;
2026-02-14T13:01:56.2707819Z                     """)
2026-02-14T13:01:56.2707895Z                     # Drop tables
2026-02-14T13:01:56.2707974Z                     cur.execute("""
2026-02-14T13:01:56.2708041Z                         DO $$
2026-02-14T13:01:56.2708182Z                         DECLARE
2026-02-14T13:01:56.2708257Z                             r RECORD;
2026-02-14T13:01:56.2708323Z                         BEGIN
2026-02-14T13:01:56.2708393Z                             FOR r IN (
2026-02-14T13:01:56.2708503Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2708592Z                                 FROM pg_tables
2026-02-14T13:01:56.2708720Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2708786Z                             )
2026-02-14T13:01:56.2708863Z                             LOOP
2026-02-14T13:01:56.2709175Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2709248Z                             END LOOP;
2026-02-14T13:01:56.2709321Z                         END $$;
2026-02-14T13:01:56.2709386Z                     """)
2026-02-14T13:01:56.2709468Z                 except psycopg2.Error:
2026-02-14T13:01:56.2709642Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2709718Z                     pass
2026-02-14T13:01:56.2709779Z     
2026-02-14T13:01:56.2709948Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2710065Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2710142Z                 if init_dir.exists():
2026-02-14T13:01:56.2710246Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2710342Z                     for script_path in scripts:
2026-02-14T13:01:56.2710466Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2710547Z                             sql = f.read()
2026-02-14T13:01:56.2710750Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2710888Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2710972Z                             statements = []
2026-02-14T13:01:56.2711147Z     
2026-02-14T13:01:56.2711335Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2711411Z                             do_blocks = []
2026-02-14T13:01:56.2711514Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2711577Z     
2026-02-14T13:01:56.2711678Z                             def replace_do_block(match):
2026-02-14T13:01:56.2711768Z                                 block = match.group(0)
2026-02-14T13:01:56.2711895Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2712000Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2712087Z                                 return placeholder
2026-02-14T13:01:56.2712144Z     
2026-02-14T13:01:56.2712261Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2712363Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2712443Z                                                     ^^
2026-02-14T13:01:56.2712633Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2712701Z                             )
2026-02-14T13:01:56.2712808Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2712813Z 
2026-02-14T13:01:56.2712918Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2713185Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_file_with_special_characters_in_name _
2026-02-14T13:01:56.2713190Z 
2026-02-14T13:01:56.2713588Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2713596Z 
2026-02-14T13:01:56.2713686Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2713790Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2713955Z         """
2026-02-14T13:01:56.2714089Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2714148Z     
2026-02-14T13:01:56.2714286Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2714408Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2714470Z         """
2026-02-14T13:01:56.2714570Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2714691Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2714750Z     
2026-02-14T13:01:56.2714855Z         # Parse connection string to get database name
2026-02-14T13:01:56.2715109Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2715167Z     
2026-02-14T13:01:56.2715352Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2715587Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2715648Z     
2026-02-14T13:01:56.2715793Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2715906Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2715983Z         if len(parts) >= 4:
2026-02-14T13:01:56.2716101Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2716167Z         else:
2026-02-14T13:01:56.2716274Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2716332Z     
2026-02-14T13:01:56.2716428Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2716660Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2716727Z         import time
2026-02-14T13:01:56.2716784Z     
2026-02-14T13:01:56.2716854Z         max_retries = 5
2026-02-14T13:01:56.2716927Z         retry_delay = 2
2026-02-14T13:01:56.2716984Z     
2026-02-14T13:01:56.2717072Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2717141Z             try:
2026-02-14T13:01:56.2717241Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2717335Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2717421Z                 conn.autocommit = True
2026-02-14T13:01:56.2717485Z                 try:
2026-02-14T13:01:56.2717561Z                     cur = conn.cursor()
2026-02-14T13:01:56.2717746Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2717833Z                     if not cur.fetchone():
2026-02-14T13:01:56.2717985Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2718105Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2718181Z                     cur.close()
2026-02-14T13:01:56.2718248Z                 finally:
2026-02-14T13:01:56.2718321Z                     conn.close()
2026-02-14T13:01:56.2718394Z                 break  # Success
2026-02-14T13:01:56.2718590Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2718681Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2718751Z                     print(
2026-02-14T13:01:56.2718972Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2719036Z                     )
2026-02-14T13:01:56.2719118Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2719190Z                 else:
2026-02-14T13:01:56.2719390Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2719661Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2719739Z                     pass
2026-02-14T13:01:56.2719864Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2724888Z                 break  # Already exists
2026-02-14T13:01:56.2724976Z     
2026-02-14T13:01:56.2725248Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2725454Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2725595Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2725664Z     
2026-02-14T13:01:56.2725744Z         close_all_pools()
2026-02-14T13:01:56.2725803Z     
2026-02-14T13:01:56.2725928Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2726107Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2726261Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2726346Z             conn.autocommit = True
2026-02-14T13:01:56.2726438Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2726637Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2726738Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2726823Z                 cur.execute(
2026-02-14T13:01:56.2726890Z                     """
2026-02-14T13:01:56.2726992Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2727074Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2727179Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2727270Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2727338Z                     """
2026-02-14T13:01:56.2727406Z                 )
2026-02-14T13:01:56.2727464Z     
2026-02-14T13:01:56.2727659Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2727851Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2727919Z                 try:
2026-02-14T13:01:56.2728035Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2728116Z                     cur.execute("""
2026-02-14T13:01:56.2728192Z                         DO $$
2026-02-14T13:01:56.2728260Z                         DECLARE
2026-02-14T13:01:56.2728333Z                             r RECORD;
2026-02-14T13:01:56.2728404Z                         BEGIN
2026-02-14T13:01:56.2728480Z                             FOR r IN (
2026-02-14T13:01:56.2728581Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2728661Z                                 FROM pg_views
2026-02-14T13:01:56.2728800Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2728866Z                             )
2026-02-14T13:01:56.2728940Z                             LOOP
2026-02-14T13:01:56.2729261Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2729340Z                             END LOOP;
2026-02-14T13:01:56.2729407Z                         END $$;
2026-02-14T13:01:56.2729481Z                     """)
2026-02-14T13:01:56.2729554Z                     # Drop tables
2026-02-14T13:01:56.2729627Z                     cur.execute("""
2026-02-14T13:01:56.2729694Z                         DO $$
2026-02-14T13:01:56.2729765Z                         DECLARE
2026-02-14T13:01:56.2729834Z                             r RECORD;
2026-02-14T13:01:56.2729898Z                         BEGIN
2026-02-14T13:01:56.2729976Z                             FOR r IN (
2026-02-14T13:01:56.2730077Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2730160Z                                 FROM pg_tables
2026-02-14T13:01:56.2730458Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2730530Z                             )
2026-02-14T13:01:56.2730598Z                             LOOP
2026-02-14T13:01:56.2731313Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2731438Z                             END LOOP;
2026-02-14T13:01:56.2731508Z                         END $$;
2026-02-14T13:01:56.2731575Z                     """)
2026-02-14T13:01:56.2731664Z                 except psycopg2.Error:
2026-02-14T13:01:56.2731843Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2731913Z                     pass
2026-02-14T13:01:56.2731982Z     
2026-02-14T13:01:56.2732160Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2732279Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2732357Z                 if init_dir.exists():
2026-02-14T13:01:56.2732471Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2732564Z                     for script_path in scripts:
2026-02-14T13:01:56.2732698Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2732784Z                             sql = f.read()
2026-02-14T13:01:56.2732997Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2733130Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2733214Z                             statements = []
2026-02-14T13:01:56.2733274Z     
2026-02-14T13:01:56.2733455Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2733533Z                             do_blocks = []
2026-02-14T13:01:56.2733646Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2733705Z     
2026-02-14T13:01:56.2733801Z                             def replace_do_block(match):
2026-02-14T13:01:56.2733902Z                                 block = match.group(0)
2026-02-14T13:01:56.2734035Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2734132Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2734228Z                                 return placeholder
2026-02-14T13:01:56.2734287Z     
2026-02-14T13:01:56.2734396Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2734495Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2734584Z                                                     ^^
2026-02-14T13:01:56.2734770Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2734839Z                             )
2026-02-14T13:01:56.2734957Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2734964Z 
2026-02-14T13:01:56.2735072Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2735304Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_very_long_cover_letter_text _
2026-02-14T13:01:56.2735312Z 
2026-02-14T13:01:56.2735638Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2735645Z 
2026-02-14T13:01:56.2735745Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2735853Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2735917Z         """
2026-02-14T13:01:56.2736066Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2736131Z     
2026-02-14T13:01:56.2736264Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2736396Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2736465Z         """
2026-02-14T13:01:56.2736702Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2736832Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2736901Z     
2026-02-14T13:01:56.2737016Z         # Parse connection string to get database name
2026-02-14T13:01:56.2737365Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2737427Z     
2026-02-14T13:01:56.2737621Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2737852Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2737912Z     
2026-02-14T13:01:56.2738066Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2738177Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2738254Z         if len(parts) >= 4:
2026-02-14T13:01:56.2738384Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2738451Z         else:
2026-02-14T13:01:56.2738553Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2738613Z     
2026-02-14T13:01:56.2738719Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2738951Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2739018Z         import time
2026-02-14T13:01:56.2739085Z     
2026-02-14T13:01:56.2739156Z         max_retries = 5
2026-02-14T13:01:56.2739223Z         retry_delay = 2
2026-02-14T13:01:56.2739289Z     
2026-02-14T13:01:56.2739377Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2739441Z             try:
2026-02-14T13:01:56.2739543Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2739645Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2739733Z                 conn.autocommit = True
2026-02-14T13:01:56.2739798Z                 try:
2026-02-14T13:01:56.2739886Z                     cur = conn.cursor()
2026-02-14T13:01:56.2740074Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2740157Z                     if not cur.fetchone():
2026-02-14T13:01:56.2740314Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2740438Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2740510Z                     cur.close()
2026-02-14T13:01:56.2740579Z                 finally:
2026-02-14T13:01:56.2740658Z                     conn.close()
2026-02-14T13:01:56.2740729Z                 break  # Success
2026-02-14T13:01:56.2740924Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2741024Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2741325Z                     print(
2026-02-14T13:01:56.2741568Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2741635Z                     )
2026-02-14T13:01:56.2741726Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2741792Z                 else:
2026-02-14T13:01:56.2741998Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2742195Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2742264Z                     pass
2026-02-14T13:01:56.2742383Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2742467Z                 break  # Already exists
2026-02-14T13:01:56.2742525Z     
2026-02-14T13:01:56.2742741Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2742924Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2743064Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2743243Z     
2026-02-14T13:01:56.2743324Z         close_all_pools()
2026-02-14T13:01:56.2743389Z     
2026-02-14T13:01:56.2743504Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2743671Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2743925Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2744006Z             conn.autocommit = True
2026-02-14T13:01:56.2744086Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2744279Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2744377Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2744451Z                 cur.execute(
2026-02-14T13:01:56.2744516Z                     """
2026-02-14T13:01:56.2744621Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2744701Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2744803Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2744898Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2744963Z                     """
2026-02-14T13:01:56.2745024Z                 )
2026-02-14T13:01:56.2745087Z     
2026-02-14T13:01:56.2745283Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2745466Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2745531Z                 try:
2026-02-14T13:01:56.2745656Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2745731Z                     cur.execute("""
2026-02-14T13:01:56.2745802Z                         DO $$
2026-02-14T13:01:56.2745878Z                         DECLARE
2026-02-14T13:01:56.2745951Z                             r RECORD;
2026-02-14T13:01:56.2746019Z                         BEGIN
2026-02-14T13:01:56.2746093Z                             FOR r IN (
2026-02-14T13:01:56.2746201Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2746282Z                                 FROM pg_views
2026-02-14T13:01:56.2746410Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2746487Z                             )
2026-02-14T13:01:56.2746556Z                             LOOP
2026-02-14T13:01:56.2746868Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2746950Z                             END LOOP;
2026-02-14T13:01:56.2747017Z                         END $$;
2026-02-14T13:01:56.2747086Z                     """)
2026-02-14T13:01:56.2747158Z                     # Drop tables
2026-02-14T13:01:56.2747237Z                     cur.execute("""
2026-02-14T13:01:56.2747307Z                         DO $$
2026-02-14T13:01:56.2747373Z                         DECLARE
2026-02-14T13:01:56.2747456Z                             r RECORD;
2026-02-14T13:01:56.2747523Z                         BEGIN
2026-02-14T13:01:56.2747594Z                             FOR r IN (
2026-02-14T13:01:56.2747694Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2747789Z                                 FROM pg_tables
2026-02-14T13:01:56.2747913Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2747979Z                             )
2026-02-14T13:01:56.2748056Z                             LOOP
2026-02-14T13:01:56.2748366Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2748439Z                             END LOOP;
2026-02-14T13:01:56.2748516Z                         END $$;
2026-02-14T13:01:56.2748583Z                     """)
2026-02-14T13:01:56.2748667Z                 except psycopg2.Error:
2026-02-14T13:01:56.2748941Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2749024Z                     pass
2026-02-14T13:01:56.2749083Z     
2026-02-14T13:01:56.2749256Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2749453Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2749531Z                 if init_dir.exists():
2026-02-14T13:01:56.2749635Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2749733Z                     for script_path in scripts:
2026-02-14T13:01:56.2749859Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2749934Z                             sql = f.read()
2026-02-14T13:01:56.2750139Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2750277Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2750359Z                             statements = []
2026-02-14T13:01:56.2750418Z     
2026-02-14T13:01:56.2750602Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2750681Z                             do_blocks = []
2026-02-14T13:01:56.2750783Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2750848Z     
2026-02-14T13:01:56.2750945Z                             def replace_do_block(match):
2026-02-14T13:01:56.2751157Z                                 block = match.group(0)
2026-02-14T13:01:56.2751289Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2751396Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2751485Z                                 return placeholder
2026-02-14T13:01:56.2751547Z     
2026-02-14T13:01:56.2751662Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2751767Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2751854Z                                                     ^^
2026-02-14T13:01:56.2752039Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2752111Z                             )
2026-02-14T13:01:56.2752219Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2752230Z 
2026-02-14T13:01:56.2752331Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2752559Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_multiple_resumes_same_name _
2026-02-14T13:01:56.2752564Z 
2026-02-14T13:01:56.2752858Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2752863Z 
2026-02-14T13:01:56.2752953Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2753064Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2753127Z         """
2026-02-14T13:01:56.2753269Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2753338Z     
2026-02-14T13:01:56.2753474Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2753599Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2753664Z         """
2026-02-14T13:01:56.2753766Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2753890Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2753950Z     
2026-02-14T13:01:56.2754067Z         # Parse connection string to get database name
2026-02-14T13:01:56.2754314Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2754374Z     
2026-02-14T13:01:56.2754567Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2754798Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2754982Z     
2026-02-14T13:01:56.2755133Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2755253Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2755329Z         if len(parts) >= 4:
2026-02-14T13:01:56.2755552Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2755623Z         else:
2026-02-14T13:01:56.2755725Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2755788Z     
2026-02-14T13:01:56.2755893Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2756123Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2756190Z         import time
2026-02-14T13:01:56.2756250Z     
2026-02-14T13:01:56.2756327Z         max_retries = 5
2026-02-14T13:01:56.2756396Z         retry_delay = 2
2026-02-14T13:01:56.2756454Z     
2026-02-14T13:01:56.2756544Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2756614Z             try:
2026-02-14T13:01:56.2756717Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2756816Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2756904Z                 conn.autocommit = True
2026-02-14T13:01:56.2756972Z                 try:
2026-02-14T13:01:56.2757051Z                     cur = conn.cursor()
2026-02-14T13:01:56.2757246Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2757327Z                     if not cur.fetchone():
2026-02-14T13:01:56.2757481Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2757605Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2757678Z                     cur.close()
2026-02-14T13:01:56.2757745Z                 finally:
2026-02-14T13:01:56.2757819Z                     conn.close()
2026-02-14T13:01:56.2757896Z                 break  # Success
2026-02-14T13:01:56.2758087Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2758177Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2758252Z                     print(
2026-02-14T13:01:56.2758474Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2758547Z                     )
2026-02-14T13:01:56.2758635Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2758700Z                 else:
2026-02-14T13:01:56.2758900Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2759084Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2759160Z                     pass
2026-02-14T13:01:56.2759276Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2759356Z                 break  # Already exists
2026-02-14T13:01:56.2759424Z     
2026-02-14T13:01:56.2759641Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2759824Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2759967Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2760025Z     
2026-02-14T13:01:56.2760099Z         close_all_pools()
2026-02-14T13:01:56.2760157Z     
2026-02-14T13:01:56.2760281Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2760449Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2760591Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2760678Z             conn.autocommit = True
2026-02-14T13:01:56.2760759Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2760953Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2761306Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2761403Z                 cur.execute(
2026-02-14T13:01:56.2761470Z                     """
2026-02-14T13:01:56.2761573Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2761762Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2761862Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2761954Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2762026Z                     """
2026-02-14T13:01:56.2762088Z                 )
2026-02-14T13:01:56.2762149Z     
2026-02-14T13:01:56.2762343Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2762534Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2762599Z                 try:
2026-02-14T13:01:56.2762717Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2762805Z                     cur.execute("""
2026-02-14T13:01:56.2762878Z                         DO $$
2026-02-14T13:01:56.2762947Z                         DECLARE
2026-02-14T13:01:56.2763030Z                             r RECORD;
2026-02-14T13:01:56.2763101Z                         BEGIN
2026-02-14T13:01:56.2763174Z                             FOR r IN (
2026-02-14T13:01:56.2763277Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2763367Z                                 FROM pg_views
2026-02-14T13:01:56.2763500Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2763567Z                             )
2026-02-14T13:01:56.2763645Z                             LOOP
2026-02-14T13:01:56.2763957Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2764030Z                             END LOOP;
2026-02-14T13:01:56.2764108Z                         END $$;
2026-02-14T13:01:56.2764176Z                     """)
2026-02-14T13:01:56.2764248Z                     # Drop tables
2026-02-14T13:01:56.2764321Z                     cur.execute("""
2026-02-14T13:01:56.2764398Z                         DO $$
2026-02-14T13:01:56.2764467Z                         DECLARE
2026-02-14T13:01:56.2764539Z                             r RECORD;
2026-02-14T13:01:56.2764610Z                         BEGIN
2026-02-14T13:01:56.2764684Z                             FOR r IN (
2026-02-14T13:01:56.2764785Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2764875Z                                 FROM pg_tables
2026-02-14T13:01:56.2764999Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2765068Z                             )
2026-02-14T13:01:56.2765138Z                             LOOP
2026-02-14T13:01:56.2765461Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2765533Z                             END LOOP;
2026-02-14T13:01:56.2765600Z                         END $$;
2026-02-14T13:01:56.2765673Z                     """)
2026-02-14T13:01:56.2765759Z                 except psycopg2.Error:
2026-02-14T13:01:56.2765934Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2766010Z                     pass
2026-02-14T13:01:56.2766069Z     
2026-02-14T13:01:56.2766241Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2766352Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2766437Z                 if init_dir.exists():
2026-02-14T13:01:56.2766543Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2766634Z                     for script_path in scripts:
2026-02-14T13:01:56.2766857Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2766940Z                             sql = f.read()
2026-02-14T13:01:56.2767148Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2767376Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2767457Z                             statements = []
2026-02-14T13:01:56.2767515Z     
2026-02-14T13:01:56.2767692Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2767774Z                             do_blocks = []
2026-02-14T13:01:56.2767877Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2767934Z     
2026-02-14T13:01:56.2768038Z                             def replace_do_block(match):
2026-02-14T13:01:56.2768130Z                                 block = match.group(0)
2026-02-14T13:01:56.2768261Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2768367Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2768455Z                                 return placeholder
2026-02-14T13:01:56.2768512Z     
2026-02-14T13:01:56.2768626Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2768731Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2768812Z                                                     ^^
2026-02-14T13:01:56.2768999Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2769072Z                             )
2026-02-14T13:01:56.2769181Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2769186Z 
2026-02-14T13:01:56.2769286Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2769557Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_get_documents_for_nonexistent_user _
2026-02-14T13:01:56.2769566Z 
2026-02-14T13:01:56.2769857Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2769862Z 
2026-02-14T13:01:56.2769959Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2770063Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2770129Z         """
2026-02-14T13:01:56.2770271Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2770331Z     
2026-02-14T13:01:56.2770463Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2770586Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2770653Z         """
2026-02-14T13:01:56.2770747Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2770874Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2770939Z     
2026-02-14T13:01:56.2771218Z         # Parse connection string to get database name
2026-02-14T13:01:56.2771525Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2771592Z     
2026-02-14T13:01:56.2771779Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2772006Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2772068Z     
2026-02-14T13:01:56.2772222Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2772331Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2772406Z         if len(parts) >= 4:
2026-02-14T13:01:56.2772532Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2772593Z         else:
2026-02-14T13:01:56.2772693Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2772757Z     
2026-02-14T13:01:56.2772852Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2773207Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2773278Z         import time
2026-02-14T13:01:56.2773342Z     
2026-02-14T13:01:56.2773410Z         max_retries = 5
2026-02-14T13:01:56.2773478Z         retry_delay = 2
2026-02-14T13:01:56.2773642Z     
2026-02-14T13:01:56.2773728Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2773789Z             try:
2026-02-14T13:01:56.2773890Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2773989Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2774070Z                 conn.autocommit = True
2026-02-14T13:01:56.2774135Z                 try:
2026-02-14T13:01:56.2774216Z                     cur = conn.cursor()
2026-02-14T13:01:56.2774400Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2774478Z                     if not cur.fetchone():
2026-02-14T13:01:56.2774639Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2774755Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2774826Z                     cur.close()
2026-02-14T13:01:56.2774894Z                 finally:
2026-02-14T13:01:56.2774975Z                     conn.close()
2026-02-14T13:01:56.2775045Z                 break  # Success
2026-02-14T13:01:56.2775235Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2775332Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2775403Z                     print(
2026-02-14T13:01:56.2775617Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2775687Z                     )
2026-02-14T13:01:56.2775770Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2775834Z                 else:
2026-02-14T13:01:56.2776040Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2776230Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2776300Z                     pass
2026-02-14T13:01:56.2776414Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2776501Z                 break  # Already exists
2026-02-14T13:01:56.2776560Z     
2026-02-14T13:01:56.2776808Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2776995Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2777128Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2777186Z     
2026-02-14T13:01:56.2777262Z         close_all_pools()
2026-02-14T13:01:56.2777327Z     
2026-02-14T13:01:56.2777448Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2777616Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2777767Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2777850Z             conn.autocommit = True
2026-02-14T13:01:56.2777930Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2778129Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2778226Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2778299Z                 cur.execute(
2026-02-14T13:01:56.2778366Z                     """
2026-02-14T13:01:56.2778470Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2778551Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2778648Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2778744Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2778808Z                     """
2026-02-14T13:01:56.2778871Z                 )
2026-02-14T13:01:56.2778930Z     
2026-02-14T13:01:56.2779248Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2779436Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2779500Z                 try:
2026-02-14T13:01:56.2779702Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2779779Z                     cur.execute("""
2026-02-14T13:01:56.2779850Z                         DO $$
2026-02-14T13:01:56.2779925Z                         DECLARE
2026-02-14T13:01:56.2779999Z                             r RECORD;
2026-02-14T13:01:56.2780068Z                         BEGIN
2026-02-14T13:01:56.2780142Z                             FOR r IN (
2026-02-14T13:01:56.2780251Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2780334Z                                 FROM pg_views
2026-02-14T13:01:56.2780465Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2780541Z                             )
2026-02-14T13:01:56.2780614Z                             LOOP
2026-02-14T13:01:56.2780925Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2781006Z                             END LOOP;
2026-02-14T13:01:56.2781198Z                         END $$;
2026-02-14T13:01:56.2781268Z                     """)
2026-02-14T13:01:56.2781341Z                     # Drop tables
2026-02-14T13:01:56.2781423Z                     cur.execute("""
2026-02-14T13:01:56.2781489Z                         DO $$
2026-02-14T13:01:56.2781562Z                         DECLARE
2026-02-14T13:01:56.2781640Z                             r RECORD;
2026-02-14T13:01:56.2781708Z                         BEGIN
2026-02-14T13:01:56.2781780Z                             FOR r IN (
2026-02-14T13:01:56.2781885Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2781980Z                                 FROM pg_tables
2026-02-14T13:01:56.2782108Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2782175Z                             )
2026-02-14T13:01:56.2782251Z                             LOOP
2026-02-14T13:01:56.2782572Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2782645Z                             END LOOP;
2026-02-14T13:01:56.2782720Z                         END $$;
2026-02-14T13:01:56.2782787Z                     """)
2026-02-14T13:01:56.2782870Z                 except psycopg2.Error:
2026-02-14T13:01:56.2783046Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2783121Z                     pass
2026-02-14T13:01:56.2783181Z     
2026-02-14T13:01:56.2783350Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2783473Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2783549Z                 if init_dir.exists():
2026-02-14T13:01:56.2783655Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2783749Z                     for script_path in scripts:
2026-02-14T13:01:56.2783877Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2783954Z                             sql = f.read()
2026-02-14T13:01:56.2784165Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2784297Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2784377Z                             statements = []
2026-02-14T13:01:56.2784436Z     
2026-02-14T13:01:56.2784619Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2784694Z                             do_blocks = []
2026-02-14T13:01:56.2784922Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2784988Z     
2026-02-14T13:01:56.2785086Z                             def replace_do_block(match):
2026-02-14T13:01:56.2785180Z                                 block = match.group(0)
2026-02-14T13:01:56.2785419Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2785516Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2785604Z                                 return placeholder
2026-02-14T13:01:56.2785662Z     
2026-02-14T13:01:56.2785775Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2785874Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2785956Z                                                     ^^
2026-02-14T13:01:56.2786147Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2786218Z                             )
2026-02-14T13:01:56.2786328Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2786333Z 
2026-02-14T13:01:56.2786441Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2786708Z _ ERROR at setup of TestDocumentEdgeCasesIntegration.test_update_document_with_all_none_values _
2026-02-14T13:01:56.2786716Z 
2026-02-14T13:01:56.2787004Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2787010Z 
2026-02-14T13:01:56.2787098Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2787202Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2787269Z         """
2026-02-14T13:01:56.2787405Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2787464Z     
2026-02-14T13:01:56.2787600Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2787724Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2787785Z         """
2026-02-14T13:01:56.2787889Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2788014Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2788073Z     
2026-02-14T13:01:56.2788179Z         # Parse connection string to get database name
2026-02-14T13:01:56.2788432Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2788491Z     
2026-02-14T13:01:56.2788683Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2788914Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2788972Z     
2026-02-14T13:01:56.2789114Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2789229Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2789305Z         if len(parts) >= 4:
2026-02-14T13:01:56.2789426Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2789490Z         else:
2026-02-14T13:01:56.2789595Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2789654Z     
2026-02-14T13:01:56.2789750Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2789987Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2790055Z         import time
2026-02-14T13:01:56.2790115Z     
2026-02-14T13:01:56.2790184Z         max_retries = 5
2026-02-14T13:01:56.2790258Z         retry_delay = 2
2026-02-14T13:01:56.2790318Z     
2026-02-14T13:01:56.2790404Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2790473Z             try:
2026-02-14T13:01:56.2790574Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2790669Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2790756Z                 conn.autocommit = True
2026-02-14T13:01:56.2790821Z                 try:
2026-02-14T13:01:56.2790989Z                     cur = conn.cursor()
2026-02-14T13:01:56.2791342Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2791432Z                     if not cur.fetchone():
2026-02-14T13:01:56.2791709Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2791826Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2791905Z                     cur.close()
2026-02-14T13:01:56.2791976Z                 finally:
2026-02-14T13:01:56.2792051Z                     conn.close()
2026-02-14T13:01:56.2792129Z                 break  # Success
2026-02-14T13:01:56.2792319Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2792409Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2792480Z                     print(
2026-02-14T13:01:56.2792712Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2792781Z                     )
2026-02-14T13:01:56.2792865Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2792936Z                 else:
2026-02-14T13:01:56.2793146Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2793330Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2793405Z                     pass
2026-02-14T13:01:56.2793524Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2793606Z                 break  # Already exists
2026-02-14T13:01:56.2793664Z     
2026-02-14T13:01:56.2793885Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2794070Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2794203Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2794269Z     
2026-02-14T13:01:56.2794342Z         close_all_pools()
2026-02-14T13:01:56.2794401Z     
2026-02-14T13:01:56.2794518Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2794692Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2794833Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2794912Z             conn.autocommit = True
2026-02-14T13:01:56.2794999Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2795190Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2795281Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2795359Z                 cur.execute(
2026-02-14T13:01:56.2795425Z                     """
2026-02-14T13:01:56.2795522Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2795602Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2795711Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2795801Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2795866Z                     """
2026-02-14T13:01:56.2795936Z                 )
2026-02-14T13:01:56.2795998Z     
2026-02-14T13:01:56.2796186Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2796374Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2796438Z                 try:
2026-02-14T13:01:56.2796556Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2796633Z                     cur.execute("""
2026-02-14T13:01:56.2796709Z                         DO $$
2026-02-14T13:01:56.2796778Z                         DECLARE
2026-02-14T13:01:56.2796852Z                             r RECORD;
2026-02-14T13:01:56.2796925Z                         BEGIN
2026-02-14T13:01:56.2797113Z                             FOR r IN (
2026-02-14T13:01:56.2797218Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2797306Z                                 FROM pg_views
2026-02-14T13:01:56.2797433Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2797579Z                             )
2026-02-14T13:01:56.2797653Z                             LOOP
2026-02-14T13:01:56.2797971Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2798043Z                             END LOOP;
2026-02-14T13:01:56.2798111Z                         END $$;
2026-02-14T13:01:56.2798184Z                     """)
2026-02-14T13:01:56.2798257Z                     # Drop tables
2026-02-14T13:01:56.2798330Z                     cur.execute("""
2026-02-14T13:01:56.2798401Z                         DO $$
2026-02-14T13:01:56.2798470Z                         DECLARE
2026-02-14T13:01:56.2798542Z                             r RECORD;
2026-02-14T13:01:56.2798609Z                         BEGIN
2026-02-14T13:01:56.2798689Z                             FOR r IN (
2026-02-14T13:01:56.2798798Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2798888Z                                 FROM pg_tables
2026-02-14T13:01:56.2799020Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2799087Z                             )
2026-02-14T13:01:56.2799156Z                             LOOP
2026-02-14T13:01:56.2799478Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2799552Z                             END LOOP;
2026-02-14T13:01:56.2799622Z                         END $$;
2026-02-14T13:01:56.2799687Z                     """)
2026-02-14T13:01:56.2799779Z                 except psycopg2.Error:
2026-02-14T13:01:56.2799954Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2800024Z                     pass
2026-02-14T13:01:56.2800088Z     
2026-02-14T13:01:56.2800257Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2800372Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2800459Z                 if init_dir.exists():
2026-02-14T13:01:56.2800563Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2800651Z                     for script_path in scripts:
2026-02-14T13:01:56.2800776Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2800860Z                             sql = f.read()
2026-02-14T13:01:56.2801190Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2801328Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2801413Z                             statements = []
2026-02-14T13:01:56.2801472Z     
2026-02-14T13:01:56.2801647Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2801733Z                             do_blocks = []
2026-02-14T13:01:56.2801837Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2801897Z     
2026-02-14T13:01:56.2801995Z                             def replace_do_block(match):
2026-02-14T13:01:56.2802092Z                                 block = match.group(0)
2026-02-14T13:01:56.2802219Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2802319Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2802412Z                                 return placeholder
2026-02-14T13:01:56.2802470Z     
2026-02-14T13:01:56.2802579Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2802812Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2802898Z                                                     ^^
2026-02-14T13:01:56.2803089Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2803268Z                             )
2026-02-14T13:01:56.2803383Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2803389Z 
2026-02-14T13:01:56.2803493Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2803742Z _ ERROR at setup of TestDocumentManagementIntegration.test_upload_resume_and_link_to_job _
2026-02-14T13:01:56.2803747Z 
2026-02-14T13:01:56.2804042Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2804047Z 
2026-02-14T13:01:56.2804142Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2804253Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2804317Z         """
2026-02-14T13:01:56.2804464Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2804523Z     
2026-02-14T13:01:56.2804659Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2804787Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2804859Z         """
2026-02-14T13:01:56.2804955Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2805081Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2805146Z     
2026-02-14T13:01:56.2805254Z         # Parse connection string to get database name
2026-02-14T13:01:56.2805502Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2805566Z     
2026-02-14T13:01:56.2805753Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2805985Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2806043Z     
2026-02-14T13:01:56.2806192Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2806301Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2806380Z         if len(parts) >= 4:
2026-02-14T13:01:56.2806504Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2806569Z         else:
2026-02-14T13:01:56.2806669Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2806734Z     
2026-02-14T13:01:56.2806829Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2807057Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2807123Z         import time
2026-02-14T13:01:56.2807191Z     
2026-02-14T13:01:56.2807260Z         max_retries = 5
2026-02-14T13:01:56.2807328Z         retry_delay = 2
2026-02-14T13:01:56.2807389Z     
2026-02-14T13:01:56.2807479Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2807542Z             try:
2026-02-14T13:01:56.2807642Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2807739Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2807822Z                 conn.autocommit = True
2026-02-14T13:01:56.2807886Z                 try:
2026-02-14T13:01:56.2807969Z                     cur = conn.cursor()
2026-02-14T13:01:56.2808158Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2808239Z                     if not cur.fetchone():
2026-02-14T13:01:56.2808395Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2808512Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2808583Z                     cur.close()
2026-02-14T13:01:56.2808650Z                 finally:
2026-02-14T13:01:56.2808729Z                     conn.close()
2026-02-14T13:01:56.2808887Z                 break  # Success
2026-02-14T13:01:56.2809078Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2809174Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2809321Z                     print(
2026-02-14T13:01:56.2809540Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2809610Z                     )
2026-02-14T13:01:56.2809694Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2809761Z                 else:
2026-02-14T13:01:56.2809963Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2810150Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2810220Z                     pass
2026-02-14T13:01:56.2810336Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2810424Z                 break  # Already exists
2026-02-14T13:01:56.2810483Z     
2026-02-14T13:01:56.2810696Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2810883Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2811020Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2811359Z     
2026-02-14T13:01:56.2811459Z         close_all_pools()
2026-02-14T13:01:56.2811526Z     
2026-02-14T13:01:56.2811651Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2811817Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2811963Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2812043Z             conn.autocommit = True
2026-02-14T13:01:56.2812121Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2812324Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2812417Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2812489Z                 cur.execute(
2026-02-14T13:01:56.2812554Z                     """
2026-02-14T13:01:56.2812658Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2812745Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2812841Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2812939Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2813005Z                     """
2026-02-14T13:01:56.2813068Z                 )
2026-02-14T13:01:56.2813126Z     
2026-02-14T13:01:56.2813321Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2813505Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2813569Z                 try:
2026-02-14T13:01:56.2813696Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2813774Z                     cur.execute("""
2026-02-14T13:01:56.2813842Z                         DO $$
2026-02-14T13:01:56.2813916Z                         DECLARE
2026-02-14T13:01:56.2813989Z                             r RECORD;
2026-02-14T13:01:56.2814068Z                         BEGIN
2026-02-14T13:01:56.2814144Z                             FOR r IN (
2026-02-14T13:01:56.2814253Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2814335Z                                 FROM pg_views
2026-02-14T13:01:56.2814469Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2814543Z                             )
2026-02-14T13:01:56.2814613Z                             LOOP
2026-02-14T13:01:56.2814929Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2815010Z                             END LOOP;
2026-02-14T13:01:56.2815225Z                         END $$;
2026-02-14T13:01:56.2815295Z                     """)
2026-02-14T13:01:56.2815370Z                     # Drop tables
2026-02-14T13:01:56.2815453Z                     cur.execute("""
2026-02-14T13:01:56.2815624Z                         DO $$
2026-02-14T13:01:56.2815691Z                         DECLARE
2026-02-14T13:01:56.2815768Z                             r RECORD;
2026-02-14T13:01:56.2815834Z                         BEGIN
2026-02-14T13:01:56.2815907Z                             FOR r IN (
2026-02-14T13:01:56.2816014Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2816099Z                                 FROM pg_tables
2026-02-14T13:01:56.2816225Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2816292Z                             )
2026-02-14T13:01:56.2816369Z                             LOOP
2026-02-14T13:01:56.2816684Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2816756Z                             END LOOP;
2026-02-14T13:01:56.2816827Z                         END $$;
2026-02-14T13:01:56.2816895Z                     """)
2026-02-14T13:01:56.2816978Z                 except psycopg2.Error:
2026-02-14T13:01:56.2817159Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2817225Z                     pass
2026-02-14T13:01:56.2817285Z     
2026-02-14T13:01:56.2817451Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2817567Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2817643Z                 if init_dir.exists():
2026-02-14T13:01:56.2817747Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2817845Z                     for script_path in scripts:
2026-02-14T13:01:56.2817973Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2818050Z                             sql = f.read()
2026-02-14T13:01:56.2818263Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2818397Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2818475Z                             statements = []
2026-02-14T13:01:56.2818533Z     
2026-02-14T13:01:56.2818718Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2818795Z                             do_blocks = []
2026-02-14T13:01:56.2818898Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2818963Z     
2026-02-14T13:01:56.2819062Z                             def replace_do_block(match):
2026-02-14T13:01:56.2819153Z                                 block = match.group(0)
2026-02-14T13:01:56.2819288Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2819385Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2819472Z                                 return placeholder
2026-02-14T13:01:56.2819534Z     
2026-02-14T13:01:56.2819648Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2819748Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2819831Z                                                     ^^
2026-02-14T13:01:56.2820024Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2820094Z                             )
2026-02-14T13:01:56.2820201Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2820207Z 
2026-02-14T13:01:56.2820317Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2820668Z _ ERROR at setup of TestDocumentManagementIntegration.test_create_text_cover_letter_and_link _
2026-02-14T13:01:56.2820674Z 
2026-02-14T13:01:56.2820970Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2820975Z 
2026-02-14T13:01:56.2821244Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2821522Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2821587Z         """
2026-02-14T13:01:56.2821731Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2821791Z     
2026-02-14T13:01:56.2821932Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2822062Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2822123Z         """
2026-02-14T13:01:56.2822225Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2822353Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2822412Z     
2026-02-14T13:01:56.2822518Z         # Parse connection string to get database name
2026-02-14T13:01:56.2822779Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2822837Z     
2026-02-14T13:01:56.2823026Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2823268Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2823326Z     
2026-02-14T13:01:56.2823472Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2823593Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2823671Z         if len(parts) >= 4:
2026-02-14T13:01:56.2823795Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2823861Z         else:
2026-02-14T13:01:56.2823968Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2824026Z     
2026-02-14T13:01:56.2824124Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2824362Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2824429Z         import time
2026-02-14T13:01:56.2824489Z     
2026-02-14T13:01:56.2824564Z         max_retries = 5
2026-02-14T13:01:56.2824632Z         retry_delay = 2
2026-02-14T13:01:56.2824695Z     
2026-02-14T13:01:56.2824782Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2824851Z             try:
2026-02-14T13:01:56.2824952Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2825048Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2825134Z                 conn.autocommit = True
2026-02-14T13:01:56.2825200Z                 try:
2026-02-14T13:01:56.2825278Z                     cur = conn.cursor()
2026-02-14T13:01:56.2825466Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2825557Z                     if not cur.fetchone():
2026-02-14T13:01:56.2825713Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2825831Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2825913Z                     cur.close()
2026-02-14T13:01:56.2825980Z                 finally:
2026-02-14T13:01:56.2826057Z                     conn.close()
2026-02-14T13:01:56.2826137Z                 break  # Success
2026-02-14T13:01:56.2826330Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2826422Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2826491Z                     print(
2026-02-14T13:01:56.2826716Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2826782Z                     )
2026-02-14T13:01:56.2826869Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2826944Z                 else:
2026-02-14T13:01:56.2827315Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2827506Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2827581Z                     pass
2026-02-14T13:01:56.2827703Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2827866Z                 break  # Already exists
2026-02-14T13:01:56.2827926Z     
2026-02-14T13:01:56.2828156Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2828340Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2828476Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2828544Z     
2026-02-14T13:01:56.2828616Z         close_all_pools()
2026-02-14T13:01:56.2828679Z     
2026-02-14T13:01:56.2828808Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2828985Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2829131Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2829215Z             conn.autocommit = True
2026-02-14T13:01:56.2829302Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2829500Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2829593Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2829674Z                 cur.execute(
2026-02-14T13:01:56.2829740Z                     """
2026-02-14T13:01:56.2829840Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2829925Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2830021Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2830112Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2830177Z                     """
2026-02-14T13:01:56.2830243Z                 )
2026-02-14T13:01:56.2830301Z     
2026-02-14T13:01:56.2830494Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2830684Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2830748Z                 try:
2026-02-14T13:01:56.2830871Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2830951Z                     cur.execute("""
2026-02-14T13:01:56.2831020Z                         DO $$
2026-02-14T13:01:56.2831238Z                         DECLARE
2026-02-14T13:01:56.2831312Z                             r RECORD;
2026-02-14T13:01:56.2831385Z                         BEGIN
2026-02-14T13:01:56.2831459Z                             FOR r IN (
2026-02-14T13:01:56.2831560Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2831646Z                                 FROM pg_views
2026-02-14T13:01:56.2831775Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2831846Z                             )
2026-02-14T13:01:56.2831917Z                             LOOP
2026-02-14T13:01:56.2832234Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2832312Z                             END LOOP;
2026-02-14T13:01:56.2832379Z                         END $$;
2026-02-14T13:01:56.2832451Z                     """)
2026-02-14T13:01:56.2832524Z                     # Drop tables
2026-02-14T13:01:56.2832597Z                     cur.execute("""
2026-02-14T13:01:56.2832669Z                         DO $$
2026-02-14T13:01:56.2832735Z                         DECLARE
2026-02-14T13:01:56.2832805Z                             r RECORD;
2026-02-14T13:01:56.2832871Z                         BEGIN
2026-02-14T13:01:56.2832948Z                             FOR r IN (
2026-02-14T13:01:56.2833049Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2833251Z                                 FROM pg_tables
2026-02-14T13:01:56.2833388Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2833457Z                             )
2026-02-14T13:01:56.2833526Z                             LOOP
2026-02-14T13:01:56.2833946Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2834018Z                             END LOOP;
2026-02-14T13:01:56.2834089Z                         END $$;
2026-02-14T13:01:56.2834155Z                     """)
2026-02-14T13:01:56.2834245Z                 except psycopg2.Error:
2026-02-14T13:01:56.2834420Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2834489Z                     pass
2026-02-14T13:01:56.2834553Z     
2026-02-14T13:01:56.2834723Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2834840Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2834923Z                 if init_dir.exists():
2026-02-14T13:01:56.2835030Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2835126Z                     for script_path in scripts:
2026-02-14T13:01:56.2835254Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2835341Z                             sql = f.read()
2026-02-14T13:01:56.2835546Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2835678Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2835764Z                             statements = []
2026-02-14T13:01:56.2835822Z     
2026-02-14T13:01:56.2835999Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2836085Z                             do_blocks = []
2026-02-14T13:01:56.2836189Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2836249Z     
2026-02-14T13:01:56.2836347Z                             def replace_do_block(match):
2026-02-14T13:01:56.2836452Z                                 block = match.group(0)
2026-02-14T13:01:56.2836582Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2836680Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2836777Z                                 return placeholder
2026-02-14T13:01:56.2836837Z     
2026-02-14T13:01:56.2836949Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2837057Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2837142Z                                                     ^^
2026-02-14T13:01:56.2837330Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2837406Z                             )
2026-02-14T13:01:56.2837522Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2837527Z 
2026-02-14T13:01:56.2837629Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2837899Z _ ERROR at setup of TestDocumentManagementIntegration.test_upload_cover_letter_file_and_link _
2026-02-14T13:01:56.2837911Z 
2026-02-14T13:01:56.2838201Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2838205Z 
2026-02-14T13:01:56.2838304Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2838415Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2838479Z         """
2026-02-14T13:01:56.2838624Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2838692Z     
2026-02-14T13:01:56.2838828Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2838962Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2839113Z         """
2026-02-14T13:01:56.2839214Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2839343Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2839410Z     
2026-02-14T13:01:56.2839613Z         # Parse connection string to get database name
2026-02-14T13:01:56.2839858Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2839923Z     
2026-02-14T13:01:56.2840110Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2840336Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2840399Z     
2026-02-14T13:01:56.2840545Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2840655Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2840731Z         if len(parts) >= 4:
2026-02-14T13:01:56.2840861Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2840926Z         else:
2026-02-14T13:01:56.2841150Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2841216Z     
2026-02-14T13:01:56.2841323Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2841550Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2841618Z         import time
2026-02-14T13:01:56.2841685Z     
2026-02-14T13:01:56.2841754Z         max_retries = 5
2026-02-14T13:01:56.2841824Z         retry_delay = 2
2026-02-14T13:01:56.2841888Z     
2026-02-14T13:01:56.2841977Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2842041Z             try:
2026-02-14T13:01:56.2842143Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2842242Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2842323Z                 conn.autocommit = True
2026-02-14T13:01:56.2842394Z                 try:
2026-02-14T13:01:56.2842478Z                     cur = conn.cursor()
2026-02-14T13:01:56.2842667Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2842754Z                     if not cur.fetchone():
2026-02-14T13:01:56.2842911Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2843031Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2843103Z                     cur.close()
2026-02-14T13:01:56.2843171Z                 finally:
2026-02-14T13:01:56.2843248Z                     conn.close()
2026-02-14T13:01:56.2843321Z                 break  # Success
2026-02-14T13:01:56.2843512Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2843608Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2843679Z                     print(
2026-02-14T13:01:56.2843903Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2843974Z                     )
2026-02-14T13:01:56.2844062Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2844127Z                 else:
2026-02-14T13:01:56.2844337Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2844529Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2844600Z                     pass
2026-02-14T13:01:56.2844716Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2844801Z                 break  # Already exists
2026-02-14T13:01:56.2844859Z     
2026-02-14T13:01:56.2845075Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2845264Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2845537Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2845599Z     
2026-02-14T13:01:56.2845676Z         close_all_pools()
2026-02-14T13:01:56.2845744Z     
2026-02-14T13:01:56.2845863Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2846131Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2846282Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2846363Z             conn.autocommit = True
2026-02-14T13:01:56.2846445Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2846644Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2846742Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2846814Z                 cur.execute(
2026-02-14T13:01:56.2846882Z                     """
2026-02-14T13:01:56.2846987Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2847073Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2847171Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2847269Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2847334Z                     """
2026-02-14T13:01:56.2847401Z                 )
2026-02-14T13:01:56.2847468Z     
2026-02-14T13:01:56.2847661Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2847845Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2847910Z                 try:
2026-02-14T13:01:56.2848037Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2848115Z                     cur.execute("""
2026-02-14T13:01:56.2848186Z                         DO $$
2026-02-14T13:01:56.2848260Z                         DECLARE
2026-02-14T13:01:56.2848334Z                             r RECORD;
2026-02-14T13:01:56.2848408Z                         BEGIN
2026-02-14T13:01:56.2848482Z                             FOR r IN (
2026-02-14T13:01:56.2848594Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2848676Z                                 FROM pg_views
2026-02-14T13:01:56.2848820Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2848894Z                             )
2026-02-14T13:01:56.2848965Z                             LOOP
2026-02-14T13:01:56.2849283Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2849367Z                             END LOOP;
2026-02-14T13:01:56.2849436Z                         END $$;
2026-02-14T13:01:56.2849503Z                     """)
2026-02-14T13:01:56.2849576Z                     # Drop tables
2026-02-14T13:01:56.2849659Z                     cur.execute("""
2026-02-14T13:01:56.2849726Z                         DO $$
2026-02-14T13:01:56.2849797Z                         DECLARE
2026-02-14T13:01:56.2849876Z                             r RECORD;
2026-02-14T13:01:56.2849946Z                         BEGIN
2026-02-14T13:01:56.2850019Z                             FOR r IN (
2026-02-14T13:01:56.2850131Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2850214Z                                 FROM pg_tables
2026-02-14T13:01:56.2850341Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2850406Z                             )
2026-02-14T13:01:56.2850480Z                             LOOP
2026-02-14T13:01:56.2850801Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2850872Z                             END LOOP;
2026-02-14T13:01:56.2850947Z                         END $$;
2026-02-14T13:01:56.2851012Z                     """)
2026-02-14T13:01:56.2851467Z                 except psycopg2.Error:
2026-02-14T13:01:56.2851663Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2851734Z                     pass
2026-02-14T13:01:56.2851793Z     
2026-02-14T13:01:56.2852075Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2852191Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2852270Z                 if init_dir.exists():
2026-02-14T13:01:56.2852375Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2852470Z                     for script_path in scripts:
2026-02-14T13:01:56.2852597Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2852675Z                             sql = f.read()
2026-02-14T13:01:56.2852886Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2853024Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2853105Z                             statements = []
2026-02-14T13:01:56.2853162Z     
2026-02-14T13:01:56.2853347Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2853428Z                             do_blocks = []
2026-02-14T13:01:56.2853532Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2853597Z     
2026-02-14T13:01:56.2853693Z                             def replace_do_block(match):
2026-02-14T13:01:56.2853785Z                                 block = match.group(0)
2026-02-14T13:01:56.2853918Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2854016Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2854103Z                                 return placeholder
2026-02-14T13:01:56.2854164Z     
2026-02-14T13:01:56.2854281Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2854380Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2854462Z                                                     ^^
2026-02-14T13:01:56.2854656Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2854732Z                             )
2026-02-14T13:01:56.2854840Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2854846Z 
2026-02-14T13:01:56.2854954Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2855211Z _ ERROR at setup of TestDocumentManagementIntegration.test_update_job_application_document _
2026-02-14T13:01:56.2855216Z 
2026-02-14T13:01:56.2855512Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2855517Z 
2026-02-14T13:01:56.2855604Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2855713Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2855779Z         """
2026-02-14T13:01:56.2855915Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2855976Z     
2026-02-14T13:01:56.2856115Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2856243Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2856304Z         """
2026-02-14T13:01:56.2856403Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2856525Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2856584Z     
2026-02-14T13:01:56.2856691Z         # Parse connection string to get database name
2026-02-14T13:01:56.2856941Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2857000Z     
2026-02-14T13:01:56.2857184Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2857507Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2857569Z     
2026-02-14T13:01:56.2857714Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2857829Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2857984Z         if len(parts) >= 4:
2026-02-14T13:01:56.2858104Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2858175Z         else:
2026-02-14T13:01:56.2858274Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2858332Z     
2026-02-14T13:01:56.2858428Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2858664Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2858730Z         import time
2026-02-14T13:01:56.2858789Z     
2026-02-14T13:01:56.2858865Z         max_retries = 5
2026-02-14T13:01:56.2858933Z         retry_delay = 2
2026-02-14T13:01:56.2858996Z     
2026-02-14T13:01:56.2859088Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2859162Z             try:
2026-02-14T13:01:56.2859260Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2859355Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2859453Z                 conn.autocommit = True
2026-02-14T13:01:56.2859518Z                 try:
2026-02-14T13:01:56.2859596Z                     cur = conn.cursor()
2026-02-14T13:01:56.2859786Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2859876Z                     if not cur.fetchone():
2026-02-14T13:01:56.2860027Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2860144Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2860223Z                     cur.close()
2026-02-14T13:01:56.2860291Z                 finally:
2026-02-14T13:01:56.2860368Z                     conn.close()
2026-02-14T13:01:56.2860448Z                 break  # Success
2026-02-14T13:01:56.2860638Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2860728Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2860803Z                     print(
2026-02-14T13:01:56.2861147Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2861216Z                     )
2026-02-14T13:01:56.2861300Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2861372Z                 else:
2026-02-14T13:01:56.2861576Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2861761Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2861836Z                     pass
2026-02-14T13:01:56.2861951Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2862034Z                 break  # Already exists
2026-02-14T13:01:56.2862092Z     
2026-02-14T13:01:56.2862316Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2862500Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2862639Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2862703Z     
2026-02-14T13:01:56.2862776Z         close_all_pools()
2026-02-14T13:01:56.2862835Z     
2026-02-14T13:01:56.2862957Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2863122Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2863263Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2863348Z             conn.autocommit = True
2026-02-14T13:01:56.2863434Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2863752Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2863849Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2863927Z                 cur.execute(
2026-02-14T13:01:56.2863995Z                     """
2026-02-14T13:01:56.2864194Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2864281Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2864375Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2864465Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2864531Z                     """
2026-02-14T13:01:56.2864598Z                 )
2026-02-14T13:01:56.2864656Z     
2026-02-14T13:01:56.2864846Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2865034Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2865098Z                 try:
2026-02-14T13:01:56.2865228Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2865310Z                     cur.execute("""
2026-02-14T13:01:56.2865381Z                         DO $$
2026-02-14T13:01:56.2865448Z                         DECLARE
2026-02-14T13:01:56.2865527Z                             r RECORD;
2026-02-14T13:01:56.2865600Z                         BEGIN
2026-02-14T13:01:56.2865673Z                             FOR r IN (
2026-02-14T13:01:56.2865773Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2865858Z                                 FROM pg_views
2026-02-14T13:01:56.2865986Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2866057Z                             )
2026-02-14T13:01:56.2866135Z                             LOOP
2026-02-14T13:01:56.2866449Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2866527Z                             END LOOP;
2026-02-14T13:01:56.2866594Z                         END $$;
2026-02-14T13:01:56.2866665Z                     """)
2026-02-14T13:01:56.2866740Z                     # Drop tables
2026-02-14T13:01:56.2866814Z                     cur.execute("""
2026-02-14T13:01:56.2866891Z                         DO $$
2026-02-14T13:01:56.2866958Z                         DECLARE
2026-02-14T13:01:56.2867029Z                             r RECORD;
2026-02-14T13:01:56.2867096Z                         BEGIN
2026-02-14T13:01:56.2867173Z                             FOR r IN (
2026-02-14T13:01:56.2867273Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2867357Z                                 FROM pg_tables
2026-02-14T13:01:56.2867490Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2867556Z                             )
2026-02-14T13:01:56.2867626Z                             LOOP
2026-02-14T13:01:56.2867954Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2868027Z                             END LOOP;
2026-02-14T13:01:56.2868094Z                         END $$;
2026-02-14T13:01:56.2868162Z                     """)
2026-02-14T13:01:56.2868252Z                 except psycopg2.Error:
2026-02-14T13:01:56.2868427Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2868495Z                     pass
2026-02-14T13:01:56.2868559Z     
2026-02-14T13:01:56.2868729Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2868839Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2868922Z                 if init_dir.exists():
2026-02-14T13:01:56.2869028Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2869118Z                     for script_path in scripts:
2026-02-14T13:01:56.2869330Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2869416Z                             sql = f.read()
2026-02-14T13:01:56.2869621Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2869879Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2869964Z                             statements = []
2026-02-14T13:01:56.2870023Z     
2026-02-14T13:01:56.2870198Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2870283Z                             do_blocks = []
2026-02-14T13:01:56.2870387Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2870446Z     
2026-02-14T13:01:56.2870544Z                             def replace_do_block(match):
2026-02-14T13:01:56.2870643Z                                 block = match.group(0)
2026-02-14T13:01:56.2870776Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2870875Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2870968Z                                 return placeholder
2026-02-14T13:01:56.2871136Z     
2026-02-14T13:01:56.2871249Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2871355Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2871441Z                                                     ^^
2026-02-14T13:01:56.2871628Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2871703Z                             )
2026-02-14T13:01:56.2871812Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2871817Z 
2026-02-14T13:01:56.2871921Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2872162Z _ ERROR at setup of TestDocumentManagementIntegration.test_delete_resume_removes_file _
2026-02-14T13:01:56.2872173Z 
2026-02-14T13:01:56.2872449Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2872454Z 
2026-02-14T13:01:56.2872549Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2872659Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2872722Z         """
2026-02-14T13:01:56.2872860Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2872921Z     
2026-02-14T13:01:56.2873053Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2873182Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2873243Z         """
2026-02-14T13:01:56.2873338Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2873465Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2873529Z     
2026-02-14T13:01:56.2873634Z         # Parse connection string to get database name
2026-02-14T13:01:56.2873879Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2873947Z     
2026-02-14T13:01:56.2874133Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2874363Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2874427Z     
2026-02-14T13:01:56.2874572Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2874683Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2874757Z         if len(parts) >= 4:
2026-02-14T13:01:56.2874881Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2874943Z         else:
2026-02-14T13:01:56.2875044Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2875106Z     
2026-02-14T13:01:56.2875202Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2875548Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2875624Z         import time
2026-02-14T13:01:56.2875683Z     
2026-02-14T13:01:56.2875753Z         max_retries = 5
2026-02-14T13:01:56.2875923Z         retry_delay = 2
2026-02-14T13:01:56.2875986Z     
2026-02-14T13:01:56.2876072Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2876135Z             try:
2026-02-14T13:01:56.2876240Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2876335Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2876415Z                 conn.autocommit = True
2026-02-14T13:01:56.2876481Z                 try:
2026-02-14T13:01:56.2876565Z                     cur = conn.cursor()
2026-02-14T13:01:56.2876784Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2876871Z                     if not cur.fetchone():
2026-02-14T13:01:56.2877032Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2877152Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2877223Z                     cur.close()
2026-02-14T13:01:56.2877306Z                 finally:
2026-02-14T13:01:56.2877379Z                     conn.close()
2026-02-14T13:01:56.2877451Z                 break  # Success
2026-02-14T13:01:56.2877641Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2877741Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2877810Z                     print(
2026-02-14T13:01:56.2878026Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2878096Z                     )
2026-02-14T13:01:56.2878181Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2878247Z                 else:
2026-02-14T13:01:56.2878452Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2878643Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2878714Z                     pass
2026-02-14T13:01:56.2878835Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2878919Z                 break  # Already exists
2026-02-14T13:01:56.2878978Z     
2026-02-14T13:01:56.2879198Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2879387Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2879519Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2879577Z     
2026-02-14T13:01:56.2879651Z         close_all_pools()
2026-02-14T13:01:56.2879718Z     
2026-02-14T13:01:56.2879835Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2880000Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2880148Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2880228Z             conn.autocommit = True
2026-02-14T13:01:56.2880308Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2880509Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2880599Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2880671Z                 cur.execute(
2026-02-14T13:01:56.2880737Z                     """
2026-02-14T13:01:56.2880840Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2880923Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2881019Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2881235Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2881303Z                     """
2026-02-14T13:01:56.2881364Z                 )
2026-02-14T13:01:56.2881546Z     
2026-02-14T13:01:56.2881741Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2881924Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2882092Z                 try:
2026-02-14T13:01:56.2882221Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2882298Z                     cur.execute("""
2026-02-14T13:01:56.2882368Z                         DO $$
2026-02-14T13:01:56.2882444Z                         DECLARE
2026-02-14T13:01:56.2882521Z                             r RECORD;
2026-02-14T13:01:56.2882588Z                         BEGIN
2026-02-14T13:01:56.2882667Z                             FOR r IN (
2026-02-14T13:01:56.2882770Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2882851Z                                 FROM pg_views
2026-02-14T13:01:56.2882985Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2883058Z                             )
2026-02-14T13:01:56.2883128Z                             LOOP
2026-02-14T13:01:56.2883442Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2883526Z                             END LOOP;
2026-02-14T13:01:56.2883594Z                         END $$;
2026-02-14T13:01:56.2883661Z                     """)
2026-02-14T13:01:56.2883740Z                     # Drop tables
2026-02-14T13:01:56.2883813Z                     cur.execute("""
2026-02-14T13:01:56.2883879Z                         DO $$
2026-02-14T13:01:56.2883944Z                         DECLARE
2026-02-14T13:01:56.2884020Z                             r RECORD;
2026-02-14T13:01:56.2884086Z                         BEGIN
2026-02-14T13:01:56.2884157Z                             FOR r IN (
2026-02-14T13:01:56.2884261Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2884349Z                                 FROM pg_tables
2026-02-14T13:01:56.2884476Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2884540Z                             )
2026-02-14T13:01:56.2884622Z                             LOOP
2026-02-14T13:01:56.2884934Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2885005Z                             END LOOP;
2026-02-14T13:01:56.2885077Z                         END $$;
2026-02-14T13:01:56.2885143Z                     """)
2026-02-14T13:01:56.2885226Z                 except psycopg2.Error:
2026-02-14T13:01:56.2885403Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2885471Z                     pass
2026-02-14T13:01:56.2885529Z     
2026-02-14T13:01:56.2885707Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2885825Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2885903Z                 if init_dir.exists():
2026-02-14T13:01:56.2886008Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2886109Z                     for script_path in scripts:
2026-02-14T13:01:56.2886237Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2886316Z                             sql = f.read()
2026-02-14T13:01:56.2886529Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2886660Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2886738Z                             statements = []
2026-02-14T13:01:56.2886802Z     
2026-02-14T13:01:56.2886980Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2887146Z                             do_blocks = []
2026-02-14T13:01:56.2887252Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2887319Z     
2026-02-14T13:01:56.2887416Z                             def replace_do_block(match):
2026-02-14T13:01:56.2887585Z                                 block = match.group(0)
2026-02-14T13:01:56.2887720Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2887818Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2887905Z                                 return placeholder
2026-02-14T13:01:56.2887970Z     
2026-02-14T13:01:56.2888081Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2888178Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2888262Z                                                     ^^
2026-02-14T13:01:56.2888462Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2888530Z                             )
2026-02-14T13:01:56.2888638Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2888644Z 
2026-02-14T13:01:56.2888758Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2888983Z _ ERROR at setup of TestDocumentManagementIntegration.test_get_user_resumes_list _
2026-02-14T13:01:56.2888988Z 
2026-02-14T13:01:56.2889274Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2889279Z 
2026-02-14T13:01:56.2889367Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2889478Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2889541Z         """
2026-02-14T13:01:56.2889675Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2889733Z     
2026-02-14T13:01:56.2889875Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2890003Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2890063Z         """
2026-02-14T13:01:56.2890167Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2890294Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2890353Z     
2026-02-14T13:01:56.2890473Z         # Parse connection string to get database name
2026-02-14T13:01:56.2890717Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2890775Z     
2026-02-14T13:01:56.2890960Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2891435Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2891498Z     
2026-02-14T13:01:56.2891649Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2891765Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2891843Z         if len(parts) >= 4:
2026-02-14T13:01:56.2891974Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2892042Z         else:
2026-02-14T13:01:56.2892144Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2892203Z     
2026-02-14T13:01:56.2892305Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2892538Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2892606Z         import time
2026-02-14T13:01:56.2892665Z     
2026-02-14T13:01:56.2892740Z         max_retries = 5
2026-02-14T13:01:56.2892810Z         retry_delay = 2
2026-02-14T13:01:56.2892868Z     
2026-02-14T13:01:56.2892957Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2893029Z             try:
2026-02-14T13:01:56.2893128Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2893224Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2893312Z                 conn.autocommit = True
2026-02-14T13:01:56.2893511Z                 try:
2026-02-14T13:01:56.2893596Z                     cur = conn.cursor()
2026-02-14T13:01:56.2893793Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2893977Z                     if not cur.fetchone():
2026-02-14T13:01:56.2894130Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2894250Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2894332Z                     cur.close()
2026-02-14T13:01:56.2894401Z                 finally:
2026-02-14T13:01:56.2894475Z                     conn.close()
2026-02-14T13:01:56.2894552Z                 break  # Success
2026-02-14T13:01:56.2894743Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2894834Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2894914Z                     print(
2026-02-14T13:01:56.2895138Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2895204Z                     )
2026-02-14T13:01:56.2895286Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2895361Z                 else:
2026-02-14T13:01:56.2895564Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2895747Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2895820Z                     pass
2026-02-14T13:01:56.2895934Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2896013Z                 break  # Already exists
2026-02-14T13:01:56.2896082Z     
2026-02-14T13:01:56.2896302Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2896484Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2896617Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2896681Z     
2026-02-14T13:01:56.2896756Z         close_all_pools()
2026-02-14T13:01:56.2896814Z     
2026-02-14T13:01:56.2896937Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2897107Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2897248Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2897337Z             conn.autocommit = True
2026-02-14T13:01:56.2897418Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2897613Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2897706Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2897784Z                 cur.execute(
2026-02-14T13:01:56.2897849Z                     """
2026-02-14T13:01:56.2897945Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2898034Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2898130Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2898220Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2898285Z                     """
2026-02-14T13:01:56.2898357Z                 )
2026-02-14T13:01:56.2898415Z     
2026-02-14T13:01:56.2898602Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2898791Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2898857Z                 try:
2026-02-14T13:01:56.2898975Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2899061Z                     cur.execute("""
2026-02-14T13:01:56.2899130Z                         DO $$
2026-02-14T13:01:56.2899199Z                         DECLARE
2026-02-14T13:01:56.2899272Z                             r RECORD;
2026-02-14T13:01:56.2899440Z                         BEGIN
2026-02-14T13:01:56.2899516Z                             FOR r IN (
2026-02-14T13:01:56.2899619Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2899708Z                                 FROM pg_views
2026-02-14T13:01:56.2899928Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2899995Z                             )
2026-02-14T13:01:56.2900073Z                             LOOP
2026-02-14T13:01:56.2900387Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2900461Z                             END LOOP;
2026-02-14T13:01:56.2900530Z                         END $$;
2026-02-14T13:01:56.2900601Z                     """)
2026-02-14T13:01:56.2900673Z                     # Drop tables
2026-02-14T13:01:56.2900748Z                     cur.execute("""
2026-02-14T13:01:56.2900821Z                         DO $$
2026-02-14T13:01:56.2900892Z                         DECLARE
2026-02-14T13:01:56.2900963Z                             r RECORD;
2026-02-14T13:01:56.2901269Z                         BEGIN
2026-02-14T13:01:56.2901406Z                             FOR r IN (
2026-02-14T13:01:56.2901540Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2901628Z                                 FROM pg_tables
2026-02-14T13:01:56.2901766Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2901835Z                             )
2026-02-14T13:01:56.2901906Z                             LOOP
2026-02-14T13:01:56.2902230Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2902303Z                             END LOOP;
2026-02-14T13:01:56.2902370Z                         END $$;
2026-02-14T13:01:56.2902442Z                     """)
2026-02-14T13:01:56.2902529Z                 except psycopg2.Error:
2026-02-14T13:01:56.2902702Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2902771Z                     pass
2026-02-14T13:01:56.2902837Z     
2026-02-14T13:01:56.2903018Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2903128Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2907147Z                 if init_dir.exists():
2026-02-14T13:01:56.2907307Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2907412Z                     for script_path in scripts:
2026-02-14T13:01:56.2907552Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2907641Z                             sql = f.read()
2026-02-14T13:01:56.2907862Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2908010Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2908100Z                             statements = []
2026-02-14T13:01:56.2908159Z     
2026-02-14T13:01:56.2908342Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2908431Z                             do_blocks = []
2026-02-14T13:01:56.2908540Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2908600Z     
2026-02-14T13:01:56.2908701Z                             def replace_do_block(match):
2026-02-14T13:01:56.2908807Z                                 block = match.group(0)
2026-02-14T13:01:56.2908943Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2909043Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2909142Z                                 return placeholder
2026-02-14T13:01:56.2909201Z     
2026-02-14T13:01:56.2909515Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2909633Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2909720Z                                                     ^^
2026-02-14T13:01:56.2910018Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2910098Z                             )
2026-02-14T13:01:56.2910213Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2910220Z 
2026-02-14T13:01:56.2910323Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2910588Z _ ERROR at setup of TestDocumentManagementIntegration.test_inline_cover_letter_text_workflow _
2026-02-14T13:01:56.2910601Z 
2026-02-14T13:01:56.2910932Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2910939Z 
2026-02-14T13:01:56.2911238Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2911365Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2911429Z         """
2026-02-14T13:01:56.2911581Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2911639Z     
2026-02-14T13:01:56.2911775Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2911915Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2911976Z         """
2026-02-14T13:01:56.2912072Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2912200Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2912265Z     
2026-02-14T13:01:56.2912375Z         # Parse connection string to get database name
2026-02-14T13:01:56.2912625Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2912688Z     
2026-02-14T13:01:56.2912874Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2913102Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2913166Z     
2026-02-14T13:01:56.2913313Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2913423Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2913505Z         if len(parts) >= 4:
2026-02-14T13:01:56.2913635Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2913697Z         else:
2026-02-14T13:01:56.2913799Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2913865Z     
2026-02-14T13:01:56.2913963Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2914194Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2914270Z         import time
2026-02-14T13:01:56.2914328Z     
2026-02-14T13:01:56.2914397Z         max_retries = 5
2026-02-14T13:01:56.2914465Z         retry_delay = 2
2026-02-14T13:01:56.2914533Z     
2026-02-14T13:01:56.2914624Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2914687Z             try:
2026-02-14T13:01:56.2914797Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2914893Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2914980Z                 conn.autocommit = True
2026-02-14T13:01:56.2915053Z                 try:
2026-02-14T13:01:56.2915139Z                     cur = conn.cursor()
2026-02-14T13:01:56.2915331Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2915414Z                     if not cur.fetchone():
2026-02-14T13:01:56.2915576Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2915699Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2915773Z                     cur.close()
2026-02-14T13:01:56.2915848Z                 finally:
2026-02-14T13:01:56.2916043Z                     conn.close()
2026-02-14T13:01:56.2916119Z                 break  # Success
2026-02-14T13:01:56.2916319Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2916421Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2916596Z                     print(
2026-02-14T13:01:56.2916821Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2916893Z                     )
2026-02-14T13:01:56.2916980Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2917044Z                 else:
2026-02-14T13:01:56.2917251Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2917442Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2917512Z                     pass
2026-02-14T13:01:56.2917631Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2917725Z                 break  # Already exists
2026-02-14T13:01:56.2917783Z     
2026-02-14T13:01:56.2918004Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2918204Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2918344Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2918402Z     
2026-02-14T13:01:56.2918475Z         close_all_pools()
2026-02-14T13:01:56.2918539Z     
2026-02-14T13:01:56.2918660Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2918826Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2918973Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2919054Z             conn.autocommit = True
2026-02-14T13:01:56.2919136Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2919345Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2919440Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2919515Z                 cur.execute(
2026-02-14T13:01:56.2919583Z                     """
2026-02-14T13:01:56.2919698Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2919780Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2919879Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2919979Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2920048Z                     """
2026-02-14T13:01:56.2920110Z                 )
2026-02-14T13:01:56.2920177Z     
2026-02-14T13:01:56.2920375Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2920564Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2920628Z                 try:
2026-02-14T13:01:56.2920757Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2920837Z                     cur.execute("""
2026-02-14T13:01:56.2920909Z                         DO $$
2026-02-14T13:01:56.2920994Z                         DECLARE
2026-02-14T13:01:56.2921185Z                             r RECORD;
2026-02-14T13:01:56.2921257Z                         BEGIN
2026-02-14T13:01:56.2921340Z                             FOR r IN (
2026-02-14T13:01:56.2921446Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2921529Z                                 FROM pg_views
2026-02-14T13:01:56.2921659Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2921732Z                             )
2026-02-14T13:01:56.2921802Z                             LOOP
2026-02-14T13:01:56.2922118Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2922318Z                             END LOOP;
2026-02-14T13:01:56.2922391Z                         END $$;
2026-02-14T13:01:56.2922460Z                     """)
2026-02-14T13:01:56.2922539Z                     # Drop tables
2026-02-14T13:01:56.2922766Z                     cur.execute("""
2026-02-14T13:01:56.2922832Z                         DO $$
2026-02-14T13:01:56.2922899Z                         DECLARE
2026-02-14T13:01:56.2922978Z                             r RECORD;
2026-02-14T13:01:56.2923044Z                         BEGIN
2026-02-14T13:01:56.2923116Z                             FOR r IN (
2026-02-14T13:01:56.2923224Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2923309Z                                 FROM pg_tables
2026-02-14T13:01:56.2923436Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2923505Z                             )
2026-02-14T13:01:56.2923579Z                             LOOP
2026-02-14T13:01:56.2923900Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2923972Z                             END LOOP;
2026-02-14T13:01:56.2924044Z                         END $$;
2026-02-14T13:01:56.2924117Z                     """)
2026-02-14T13:01:56.2924201Z                 except psycopg2.Error:
2026-02-14T13:01:56.2924384Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2924452Z                     pass
2026-02-14T13:01:56.2924511Z     
2026-02-14T13:01:56.2924681Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2924800Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2924879Z                 if init_dir.exists():
2026-02-14T13:01:56.2924986Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2925085Z                     for script_path in scripts:
2026-02-14T13:01:56.2925215Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2925292Z                             sql = f.read()
2026-02-14T13:01:56.2925506Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2925640Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2925719Z                             statements = []
2026-02-14T13:01:56.2925784Z     
2026-02-14T13:01:56.2925963Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2926038Z                             do_blocks = []
2026-02-14T13:01:56.2926141Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2926206Z     
2026-02-14T13:01:56.2926307Z                             def replace_do_block(match):
2026-02-14T13:01:56.2926404Z                                 block = match.group(0)
2026-02-14T13:01:56.2926539Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2926635Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2926724Z                                 return placeholder
2026-02-14T13:01:56.2926794Z     
2026-02-14T13:01:56.2926904Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2927003Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2927084Z                                                     ^^
2026-02-14T13:01:56.2927274Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2927342Z                             )
2026-02-14T13:01:56.2927452Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2927458Z 
2026-02-14T13:01:56.2927565Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2927900Z _ ERROR at setup of TestDocumentManagementIntegration.test_mixed_document_types_workflow _
2026-02-14T13:01:56.2927906Z 
2026-02-14T13:01:56.2928196Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2928202Z 
2026-02-14T13:01:56.2928294Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2928489Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2928552Z         """
2026-02-14T13:01:56.2928692Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2928752Z     
2026-02-14T13:01:56.2928900Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2929026Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2929089Z         """
2026-02-14T13:01:56.2929189Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2929317Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2929377Z     
2026-02-14T13:01:56.2929499Z         # Parse connection string to get database name
2026-02-14T13:01:56.2929745Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2929804Z     
2026-02-14T13:01:56.2929991Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2930236Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2930296Z     
2026-02-14T13:01:56.2930444Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2930564Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2930641Z         if len(parts) >= 4:
2026-02-14T13:01:56.2930762Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2930832Z         else:
2026-02-14T13:01:56.2930935Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2930999Z     
2026-02-14T13:01:56.2931343Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2931624Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2931694Z         import time
2026-02-14T13:01:56.2931755Z     
2026-02-14T13:01:56.2931834Z         max_retries = 5
2026-02-14T13:01:56.2931913Z         retry_delay = 2
2026-02-14T13:01:56.2931974Z     
2026-02-14T13:01:56.2932063Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2932137Z             try:
2026-02-14T13:01:56.2932240Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2932338Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2932427Z                 conn.autocommit = True
2026-02-14T13:01:56.2932493Z                 try:
2026-02-14T13:01:56.2932573Z                     cur = conn.cursor()
2026-02-14T13:01:56.2932774Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2932857Z                     if not cur.fetchone():
2026-02-14T13:01:56.2933022Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2933141Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2933222Z                     cur.close()
2026-02-14T13:01:56.2933295Z                 finally:
2026-02-14T13:01:56.2933369Z                     conn.close()
2026-02-14T13:01:56.2933449Z                 break  # Success
2026-02-14T13:01:56.2933641Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2933735Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2933809Z                     print(
2026-02-14T13:01:56.2934038Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2934104Z                     )
2026-02-14T13:01:56.2934188Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2934259Z                 else:
2026-02-14T13:01:56.2934597Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2934786Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2934860Z                     pass
2026-02-14T13:01:56.2935088Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2935177Z                 break  # Already exists
2026-02-14T13:01:56.2935236Z     
2026-02-14T13:01:56.2935455Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2935638Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2935782Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2935841Z     
2026-02-14T13:01:56.2935914Z         close_all_pools()
2026-02-14T13:01:56.2935976Z     
2026-02-14T13:01:56.2936094Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2936262Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2936404Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2936493Z             conn.autocommit = True
2026-02-14T13:01:56.2936580Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2936772Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2936870Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2936945Z                 cur.execute(
2026-02-14T13:01:56.2937010Z                     """
2026-02-14T13:01:56.2937118Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2937200Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2937294Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2937384Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2937457Z                     """
2026-02-14T13:01:56.2937518Z                 )
2026-02-14T13:01:56.2937580Z     
2026-02-14T13:01:56.2937781Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2937966Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2938037Z                 try:
2026-02-14T13:01:56.2938163Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2938240Z                     cur.execute("""
2026-02-14T13:01:56.2938311Z                         DO $$
2026-02-14T13:01:56.2938379Z                         DECLARE
2026-02-14T13:01:56.2938464Z                             r RECORD;
2026-02-14T13:01:56.2938534Z                         BEGIN
2026-02-14T13:01:56.2938608Z                             FOR r IN (
2026-02-14T13:01:56.2938717Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2938798Z                                 FROM pg_views
2026-02-14T13:01:56.2938932Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2939006Z                             )
2026-02-14T13:01:56.2939075Z                             LOOP
2026-02-14T13:01:56.2939388Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2939465Z                             END LOOP;
2026-02-14T13:01:56.2939537Z                         END $$;
2026-02-14T13:01:56.2939602Z                     """)
2026-02-14T13:01:56.2939677Z                     # Drop tables
2026-02-14T13:01:56.2939754Z                     cur.execute("""
2026-02-14T13:01:56.2939822Z                         DO $$
2026-02-14T13:01:56.2939890Z                         DECLARE
2026-02-14T13:01:56.2939960Z                             r RECORD;
2026-02-14T13:01:56.2940034Z                         BEGIN
2026-02-14T13:01:56.2940106Z                             FOR r IN (
2026-02-14T13:01:56.2940315Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2940408Z                                 FROM pg_tables
2026-02-14T13:01:56.2940535Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2940601Z                             )
2026-02-14T13:01:56.2940752Z                             LOOP
2026-02-14T13:01:56.2941198Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2941273Z                             END LOOP;
2026-02-14T13:01:56.2941340Z                         END $$;
2026-02-14T13:01:56.2941414Z                     """)
2026-02-14T13:01:56.2941497Z                 except psycopg2.Error:
2026-02-14T13:01:56.2941671Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2941746Z                     pass
2026-02-14T13:01:56.2941804Z     
2026-02-14T13:01:56.2941979Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2942093Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2942169Z                 if init_dir.exists():
2026-02-14T13:01:56.2942274Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2942371Z                     for script_path in scripts:
2026-02-14T13:01:56.2942507Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2942583Z                             sql = f.read()
2026-02-14T13:01:56.2942790Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2942931Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2943010Z                             statements = []
2026-02-14T13:01:56.2943069Z     
2026-02-14T13:01:56.2943251Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2943330Z                             do_blocks = []
2026-02-14T13:01:56.2943433Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2943500Z     
2026-02-14T13:01:56.2943597Z                             def replace_do_block(match):
2026-02-14T13:01:56.2943695Z                                 block = match.group(0)
2026-02-14T13:01:56.2943824Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2943928Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2944016Z                                 return placeholder
2026-02-14T13:01:56.2944074Z     
2026-02-14T13:01:56.2944191Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2944289Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2944371Z                                                     ^^
2026-02-14T13:01:56.2944571Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2944639Z                             )
2026-02-14T13:01:56.2944746Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2944752Z 
2026-02-14T13:01:56.2944853Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2945146Z _ ERROR at setup of TestDocumentManagementIntegration.test_get_user_cover_letters_filtered_by_job _
2026-02-14T13:01:56.2945151Z 
2026-02-14T13:01:56.2945450Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2945457Z 
2026-02-14T13:01:56.2945548Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2945658Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2945726Z         """
2026-02-14T13:01:56.2945866Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2945929Z     
2026-02-14T13:01:56.2946071Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2946324Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2946388Z         """
2026-02-14T13:01:56.2946484Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2946618Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2946792Z     
2026-02-14T13:01:56.2946902Z         # Parse connection string to get database name
2026-02-14T13:01:56.2947156Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2947215Z     
2026-02-14T13:01:56.2947401Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2947638Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2947696Z     
2026-02-14T13:01:56.2947839Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2947954Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2948042Z         if len(parts) >= 4:
2026-02-14T13:01:56.2948162Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2948225Z         else:
2026-02-14T13:01:56.2948332Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2948399Z     
2026-02-14T13:01:56.2948497Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2948735Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2948804Z         import time
2026-02-14T13:01:56.2948864Z     
2026-02-14T13:01:56.2948934Z         max_retries = 5
2026-02-14T13:01:56.2949010Z         retry_delay = 2
2026-02-14T13:01:56.2949069Z     
2026-02-14T13:01:56.2949160Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2949232Z             try:
2026-02-14T13:01:56.2949336Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2949432Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2949522Z                 conn.autocommit = True
2026-02-14T13:01:56.2949594Z                 try:
2026-02-14T13:01:56.2949674Z                     cur = conn.cursor()
2026-02-14T13:01:56.2949864Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2949957Z                     if not cur.fetchone():
2026-02-14T13:01:56.2950109Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2950233Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2950312Z                     cur.close()
2026-02-14T13:01:56.2950381Z                 finally:
2026-02-14T13:01:56.2950459Z                     conn.close()
2026-02-14T13:01:56.2950530Z                 break  # Success
2026-02-14T13:01:56.2950729Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2950819Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2950893Z                     print(
2026-02-14T13:01:56.2951246Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2951313Z                     )
2026-02-14T13:01:56.2951397Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2951471Z                 else:
2026-02-14T13:01:56.2951677Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2951861Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2951933Z                     pass
2026-02-14T13:01:56.2952052Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2952130Z                 break  # Already exists
2026-02-14T13:01:56.2952189Z     
2026-02-14T13:01:56.2952406Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2952699Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2952836Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2952896Z     
2026-02-14T13:01:56.2952984Z         close_all_pools()
2026-02-14T13:01:56.2953043Z     
2026-02-14T13:01:56.2953269Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2953432Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2953581Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2953665Z             conn.autocommit = True
2026-02-14T13:01:56.2953744Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2953940Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2954033Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2954106Z                 cur.execute(
2026-02-14T13:01:56.2954177Z                     """
2026-02-14T13:01:56.2954281Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2954365Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2954460Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2954558Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2954627Z                     """
2026-02-14T13:01:56.2954688Z                 )
2026-02-14T13:01:56.2954756Z     
2026-02-14T13:01:56.2954943Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2955127Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2955202Z                 try:
2026-02-14T13:01:56.2955320Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2955397Z                     cur.execute("""
2026-02-14T13:01:56.2955468Z                         DO $$
2026-02-14T13:01:56.2955547Z                         DECLARE
2026-02-14T13:01:56.2955622Z                             r RECORD;
2026-02-14T13:01:56.2955695Z                         BEGIN
2026-02-14T13:01:56.2955775Z                             FOR r IN (
2026-02-14T13:01:56.2955878Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2955960Z                                 FROM pg_views
2026-02-14T13:01:56.2956096Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2956169Z                             )
2026-02-14T13:01:56.2956240Z                             LOOP
2026-02-14T13:01:56.2956555Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2956634Z                             END LOOP;
2026-02-14T13:01:56.2956704Z                         END $$;
2026-02-14T13:01:56.2956771Z                     """)
2026-02-14T13:01:56.2956850Z                     # Drop tables
2026-02-14T13:01:56.2956923Z                     cur.execute("""
2026-02-14T13:01:56.2956997Z                         DO $$
2026-02-14T13:01:56.2957063Z                         DECLARE
2026-02-14T13:01:56.2957138Z                             r RECORD;
2026-02-14T13:01:56.2957203Z                         BEGIN
2026-02-14T13:01:56.2957281Z                             FOR r IN (
2026-02-14T13:01:56.2957386Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2957470Z                                 FROM pg_tables
2026-02-14T13:01:56.2957597Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2957667Z                             )
2026-02-14T13:01:56.2957739Z                             LOOP
2026-02-14T13:01:56.2958051Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2958122Z                             END LOOP;
2026-02-14T13:01:56.2958196Z                         END $$;
2026-02-14T13:01:56.2958353Z                     """)
2026-02-14T13:01:56.2958439Z                 except psycopg2.Error:
2026-02-14T13:01:56.2958619Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2958686Z                     pass
2026-02-14T13:01:56.2958843Z     
2026-02-14T13:01:56.2959024Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2959137Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2959212Z                 if init_dir.exists():
2026-02-14T13:01:56.2959316Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2959413Z                     for script_path in scripts:
2026-02-14T13:01:56.2959541Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2959620Z                             sql = f.read()
2026-02-14T13:01:56.2959840Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2959972Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2960051Z                             statements = []
2026-02-14T13:01:56.2960114Z     
2026-02-14T13:01:56.2960297Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2960372Z                             do_blocks = []
2026-02-14T13:01:56.2960474Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2960539Z     
2026-02-14T13:01:56.2960636Z                             def replace_do_block(match):
2026-02-14T13:01:56.2960729Z                                 block = match.group(0)
2026-02-14T13:01:56.2960861Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2960957Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2961158Z                                 return placeholder
2026-02-14T13:01:56.2961224Z     
2026-02-14T13:01:56.2961337Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2961436Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2961518Z                                                     ^^
2026-02-14T13:01:56.2961721Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2961788Z                             )
2026-02-14T13:01:56.2961898Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2961903Z 
2026-02-14T13:01:56.2962010Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2962376Z _ ERROR at setup of TestDocumentManagementIntegration.test_documents_uploaded_from_job_details_not_in_documents_section _
2026-02-14T13:01:56.2962381Z 
2026-02-14T13:01:56.2962670Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2962675Z 
2026-02-14T13:01:56.2962762Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2962876Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2962938Z         """
2026-02-14T13:01:56.2963073Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2963137Z     
2026-02-14T13:01:56.2963273Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2963398Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2963459Z         """
2026-02-14T13:01:56.2963559Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2963684Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2963745Z     
2026-02-14T13:01:56.2963856Z         # Parse connection string to get database name
2026-02-14T13:01:56.2964097Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2964156Z     
2026-02-14T13:01:56.2964476Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2964718Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2964777Z     
2026-02-14T13:01:56.2964920Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2965142Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2965218Z         if len(parts) >= 4:
2026-02-14T13:01:56.2965338Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2965407Z         else:
2026-02-14T13:01:56.2965509Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2965568Z     
2026-02-14T13:01:56.2965663Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2965901Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2965968Z         import time
2026-02-14T13:01:56.2966027Z     
2026-02-14T13:01:56.2966102Z         max_retries = 5
2026-02-14T13:01:56.2966176Z         retry_delay = 2
2026-02-14T13:01:56.2966235Z     
2026-02-14T13:01:56.2966327Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2966391Z             try:
2026-02-14T13:01:56.2966492Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2966593Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2966680Z                 conn.autocommit = True
2026-02-14T13:01:56.2966743Z                 try:
2026-02-14T13:01:56.2966821Z                     cur = conn.cursor()
2026-02-14T13:01:56.2967013Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2967096Z                     if not cur.fetchone():
2026-02-14T13:01:56.2967246Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2967366Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2967436Z                     cur.close()
2026-02-14T13:01:56.2967506Z                 finally:
2026-02-14T13:01:56.2967578Z                     conn.close()
2026-02-14T13:01:56.2967655Z                 break  # Success
2026-02-14T13:01:56.2967844Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2967941Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2968018Z                     print(
2026-02-14T13:01:56.2968233Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2968298Z                     )
2026-02-14T13:01:56.2968381Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2968449Z                 else:
2026-02-14T13:01:56.2968653Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2968837Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2968910Z                     pass
2026-02-14T13:01:56.2969030Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2969106Z                 break  # Already exists
2026-02-14T13:01:56.2969172Z     
2026-02-14T13:01:56.2969383Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2969570Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2969708Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2969767Z     
2026-02-14T13:01:56.2969840Z         close_all_pools()
2026-02-14T13:01:56.2969897Z     
2026-02-14T13:01:56.2970018Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2970185Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2970326Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2970412Z             conn.autocommit = True
2026-02-14T13:01:56.2970619Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2970816Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2970907Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2970986Z                 cur.execute(
2026-02-14T13:01:56.2971405Z                     """
2026-02-14T13:01:56.2971514Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2971602Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2971699Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2971789Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2971859Z                     """
2026-02-14T13:01:56.2971920Z                 )
2026-02-14T13:01:56.2971979Z     
2026-02-14T13:01:56.2972170Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2972361Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2972432Z                 try:
2026-02-14T13:01:56.2972552Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2972635Z                     cur.execute("""
2026-02-14T13:01:56.2972706Z                         DO $$
2026-02-14T13:01:56.2972781Z                         DECLARE
2026-02-14T13:01:56.2972861Z                             r RECORD;
2026-02-14T13:01:56.2972932Z                         BEGIN
2026-02-14T13:01:56.2973005Z                             FOR r IN (
2026-02-14T13:01:56.2973108Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2973195Z                                 FROM pg_views
2026-02-14T13:01:56.2973325Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2973391Z                             )
2026-02-14T13:01:56.2973466Z                             LOOP
2026-02-14T13:01:56.2973782Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2973855Z                             END LOOP;
2026-02-14T13:01:56.2973928Z                         END $$;
2026-02-14T13:01:56.2973994Z                     """)
2026-02-14T13:01:56.2974070Z                     # Drop tables
2026-02-14T13:01:56.2974147Z                     cur.execute("""
2026-02-14T13:01:56.2974220Z                         DO $$
2026-02-14T13:01:56.2974288Z                         DECLARE
2026-02-14T13:01:56.2974358Z                             r RECORD;
2026-02-14T13:01:56.2974429Z                         BEGIN
2026-02-14T13:01:56.2974500Z                             FOR r IN (
2026-02-14T13:01:56.2974600Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2974683Z                                 FROM pg_tables
2026-02-14T13:01:56.2974815Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2974881Z                             )
2026-02-14T13:01:56.2974955Z                             LOOP
2026-02-14T13:01:56.2975278Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2975351Z                             END LOOP;
2026-02-14T13:01:56.2975423Z                         END $$;
2026-02-14T13:01:56.2975494Z                     """)
2026-02-14T13:01:56.2975577Z                 except psycopg2.Error:
2026-02-14T13:01:56.2975752Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2975823Z                     pass
2026-02-14T13:01:56.2975888Z     
2026-02-14T13:01:56.2976062Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2976173Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2976256Z                 if init_dir.exists():
2026-02-14T13:01:56.2976488Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2976585Z                     for script_path in scripts:
2026-02-14T13:01:56.2976716Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2976835Z                             sql = f.read()
2026-02-14T13:01:56.2977140Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2977277Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2977358Z                             statements = []
2026-02-14T13:01:56.2977418Z     
2026-02-14T13:01:56.2977596Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2977680Z                             do_blocks = []
2026-02-14T13:01:56.2977781Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2977839Z     
2026-02-14T13:01:56.2977943Z                             def replace_do_block(match):
2026-02-14T13:01:56.2978042Z                                 block = match.group(0)
2026-02-14T13:01:56.2978169Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2978271Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2978361Z                                 return placeholder
2026-02-14T13:01:56.2978419Z     
2026-02-14T13:01:56.2978528Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2978634Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2978714Z                                                     ^^
2026-02-14T13:01:56.2978900Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2978971Z                             )
2026-02-14T13:01:56.2979077Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2979082Z 
2026-02-14T13:01:56.2979189Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2979560Z _ ERROR at setup of TestDocumentManagementIntegration.test_only_documents_section_documents_in_job_attachment_dropdowns _
2026-02-14T13:01:56.2979566Z 
2026-02-14T13:01:56.2979863Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2979873Z 
2026-02-14T13:01:56.2979960Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2980064Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2980126Z         """
2026-02-14T13:01:56.2980264Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2980322Z     
2026-02-14T13:01:56.2980457Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2980587Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2980646Z         """
2026-02-14T13:01:56.2980741Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2980872Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2980935Z     
2026-02-14T13:01:56.2981217Z         # Parse connection string to get database name
2026-02-14T13:01:56.2981524Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2981604Z     
2026-02-14T13:01:56.2981790Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2982018Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2982082Z     
2026-02-14T13:01:56.2982226Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2982336Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2982417Z         if len(parts) >= 4:
2026-02-14T13:01:56.2982535Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2982599Z         else:
2026-02-14T13:01:56.2982698Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2982927Z     
2026-02-14T13:01:56.2983033Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2983265Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.2983445Z         import time
2026-02-14T13:01:56.2983506Z     
2026-02-14T13:01:56.2983576Z         max_retries = 5
2026-02-14T13:01:56.2983644Z         retry_delay = 2
2026-02-14T13:01:56.2983707Z     
2026-02-14T13:01:56.2983797Z         for attempt in range(max_retries):
2026-02-14T13:01:56.2983859Z             try:
2026-02-14T13:01:56.2983970Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.2984070Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.2984152Z                 conn.autocommit = True
2026-02-14T13:01:56.2984223Z                 try:
2026-02-14T13:01:56.2984302Z                     cur = conn.cursor()
2026-02-14T13:01:56.2984499Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.2984580Z                     if not cur.fetchone():
2026-02-14T13:01:56.2984740Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.2984858Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.2984935Z                     cur.close()
2026-02-14T13:01:56.2985010Z                 finally:
2026-02-14T13:01:56.2985082Z                     conn.close()
2026-02-14T13:01:56.2985153Z                 break  # Success
2026-02-14T13:01:56.2985351Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.2985443Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.2985513Z                     print(
2026-02-14T13:01:56.2985733Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.2985805Z                     )
2026-02-14T13:01:56.2985893Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.2985957Z                 else:
2026-02-14T13:01:56.2986169Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.2986352Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.2986427Z                     pass
2026-02-14T13:01:56.2986550Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.2986629Z                 break  # Already exists
2026-02-14T13:01:56.2986686Z     
2026-02-14T13:01:56.2986904Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.2987094Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.2987225Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.2987284Z     
2026-02-14T13:01:56.2987364Z         close_all_pools()
2026-02-14T13:01:56.2987422Z     
2026-02-14T13:01:56.2987544Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.2987708Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.2987860Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.2987945Z             conn.autocommit = True
2026-02-14T13:01:56.2988024Z             with conn.cursor() as cur:
2026-02-14T13:01:56.2988225Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.2988318Z                 # EXCEPT our current connection
2026-02-14T13:01:56.2988392Z                 cur.execute(
2026-02-14T13:01:56.2988462Z                     """
2026-02-14T13:01:56.2988560Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.2988641Z                     FROM pg_stat_activity
2026-02-14T13:01:56.2988737Z                     WHERE datname = current_database()
2026-02-14T13:01:56.2988835Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.2988989Z                     """
2026-02-14T13:01:56.2989052Z                 )
2026-02-14T13:01:56.2989116Z     
2026-02-14T13:01:56.2989308Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.2989570Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.2989641Z                 try:
2026-02-14T13:01:56.2989758Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.2989834Z                     cur.execute("""
2026-02-14T13:01:56.2989902Z                         DO $$
2026-02-14T13:01:56.2989975Z                         DECLARE
2026-02-14T13:01:56.2990047Z                             r RECORD;
2026-02-14T13:01:56.2990114Z                         BEGIN
2026-02-14T13:01:56.2990191Z                             FOR r IN (
2026-02-14T13:01:56.2990290Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.2990377Z                                 FROM pg_views
2026-02-14T13:01:56.2990511Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2990577Z                             )
2026-02-14T13:01:56.2990647Z                             LOOP
2026-02-14T13:01:56.2990968Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.2991167Z                             END LOOP;
2026-02-14T13:01:56.2991238Z                         END $$;
2026-02-14T13:01:56.2991302Z                     """)
2026-02-14T13:01:56.2991379Z                     # Drop tables
2026-02-14T13:01:56.2991452Z                     cur.execute("""
2026-02-14T13:01:56.2991518Z                         DO $$
2026-02-14T13:01:56.2991589Z                         DECLARE
2026-02-14T13:01:56.2991659Z                             r RECORD;
2026-02-14T13:01:56.2991723Z                         BEGIN
2026-02-14T13:01:56.2991799Z                             FOR r IN (
2026-02-14T13:01:56.2991903Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.2991985Z                                 FROM pg_tables
2026-02-14T13:01:56.2992111Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.2992191Z                             )
2026-02-14T13:01:56.2992260Z                             LOOP
2026-02-14T13:01:56.2992573Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.2992651Z                             END LOOP;
2026-02-14T13:01:56.2992717Z                         END $$;
2026-02-14T13:01:56.2992782Z                     """)
2026-02-14T13:01:56.2992867Z                 except psycopg2.Error:
2026-02-14T13:01:56.2993045Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.2993113Z                     pass
2026-02-14T13:01:56.2993179Z     
2026-02-14T13:01:56.2993354Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.2993465Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.2993549Z                 if init_dir.exists():
2026-02-14T13:01:56.2993654Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.2993752Z                     for script_path in scripts:
2026-02-14T13:01:56.2993880Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.2993957Z                             sql = f.read()
2026-02-14T13:01:56.2994167Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.2994299Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.2994378Z                             statements = []
2026-02-14T13:01:56.2994441Z     
2026-02-14T13:01:56.2994736Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.2994816Z                             do_blocks = []
2026-02-14T13:01:56.2994922Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.2995086Z     
2026-02-14T13:01:56.2995184Z                             def replace_do_block(match):
2026-02-14T13:01:56.2995276Z                                 block = match.group(0)
2026-02-14T13:01:56.2995410Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.2995505Z                                 do_blocks.append(block)
2026-02-14T13:01:56.2995594Z                                 return placeholder
2026-02-14T13:01:56.2995657Z     
2026-02-14T13:01:56.2995767Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.2995868Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.2995959Z                                                     ^^
2026-02-14T13:01:56.2996148Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.2996215Z                             )
2026-02-14T13:01:56.2996322Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.2996338Z 
2026-02-14T13:01:56.2996439Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.2996635Z ____ ERROR at setup of TestDocumentRoutes.test_upload_resume_route_success _____
2026-02-14T13:01:56.2996640Z 
2026-02-14T13:01:56.2996927Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.2996933Z 
2026-02-14T13:01:56.2997020Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.2997133Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.2997193Z         """
2026-02-14T13:01:56.2997327Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.2997399Z     
2026-02-14T13:01:56.2997538Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.2997664Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.2997729Z         """
2026-02-14T13:01:56.2997829Z         # Read schema and table creation scripts
2026-02-14T13:01:56.2997961Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.2998020Z     
2026-02-14T13:01:56.2998133Z         # Parse connection string to get database name
2026-02-14T13:01:56.2998378Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.2998438Z     
2026-02-14T13:01:56.2998631Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.2998857Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.2998916Z     
2026-02-14T13:01:56.2999059Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.2999180Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.2999257Z         if len(parts) >= 4:
2026-02-14T13:01:56.2999377Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.2999447Z         else:
2026-02-14T13:01:56.2999554Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.2999613Z     
2026-02-14T13:01:56.2999714Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.2999941Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3000008Z         import time
2026-02-14T13:01:56.3000070Z     
2026-02-14T13:01:56.3000145Z         max_retries = 5
2026-02-14T13:01:56.3000214Z         retry_delay = 2
2026-02-14T13:01:56.3000271Z     
2026-02-14T13:01:56.3000362Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3000425Z             try:
2026-02-14T13:01:56.3000523Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3000705Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3000794Z                 conn.autocommit = True
2026-02-14T13:01:56.3000858Z                 try:
2026-02-14T13:01:56.3000937Z                     cur = conn.cursor()
2026-02-14T13:01:56.3001317Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3001399Z                     if not cur.fetchone():
2026-02-14T13:01:56.3001555Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3001676Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3001746Z                     cur.close()
2026-02-14T13:01:56.3001813Z                 finally:
2026-02-14T13:01:56.3001883Z                     conn.close()
2026-02-14T13:01:56.3001960Z                 break  # Success
2026-02-14T13:01:56.3002148Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3002245Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3002320Z                     print(
2026-02-14T13:01:56.3002535Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3002605Z                     )
2026-02-14T13:01:56.3002696Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3002764Z                 else:
2026-02-14T13:01:56.3002966Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3003149Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3003222Z                     pass
2026-02-14T13:01:56.3003337Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3003415Z                 break  # Already exists
2026-02-14T13:01:56.3003478Z     
2026-02-14T13:01:56.3003695Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3003881Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3004019Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3004077Z     
2026-02-14T13:01:56.3004155Z         close_all_pools()
2026-02-14T13:01:56.3004213Z     
2026-02-14T13:01:56.3004340Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3004504Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3004643Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3004732Z             conn.autocommit = True
2026-02-14T13:01:56.3004811Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3005002Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3005099Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3005171Z                 cur.execute(
2026-02-14T13:01:56.3005243Z                     """
2026-02-14T13:01:56.3005341Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3005428Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3005522Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3005616Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3005689Z                     """
2026-02-14T13:01:56.3005750Z                 )
2026-02-14T13:01:56.3005808Z     
2026-02-14T13:01:56.3005997Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3006188Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3006254Z                 try:
2026-02-14T13:01:56.3006371Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3006452Z                     cur.execute("""
2026-02-14T13:01:56.3006522Z                         DO $$
2026-02-14T13:01:56.3006705Z                         DECLARE
2026-02-14T13:01:56.3006788Z                             r RECORD;
2026-02-14T13:01:56.3006855Z                         BEGIN
2026-02-14T13:01:56.3006929Z                             FOR r IN (
2026-02-14T13:01:56.3007029Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3007223Z                                 FROM pg_views
2026-02-14T13:01:56.3007352Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3007419Z                             )
2026-02-14T13:01:56.3007495Z                             LOOP
2026-02-14T13:01:56.3007805Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3007879Z                             END LOOP;
2026-02-14T13:01:56.3007955Z                         END $$;
2026-02-14T13:01:56.3008019Z                     """)
2026-02-14T13:01:56.3008092Z                     # Drop tables
2026-02-14T13:01:56.3008169Z                     cur.execute("""
2026-02-14T13:01:56.3008246Z                         DO $$
2026-02-14T13:01:56.3008313Z                         DECLARE
2026-02-14T13:01:56.3008384Z                             r RECORD;
2026-02-14T13:01:56.3008463Z                         BEGIN
2026-02-14T13:01:56.3008536Z                             FOR r IN (
2026-02-14T13:01:56.3008634Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3008720Z                                 FROM pg_tables
2026-02-14T13:01:56.3008852Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3008918Z                             )
2026-02-14T13:01:56.3008988Z                             LOOP
2026-02-14T13:01:56.3009311Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3009384Z                             END LOOP;
2026-02-14T13:01:56.3009456Z                         END $$;
2026-02-14T13:01:56.3009528Z                     """)
2026-02-14T13:01:56.3009612Z                 except psycopg2.Error:
2026-02-14T13:01:56.3009783Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3009861Z                     pass
2026-02-14T13:01:56.3009919Z     
2026-02-14T13:01:56.3010090Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3010199Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3010284Z                 if init_dir.exists():
2026-02-14T13:01:56.3010387Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3010479Z                     for script_path in scripts:
2026-02-14T13:01:56.3010611Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3010689Z                             sql = f.read()
2026-02-14T13:01:56.3010894Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3011240Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3011376Z                             statements = []
2026-02-14T13:01:56.3011442Z     
2026-02-14T13:01:56.3011620Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3011701Z                             do_blocks = []
2026-02-14T13:01:56.3011802Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3011861Z     
2026-02-14T13:01:56.3011962Z                             def replace_do_block(match):
2026-02-14T13:01:56.3012053Z                                 block = match.group(0)
2026-02-14T13:01:56.3012178Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3012281Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3012489Z                                 return placeholder
2026-02-14T13:01:56.3012550Z     
2026-02-14T13:01:56.3012661Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3012765Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3012957Z                                                     ^^
2026-02-14T13:01:56.3013145Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3013222Z                             )
2026-02-14T13:01:56.3013329Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3013335Z 
2026-02-14T13:01:56.3013436Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3013638Z ___ ERROR at setup of TestDocumentRoutes.test_download_resume_route_success ____
2026-02-14T13:01:56.3013643Z 
2026-02-14T13:01:56.3013928Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3013933Z 
2026-02-14T13:01:56.3014025Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3014129Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3014190Z         """
2026-02-14T13:01:56.3014330Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3014397Z     
2026-02-14T13:01:56.3014529Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3014659Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3014720Z         """
2026-02-14T13:01:56.3014814Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3014946Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3015004Z     
2026-02-14T13:01:56.3015112Z         # Parse connection string to get database name
2026-02-14T13:01:56.3015354Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3015418Z     
2026-02-14T13:01:56.3015608Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3015834Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3015897Z     
2026-02-14T13:01:56.3016041Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3016152Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3016232Z         if len(parts) >= 4:
2026-02-14T13:01:56.3016350Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3016414Z         else:
2026-02-14T13:01:56.3016514Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3016578Z     
2026-02-14T13:01:56.3016672Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3016899Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3016971Z         import time
2026-02-14T13:01:56.3017031Z     
2026-02-14T13:01:56.3017105Z         max_retries = 5
2026-02-14T13:01:56.3017174Z         retry_delay = 2
2026-02-14T13:01:56.3017238Z     
2026-02-14T13:01:56.3017326Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3017388Z             try:
2026-02-14T13:01:56.3017499Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3017592Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3017672Z                 conn.autocommit = True
2026-02-14T13:01:56.3017746Z                 try:
2026-02-14T13:01:56.3017824Z                     cur = conn.cursor()
2026-02-14T13:01:56.3018012Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3018091Z                     if not cur.fetchone():
2026-02-14T13:01:56.3018246Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3018365Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3018565Z                     cur.close()
2026-02-14T13:01:56.3018645Z                 finally:
2026-02-14T13:01:56.3018718Z                     conn.close()
2026-02-14T13:01:56.3018789Z                 break  # Success
2026-02-14T13:01:56.3018983Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3019150Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3019220Z                     print(
2026-02-14T13:01:56.3019436Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3019509Z                     )
2026-02-14T13:01:56.3019596Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3019661Z                 else:
2026-02-14T13:01:56.3019872Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3020053Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3020125Z                     pass
2026-02-14T13:01:56.3020246Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3020324Z                 break  # Already exists
2026-02-14T13:01:56.3020384Z     
2026-02-14T13:01:56.3020598Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3020791Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3020922Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3020980Z     
2026-02-14T13:01:56.3021189Z         close_all_pools()
2026-02-14T13:01:56.3021251Z     
2026-02-14T13:01:56.3021374Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3021547Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3021691Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3021774Z             conn.autocommit = True
2026-02-14T13:01:56.3021860Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3022060Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3022152Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3022231Z                 cur.execute(
2026-02-14T13:01:56.3022302Z                     """
2026-02-14T13:01:56.3022400Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3022480Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3022580Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3022668Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3022732Z                     """
2026-02-14T13:01:56.3022793Z                 )
2026-02-14T13:01:56.3022856Z     
2026-02-14T13:01:56.3023044Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3023229Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3023299Z                 try:
2026-02-14T13:01:56.3023414Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3023491Z                     cur.execute("""
2026-02-14T13:01:56.3023565Z                         DO $$
2026-02-14T13:01:56.3023638Z                         DECLARE
2026-02-14T13:01:56.3023710Z                             r RECORD;
2026-02-14T13:01:56.3023776Z                         BEGIN
2026-02-14T13:01:56.3023855Z                             FOR r IN (
2026-02-14T13:01:56.3023956Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3024038Z                                 FROM pg_views
2026-02-14T13:01:56.3024170Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3024236Z                             )
2026-02-14T13:01:56.3024305Z                             LOOP
2026-02-14T13:01:56.3024737Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3024819Z                             END LOOP;
2026-02-14T13:01:56.3024888Z                         END $$;
2026-02-14T13:01:56.3024954Z                     """)
2026-02-14T13:01:56.3025139Z                     # Drop tables
2026-02-14T13:01:56.3025213Z                     cur.execute("""
2026-02-14T13:01:56.3025278Z                         DO $$
2026-02-14T13:01:56.3025349Z                         DECLARE
2026-02-14T13:01:56.3025419Z                             r RECORD;
2026-02-14T13:01:56.3025484Z                         BEGIN
2026-02-14T13:01:56.3025556Z                             FOR r IN (
2026-02-14T13:01:56.3025661Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3025744Z                                 FROM pg_tables
2026-02-14T13:01:56.3025869Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3025948Z                             )
2026-02-14T13:01:56.3026016Z                             LOOP
2026-02-14T13:01:56.3026330Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3026412Z                             END LOOP;
2026-02-14T13:01:56.3026477Z                         END $$;
2026-02-14T13:01:56.3026543Z                     """)
2026-02-14T13:01:56.3026625Z                 except psycopg2.Error:
2026-02-14T13:01:56.3026803Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3026871Z                     pass
2026-02-14T13:01:56.3026931Z     
2026-02-14T13:01:56.3027104Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3027214Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3027290Z                 if init_dir.exists():
2026-02-14T13:01:56.3027405Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3027496Z                     for script_path in scripts:
2026-02-14T13:01:56.3027622Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3027704Z                             sql = f.read()
2026-02-14T13:01:56.3027916Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3028047Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3028128Z                             statements = []
2026-02-14T13:01:56.3028192Z     
2026-02-14T13:01:56.3028370Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3028445Z                             do_blocks = []
2026-02-14T13:01:56.3028554Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3028614Z     
2026-02-14T13:01:56.3028716Z                             def replace_do_block(match):
2026-02-14T13:01:56.3028807Z                                 block = match.group(0)
2026-02-14T13:01:56.3028938Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3029035Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3029127Z                                 return placeholder
2026-02-14T13:01:56.3029191Z     
2026-02-14T13:01:56.3029301Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3029399Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3029486Z                                                     ^^
2026-02-14T13:01:56.3029673Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3029739Z                             )
2026-02-14T13:01:56.3029844Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3029858Z 
2026-02-14T13:01:56.3030046Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3030250Z _ ERROR at setup of TestDocumentRoutes.test_download_cover_letter_inline_text __
2026-02-14T13:01:56.3030254Z 
2026-02-14T13:01:56.3030540Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3030632Z 
2026-02-14T13:01:56.3030722Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3030832Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3030894Z         """
2026-02-14T13:01:56.3031151Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3031218Z     
2026-02-14T13:01:56.3031353Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3031482Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3031542Z         """
2026-02-14T13:01:56.3031644Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3031769Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3031833Z     
2026-02-14T13:01:56.3031945Z         # Parse connection string to get database name
2026-02-14T13:01:56.3032187Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3032251Z     
2026-02-14T13:01:56.3032440Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3032670Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3032731Z     
2026-02-14T13:01:56.3032873Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3032992Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3033066Z         if len(parts) >= 4:
2026-02-14T13:01:56.3033185Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3033254Z         else:
2026-02-14T13:01:56.3033380Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3033443Z     
2026-02-14T13:01:56.3033544Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3033790Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3033864Z         import time
2026-02-14T13:01:56.3033921Z     
2026-02-14T13:01:56.3033996Z         max_retries = 5
2026-02-14T13:01:56.3034063Z         retry_delay = 2
2026-02-14T13:01:56.3034120Z     
2026-02-14T13:01:56.3034212Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3034275Z             try:
2026-02-14T13:01:56.3034376Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3034472Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3034557Z                 conn.autocommit = True
2026-02-14T13:01:56.3034621Z                 try:
2026-02-14T13:01:56.3034699Z                     cur = conn.cursor()
2026-02-14T13:01:56.3034897Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3034979Z                     if not cur.fetchone():
2026-02-14T13:01:56.3035130Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3035251Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3035327Z                     cur.close()
2026-02-14T13:01:56.3035394Z                 finally:
2026-02-14T13:01:56.3035465Z                     conn.close()
2026-02-14T13:01:56.3035542Z                 break  # Success
2026-02-14T13:01:56.3035731Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3035822Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3035897Z                     print(
2026-02-14T13:01:56.3036113Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3036178Z                     )
2026-02-14T13:01:56.3036410Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3036477Z                 else:
2026-02-14T13:01:56.3036679Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3036859Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3037033Z                     pass
2026-02-14T13:01:56.3037147Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3037224Z                 break  # Already exists
2026-02-14T13:01:56.3037288Z     
2026-02-14T13:01:56.3037503Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3037683Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3037821Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3037878Z     
2026-02-14T13:01:56.3037951Z         close_all_pools()
2026-02-14T13:01:56.3038009Z     
2026-02-14T13:01:56.3038134Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3038301Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3038441Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3038534Z             conn.autocommit = True
2026-02-14T13:01:56.3038613Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3038807Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3038904Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3038977Z                 cur.execute(
2026-02-14T13:01:56.3039043Z                     """
2026-02-14T13:01:56.3039141Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3039227Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3039320Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3039409Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3039483Z                     """
2026-02-14T13:01:56.3039545Z                 )
2026-02-14T13:01:56.3039603Z     
2026-02-14T13:01:56.3039792Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3039989Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3040055Z                 try:
2026-02-14T13:01:56.3040174Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3040255Z                     cur.execute("""
2026-02-14T13:01:56.3040327Z                         DO $$
2026-02-14T13:01:56.3040396Z                         DECLARE
2026-02-14T13:01:56.3040473Z                             r RECORD;
2026-02-14T13:01:56.3040540Z                         BEGIN
2026-02-14T13:01:56.3040613Z                             FOR r IN (
2026-02-14T13:01:56.3040713Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3040806Z                                 FROM pg_views
2026-02-14T13:01:56.3040936Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3041002Z                             )
2026-02-14T13:01:56.3041222Z                             LOOP
2026-02-14T13:01:56.3041740Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3041876Z                             END LOOP;
2026-02-14T13:01:56.3041995Z                         END $$;
2026-02-14T13:01:56.3042063Z                     """)
2026-02-14T13:01:56.3042138Z                     # Drop tables
2026-02-14T13:01:56.3042213Z                     cur.execute("""
2026-02-14T13:01:56.3042287Z                         DO $$
2026-02-14T13:01:56.3042357Z                         DECLARE
2026-02-14T13:01:56.3042428Z                             r RECORD;
2026-02-14T13:01:56.3042503Z                         BEGIN
2026-02-14T13:01:56.3042740Z                             FOR r IN (
2026-02-14T13:01:56.3042846Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3042939Z                                 FROM pg_tables
2026-02-14T13:01:56.3043065Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3043237Z                             )
2026-02-14T13:01:56.3043310Z                             LOOP
2026-02-14T13:01:56.3043630Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3043704Z                             END LOOP;
2026-02-14T13:01:56.3043772Z                         END $$;
2026-02-14T13:01:56.3043844Z                     """)
2026-02-14T13:01:56.3043928Z                 except psycopg2.Error:
2026-02-14T13:01:56.3044101Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3044178Z                     pass
2026-02-14T13:01:56.3044239Z     
2026-02-14T13:01:56.3044409Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3044519Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3044606Z                 if init_dir.exists():
2026-02-14T13:01:56.3044709Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3044798Z                     for script_path in scripts:
2026-02-14T13:01:56.3044926Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3045002Z                             sql = f.read()
2026-02-14T13:01:56.3045205Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3045340Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3045418Z                             statements = []
2026-02-14T13:01:56.3045476Z     
2026-02-14T13:01:56.3045655Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3045738Z                             do_blocks = []
2026-02-14T13:01:56.3045836Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3045898Z     
2026-02-14T13:01:56.3046001Z                             def replace_do_block(match):
2026-02-14T13:01:56.3046090Z                                 block = match.group(0)
2026-02-14T13:01:56.3046215Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3046315Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3046401Z                                 return placeholder
2026-02-14T13:01:56.3046459Z     
2026-02-14T13:01:56.3046569Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3046672Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3046753Z                                                     ^^
2026-02-14T13:01:56.3046942Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3047016Z                             )
2026-02-14T13:01:56.3047126Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3047136Z 
2026-02-14T13:01:56.3047236Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3047440Z __ ERROR at setup of TestDocumentRoutes.test_download_cover_letter_text_based __
2026-02-14T13:01:56.3047445Z 
2026-02-14T13:01:56.3047828Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3047835Z 
2026-02-14T13:01:56.3047927Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3048032Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3048093Z         """
2026-02-14T13:01:56.3048234Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3048293Z     
2026-02-14T13:01:56.3048521Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3048659Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3048718Z         """
2026-02-14T13:01:56.3048812Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3049022Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3049080Z     
2026-02-14T13:01:56.3049184Z         # Parse connection string to get database name
2026-02-14T13:01:56.3049424Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3049489Z     
2026-02-14T13:01:56.3049674Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3049902Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3049966Z     
2026-02-14T13:01:56.3050109Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3050222Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3050302Z         if len(parts) >= 4:
2026-02-14T13:01:56.3050420Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3050482Z         else:
2026-02-14T13:01:56.3050589Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3050654Z     
2026-02-14T13:01:56.3050749Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3050976Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3051303Z         import time
2026-02-14T13:01:56.3051403Z     
2026-02-14T13:01:56.3051480Z         max_retries = 5
2026-02-14T13:01:56.3051557Z         retry_delay = 2
2026-02-14T13:01:56.3051617Z     
2026-02-14T13:01:56.3051704Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3051768Z             try:
2026-02-14T13:01:56.3051881Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3051982Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3052065Z                 conn.autocommit = True
2026-02-14T13:01:56.3052135Z                 try:
2026-02-14T13:01:56.3052213Z                     cur = conn.cursor()
2026-02-14T13:01:56.3052410Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3052491Z                     if not cur.fetchone():
2026-02-14T13:01:56.3052650Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3052767Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3052839Z                     cur.close()
2026-02-14T13:01:56.3052913Z                 finally:
2026-02-14T13:01:56.3052985Z                     conn.close()
2026-02-14T13:01:56.3053055Z                 break  # Success
2026-02-14T13:01:56.3053252Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3053349Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3053420Z                     print(
2026-02-14T13:01:56.3053637Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3053711Z                     )
2026-02-14T13:01:56.3053795Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3053861Z                 else:
2026-02-14T13:01:56.3054074Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3054257Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3054327Z                     pass
2026-02-14T13:01:56.3054449Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3054529Z                 break  # Already exists
2026-02-14T13:01:56.3054587Z     
2026-02-14T13:01:56.3054809Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3055146Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3055286Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3055345Z     
2026-02-14T13:01:56.3055426Z         close_all_pools()
2026-02-14T13:01:56.3055587Z     
2026-02-14T13:01:56.3055706Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3055879Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3056022Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3056103Z             conn.autocommit = True
2026-02-14T13:01:56.3056186Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3056386Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3056477Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3056550Z                 cur.execute(
2026-02-14T13:01:56.3056630Z                     """
2026-02-14T13:01:56.3056726Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3056806Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3056906Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3057001Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3057065Z                     """
2026-02-14T13:01:56.3057124Z                 )
2026-02-14T13:01:56.3057186Z     
2026-02-14T13:01:56.3057408Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3057592Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3057662Z                 try:
2026-02-14T13:01:56.3057779Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3057853Z                     cur.execute("""
2026-02-14T13:01:56.3057921Z                         DO $$
2026-02-14T13:01:56.3057997Z                         DECLARE
2026-02-14T13:01:56.3058069Z                             r RECORD;
2026-02-14T13:01:56.3058138Z                         BEGIN
2026-02-14T13:01:56.3058216Z                             FOR r IN (
2026-02-14T13:01:56.3058328Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3058414Z                                 FROM pg_views
2026-02-14T13:01:56.3058550Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3058614Z                             )
2026-02-14T13:01:56.3058683Z                             LOOP
2026-02-14T13:01:56.3059000Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3059078Z                             END LOOP;
2026-02-14T13:01:56.3059146Z                         END $$;
2026-02-14T13:01:56.3059213Z                     """)
2026-02-14T13:01:56.3059290Z                     # Drop tables
2026-02-14T13:01:56.3059366Z                     cur.execute("""
2026-02-14T13:01:56.3059433Z                         DO $$
2026-02-14T13:01:56.3059503Z                         DECLARE
2026-02-14T13:01:56.3059574Z                             r RECORD;
2026-02-14T13:01:56.3059647Z                         BEGIN
2026-02-14T13:01:56.3059718Z                             FOR r IN (
2026-02-14T13:01:56.3059825Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3059908Z                                 FROM pg_tables
2026-02-14T13:01:56.3060034Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3060108Z                             )
2026-02-14T13:01:56.3060177Z                             LOOP
2026-02-14T13:01:56.3060491Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3060569Z                             END LOOP;
2026-02-14T13:01:56.3060733Z                         END $$;
2026-02-14T13:01:56.3060801Z                     """)
2026-02-14T13:01:56.3060883Z                 except psycopg2.Error:
2026-02-14T13:01:56.3061304Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3061569Z                     pass
2026-02-14T13:01:56.3061630Z     
2026-02-14T13:01:56.3061820Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3061938Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3062018Z                 if init_dir.exists():
2026-02-14T13:01:56.3062133Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3062226Z                     for script_path in scripts:
2026-02-14T13:01:56.3062356Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3062435Z                             sql = f.read()
2026-02-14T13:01:56.3062658Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3062791Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3062873Z                             statements = []
2026-02-14T13:01:56.3062945Z     
2026-02-14T13:01:56.3063130Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3063207Z                             do_blocks = []
2026-02-14T13:01:56.3063313Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3063371Z     
2026-02-14T13:01:56.3063468Z                             def replace_do_block(match):
2026-02-14T13:01:56.3063559Z                                 block = match.group(0)
2026-02-14T13:01:56.3063695Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3063791Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3063884Z                                 return placeholder
2026-02-14T13:01:56.3063948Z     
2026-02-14T13:01:56.3064058Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3064157Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3064253Z                                                     ^^
2026-02-14T13:01:56.3064439Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3064510Z                             )
2026-02-14T13:01:56.3064617Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3064628Z 
2026-02-14T13:01:56.3064732Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3064926Z ______ ERROR at setup of TestDocumentRoutes.test_link_resume_to_job_route ______
2026-02-14T13:01:56.3064931Z 
2026-02-14T13:01:56.3065278Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3065283Z 
2026-02-14T13:01:56.3065379Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3065491Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3065555Z         """
2026-02-14T13:01:56.3065690Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3065759Z     
2026-02-14T13:01:56.3065891Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3066017Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3066078Z         """
2026-02-14T13:01:56.3066180Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3066307Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3066366Z     
2026-02-14T13:01:56.3066481Z         # Parse connection string to get database name
2026-02-14T13:01:56.3066727Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3066785Z     
2026-02-14T13:01:56.3067092Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3067321Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3067379Z     
2026-02-14T13:01:56.3067525Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3067722Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3067798Z         if len(parts) >= 4:
2026-02-14T13:01:56.3067916Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3067984Z         else:
2026-02-14T13:01:56.3068083Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3068140Z     
2026-02-14T13:01:56.3068242Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3068467Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3068533Z         import time
2026-02-14T13:01:56.3068591Z     
2026-02-14T13:01:56.3068670Z         max_retries = 5
2026-02-14T13:01:56.3068739Z         retry_delay = 2
2026-02-14T13:01:56.3068796Z     
2026-02-14T13:01:56.3068887Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3068949Z             try:
2026-02-14T13:01:56.3069054Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3069148Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3069235Z                 conn.autocommit = True
2026-02-14T13:01:56.3069299Z                 try:
2026-02-14T13:01:56.3069376Z                     cur = conn.cursor()
2026-02-14T13:01:56.3069569Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3069648Z                     if not cur.fetchone():
2026-02-14T13:01:56.3069798Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3069919Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3069995Z                     cur.close()
2026-02-14T13:01:56.3070062Z                 finally:
2026-02-14T13:01:56.3070134Z                     conn.close()
2026-02-14T13:01:56.3070210Z                 break  # Success
2026-02-14T13:01:56.3070399Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3070494Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3070569Z                     print(
2026-02-14T13:01:56.3070785Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3070849Z                     )
2026-02-14T13:01:56.3070938Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3071001Z                 else:
2026-02-14T13:01:56.3071339Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3071521Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3071599Z                     pass
2026-02-14T13:01:56.3071714Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3071791Z                 break  # Already exists
2026-02-14T13:01:56.3071855Z     
2026-02-14T13:01:56.3072070Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3072257Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3072396Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3072455Z     
2026-02-14T13:01:56.3072529Z         close_all_pools()
2026-02-14T13:01:56.3072590Z     
2026-02-14T13:01:56.3072711Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3072875Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3073016Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3073106Z             conn.autocommit = True
2026-02-14T13:01:56.3073321Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3073520Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3073617Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3073793Z                 cur.execute(
2026-02-14T13:01:56.3073859Z                     """
2026-02-14T13:01:56.3073957Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3074044Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3074139Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3074230Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3074300Z                     """
2026-02-14T13:01:56.3074362Z                 )
2026-02-14T13:01:56.3074420Z     
2026-02-14T13:01:56.3074606Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3074806Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3074873Z                 try:
2026-02-14T13:01:56.3074989Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3075071Z                     cur.execute("""
2026-02-14T13:01:56.3075146Z                         DO $$
2026-02-14T13:01:56.3075214Z                         DECLARE
2026-02-14T13:01:56.3075296Z                             r RECORD;
2026-02-14T13:01:56.3075363Z                         BEGIN
2026-02-14T13:01:56.3075434Z                             FOR r IN (
2026-02-14T13:01:56.3075535Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3075626Z                                 FROM pg_views
2026-02-14T13:01:56.3075755Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3075822Z                             )
2026-02-14T13:01:56.3075902Z                             LOOP
2026-02-14T13:01:56.3076218Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3076290Z                             END LOOP;
2026-02-14T13:01:56.3076362Z                         END $$;
2026-02-14T13:01:56.3076430Z                     """)
2026-02-14T13:01:56.3076508Z                     # Drop tables
2026-02-14T13:01:56.3076585Z                     cur.execute("""
2026-02-14T13:01:56.3076660Z                         DO $$
2026-02-14T13:01:56.3076728Z                         DECLARE
2026-02-14T13:01:56.3076845Z                             r RECORD;
2026-02-14T13:01:56.3076919Z                         BEGIN
2026-02-14T13:01:56.3076990Z                             FOR r IN (
2026-02-14T13:01:56.3077091Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3077180Z                                 FROM pg_tables
2026-02-14T13:01:56.3077305Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3077381Z                             )
2026-02-14T13:01:56.3077450Z                             LOOP
2026-02-14T13:01:56.3077768Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3077844Z                             END LOOP;
2026-02-14T13:01:56.3077911Z                         END $$;
2026-02-14T13:01:56.3077982Z                     """)
2026-02-14T13:01:56.3078065Z                 except psycopg2.Error:
2026-02-14T13:01:56.3078236Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3078308Z                     pass
2026-02-14T13:01:56.3078364Z     
2026-02-14T13:01:56.3078534Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3078642Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3078724Z                 if init_dir.exists():
2026-02-14T13:01:56.3078919Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3079012Z                     for script_path in scripts:
2026-02-14T13:01:56.3079140Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3079217Z                             sql = f.read()
2026-02-14T13:01:56.3079500Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3079635Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3079714Z                             statements = []
2026-02-14T13:01:56.3079772Z     
2026-02-14T13:01:56.3079946Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3080025Z                             do_blocks = []
2026-02-14T13:01:56.3080127Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3080184Z     
2026-02-14T13:01:56.3080289Z                             def replace_do_block(match):
2026-02-14T13:01:56.3080382Z                                 block = match.group(0)
2026-02-14T13:01:56.3080510Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3080615Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3080710Z                                 return placeholder
2026-02-14T13:01:56.3080768Z     
2026-02-14T13:01:56.3080878Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3081203Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3081333Z                                                     ^^
2026-02-14T13:01:56.3081593Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3081669Z                             )
2026-02-14T13:01:56.3081779Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3081785Z 
2026-02-14T13:01:56.3081894Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3082106Z _ ERROR at setup of TestDocumentRoutes.test_update_application_documents_route _
2026-02-14T13:01:56.3082110Z 
2026-02-14T13:01:56.3082415Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3082429Z 
2026-02-14T13:01:56.3082517Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3082621Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3082689Z         """
2026-02-14T13:01:56.3082825Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3082883Z     
2026-02-14T13:01:56.3083014Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3083148Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3083210Z         """
2026-02-14T13:01:56.3083305Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3083435Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3083497Z     
2026-02-14T13:01:56.3083602Z         # Parse connection string to get database name
2026-02-14T13:01:56.3083847Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3083916Z     
2026-02-14T13:01:56.3084102Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3084331Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3084394Z     
2026-02-14T13:01:56.3084536Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3084646Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3084730Z         if len(parts) >= 4:
2026-02-14T13:01:56.3084851Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3084912Z         else:
2026-02-14T13:01:56.3085012Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3085218Z     
2026-02-14T13:01:56.3085320Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3085546Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3085722Z         import time
2026-02-14T13:01:56.3085781Z     
2026-02-14T13:01:56.3085850Z         max_retries = 5
2026-02-14T13:01:56.3085927Z         retry_delay = 2
2026-02-14T13:01:56.3085985Z     
2026-02-14T13:01:56.3086072Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3086134Z             try:
2026-02-14T13:01:56.3086238Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3086333Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3086413Z                 conn.autocommit = True
2026-02-14T13:01:56.3086489Z                 try:
2026-02-14T13:01:56.3090606Z                     cur = conn.cursor()
2026-02-14T13:01:56.3090874Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3090971Z                     if not cur.fetchone():
2026-02-14T13:01:56.3091469Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3091687Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3091778Z                     cur.close()
2026-02-14T13:01:56.3091902Z                 finally:
2026-02-14T13:01:56.3092038Z                     conn.close()
2026-02-14T13:01:56.3092156Z                 break  # Success
2026-02-14T13:01:56.3092485Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3092645Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3092772Z                     print(
2026-02-14T13:01:56.3093012Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3093090Z                     )
2026-02-14T13:01:56.3093178Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3093250Z                 else:
2026-02-14T13:01:56.3093485Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3093682Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3093760Z                     pass
2026-02-14T13:01:56.3093889Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3093975Z                 break  # Already exists
2026-02-14T13:01:56.3094036Z     
2026-02-14T13:01:56.3094264Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3094461Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3094596Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3094654Z     
2026-02-14T13:01:56.3094736Z         close_all_pools()
2026-02-14T13:01:56.3094797Z     
2026-02-14T13:01:56.3094922Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3095095Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3095241Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3095325Z             conn.autocommit = True
2026-02-14T13:01:56.3095408Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3095609Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3095704Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3095776Z                 cur.execute(
2026-02-14T13:01:56.3095850Z                     """
2026-02-14T13:01:56.3095951Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3096035Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3096140Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3096232Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3096507Z                     """
2026-02-14T13:01:56.3096575Z                 )
2026-02-14T13:01:56.3096639Z     
2026-02-14T13:01:56.3096840Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3097139Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3097212Z                 try:
2026-02-14T13:01:56.3097331Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3097409Z                     cur.execute("""
2026-02-14T13:01:56.3097478Z                         DO $$
2026-02-14T13:01:56.3097553Z                         DECLARE
2026-02-14T13:01:56.3097626Z                             r RECORD;
2026-02-14T13:01:56.3097695Z                         BEGIN
2026-02-14T13:01:56.3097775Z                             FOR r IN (
2026-02-14T13:01:56.3097878Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3097967Z                                 FROM pg_views
2026-02-14T13:01:56.3098103Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3098169Z                             )
2026-02-14T13:01:56.3098244Z                             LOOP
2026-02-14T13:01:56.3098563Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3098644Z                             END LOOP;
2026-02-14T13:01:56.3098711Z                         END $$;
2026-02-14T13:01:56.3098780Z                     """)
2026-02-14T13:01:56.3098858Z                     # Drop tables
2026-02-14T13:01:56.3098932Z                     cur.execute("""
2026-02-14T13:01:56.3098997Z                         DO $$
2026-02-14T13:01:56.3099070Z                         DECLARE
2026-02-14T13:01:56.3099140Z                             r RECORD;
2026-02-14T13:01:56.3099205Z                         BEGIN
2026-02-14T13:01:56.3099279Z                             FOR r IN (
2026-02-14T13:01:56.3099388Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3099471Z                                 FROM pg_tables
2026-02-14T13:01:56.3099597Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3099676Z                             )
2026-02-14T13:01:56.3099748Z                             LOOP
2026-02-14T13:01:56.3100062Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3100143Z                             END LOOP;
2026-02-14T13:01:56.3100209Z                         END $$;
2026-02-14T13:01:56.3100274Z                     """)
2026-02-14T13:01:56.3100360Z                 except psycopg2.Error:
2026-02-14T13:01:56.3100543Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3100611Z                     pass
2026-02-14T13:01:56.3100675Z     
2026-02-14T13:01:56.3100852Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3100996Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3101367Z                 if init_dir.exists():
2026-02-14T13:01:56.3101492Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3101585Z                     for script_path in scripts:
2026-02-14T13:01:56.3101713Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3101792Z                             sql = f.read()
2026-02-14T13:01:56.3102014Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3102144Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3102224Z                             statements = []
2026-02-14T13:01:56.3102290Z     
2026-02-14T13:01:56.3102608Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3102694Z                             do_blocks = []
2026-02-14T13:01:56.3102805Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3102967Z     
2026-02-14T13:01:56.3103070Z                             def replace_do_block(match):
2026-02-14T13:01:56.3103165Z                                 block = match.group(0)
2026-02-14T13:01:56.3103303Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3103401Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3103491Z                                 return placeholder
2026-02-14T13:01:56.3103560Z     
2026-02-14T13:01:56.3103670Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3103773Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3103866Z                                                     ^^
2026-02-14T13:01:56.3104061Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3104131Z                             )
2026-02-14T13:01:56.3104270Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3104292Z 
2026-02-14T13:01:56.3104396Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3104589Z ________ ERROR at setup of TestDocumentRoutes.test_get_user_resumes_api ________
2026-02-14T13:01:56.3104593Z 
2026-02-14T13:01:56.3104929Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3104934Z 
2026-02-14T13:01:56.3105029Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3105147Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3105209Z         """
2026-02-14T13:01:56.3105352Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3105416Z     
2026-02-14T13:01:56.3105557Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3105687Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3105748Z         """
2026-02-14T13:01:56.3105850Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3105979Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3106041Z     
2026-02-14T13:01:56.3106156Z         # Parse connection string to get database name
2026-02-14T13:01:56.3106403Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3106463Z     
2026-02-14T13:01:56.3106655Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3106884Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3106943Z     
2026-02-14T13:01:56.3107086Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3107208Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3107286Z         if len(parts) >= 4:
2026-02-14T13:01:56.3107406Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3107478Z         else:
2026-02-14T13:01:56.3107585Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3107644Z     
2026-02-14T13:01:56.3107745Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3107973Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3108038Z         import time
2026-02-14T13:01:56.3108096Z     
2026-02-14T13:01:56.3108171Z         max_retries = 5
2026-02-14T13:01:56.3108238Z         retry_delay = 2
2026-02-14T13:01:56.3108296Z     
2026-02-14T13:01:56.3108391Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3108456Z             try:
2026-02-14T13:01:56.3108561Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3108750Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3108845Z                 conn.autocommit = True
2026-02-14T13:01:56.3108908Z                 try:
2026-02-14T13:01:56.3108986Z                     cur = conn.cursor()
2026-02-14T13:01:56.3109264Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3109343Z                     if not cur.fetchone():
2026-02-14T13:01:56.3109495Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3109617Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3109689Z                     cur.close()
2026-02-14T13:01:56.3109756Z                 finally:
2026-02-14T13:01:56.3109829Z                     conn.close()
2026-02-14T13:01:56.3109907Z                 break  # Success
2026-02-14T13:01:56.3110099Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3110193Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3110270Z                     print(
2026-02-14T13:01:56.3110487Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3110553Z                     )
2026-02-14T13:01:56.3110648Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3110716Z                 else:
2026-02-14T13:01:56.3110917Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3111252Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3111333Z                     pass
2026-02-14T13:01:56.3111451Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3111528Z                 break  # Already exists
2026-02-14T13:01:56.3111594Z     
2026-02-14T13:01:56.3111810Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3111996Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3112135Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3112193Z     
2026-02-14T13:01:56.3112265Z         close_all_pools()
2026-02-14T13:01:56.3112327Z     
2026-02-14T13:01:56.3112452Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3112616Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3112757Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3112844Z             conn.autocommit = True
2026-02-14T13:01:56.3112930Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3113122Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3113219Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3113292Z                 cur.execute(
2026-02-14T13:01:56.3113362Z                     """
2026-02-14T13:01:56.3113461Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3113545Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3113640Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3113733Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3113803Z                     """
2026-02-14T13:01:56.3113865Z                 )
2026-02-14T13:01:56.3113922Z     
2026-02-14T13:01:56.3114111Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3114302Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3114369Z                 try:
2026-02-14T13:01:56.3114485Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3114567Z                     cur.execute("""
2026-02-14T13:01:56.3114638Z                         DO $$
2026-02-14T13:01:56.3114827Z                         DECLARE
2026-02-14T13:01:56.3114916Z                             r RECORD;
2026-02-14T13:01:56.3114983Z                         BEGIN
2026-02-14T13:01:56.3115056Z                             FOR r IN (
2026-02-14T13:01:56.3115159Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3115393Z                                 FROM pg_views
2026-02-14T13:01:56.3115523Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3115589Z                             )
2026-02-14T13:01:56.3115667Z                             LOOP
2026-02-14T13:01:56.3115980Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3116055Z                             END LOOP;
2026-02-14T13:01:56.3116131Z                         END $$;
2026-02-14T13:01:56.3116197Z                     """)
2026-02-14T13:01:56.3116269Z                     # Drop tables
2026-02-14T13:01:56.3116347Z                     cur.execute("""
2026-02-14T13:01:56.3116423Z                         DO $$
2026-02-14T13:01:56.3116490Z                         DECLARE
2026-02-14T13:01:56.3116561Z                             r RECORD;
2026-02-14T13:01:56.3116639Z                         BEGIN
2026-02-14T13:01:56.3116711Z                             FOR r IN (
2026-02-14T13:01:56.3116817Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3116906Z                                 FROM pg_tables
2026-02-14T13:01:56.3117032Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3117098Z                             )
2026-02-14T13:01:56.3117165Z                             LOOP
2026-02-14T13:01:56.3117490Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3117560Z                             END LOOP;
2026-02-14T13:01:56.3117629Z                         END $$;
2026-02-14T13:01:56.3117702Z                     """)
2026-02-14T13:01:56.3117787Z                 except psycopg2.Error:
2026-02-14T13:01:56.3117960Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3118039Z                     pass
2026-02-14T13:01:56.3118098Z     
2026-02-14T13:01:56.3118267Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3118381Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3118461Z                 if init_dir.exists():
2026-02-14T13:01:56.3118565Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3118661Z                     for script_path in scripts:
2026-02-14T13:01:56.3118789Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3118866Z                             sql = f.read()
2026-02-14T13:01:56.3119082Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3119214Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3119292Z                             statements = []
2026-02-14T13:01:56.3119354Z     
2026-02-14T13:01:56.3119533Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3119608Z                             do_blocks = []
2026-02-14T13:01:56.3119709Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3119772Z     
2026-02-14T13:01:56.3119870Z                             def replace_do_block(match):
2026-02-14T13:01:56.3119958Z                                 block = match.group(0)
2026-02-14T13:01:56.3120091Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3120188Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3120362Z                                 return placeholder
2026-02-14T13:01:56.3120425Z     
2026-02-14T13:01:56.3120540Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3120639Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3120799Z                                                     ^^
2026-02-14T13:01:56.3120990Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3121190Z                             )
2026-02-14T13:01:56.3121305Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3121311Z 
2026-02-14T13:01:56.3121420Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3121617Z _____ ERROR at setup of TestDocumentRoutes.test_get_user_cover_letters_api _____
2026-02-14T13:01:56.3121622Z 
2026-02-14T13:01:56.3121913Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3121919Z 
2026-02-14T13:01:56.3122015Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3122122Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3122195Z         """
2026-02-14T13:01:56.3122337Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3122405Z     
2026-02-14T13:01:56.3122549Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3122675Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3122736Z         """
2026-02-14T13:01:56.3122837Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3122964Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3123023Z     
2026-02-14T13:01:56.3123131Z         # Parse connection string to get database name
2026-02-14T13:01:56.3123381Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3123440Z     
2026-02-14T13:01:56.3123628Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3123861Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3123918Z     
2026-02-14T13:01:56.3124063Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3124182Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3124257Z         if len(parts) >= 4:
2026-02-14T13:01:56.3124376Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3124439Z         else:
2026-02-14T13:01:56.3124548Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3124606Z     
2026-02-14T13:01:56.3124700Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3124934Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3125002Z         import time
2026-02-14T13:01:56.3125060Z     
2026-02-14T13:01:56.3125138Z         max_retries = 5
2026-02-14T13:01:56.3125208Z         retry_delay = 2
2026-02-14T13:01:56.3125265Z     
2026-02-14T13:01:56.3125351Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3125420Z             try:
2026-02-14T13:01:56.3125518Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3125616Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3125704Z                 conn.autocommit = True
2026-02-14T13:01:56.3125768Z                 try:
2026-02-14T13:01:56.3125846Z                     cur = conn.cursor()
2026-02-14T13:01:56.3126034Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3126122Z                     if not cur.fetchone():
2026-02-14T13:01:56.3126273Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3126391Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3126594Z                     cur.close()
2026-02-14T13:01:56.3126668Z                 finally:
2026-02-14T13:01:56.3126741Z                     conn.close()
2026-02-14T13:01:56.3126818Z                 break  # Success
2026-02-14T13:01:56.3127005Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3127199Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3127269Z                     print(
2026-02-14T13:01:56.3127497Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3127563Z                     )
2026-02-14T13:01:56.3127647Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3127719Z                 else:
2026-02-14T13:01:56.3127923Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3128108Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3128188Z                     pass
2026-02-14T13:01:56.3128304Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3128383Z                 break  # Already exists
2026-02-14T13:01:56.3128441Z     
2026-02-14T13:01:56.3128662Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3128849Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3128980Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3129044Z     
2026-02-14T13:01:56.3129118Z         close_all_pools()
2026-02-14T13:01:56.3129177Z     
2026-02-14T13:01:56.3129298Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3129471Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3129614Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3129696Z             conn.autocommit = True
2026-02-14T13:01:56.3129790Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3129984Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3130076Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3130162Z                 cur.execute(
2026-02-14T13:01:56.3130228Z                     """
2026-02-14T13:01:56.3130326Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3130412Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3130509Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3130602Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3130667Z                     """
2026-02-14T13:01:56.3130733Z                 )
2026-02-14T13:01:56.3130791Z     
2026-02-14T13:01:56.3130980Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3131520Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3131597Z                 try:
2026-02-14T13:01:56.3131721Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3131801Z                     cur.execute("""
2026-02-14T13:01:56.3131883Z                         DO $$
2026-02-14T13:01:56.3131952Z                         DECLARE
2026-02-14T13:01:56.3132027Z                             r RECORD;
2026-02-14T13:01:56.3132102Z                         BEGIN
2026-02-14T13:01:56.3132176Z                             FOR r IN (
2026-02-14T13:01:56.3132281Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3132369Z                                 FROM pg_views
2026-02-14T13:01:56.3132500Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3132567Z                             )
2026-02-14T13:01:56.3132640Z                             LOOP
2026-02-14T13:01:56.3133108Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3133190Z                             END LOOP;
2026-02-14T13:01:56.3133263Z                         END $$;
2026-02-14T13:01:56.3133334Z                     """)
2026-02-14T13:01:56.3133512Z                     # Drop tables
2026-02-14T13:01:56.3133586Z                     cur.execute("""
2026-02-14T13:01:56.3133659Z                         DO $$
2026-02-14T13:01:56.3133728Z                         DECLARE
2026-02-14T13:01:56.3133800Z                             r RECORD;
2026-02-14T13:01:56.3133866Z                         BEGIN
2026-02-14T13:01:56.3133945Z                             FOR r IN (
2026-02-14T13:01:56.3134048Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3134132Z                                 FROM pg_tables
2026-02-14T13:01:56.3134265Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3134336Z                             )
2026-02-14T13:01:56.3134406Z                             LOOP
2026-02-14T13:01:56.3134727Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3134804Z                             END LOOP;
2026-02-14T13:01:56.3134871Z                         END $$;
2026-02-14T13:01:56.3134936Z                     """)
2026-02-14T13:01:56.3135027Z                 except psycopg2.Error:
2026-02-14T13:01:56.3135202Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3135272Z                     pass
2026-02-14T13:01:56.3135337Z     
2026-02-14T13:01:56.3135507Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3135616Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3135698Z                 if init_dir.exists():
2026-02-14T13:01:56.3135807Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3135899Z                     for script_path in scripts:
2026-02-14T13:01:56.3136025Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3136108Z                             sql = f.read()
2026-02-14T13:01:56.3136319Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3136460Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3136542Z                             statements = []
2026-02-14T13:01:56.3136607Z     
2026-02-14T13:01:56.3136786Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3136862Z                             do_blocks = []
2026-02-14T13:01:56.3136972Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3137031Z     
2026-02-14T13:01:56.3137135Z                             def replace_do_block(match):
2026-02-14T13:01:56.3137227Z                                 block = match.group(0)
2026-02-14T13:01:56.3137365Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3137462Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3137555Z                                 return placeholder
2026-02-14T13:01:56.3137620Z     
2026-02-14T13:01:56.3137729Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3137827Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3137916Z                                                     ^^
2026-02-14T13:01:56.3138103Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3138170Z                             )
2026-02-14T13:01:56.3138289Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3138295Z 
2026-02-14T13:01:56.3138488Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3138691Z __ ERROR at setup of TestDocumentRoutes.test_download_cover_letter_file_based __
2026-02-14T13:01:56.3138695Z 
2026-02-14T13:01:56.3138993Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3139076Z 
2026-02-14T13:01:56.3139168Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3139279Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3139342Z         """
2026-02-14T13:01:56.3139477Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3139541Z     
2026-02-14T13:01:56.3139672Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3139795Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3139862Z         """
2026-02-14T13:01:56.3139957Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3140083Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3140147Z     
2026-02-14T13:01:56.3140259Z         # Parse connection string to get database name
2026-02-14T13:01:56.3140503Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3140566Z     
2026-02-14T13:01:56.3140756Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3140982Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3141326Z     
2026-02-14T13:01:56.3141547Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3141667Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3141747Z         if len(parts) >= 4:
2026-02-14T13:01:56.3141871Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3141938Z         else:
2026-02-14T13:01:56.3142040Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3142104Z     
2026-02-14T13:01:56.3142205Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3142435Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3142502Z         import time
2026-02-14T13:01:56.3142566Z     
2026-02-14T13:01:56.3142645Z         max_retries = 5
2026-02-14T13:01:56.3142715Z         retry_delay = 2
2026-02-14T13:01:56.3142773Z     
2026-02-14T13:01:56.3142868Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3142935Z             try:
2026-02-14T13:01:56.3143041Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3143139Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3143229Z                 conn.autocommit = True
2026-02-14T13:01:56.3143293Z                 try:
2026-02-14T13:01:56.3143371Z                     cur = conn.cursor()
2026-02-14T13:01:56.3143576Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3143659Z                     if not cur.fetchone():
2026-02-14T13:01:56.3143812Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3143936Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3144014Z                     cur.close()
2026-02-14T13:01:56.3144082Z                 finally:
2026-02-14T13:01:56.3144158Z                     conn.close()
2026-02-14T13:01:56.3144234Z                 break  # Success
2026-02-14T13:01:56.3144424Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3144515Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3144595Z                     print(
2026-02-14T13:01:56.3144818Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3144885Z                     )
2026-02-14T13:01:56.3144976Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3145168Z                 else:
2026-02-14T13:01:56.3145379Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3145565Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3145744Z                     pass
2026-02-14T13:01:56.3145862Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3145941Z                 break  # Already exists
2026-02-14T13:01:56.3146005Z     
2026-02-14T13:01:56.3146223Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3146406Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3146545Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3146604Z     
2026-02-14T13:01:56.3146680Z         close_all_pools()
2026-02-14T13:01:56.3146739Z     
2026-02-14T13:01:56.3146867Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3147032Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3147174Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3147268Z             conn.autocommit = True
2026-02-14T13:01:56.3147349Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3147548Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3147645Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3147720Z                 cur.execute(
2026-02-14T13:01:56.3147786Z                     """
2026-02-14T13:01:56.3147884Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3147971Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3148069Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3148159Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3148233Z                     """
2026-02-14T13:01:56.3148295Z                 )
2026-02-14T13:01:56.3148356Z     
2026-02-14T13:01:56.3148553Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3148743Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3148808Z                 try:
2026-02-14T13:01:56.3148929Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3149013Z                     cur.execute("""
2026-02-14T13:01:56.3149083Z                         DO $$
2026-02-14T13:01:56.3149153Z                         DECLARE
2026-02-14T13:01:56.3149238Z                             r RECORD;
2026-02-14T13:01:56.3149316Z                         BEGIN
2026-02-14T13:01:56.3149390Z                             FOR r IN (
2026-02-14T13:01:56.3149492Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3149588Z                                 FROM pg_views
2026-02-14T13:01:56.3149718Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3149785Z                             )
2026-02-14T13:01:56.3149866Z                             LOOP
2026-02-14T13:01:56.3150181Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3150257Z                             END LOOP;
2026-02-14T13:01:56.3150332Z                         END $$;
2026-02-14T13:01:56.3150401Z                     """)
2026-02-14T13:01:56.3150473Z                     # Drop tables
2026-02-14T13:01:56.3150546Z                     cur.execute("""
2026-02-14T13:01:56.3150619Z                         DO $$
2026-02-14T13:01:56.3150686Z                         DECLARE
2026-02-14T13:01:56.3150755Z                             r RECORD;
2026-02-14T13:01:56.3150827Z                         BEGIN
2026-02-14T13:01:56.3150994Z                             FOR r IN (
2026-02-14T13:01:56.3151240Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3151330Z                                 FROM pg_tables
2026-02-14T13:01:56.3151459Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3151639Z                             )
2026-02-14T13:01:56.3151711Z                             LOOP
2026-02-14T13:01:56.3152034Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3152106Z                             END LOOP;
2026-02-14T13:01:56.3152172Z                         END $$;
2026-02-14T13:01:56.3152241Z                     """)
2026-02-14T13:01:56.3152323Z                 except psycopg2.Error:
2026-02-14T13:01:56.3152498Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3152569Z                     pass
2026-02-14T13:01:56.3152632Z     
2026-02-14T13:01:56.3152803Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3152913Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3152999Z                 if init_dir.exists():
2026-02-14T13:01:56.3153103Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3153193Z                     for script_path in scripts:
2026-02-14T13:01:56.3153324Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3153402Z                             sql = f.read()
2026-02-14T13:01:56.3153609Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3153746Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3153827Z                             statements = []
2026-02-14T13:01:56.3153887Z     
2026-02-14T13:01:56.3154068Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3154152Z                             do_blocks = []
2026-02-14T13:01:56.3154259Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3154321Z     
2026-02-14T13:01:56.3154425Z                             def replace_do_block(match):
2026-02-14T13:01:56.3154517Z                                 block = match.group(0)
2026-02-14T13:01:56.3154644Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3154746Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3154835Z                                 return placeholder
2026-02-14T13:01:56.3154894Z     
2026-02-14T13:01:56.3155004Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3155111Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3155197Z                                                     ^^
2026-02-14T13:01:56.3155387Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3155464Z                             )
2026-02-14T13:01:56.3155572Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3155582Z 
2026-02-14T13:01:56.3155684Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3155929Z _ ERROR at setup of TestDocumentRoutes.test_download_cover_letter_text_based_raises_error _
2026-02-14T13:01:56.3155934Z 
2026-02-14T13:01:56.3156237Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3156241Z 
2026-02-14T13:01:56.3156330Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3156439Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3156506Z         """
2026-02-14T13:01:56.3156643Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3156701Z     
2026-02-14T13:01:56.3156972Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3157109Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3157171Z         """
2026-02-14T13:01:56.3157267Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3157476Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3157535Z     
2026-02-14T13:01:56.3157641Z         # Parse connection string to get database name
2026-02-14T13:01:56.3157889Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3157948Z     
2026-02-14T13:01:56.3158133Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3158363Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3158429Z     
2026-02-14T13:01:56.3158572Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3158688Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3158771Z         if len(parts) >= 4:
2026-02-14T13:01:56.3158891Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3158952Z         else:
2026-02-14T13:01:56.3159065Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3159124Z     
2026-02-14T13:01:56.3159225Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3159458Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3159532Z         import time
2026-02-14T13:01:56.3159591Z     
2026-02-14T13:01:56.3159660Z         max_retries = 5
2026-02-14T13:01:56.3159734Z         retry_delay = 2
2026-02-14T13:01:56.3159795Z     
2026-02-14T13:01:56.3159881Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3159943Z             try:
2026-02-14T13:01:56.3160049Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3160149Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3160232Z                 conn.autocommit = True
2026-02-14T13:01:56.3160302Z                 try:
2026-02-14T13:01:56.3160380Z                     cur = conn.cursor()
2026-02-14T13:01:56.3160569Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3160651Z                     if not cur.fetchone():
2026-02-14T13:01:56.3160813Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3160934Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3161009Z                     cur.close()
2026-02-14T13:01:56.3161220Z                 finally:
2026-02-14T13:01:56.3161295Z                     conn.close()
2026-02-14T13:01:56.3161368Z                 break  # Success
2026-02-14T13:01:56.3161564Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3161659Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3161729Z                     print(
2026-02-14T13:01:56.3161945Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3162020Z                     )
2026-02-14T13:01:56.3162104Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3162169Z                 else:
2026-02-14T13:01:56.3162377Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3162559Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3162627Z                     pass
2026-02-14T13:01:56.3162747Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3162823Z                 break  # Already exists
2026-02-14T13:01:56.3162881Z     
2026-02-14T13:01:56.3163094Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3163438Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3163574Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3163632Z     
2026-02-14T13:01:56.3163812Z         close_all_pools()
2026-02-14T13:01:56.3163870Z     
2026-02-14T13:01:56.3163986Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3164156Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3164296Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3164376Z             conn.autocommit = True
2026-02-14T13:01:56.3164458Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3164653Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3164748Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3164820Z                 cur.execute(
2026-02-14T13:01:56.3164894Z                     """
2026-02-14T13:01:56.3164992Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3165073Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3165176Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3165270Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3165336Z                     """
2026-02-14T13:01:56.3165397Z                 )
2026-02-14T13:01:56.3165463Z     
2026-02-14T13:01:56.3165653Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3165835Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3165904Z                 try:
2026-02-14T13:01:56.3166022Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3166098Z                     cur.execute("""
2026-02-14T13:01:56.3166172Z                         DO $$
2026-02-14T13:01:56.3166244Z                         DECLARE
2026-02-14T13:01:56.3166317Z                             r RECORD;
2026-02-14T13:01:56.3166384Z                         BEGIN
2026-02-14T13:01:56.3166462Z                             FOR r IN (
2026-02-14T13:01:56.3166563Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3166650Z                                 FROM pg_views
2026-02-14T13:01:56.3166784Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3166852Z                             )
2026-02-14T13:01:56.3166921Z                             LOOP
2026-02-14T13:01:56.3167240Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3167317Z                             END LOOP;
2026-02-14T13:01:56.3167383Z                         END $$;
2026-02-14T13:01:56.3167450Z                     """)
2026-02-14T13:01:56.3167529Z                     # Drop tables
2026-02-14T13:01:56.3167608Z                     cur.execute("""
2026-02-14T13:01:56.3167675Z                         DO $$
2026-02-14T13:01:56.3167748Z                         DECLARE
2026-02-14T13:01:56.3167817Z                             r RECORD;
2026-02-14T13:01:56.3167887Z                         BEGIN
2026-02-14T13:01:56.3167961Z                             FOR r IN (
2026-02-14T13:01:56.3168068Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3168153Z                                 FROM pg_tables
2026-02-14T13:01:56.3168281Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3168356Z                             )
2026-02-14T13:01:56.3168426Z                             LOOP
2026-02-14T13:01:56.3168740Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3168817Z                             END LOOP;
2026-02-14T13:01:56.3168972Z                         END $$;
2026-02-14T13:01:56.3169043Z                     """)
2026-02-14T13:01:56.3169125Z                 except psycopg2.Error:
2026-02-14T13:01:56.3169305Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3169452Z                     pass
2026-02-14T13:01:56.3169510Z     
2026-02-14T13:01:56.3169687Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3169799Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3169877Z                 if init_dir.exists():
2026-02-14T13:01:56.3169988Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3170081Z                     for script_path in scripts:
2026-02-14T13:01:56.3170207Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3170283Z                             sql = f.read()
2026-02-14T13:01:56.3170500Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3170631Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3170709Z                             statements = []
2026-02-14T13:01:56.3170777Z     
2026-02-14T13:01:56.3170953Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3171254Z                             do_blocks = []
2026-02-14T13:01:56.3171462Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3171547Z     
2026-02-14T13:01:56.3171651Z                             def replace_do_block(match):
2026-02-14T13:01:56.3171757Z                                 block = match.group(0)
2026-02-14T13:01:56.3171887Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3171984Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3172076Z                                 return placeholder
2026-02-14T13:01:56.3172141Z     
2026-02-14T13:01:56.3172252Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3172350Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3172448Z                                                     ^^
2026-02-14T13:01:56.3172637Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3172705Z                             )
2026-02-14T13:01:56.3172820Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3172827Z 
2026-02-14T13:01:56.3172930Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3173152Z _ ERROR at setup of TestDocumentRoutes.test_cover_letter_download_handles_both_types _
2026-02-14T13:01:56.3173157Z 
2026-02-14T13:01:56.3173469Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3173476Z 
2026-02-14T13:01:56.3173570Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3173681Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3173742Z         """
2026-02-14T13:01:56.3173875Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3173944Z     
2026-02-14T13:01:56.3174077Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3174200Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3174267Z         """
2026-02-14T13:01:56.3174360Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3174486Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3174544Z     
2026-02-14T13:01:56.3174657Z         # Parse connection string to get database name
2026-02-14T13:01:56.3174897Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3174956Z     
2026-02-14T13:01:56.3175292Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3175523Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3175581Z     
2026-02-14T13:01:56.3175727Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3175941Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3176016Z         if len(parts) >= 4:
2026-02-14T13:01:56.3176136Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3176203Z         else:
2026-02-14T13:01:56.3176304Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3176362Z     
2026-02-14T13:01:56.3176463Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3176691Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3176758Z         import time
2026-02-14T13:01:56.3176858Z     
2026-02-14T13:01:56.3176940Z         max_retries = 5
2026-02-14T13:01:56.3177009Z         retry_delay = 2
2026-02-14T13:01:56.3177066Z     
2026-02-14T13:01:56.3177157Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3177220Z             try:
2026-02-14T13:01:56.3177327Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3177432Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3177514Z                 conn.autocommit = True
2026-02-14T13:01:56.3177579Z                 try:
2026-02-14T13:01:56.3177658Z                     cur = conn.cursor()
2026-02-14T13:01:56.3177852Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3177934Z                     if not cur.fetchone():
2026-02-14T13:01:56.3178086Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3178209Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3178283Z                     cur.close()
2026-02-14T13:01:56.3178351Z                 finally:
2026-02-14T13:01:56.3178431Z                     conn.close()
2026-02-14T13:01:56.3178503Z                 break  # Success
2026-02-14T13:01:56.3178692Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3178787Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3178862Z                     print(
2026-02-14T13:01:56.3179078Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3179143Z                     )
2026-02-14T13:01:56.3179231Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3179296Z                 else:
2026-02-14T13:01:56.3179508Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3179693Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3179767Z                     pass
2026-02-14T13:01:56.3179881Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3179959Z                 break  # Already exists
2026-02-14T13:01:56.3180025Z     
2026-02-14T13:01:56.3180240Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3180429Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3180563Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3180621Z     
2026-02-14T13:01:56.3180693Z         close_all_pools()
2026-02-14T13:01:56.3180751Z     
2026-02-14T13:01:56.3180874Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3181304Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3181497Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3181589Z             conn.autocommit = True
2026-02-14T13:01:56.3181806Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3182007Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3182110Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3182287Z                 cur.execute(
2026-02-14T13:01:56.3182353Z                     """
2026-02-14T13:01:56.3182450Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3182538Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3182634Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3182723Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3182794Z                     """
2026-02-14T13:01:56.3182857Z                 )
2026-02-14T13:01:56.3182915Z     
2026-02-14T13:01:56.3183109Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3183297Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3183362Z                 try:
2026-02-14T13:01:56.3183481Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3183564Z                     cur.execute("""
2026-02-14T13:01:56.3183638Z                         DO $$
2026-02-14T13:01:56.3183705Z                         DECLARE
2026-02-14T13:01:56.3183785Z                             r RECORD;
2026-02-14T13:01:56.3183853Z                         BEGIN
2026-02-14T13:01:56.3183927Z                             FOR r IN (
2026-02-14T13:01:56.3184034Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3184117Z                                 FROM pg_views
2026-02-14T13:01:56.3184246Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3184313Z                             )
2026-02-14T13:01:56.3184389Z                             LOOP
2026-02-14T13:01:56.3184707Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3184782Z                             END LOOP;
2026-02-14T13:01:56.3184855Z                         END $$;
2026-02-14T13:01:56.3184925Z                     """)
2026-02-14T13:01:56.3184997Z                     # Drop tables
2026-02-14T13:01:56.3185075Z                     cur.execute("""
2026-02-14T13:01:56.3185143Z                         DO $$
2026-02-14T13:01:56.3185210Z                         DECLARE
2026-02-14T13:01:56.3185279Z                             r RECORD;
2026-02-14T13:01:56.3185351Z                         BEGIN
2026-02-14T13:01:56.3185423Z                             FOR r IN (
2026-02-14T13:01:56.3185521Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3185608Z                                 FROM pg_tables
2026-02-14T13:01:56.3185735Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3185806Z                             )
2026-02-14T13:01:56.3185875Z                             LOOP
2026-02-14T13:01:56.3186190Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3186267Z                             END LOOP;
2026-02-14T13:01:56.3186334Z                         END $$;
2026-02-14T13:01:56.3186406Z                     """)
2026-02-14T13:01:56.3186488Z                 except psycopg2.Error:
2026-02-14T13:01:56.3186662Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3186736Z                     pass
2026-02-14T13:01:56.3186794Z     
2026-02-14T13:01:56.3186963Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3187071Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3187152Z                 if init_dir.exists():
2026-02-14T13:01:56.3187344Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3187438Z                     for script_path in scripts:
2026-02-14T13:01:56.3187567Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3187722Z                             sql = f.read()
2026-02-14T13:01:56.3187926Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3188062Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3188140Z                             statements = []
2026-02-14T13:01:56.3188199Z     
2026-02-14T13:01:56.3188382Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3188456Z                             do_blocks = []
2026-02-14T13:01:56.3188559Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3188616Z     
2026-02-14T13:01:56.3188724Z                             def replace_do_block(match):
2026-02-14T13:01:56.3188818Z                                 block = match.group(0)
2026-02-14T13:01:56.3188944Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3189050Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3189137Z                                 return placeholder
2026-02-14T13:01:56.3189195Z     
2026-02-14T13:01:56.3189316Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3189413Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3189495Z                                                     ^^
2026-02-14T13:01:56.3189681Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3189757Z                             )
2026-02-14T13:01:56.3189866Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3189872Z 
2026-02-14T13:01:56.3189976Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3190186Z _ ERROR at setup of TestDocumentsPage.test_upload_resume_from_documents_section _
2026-02-14T13:01:56.3190191Z 
2026-02-14T13:01:56.3190514Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3190524Z 
2026-02-14T13:01:56.3190613Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3190719Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3190786Z         """
2026-02-14T13:01:56.3190923Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3190982Z     
2026-02-14T13:01:56.3191264Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3191395Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3191458Z         """
2026-02-14T13:01:56.3191554Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3191685Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3191748Z     
2026-02-14T13:01:56.3191854Z         # Parse connection string to get database name
2026-02-14T13:01:56.3192108Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3192173Z     
2026-02-14T13:01:56.3192358Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3192588Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3192653Z     
2026-02-14T13:01:56.3192797Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3192906Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3192992Z         if len(parts) >= 4:
2026-02-14T13:01:56.3193114Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3193177Z         else:
2026-02-14T13:01:56.3193284Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3193465Z     
2026-02-14T13:01:56.3193566Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3193795Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3193975Z         import time
2026-02-14T13:01:56.3194034Z     
2026-02-14T13:01:56.3194103Z         max_retries = 5
2026-02-14T13:01:56.3194178Z         retry_delay = 2
2026-02-14T13:01:56.3194237Z     
2026-02-14T13:01:56.3194326Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3194389Z             try:
2026-02-14T13:01:56.3194497Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3194592Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3194673Z                 conn.autocommit = True
2026-02-14T13:01:56.3194744Z                 try:
2026-02-14T13:01:56.3194820Z                     cur = conn.cursor()
2026-02-14T13:01:56.3195013Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3195100Z                     if not cur.fetchone():
2026-02-14T13:01:56.3195253Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3195370Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3195445Z                     cur.close()
2026-02-14T13:01:56.3195517Z                 finally:
2026-02-14T13:01:56.3195588Z                     conn.close()
2026-02-14T13:01:56.3195659Z                 break  # Success
2026-02-14T13:01:56.3195853Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3195942Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3196011Z                     print(
2026-02-14T13:01:56.3196231Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3196296Z                     )
2026-02-14T13:01:56.3196386Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3196450Z                 else:
2026-02-14T13:01:56.3196659Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3196840Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3196912Z                     pass
2026-02-14T13:01:56.3197031Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3197110Z                 break  # Already exists
2026-02-14T13:01:56.3197169Z     
2026-02-14T13:01:56.3197388Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3197572Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3197702Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3197760Z     
2026-02-14T13:01:56.3197837Z         close_all_pools()
2026-02-14T13:01:56.3197895Z     
2026-02-14T13:01:56.3198017Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3198186Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3198327Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3198412Z             conn.autocommit = True
2026-02-14T13:01:56.3198496Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3198688Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3198779Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3198850Z                 cur.execute(
2026-02-14T13:01:56.3198922Z                     """
2026-02-14T13:01:56.3199018Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3199097Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3199197Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3199287Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3199447Z                     """
2026-02-14T13:01:56.3199511Z                 )
2026-02-14T13:01:56.3199574Z     
2026-02-14T13:01:56.3199764Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3200022Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3200092Z                 try:
2026-02-14T13:01:56.3200209Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3200285Z                     cur.execute("""
2026-02-14T13:01:56.3200360Z                         DO $$
2026-02-14T13:01:56.3200429Z                         DECLARE
2026-02-14T13:01:56.3200502Z                             r RECORD;
2026-02-14T13:01:56.3200571Z                         BEGIN
2026-02-14T13:01:56.3200650Z                             FOR r IN (
2026-02-14T13:01:56.3200749Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3200836Z                                 FROM pg_views
2026-02-14T13:01:56.3200971Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3201151Z                             )
2026-02-14T13:01:56.3201223Z                             LOOP
2026-02-14T13:01:56.3201545Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3201620Z                             END LOOP;
2026-02-14T13:01:56.3201687Z                         END $$;
2026-02-14T13:01:56.3201752Z                     """)
2026-02-14T13:01:56.3201830Z                     # Drop tables
2026-02-14T13:01:56.3201903Z                     cur.execute("""
2026-02-14T13:01:56.3201978Z                         DO $$
2026-02-14T13:01:56.3202049Z                         DECLARE
2026-02-14T13:01:56.3202119Z                             r RECORD;
2026-02-14T13:01:56.3202187Z                         BEGIN
2026-02-14T13:01:56.3202264Z                             FOR r IN (
2026-02-14T13:01:56.3202374Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3202458Z                                 FROM pg_tables
2026-02-14T13:01:56.3202582Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3202658Z                             )
2026-02-14T13:01:56.3202727Z                             LOOP
2026-02-14T13:01:56.3203036Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3203113Z                             END LOOP;
2026-02-14T13:01:56.3203182Z                         END $$;
2026-02-14T13:01:56.3203248Z                     """)
2026-02-14T13:01:56.3203336Z                 except psycopg2.Error:
2026-02-14T13:01:56.3203508Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3203577Z                     pass
2026-02-14T13:01:56.3203639Z     
2026-02-14T13:01:56.3203814Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3203924Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3204004Z                 if init_dir.exists():
2026-02-14T13:01:56.3204117Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3204209Z                     for script_path in scripts:
2026-02-14T13:01:56.3204333Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3204416Z                             sql = f.read()
2026-02-14T13:01:56.3204623Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3204753Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3204836Z                             statements = []
2026-02-14T13:01:56.3204903Z     
2026-02-14T13:01:56.3205215Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3205300Z                             do_blocks = []
2026-02-14T13:01:56.3205410Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3205575Z     
2026-02-14T13:01:56.3205675Z                             def replace_do_block(match):
2026-02-14T13:01:56.3205774Z                                 block = match.group(0)
2026-02-14T13:01:56.3205900Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3205998Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3206089Z                                 return placeholder
2026-02-14T13:01:56.3206153Z     
2026-02-14T13:01:56.3206259Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3206356Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3206456Z                                                     ^^
2026-02-14T13:01:56.3206641Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3206709Z                             )
2026-02-14T13:01:56.3206820Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3206833Z 
2026-02-14T13:01:56.3206933Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3207203Z _ ERROR at setup of TestDocumentsPage.test_upload_resume_from_job_details_not_in_documents_section _
2026-02-14T13:01:56.3207207Z 
2026-02-14T13:01:56.3207492Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3207496Z 
2026-02-14T13:01:56.3207589Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3207694Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3207754Z         """
2026-02-14T13:01:56.3207888Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3207951Z     
2026-02-14T13:01:56.3208086Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3208208Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3208275Z         """
2026-02-14T13:01:56.3208371Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3208501Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3208559Z     
2026-02-14T13:01:56.3208671Z         # Parse connection string to get database name
2026-02-14T13:01:56.3208917Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3208977Z     
2026-02-14T13:01:56.3209166Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3209399Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3209457Z     
2026-02-14T13:01:56.3209604Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3209715Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3209791Z         if len(parts) >= 4:
2026-02-14T13:01:56.3209910Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3209982Z         else:
2026-02-14T13:01:56.3210082Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3210142Z     
2026-02-14T13:01:56.3210244Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3210472Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3210539Z         import time
2026-02-14T13:01:56.3210603Z     
2026-02-14T13:01:56.3210672Z         max_retries = 5
2026-02-14T13:01:56.3210741Z         retry_delay = 2
2026-02-14T13:01:56.3210799Z     
2026-02-14T13:01:56.3210891Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3210954Z             try:
2026-02-14T13:01:56.3211292Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3211669Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3211768Z                 conn.autocommit = True
2026-02-14T13:01:56.3211836Z                 try:
2026-02-14T13:01:56.3211915Z                     cur = conn.cursor()
2026-02-14T13:01:56.3212216Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3212297Z                     if not cur.fetchone():
2026-02-14T13:01:56.3212450Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3212572Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3212644Z                     cur.close()
2026-02-14T13:01:56.3212711Z                 finally:
2026-02-14T13:01:56.3212791Z                     conn.close()
2026-02-14T13:01:56.3212862Z                 break  # Success
2026-02-14T13:01:56.3213051Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3213147Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3213224Z                     print(
2026-02-14T13:01:56.3213442Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3213512Z                     )
2026-02-14T13:01:56.3213603Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3213667Z                 else:
2026-02-14T13:01:56.3213872Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3214060Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3214129Z                     pass
2026-02-14T13:01:56.3214246Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3214327Z                 break  # Already exists
2026-02-14T13:01:56.3214392Z     
2026-02-14T13:01:56.3214618Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3214800Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3214937Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3214996Z     
2026-02-14T13:01:56.3215074Z         close_all_pools()
2026-02-14T13:01:56.3215140Z     
2026-02-14T13:01:56.3215258Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3215419Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3215563Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3215654Z             conn.autocommit = True
2026-02-14T13:01:56.3215734Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3215927Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3216025Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3216097Z                 cur.execute(
2026-02-14T13:01:56.3216168Z                     """
2026-02-14T13:01:56.3216271Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3216351Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3216446Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3216542Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3216613Z                     """
2026-02-14T13:01:56.3216675Z                 )
2026-02-14T13:01:56.3216733Z     
2026-02-14T13:01:56.3216930Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3217114Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3217180Z                 try:
2026-02-14T13:01:56.3217297Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3217379Z                     cur.execute("""
2026-02-14T13:01:56.3217449Z                         DO $$
2026-02-14T13:01:56.3217609Z                         DECLARE
2026-02-14T13:01:56.3217691Z                             r RECORD;
2026-02-14T13:01:56.3217759Z                         BEGIN
2026-02-14T13:01:56.3217832Z                             FOR r IN (
2026-02-14T13:01:56.3218015Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3218100Z                                 FROM pg_views
2026-02-14T13:01:56.3218229Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3218295Z                             )
2026-02-14T13:01:56.3218371Z                             LOOP
2026-02-14T13:01:56.3218682Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3218755Z                             END LOOP;
2026-02-14T13:01:56.3218827Z                         END $$;
2026-02-14T13:01:56.3218892Z                     """)
2026-02-14T13:01:56.3218968Z                     # Drop tables
2026-02-14T13:01:56.3219046Z                     cur.execute("""
2026-02-14T13:01:56.3219112Z                         DO $$
2026-02-14T13:01:56.3219178Z                         DECLARE
2026-02-14T13:01:56.3219246Z                             r RECORD;
2026-02-14T13:01:56.3219324Z                         BEGIN
2026-02-14T13:01:56.3219395Z                             FOR r IN (
2026-02-14T13:01:56.3219497Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3219592Z                                 FROM pg_tables
2026-02-14T13:01:56.3219717Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3219784Z                             )
2026-02-14T13:01:56.3219859Z                             LOOP
2026-02-14T13:01:56.3220171Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3220244Z                             END LOOP;
2026-02-14T13:01:56.3220315Z                         END $$;
2026-02-14T13:01:56.3220385Z                     """)
2026-02-14T13:01:56.3220468Z                 except psycopg2.Error:
2026-02-14T13:01:56.3220640Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3220718Z                     pass
2026-02-14T13:01:56.3220776Z     
2026-02-14T13:01:56.3220947Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3221314Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3221428Z                 if init_dir.exists():
2026-02-14T13:01:56.3221538Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3221631Z                     for script_path in scripts:
2026-02-14T13:01:56.3221767Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3221845Z                             sql = f.read()
2026-02-14T13:01:56.3222058Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3222198Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3222277Z                             statements = []
2026-02-14T13:01:56.3222346Z     
2026-02-14T13:01:56.3222532Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3222608Z                             do_blocks = []
2026-02-14T13:01:56.3222713Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3222773Z     
2026-02-14T13:01:56.3222876Z                             def replace_do_block(match):
2026-02-14T13:01:56.3222972Z                                 block = match.group(0)
2026-02-14T13:01:56.3223099Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3223202Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3223455Z                                 return placeholder
2026-02-14T13:01:56.3223524Z     
2026-02-14T13:01:56.3223643Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3223747Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3223950Z                                                     ^^
2026-02-14T13:01:56.3224138Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3224215Z                             )
2026-02-14T13:01:56.3224323Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3224330Z 
2026-02-14T13:01:56.3224431Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3224640Z _ ERROR at setup of TestDocumentsPage.test_delete_resume_from_documents_section _
2026-02-14T13:01:56.3224645Z 
2026-02-14T13:01:56.3224961Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3224966Z 
2026-02-14T13:01:56.3225062Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3225174Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3225242Z         """
2026-02-14T13:01:56.3225377Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3225442Z     
2026-02-14T13:01:56.3225574Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3225704Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3225767Z         """
2026-02-14T13:01:56.3225863Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3225994Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3226060Z     
2026-02-14T13:01:56.3226167Z         # Parse connection string to get database name
2026-02-14T13:01:56.3226418Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3226480Z     
2026-02-14T13:01:56.3226669Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3226899Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3226964Z     
2026-02-14T13:01:56.3227112Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3227221Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3227303Z         if len(parts) >= 4:
2026-02-14T13:01:56.3227426Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3227488Z         else:
2026-02-14T13:01:56.3227596Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3227656Z     
2026-02-14T13:01:56.3227751Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3227979Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3228055Z         import time
2026-02-14T13:01:56.3228114Z     
2026-02-14T13:01:56.3228189Z         max_retries = 5
2026-02-14T13:01:56.3228266Z         retry_delay = 2
2026-02-14T13:01:56.3228325Z     
2026-02-14T13:01:56.3228411Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3228476Z             try:
2026-02-14T13:01:56.3228587Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3228683Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3228765Z                 conn.autocommit = True
2026-02-14T13:01:56.3228838Z                 try:
2026-02-14T13:01:56.3228916Z                     cur = conn.cursor()
2026-02-14T13:01:56.3229103Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3229191Z                     if not cur.fetchone():
2026-02-14T13:01:56.3229345Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3229460Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3229625Z                     cur.close()
2026-02-14T13:01:56.3229704Z                 finally:
2026-02-14T13:01:56.3229777Z                     conn.close()
2026-02-14T13:01:56.3229848Z                 break  # Success
2026-02-14T13:01:56.3230046Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3230215Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3230286Z                     print(
2026-02-14T13:01:56.3230512Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3230576Z                     )
2026-02-14T13:01:56.3230660Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3230723Z                 else:
2026-02-14T13:01:56.3230935Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3231259Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3231333Z                     pass
2026-02-14T13:01:56.3231455Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3231533Z                 break  # Already exists
2026-02-14T13:01:56.3231593Z     
2026-02-14T13:01:56.3231829Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3232012Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3232143Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3232201Z     
2026-02-14T13:01:56.3232280Z         close_all_pools()
2026-02-14T13:01:56.3232338Z     
2026-02-14T13:01:56.3232456Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3232626Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3232767Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3232853Z             conn.autocommit = True
2026-02-14T13:01:56.3232939Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3233130Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3233223Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3233299Z                 cur.execute(
2026-02-14T13:01:56.3233371Z                     """
2026-02-14T13:01:56.3233469Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3233552Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3233654Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3233744Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3233810Z                     """
2026-02-14T13:01:56.3233878Z                 )
2026-02-14T13:01:56.3233937Z     
2026-02-14T13:01:56.3234125Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3234313Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3234384Z                 try:
2026-02-14T13:01:56.3234501Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3234577Z                     cur.execute("""
2026-02-14T13:01:56.3234657Z                         DO $$
2026-02-14T13:01:56.3234725Z                         DECLARE
2026-02-14T13:01:56.3234799Z                             r RECORD;
2026-02-14T13:01:56.3234868Z                         BEGIN
2026-02-14T13:01:56.3234948Z                             FOR r IN (
2026-02-14T13:01:56.3235051Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3235133Z                                 FROM pg_views
2026-02-14T13:01:56.3235266Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3235334Z                             )
2026-02-14T13:01:56.3235407Z                             LOOP
2026-02-14T13:01:56.3235851Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3235930Z                             END LOOP;
2026-02-14T13:01:56.3236000Z                         END $$;
2026-02-14T13:01:56.3236169Z                     """)
2026-02-14T13:01:56.3236248Z                     # Drop tables
2026-02-14T13:01:56.3236322Z                     cur.execute("""
2026-02-14T13:01:56.3236389Z                         DO $$
2026-02-14T13:01:56.3236462Z                         DECLARE
2026-02-14T13:01:56.3236533Z                             r RECORD;
2026-02-14T13:01:56.3236601Z                         BEGIN
2026-02-14T13:01:56.3236678Z                             FOR r IN (
2026-02-14T13:01:56.3236781Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3236864Z                                 FROM pg_tables
2026-02-14T13:01:56.3236990Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3237069Z                             )
2026-02-14T13:01:56.3237142Z                             LOOP
2026-02-14T13:01:56.3237456Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3237544Z                             END LOOP;
2026-02-14T13:01:56.3237612Z                         END $$;
2026-02-14T13:01:56.3237677Z                     """)
2026-02-14T13:01:56.3237767Z                 except psycopg2.Error:
2026-02-14T13:01:56.3237940Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3238010Z                     pass
2026-02-14T13:01:56.3238068Z     
2026-02-14T13:01:56.3238246Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3238356Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3238434Z                 if init_dir.exists():
2026-02-14T13:01:56.3238551Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3238642Z                     for script_path in scripts:
2026-02-14T13:01:56.3238771Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3238855Z                             sql = f.read()
2026-02-14T13:01:56.3239059Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3239191Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3239270Z                             statements = []
2026-02-14T13:01:56.3239341Z     
2026-02-14T13:01:56.3239529Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3239606Z                             do_blocks = []
2026-02-14T13:01:56.3239715Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3239774Z     
2026-02-14T13:01:56.3239875Z                             def replace_do_block(match):
2026-02-14T13:01:56.3239973Z                                 block = match.group(0)
2026-02-14T13:01:56.3240100Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3240203Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3240289Z                                 return placeholder
2026-02-14T13:01:56.3240353Z     
2026-02-14T13:01:56.3240460Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3240557Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3240644Z                                                     ^^
2026-02-14T13:01:56.3240831Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3240898Z                             )
2026-02-14T13:01:56.3241009Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3241014Z 
2026-02-14T13:01:56.3241343Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3241571Z _ ERROR at setup of TestDocumentsPage.test_create_cover_letter_from_documents_section _
2026-02-14T13:01:56.3241576Z 
2026-02-14T13:01:56.3241867Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3241975Z 
2026-02-14T13:01:56.3242071Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3242176Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3242239Z         """
2026-02-14T13:01:56.3242376Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3242441Z     
2026-02-14T13:01:56.3242573Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3242697Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3242764Z         """
2026-02-14T13:01:56.3242859Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3242990Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3243048Z     
2026-02-14T13:01:56.3243159Z         # Parse connection string to get database name
2026-02-14T13:01:56.3243402Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3243466Z     
2026-02-14T13:01:56.3243655Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3243880Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3243939Z     
2026-02-14T13:01:56.3244088Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3244198Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3244274Z         if len(parts) >= 4:
2026-02-14T13:01:56.3244393Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3244461Z         else:
2026-02-14T13:01:56.3244566Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3244626Z     
2026-02-14T13:01:56.3244730Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3244959Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3245033Z         import time
2026-02-14T13:01:56.3245097Z     
2026-02-14T13:01:56.3245167Z         max_retries = 5
2026-02-14T13:01:56.3245236Z         retry_delay = 2
2026-02-14T13:01:56.3245293Z     
2026-02-14T13:01:56.3245388Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3245453Z             try:
2026-02-14T13:01:56.3245553Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3245654Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3245735Z                 conn.autocommit = True
2026-02-14T13:01:56.3245800Z                 try:
2026-02-14T13:01:56.3245878Z                     cur = conn.cursor()
2026-02-14T13:01:56.3246081Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3246163Z                     if not cur.fetchone():
2026-02-14T13:01:56.3246316Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3246445Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3246516Z                     cur.close()
2026-02-14T13:01:56.3246584Z                 finally:
2026-02-14T13:01:56.3246662Z                     conn.close()
2026-02-14T13:01:56.3246734Z                 break  # Success
2026-02-14T13:01:56.3246924Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3247014Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3247088Z                     print(
2026-02-14T13:01:56.3247316Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3247381Z                     )
2026-02-14T13:01:56.3247567Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3247636Z                 else:
2026-02-14T13:01:56.3247845Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3248039Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3248186Z                     pass
2026-02-14T13:01:56.3248308Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3248388Z                 break  # Already exists
2026-02-14T13:01:56.3248455Z     
2026-02-14T13:01:56.3248678Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3248862Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3249004Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3249063Z     
2026-02-14T13:01:56.3249141Z         close_all_pools()
2026-02-14T13:01:56.3249210Z     
2026-02-14T13:01:56.3249336Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3249502Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3249649Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3249749Z             conn.autocommit = True
2026-02-14T13:01:56.3249829Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3250023Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3250126Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3250201Z                 cur.execute(
2026-02-14T13:01:56.3250268Z                     """
2026-02-14T13:01:56.3250372Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3250453Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3250550Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3250644Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3250716Z                     """
2026-02-14T13:01:56.3250777Z                 )
2026-02-14T13:01:56.3250835Z     
2026-02-14T13:01:56.3251266Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3251590Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3251662Z                 try:
2026-02-14T13:01:56.3251791Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3251870Z                     cur.execute("""
2026-02-14T13:01:56.3251941Z                         DO $$
2026-02-14T13:01:56.3252010Z                         DECLARE
2026-02-14T13:01:56.3252091Z                             r RECORD;
2026-02-14T13:01:56.3252159Z                         BEGIN
2026-02-14T13:01:56.3252233Z                             FOR r IN (
2026-02-14T13:01:56.3252340Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3252431Z                                 FROM pg_views
2026-02-14T13:01:56.3252559Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3252626Z                             )
2026-02-14T13:01:56.3252707Z                             LOOP
2026-02-14T13:01:56.3253025Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3253099Z                             END LOOP;
2026-02-14T13:01:56.3253172Z                         END $$;
2026-02-14T13:01:56.3253238Z                     """)
2026-02-14T13:01:56.3253312Z                     # Drop tables
2026-02-14T13:01:56.3253392Z                     cur.execute("""
2026-02-14T13:01:56.3253458Z                         DO $$
2026-02-14T13:01:56.3253524Z                         DECLARE
2026-02-14T13:01:56.3253594Z                             r RECORD;
2026-02-14T13:01:56.3253666Z                         BEGIN
2026-02-14T13:01:56.3253879Z                             FOR r IN (
2026-02-14T13:01:56.3253986Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3254077Z                                 FROM pg_tables
2026-02-14T13:01:56.3254367Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3254435Z                             )
2026-02-14T13:01:56.3254512Z                             LOOP
2026-02-14T13:01:56.3254827Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3254899Z                             END LOOP;
2026-02-14T13:01:56.3254967Z                         END $$;
2026-02-14T13:01:56.3255038Z                     """)
2026-02-14T13:01:56.3255123Z                 except psycopg2.Error:
2026-02-14T13:01:56.3255298Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3255379Z                     pass
2026-02-14T13:01:56.3255436Z     
2026-02-14T13:01:56.3255606Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3255722Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3255803Z                 if init_dir.exists():
2026-02-14T13:01:56.3255910Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3256000Z                     for script_path in scripts:
2026-02-14T13:01:56.3256133Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3256212Z                             sql = f.read()
2026-02-14T13:01:56.3256419Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3256563Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3256643Z                             statements = []
2026-02-14T13:01:56.3256701Z     
2026-02-14T13:01:56.3256890Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3256966Z                             do_blocks = []
2026-02-14T13:01:56.3257069Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3257135Z     
2026-02-14T13:01:56.3257239Z                             def replace_do_block(match):
2026-02-14T13:01:56.3257330Z                                 block = match.group(0)
2026-02-14T13:01:56.3257457Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3257563Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3257651Z                                 return placeholder
2026-02-14T13:01:56.3257710Z     
2026-02-14T13:01:56.3257827Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3257929Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3258018Z                                                     ^^
2026-02-14T13:01:56.3258206Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3258286Z                             )
2026-02-14T13:01:56.3258395Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3258406Z 
2026-02-14T13:01:56.3258508Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3258811Z _ ERROR at setup of TestDocumentsPage.test_create_cover_letter_from_job_details_not_in_documents_section _
2026-02-14T13:01:56.3258816Z 
2026-02-14T13:01:56.3259126Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3259131Z 
2026-02-14T13:01:56.3259220Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3259327Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3259395Z         """
2026-02-14T13:01:56.3259531Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3259590Z     
2026-02-14T13:01:56.3259817Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3259947Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3260009Z         """
2026-02-14T13:01:56.3260187Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3260321Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3260381Z     
2026-02-14T13:01:56.3260491Z         # Parse connection string to get database name
2026-02-14T13:01:56.3260743Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3260803Z     
2026-02-14T13:01:56.3260989Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3261517Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3261581Z     
2026-02-14T13:01:56.3261736Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3261846Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3261929Z         if len(parts) >= 4:
2026-02-14T13:01:56.3262050Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3262120Z         else:
2026-02-14T13:01:56.3262229Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3262288Z     
2026-02-14T13:01:56.3262383Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3262616Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3262690Z         import time
2026-02-14T13:01:56.3262749Z     
2026-02-14T13:01:56.3262820Z         max_retries = 5
2026-02-14T13:01:56.3262893Z         retry_delay = 2
2026-02-14T13:01:56.3262950Z     
2026-02-14T13:01:56.3263036Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3263105Z             try:
2026-02-14T13:01:56.3263209Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3263303Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3263386Z                 conn.autocommit = True
2026-02-14T13:01:56.3263455Z                 try:
2026-02-14T13:01:56.3263539Z                     cur = conn.cursor()
2026-02-14T13:01:56.3263725Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3263812Z                     if not cur.fetchone():
2026-02-14T13:01:56.3263965Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3264080Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3264161Z                     cur.close()
2026-02-14T13:01:56.3264228Z                 finally:
2026-02-14T13:01:56.3264300Z                     conn.close()
2026-02-14T13:01:56.3264370Z                 break  # Success
2026-02-14T13:01:56.3264570Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3264663Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3264734Z                     print(
2026-02-14T13:01:56.3264959Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3265030Z                     )
2026-02-14T13:01:56.3265114Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3265179Z                 else:
2026-02-14T13:01:56.3265388Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3265570Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3265638Z                     pass
2026-02-14T13:01:56.3265764Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3265842Z                 break  # Already exists
2026-02-14T13:01:56.3265901Z     
2026-02-14T13:01:56.3266253Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3266439Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3266570Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3266738Z     
2026-02-14T13:01:56.3266812Z         close_all_pools()
2026-02-14T13:01:56.3266871Z     
2026-02-14T13:01:56.3266988Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3267157Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3267298Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3267381Z             conn.autocommit = True
2026-02-14T13:01:56.3267466Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3267660Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3267751Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3267833Z                 cur.execute(
2026-02-14T13:01:56.3267905Z                     """
2026-02-14T13:01:56.3268003Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3268084Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3268189Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3268282Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3268347Z                     """
2026-02-14T13:01:56.3268415Z                 )
2026-02-14T13:01:56.3268474Z     
2026-02-14T13:01:56.3268663Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3268848Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3268918Z                 try:
2026-02-14T13:01:56.3269034Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3269110Z                     cur.execute("""
2026-02-14T13:01:56.3269187Z                         DO $$
2026-02-14T13:01:56.3269259Z                         DECLARE
2026-02-14T13:01:56.3269335Z                             r RECORD;
2026-02-14T13:01:56.3269411Z                         BEGIN
2026-02-14T13:01:56.3269484Z                             FOR r IN (
2026-02-14T13:01:56.3269589Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3269672Z                                 FROM pg_views
2026-02-14T13:01:56.3269808Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3269875Z                             )
2026-02-14T13:01:56.3269949Z                             LOOP
2026-02-14T13:01:56.3270269Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3270342Z                             END LOOP;
2026-02-14T13:01:56.3270409Z                         END $$;
2026-02-14T13:01:56.3270481Z                     """)
2026-02-14T13:01:56.3270562Z                     # Drop tables
2026-02-14T13:01:56.3270636Z                     cur.execute("""
2026-02-14T13:01:56.3270713Z                         DO $$
2026-02-14T13:01:56.3274896Z                         DECLARE
2026-02-14T13:01:56.3275017Z                             r RECORD;
2026-02-14T13:01:56.3275091Z                         BEGIN
2026-02-14T13:01:56.3275178Z                             FOR r IN (
2026-02-14T13:01:56.3275292Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3275382Z                                 FROM pg_tables
2026-02-14T13:01:56.3275517Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3275592Z                             )
2026-02-14T13:01:56.3275662Z                             LOOP
2026-02-14T13:01:56.3275990Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3276240Z                             END LOOP;
2026-02-14T13:01:56.3276316Z                         END $$;
2026-02-14T13:01:56.3276383Z                     """)
2026-02-14T13:01:56.3276479Z                 except psycopg2.Error:
2026-02-14T13:01:56.3276669Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3276893Z                     pass
2026-02-14T13:01:56.3276956Z     
2026-02-14T13:01:56.3277145Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3277264Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3277344Z                 if init_dir.exists():
2026-02-14T13:01:56.3277463Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3277555Z                     for script_path in scripts:
2026-02-14T13:01:56.3277683Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3277773Z                             sql = f.read()
2026-02-14T13:01:56.3277985Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3278119Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3278203Z                             statements = []
2026-02-14T13:01:56.3278273Z     
2026-02-14T13:01:56.3278451Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3278529Z                             do_blocks = []
2026-02-14T13:01:56.3278639Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3278696Z     
2026-02-14T13:01:56.3278791Z                             def replace_do_block(match):
2026-02-14T13:01:56.3278890Z                                 block = match.group(0)
2026-02-14T13:01:56.3279016Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3279116Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3279205Z                                 return placeholder
2026-02-14T13:01:56.3279268Z     
2026-02-14T13:01:56.3279379Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3279483Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3279572Z                                                     ^^
2026-02-14T13:01:56.3279759Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3279828Z                             )
2026-02-14T13:01:56.3279942Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3279950Z 
2026-02-14T13:01:56.3280050Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3280275Z _ ERROR at setup of TestDocumentsPage.test_delete_cover_letter_from_documents_section _
2026-02-14T13:01:56.3280281Z 
2026-02-14T13:01:56.3280612Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3280624Z 
2026-02-14T13:01:56.3280722Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3280829Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3280889Z         """
2026-02-14T13:01:56.3281246Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3281385Z     
2026-02-14T13:01:56.3281535Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3281666Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3281733Z         """
2026-02-14T13:01:56.3281829Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3281959Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3282018Z     
2026-02-14T13:01:56.3282136Z         # Parse connection string to get database name
2026-02-14T13:01:56.3282387Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3282450Z     
2026-02-14T13:01:56.3282775Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3283013Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3283178Z     
2026-02-14T13:01:56.3283333Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3283444Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3283522Z         if len(parts) >= 4:
2026-02-14T13:01:56.3283645Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3283715Z         else:
2026-02-14T13:01:56.3283813Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3283870Z     
2026-02-14T13:01:56.3283970Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3284198Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3284264Z         import time
2026-02-14T13:01:56.3284332Z     
2026-02-14T13:01:56.3284404Z         max_retries = 5
2026-02-14T13:01:56.3284474Z         retry_delay = 2
2026-02-14T13:01:56.3284532Z     
2026-02-14T13:01:56.3284628Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3284695Z             try:
2026-02-14T13:01:56.3284797Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3284897Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3284977Z                 conn.autocommit = True
2026-02-14T13:01:56.3285040Z                 try:
2026-02-14T13:01:56.3285116Z                     cur = conn.cursor()
2026-02-14T13:01:56.3285311Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3285390Z                     if not cur.fetchone():
2026-02-14T13:01:56.3285541Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3285668Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3285739Z                     cur.close()
2026-02-14T13:01:56.3285809Z                 finally:
2026-02-14T13:01:56.3285888Z                     conn.close()
2026-02-14T13:01:56.3285958Z                 break  # Success
2026-02-14T13:01:56.3286150Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3286245Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3286323Z                     print(
2026-02-14T13:01:56.3286549Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3286614Z                     )
2026-02-14T13:01:56.3286708Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3286773Z                 else:
2026-02-14T13:01:56.3286977Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3287172Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3287241Z                     pass
2026-02-14T13:01:56.3287359Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3287439Z                 break  # Already exists
2026-02-14T13:01:56.3287509Z     
2026-02-14T13:01:56.3287730Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3287914Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3288057Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3288114Z     
2026-02-14T13:01:56.3288187Z         close_all_pools()
2026-02-14T13:01:56.3288251Z     
2026-02-14T13:01:56.3288365Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3288532Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3288672Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3288856Z             conn.autocommit = True
2026-02-14T13:01:56.3288940Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3289135Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3289310Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3289382Z                 cur.execute(
2026-02-14T13:01:56.3289445Z                     """
2026-02-14T13:01:56.3289547Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3289625Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3289720Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3289809Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3289885Z                     """
2026-02-14T13:01:56.3289943Z                 )
2026-02-14T13:01:56.3290000Z     
2026-02-14T13:01:56.3290193Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3290381Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3290444Z                 try:
2026-02-14T13:01:56.3290569Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3290648Z                     cur.execute("""
2026-02-14T13:01:56.3290717Z                         DO $$
2026-02-14T13:01:56.3290784Z                         DECLARE
2026-02-14T13:01:56.3290862Z                             r RECORD;
2026-02-14T13:01:56.3290928Z                         BEGIN
2026-02-14T13:01:56.3291001Z                             FOR r IN (
2026-02-14T13:01:56.3291236Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3291319Z                                 FROM pg_views
2026-02-14T13:01:56.3291448Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3291513Z                             )
2026-02-14T13:01:56.3291587Z                             LOOP
2026-02-14T13:01:56.3291906Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3291980Z                             END LOOP;
2026-02-14T13:01:56.3292053Z                         END $$;
2026-02-14T13:01:56.3292122Z                     """)
2026-02-14T13:01:56.3292193Z                     # Drop tables
2026-02-14T13:01:56.3292270Z                     cur.execute("""
2026-02-14T13:01:56.3292335Z                         DO $$
2026-02-14T13:01:56.3292400Z                         DECLARE
2026-02-14T13:01:56.3292468Z                             r RECORD;
2026-02-14T13:01:56.3292540Z                         BEGIN
2026-02-14T13:01:56.3292611Z                             FOR r IN (
2026-02-14T13:01:56.3292710Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3292804Z                                 FROM pg_tables
2026-02-14T13:01:56.3292933Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3292999Z                             )
2026-02-14T13:01:56.3293076Z                             LOOP
2026-02-14T13:01:56.3293389Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3293468Z                             END LOOP;
2026-02-14T13:01:56.3293533Z                         END $$;
2026-02-14T13:01:56.3293603Z                     """)
2026-02-14T13:01:56.3293685Z                 except psycopg2.Error:
2026-02-14T13:01:56.3293856Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3293930Z                     pass
2026-02-14T13:01:56.3293987Z     
2026-02-14T13:01:56.3294160Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3294275Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3294474Z                 if init_dir.exists():
2026-02-14T13:01:56.3294583Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3294675Z                     for script_path in scripts:
2026-02-14T13:01:56.3294808Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3294991Z                             sql = f.read()
2026-02-14T13:01:56.3295196Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3295332Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3295413Z                             statements = []
2026-02-14T13:01:56.3295471Z     
2026-02-14T13:01:56.3295658Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3295734Z                             do_blocks = []
2026-02-14T13:01:56.3295838Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3295898Z     
2026-02-14T13:01:56.3296007Z                             def replace_do_block(match):
2026-02-14T13:01:56.3296099Z                                 block = match.group(0)
2026-02-14T13:01:56.3296228Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3296337Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3296425Z                                 return placeholder
2026-02-14T13:01:56.3296482Z     
2026-02-14T13:01:56.3296601Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3296699Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3296781Z                                                     ^^
2026-02-14T13:01:56.3296977Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3297044Z                             )
2026-02-14T13:01:56.3297150Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3297159Z 
2026-02-14T13:01:56.3297259Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3297543Z _ ERROR at setup of TestDocumentsPage.test_only_documents_section_resumes_appear_in_job_attachment _
2026-02-14T13:01:56.3297553Z 
2026-02-14T13:01:56.3297853Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3297858Z 
2026-02-14T13:01:56.3297951Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3298058Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3298126Z         """
2026-02-14T13:01:56.3298270Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3298330Z     
2026-02-14T13:01:56.3298474Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3298601Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3298662Z         """
2026-02-14T13:01:56.3298759Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3298900Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3298959Z     
2026-02-14T13:01:56.3299070Z         # Parse connection string to get database name
2026-02-14T13:01:56.3299324Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3299387Z     
2026-02-14T13:01:56.3299575Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3299811Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3299869Z     
2026-02-14T13:01:56.3300018Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3300128Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3300213Z         if len(parts) >= 4:
2026-02-14T13:01:56.3300333Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3300395Z         else:
2026-02-14T13:01:56.3300592Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3300651Z     
2026-02-14T13:01:56.3300748Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3300976Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3301364Z         import time
2026-02-14T13:01:56.3301425Z     
2026-02-14T13:01:56.3301502Z         max_retries = 5
2026-02-14T13:01:56.3301578Z         retry_delay = 2
2026-02-14T13:01:56.3301635Z     
2026-02-14T13:01:56.3301728Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3301797Z             try:
2026-02-14T13:01:56.3301904Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3302004Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3302089Z                 conn.autocommit = True
2026-02-14T13:01:56.3302159Z                 try:
2026-02-14T13:01:56.3302241Z                     cur = conn.cursor()
2026-02-14T13:01:56.3302444Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3302526Z                     if not cur.fetchone():
2026-02-14T13:01:56.3302677Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3302801Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3302880Z                     cur.close()
2026-02-14T13:01:56.3302947Z                 finally:
2026-02-14T13:01:56.3303019Z                     conn.close()
2026-02-14T13:01:56.3303093Z                 break  # Success
2026-02-14T13:01:56.3303285Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3303380Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3303454Z                     print(
2026-02-14T13:01:56.3303679Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3303747Z                     )
2026-02-14T13:01:56.3303832Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3303903Z                 else:
2026-02-14T13:01:56.3304108Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3304297Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3304374Z                     pass
2026-02-14T13:01:56.3304493Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3304573Z                 break  # Already exists
2026-02-14T13:01:56.3304639Z     
2026-02-14T13:01:56.3304861Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3305043Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3305179Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3305242Z     
2026-02-14T13:01:56.3305319Z         close_all_pools()
2026-02-14T13:01:56.3305377Z     
2026-02-14T13:01:56.3305500Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3305664Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3305811Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3305898Z             conn.autocommit = True
2026-02-14T13:01:56.3305977Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3306172Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3306262Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3306341Z                 cur.execute(
2026-02-14T13:01:56.3306408Z                     """
2026-02-14T13:01:56.3306512Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3306600Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3306696Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3306901Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3306975Z                     """
2026-02-14T13:01:56.3307035Z                 )
2026-02-14T13:01:56.3307093Z     
2026-02-14T13:01:56.3307283Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3307606Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3307671Z                 try:
2026-02-14T13:01:56.3307788Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3307869Z                     cur.execute("""
2026-02-14T13:01:56.3307938Z                         DO $$
2026-02-14T13:01:56.3308004Z                         DECLARE
2026-02-14T13:01:56.3308082Z                             r RECORD;
2026-02-14T13:01:56.3308148Z                         BEGIN
2026-02-14T13:01:56.3308219Z                             FOR r IN (
2026-02-14T13:01:56.3308325Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3308410Z                                 FROM pg_views
2026-02-14T13:01:56.3308539Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3308603Z                             )
2026-02-14T13:01:56.3308684Z                             LOOP
2026-02-14T13:01:56.3308999Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3309070Z                             END LOOP;
2026-02-14T13:01:56.3309144Z                         END $$;
2026-02-14T13:01:56.3309210Z                     """)
2026-02-14T13:01:56.3309281Z                     # Drop tables
2026-02-14T13:01:56.3309354Z                     cur.execute("""
2026-02-14T13:01:56.3309424Z                         DO $$
2026-02-14T13:01:56.3309488Z                         DECLARE
2026-02-14T13:01:56.3309556Z                             r RECORD;
2026-02-14T13:01:56.3309628Z                         BEGIN
2026-02-14T13:01:56.3309699Z                             FOR r IN (
2026-02-14T13:01:56.3309803Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3309886Z                                 FROM pg_tables
2026-02-14T13:01:56.3310022Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3310089Z                             )
2026-02-14T13:01:56.3310157Z                             LOOP
2026-02-14T13:01:56.3310475Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3310547Z                             END LOOP;
2026-02-14T13:01:56.3310612Z                         END $$;
2026-02-14T13:01:56.3310682Z                     """)
2026-02-14T13:01:56.3310763Z                 except psycopg2.Error:
2026-02-14T13:01:56.3310945Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3311014Z                     pass
2026-02-14T13:01:56.3311202Z     
2026-02-14T13:01:56.3311377Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3311489Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3311575Z                 if init_dir.exists():
2026-02-14T13:01:56.3311679Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3311769Z                     for script_path in scripts:
2026-02-14T13:01:56.3311902Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3311979Z                             sql = f.read()
2026-02-14T13:01:56.3312185Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3312316Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3312402Z                             statements = []
2026-02-14T13:01:56.3312575Z     
2026-02-14T13:01:56.3312759Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3312840Z                             do_blocks = []
2026-02-14T13:01:56.3313044Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3313101Z     
2026-02-14T13:01:56.3313205Z                             def replace_do_block(match):
2026-02-14T13:01:56.3313297Z                                 block = match.group(0)
2026-02-14T13:01:56.3313424Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3313525Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3313614Z                                 return placeholder
2026-02-14T13:01:56.3313671Z     
2026-02-14T13:01:56.3313781Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3313884Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3313970Z                                                     ^^
2026-02-14T13:01:56.3314156Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3314227Z                             )
2026-02-14T13:01:56.3314341Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3314347Z 
2026-02-14T13:01:56.3314447Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3314749Z _ ERROR at setup of TestDocumentsPage.test_only_documents_section_cover_letters_appear_in_job_attachment _
2026-02-14T13:01:56.3314754Z 
2026-02-14T13:01:56.3315048Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3315053Z 
2026-02-14T13:01:56.3315141Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3315247Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3315309Z         """
2026-02-14T13:01:56.3315454Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3315512Z     
2026-02-14T13:01:56.3315644Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3315779Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3315843Z         """
2026-02-14T13:01:56.3315939Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3316074Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3316133Z     
2026-02-14T13:01:56.3316238Z         # Parse connection string to get database name
2026-02-14T13:01:56.3316483Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3316549Z     
2026-02-14T13:01:56.3316733Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3316963Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3317026Z     
2026-02-14T13:01:56.3317173Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3317283Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3317364Z         if len(parts) >= 4:
2026-02-14T13:01:56.3317484Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3317552Z         else:
2026-02-14T13:01:56.3317651Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3317716Z     
2026-02-14T13:01:56.3317809Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3318033Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3318104Z         import time
2026-02-14T13:01:56.3318160Z     
2026-02-14T13:01:56.3318226Z         max_retries = 5
2026-02-14T13:01:56.3318293Z         retry_delay = 2
2026-02-14T13:01:56.3318358Z     
2026-02-14T13:01:56.3318444Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3318506Z             try:
2026-02-14T13:01:56.3318697Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3318796Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3318876Z                 conn.autocommit = True
2026-02-14T13:01:56.3319018Z                 try:
2026-02-14T13:01:56.3319100Z                     cur = conn.cursor()
2026-02-14T13:01:56.3319288Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3319367Z                     if not cur.fetchone():
2026-02-14T13:01:56.3319523Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3319639Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3319708Z                     cur.close()
2026-02-14T13:01:56.3319782Z                 finally:
2026-02-14T13:01:56.3319863Z                     conn.close()
2026-02-14T13:01:56.3319934Z                 break  # Success
2026-02-14T13:01:56.3320130Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3320227Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3320295Z                     print(
2026-02-14T13:01:56.3320512Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3320582Z                     )
2026-02-14T13:01:56.3320672Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3320737Z                 else:
2026-02-14T13:01:56.3320939Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3321376Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3321454Z                     pass
2026-02-14T13:01:56.3321572Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3321657Z                 break  # Already exists
2026-02-14T13:01:56.3321717Z     
2026-02-14T13:01:56.3321936Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3322118Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3322254Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3322319Z     
2026-02-14T13:01:56.3322390Z         close_all_pools()
2026-02-14T13:01:56.3322459Z     
2026-02-14T13:01:56.3322574Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3322734Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3322878Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3322959Z             conn.autocommit = True
2026-02-14T13:01:56.3323038Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3323229Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3323330Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3323403Z                 cur.execute(
2026-02-14T13:01:56.3323467Z                     """
2026-02-14T13:01:56.3323569Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3323649Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3323748Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3323843Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3323905Z                     """
2026-02-14T13:01:56.3323966Z                 )
2026-02-14T13:01:56.3324026Z     
2026-02-14T13:01:56.3324218Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3324401Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3324464Z                 try:
2026-02-14T13:01:56.3324586Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3324659Z                     cur.execute("""
2026-02-14T13:01:56.3324866Z                         DO $$
2026-02-14T13:01:56.3324937Z                         DECLARE
2026-02-14T13:01:56.3325016Z                             r RECORD;
2026-02-14T13:01:56.3325081Z                         BEGIN
2026-02-14T13:01:56.3325256Z                             FOR r IN (
2026-02-14T13:01:56.3325365Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3325445Z                                 FROM pg_views
2026-02-14T13:01:56.3325573Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3325642Z                             )
2026-02-14T13:01:56.3325713Z                             LOOP
2026-02-14T13:01:56.3326023Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3326094Z                             END LOOP;
2026-02-14T13:01:56.3326166Z                         END $$;
2026-02-14T13:01:56.3326234Z                     """)
2026-02-14T13:01:56.3326306Z                     # Drop tables
2026-02-14T13:01:56.3326384Z                     cur.execute("""
2026-02-14T13:01:56.3326448Z                         DO $$
2026-02-14T13:01:56.3326512Z                         DECLARE
2026-02-14T13:01:56.3326591Z                             r RECORD;
2026-02-14T13:01:56.3326656Z                         BEGIN
2026-02-14T13:01:56.3326727Z                             FOR r IN (
2026-02-14T13:01:56.3326827Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3326915Z                                 FROM pg_tables
2026-02-14T13:01:56.3327039Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3327104Z                             )
2026-02-14T13:01:56.3327176Z                             LOOP
2026-02-14T13:01:56.3327489Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3327562Z                             END LOOP;
2026-02-14T13:01:56.3327636Z                         END $$;
2026-02-14T13:01:56.3327701Z                     """)
2026-02-14T13:01:56.3327784Z                 except psycopg2.Error:
2026-02-14T13:01:56.3327960Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3328033Z                     pass
2026-02-14T13:01:56.3328089Z     
2026-02-14T13:01:56.3328259Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3328372Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3328450Z                 if init_dir.exists():
2026-02-14T13:01:56.3328552Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3328647Z                     for script_path in scripts:
2026-02-14T13:01:56.3328774Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3328855Z                             sql = f.read()
2026-02-14T13:01:56.3329059Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3329196Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3329277Z                             statements = []
2026-02-14T13:01:56.3329334Z     
2026-02-14T13:01:56.3329517Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3329592Z                             do_blocks = []
2026-02-14T13:01:56.3329695Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3329758Z     
2026-02-14T13:01:56.3329856Z                             def replace_do_block(match):
2026-02-14T13:01:56.3329946Z                                 block = match.group(0)
2026-02-14T13:01:56.3330071Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3330263Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3330353Z                                 return placeholder
2026-02-14T13:01:56.3330409Z     
2026-02-14T13:01:56.3330524Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3330700Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3330783Z                                                     ^^
2026-02-14T13:01:56.3330974Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3331174Z                             )
2026-02-14T13:01:56.3331284Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3331290Z 
2026-02-14T13:01:56.3331395Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3331588Z ______ ERROR at setup of TestDocumentsPage.test_delete_nonexistent_resume ______
2026-02-14T13:01:56.3331593Z 
2026-02-14T13:01:56.3331892Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3331897Z 
2026-02-14T13:01:56.3331985Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3332090Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3332162Z         """
2026-02-14T13:01:56.3332306Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3332365Z     
2026-02-14T13:01:56.3332505Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3332631Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3332691Z         """
2026-02-14T13:01:56.3332788Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3332921Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3332978Z     
2026-02-14T13:01:56.3333085Z         # Parse connection string to get database name
2026-02-14T13:01:56.3333334Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3333396Z     
2026-02-14T13:01:56.3333584Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3333816Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3333880Z     
2026-02-14T13:01:56.3334023Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3334131Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3334214Z         if len(parts) >= 4:
2026-02-14T13:01:56.3334332Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3334393Z         else:
2026-02-14T13:01:56.3334496Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3334553Z     
2026-02-14T13:01:56.3334647Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3334878Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3334948Z         import time
2026-02-14T13:01:56.3335004Z     
2026-02-14T13:01:56.3335069Z         max_retries = 5
2026-02-14T13:01:56.3335142Z         retry_delay = 2
2026-02-14T13:01:56.3335197Z     
2026-02-14T13:01:56.3335283Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3335353Z             try:
2026-02-14T13:01:56.3335452Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3335545Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3335624Z                 conn.autocommit = True
2026-02-14T13:01:56.3335691Z                 try:
2026-02-14T13:01:56.3335766Z                     cur = conn.cursor()
2026-02-14T13:01:56.3335952Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3336036Z                     if not cur.fetchone():
2026-02-14T13:01:56.3336184Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3336421Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3336501Z                     cur.close()
2026-02-14T13:01:56.3336566Z                 finally:
2026-02-14T13:01:56.3336636Z                     conn.close()
2026-02-14T13:01:56.3336807Z                 break  # Success
2026-02-14T13:01:56.3337000Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3337087Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3337159Z                     print(
2026-02-14T13:01:56.3337382Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3337445Z                     )
2026-02-14T13:01:56.3337526Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3337594Z                 else:
2026-02-14T13:01:56.3337801Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3337987Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3338055Z                     pass
2026-02-14T13:01:56.3338174Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3338250Z                 break  # Already exists
2026-02-14T13:01:56.3338312Z     
2026-02-14T13:01:56.3338535Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3338715Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3338847Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3338909Z     
2026-02-14T13:01:56.3338981Z         close_all_pools()
2026-02-14T13:01:56.3339038Z     
2026-02-14T13:01:56.3339155Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3339320Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3339462Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3339542Z             conn.autocommit = True
2026-02-14T13:01:56.3339625Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3339815Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3339910Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3339987Z                 cur.execute(
2026-02-14T13:01:56.3340051Z                     """
2026-02-14T13:01:56.3340148Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3340226Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3340327Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3340417Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3340481Z                     """
2026-02-14T13:01:56.3340545Z                 )
2026-02-14T13:01:56.3340602Z     
2026-02-14T13:01:56.3340794Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3340978Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3341203Z                 try:
2026-02-14T13:01:56.3341376Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3341458Z                     cur.execute("""
2026-02-14T13:01:56.3341532Z                         DO $$
2026-02-14T13:01:56.3341599Z                         DECLARE
2026-02-14T13:01:56.3341671Z                             r RECORD;
2026-02-14T13:01:56.3341744Z                         BEGIN
2026-02-14T13:01:56.3341816Z                             FOR r IN (
2026-02-14T13:01:56.3341918Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3341997Z                                 FROM pg_views
2026-02-14T13:01:56.3342131Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3342197Z                             )
2026-02-14T13:01:56.3342388Z                             LOOP
2026-02-14T13:01:56.3342710Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3342784Z                             END LOOP;
2026-02-14T13:01:56.3342952Z                         END $$;
2026-02-14T13:01:56.3343023Z                     """)
2026-02-14T13:01:56.3343095Z                     # Drop tables
2026-02-14T13:01:56.3343170Z                     cur.execute("""
2026-02-14T13:01:56.3343235Z                         DO $$
2026-02-14T13:01:56.3343307Z                         DECLARE
2026-02-14T13:01:56.3343378Z                             r RECORD;
2026-02-14T13:01:56.3343444Z                         BEGIN
2026-02-14T13:01:56.3343523Z                             FOR r IN (
2026-02-14T13:01:56.3343622Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3343704Z                                 FROM pg_tables
2026-02-14T13:01:56.3343840Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3343907Z                             )
2026-02-14T13:01:56.3343975Z                             LOOP
2026-02-14T13:01:56.3344287Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3344373Z                             END LOOP;
2026-02-14T13:01:56.3344437Z                         END $$;
2026-02-14T13:01:56.3344503Z                     """)
2026-02-14T13:01:56.3344589Z                 except psycopg2.Error:
2026-02-14T13:01:56.3344761Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3344828Z                     pass
2026-02-14T13:01:56.3344889Z     
2026-02-14T13:01:56.3345056Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3345165Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3345242Z                 if init_dir.exists():
2026-02-14T13:01:56.3345352Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3345441Z                     for script_path in scripts:
2026-02-14T13:01:56.3345569Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3345650Z                             sql = f.read()
2026-02-14T13:01:56.3345854Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3345983Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3346066Z                             statements = []
2026-02-14T13:01:56.3346122Z     
2026-02-14T13:01:56.3346298Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3346374Z                             do_blocks = []
2026-02-14T13:01:56.3346484Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3346540Z     
2026-02-14T13:01:56.3346635Z                             def replace_do_block(match):
2026-02-14T13:01:56.3346729Z                                 block = match.group(0)
2026-02-14T13:01:56.3346854Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3346951Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3347040Z                                 return placeholder
2026-02-14T13:01:56.3347096Z     
2026-02-14T13:01:56.3347201Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3347296Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3347383Z                                                     ^^
2026-02-14T13:01:56.3347566Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3347633Z                             )
2026-02-14T13:01:56.3347833Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3347839Z 
2026-02-14T13:01:56.3347940Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3348138Z ___ ERROR at setup of TestDocumentsPage.test_delete_nonexistent_cover_letter ___
2026-02-14T13:01:56.3348217Z 
2026-02-14T13:01:56.3348515Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3348520Z 
2026-02-14T13:01:56.3348613Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3348716Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3348778Z         """
2026-02-14T13:01:56.3348909Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3348972Z     
2026-02-14T13:01:56.3349105Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3349229Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3349294Z         """
2026-02-14T13:01:56.3349386Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3349514Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3349576Z     
2026-02-14T13:01:56.3349682Z         # Parse connection string to get database name
2026-02-14T13:01:56.3349922Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3349984Z     
2026-02-14T13:01:56.3350173Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3350399Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3350457Z     
2026-02-14T13:01:56.3350605Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3350711Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3350785Z         if len(parts) >= 4:
2026-02-14T13:01:56.3350908Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3350969Z         else:
2026-02-14T13:01:56.3351193Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3351252Z     
2026-02-14T13:01:56.3351355Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3351580Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3351650Z         import time
2026-02-14T13:01:56.3351713Z     
2026-02-14T13:01:56.3351780Z         max_retries = 5
2026-02-14T13:01:56.3351847Z         retry_delay = 2
2026-02-14T13:01:56.3351904Z     
2026-02-14T13:01:56.3351995Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3352057Z             try:
2026-02-14T13:01:56.3352156Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3352254Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3352334Z                 conn.autocommit = True
2026-02-14T13:01:56.3352397Z                 try:
2026-02-14T13:01:56.3352479Z                     cur = conn.cursor()
2026-02-14T13:01:56.3352668Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3352748Z                     if not cur.fetchone():
2026-02-14T13:01:56.3352897Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3353024Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3353094Z                     cur.close()
2026-02-14T13:01:56.3353162Z                 finally:
2026-02-14T13:01:56.3353240Z                     conn.close()
2026-02-14T13:01:56.3353310Z                 break  # Success
2026-02-14T13:01:56.3353498Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3353591Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3353661Z                     print(
2026-02-14T13:01:56.3353879Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3354104Z                     )
2026-02-14T13:01:56.3354199Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3354264Z                 else:
2026-02-14T13:01:56.3354475Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3354790Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3354858Z                     pass
2026-02-14T13:01:56.3354975Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3355058Z                 break  # Already exists
2026-02-14T13:01:56.3355115Z     
2026-02-14T13:01:56.3355330Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3355510Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3355646Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3355704Z     
2026-02-14T13:01:56.3355780Z         close_all_pools()
2026-02-14T13:01:56.3355842Z     
2026-02-14T13:01:56.3355961Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3356121Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3356269Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3356348Z             conn.autocommit = True
2026-02-14T13:01:56.3356425Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3356614Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3356709Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3356780Z                 cur.execute(
2026-02-14T13:01:56.3356843Z                     """
2026-02-14T13:01:56.3356944Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3357023Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3357118Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3357213Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3357275Z                     """
2026-02-14T13:01:56.3357335Z                 )
2026-02-14T13:01:56.3357393Z     
2026-02-14T13:01:56.3357591Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3357774Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3357838Z                 try:
2026-02-14T13:01:56.3357959Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3358034Z                     cur.execute("""
2026-02-14T13:01:56.3358100Z                         DO $$
2026-02-14T13:01:56.3358169Z                         DECLARE
2026-02-14T13:01:56.3358245Z                             r RECORD;
2026-02-14T13:01:56.3358312Z                         BEGIN
2026-02-14T13:01:56.3358383Z                             FOR r IN (
2026-02-14T13:01:56.3358492Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3358572Z                                 FROM pg_views
2026-02-14T13:01:56.3358697Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3358771Z                             )
2026-02-14T13:01:56.3358839Z                             LOOP
2026-02-14T13:01:56.3359149Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3359228Z                             END LOOP;
2026-02-14T13:01:56.3359294Z                         END $$;
2026-02-14T13:01:56.3359359Z                     """)
2026-02-14T13:01:56.3359433Z                     # Drop tables
2026-02-14T13:01:56.3359511Z                     cur.execute("""
2026-02-14T13:01:56.3359576Z                         DO $$
2026-02-14T13:01:56.3359643Z                         DECLARE
2026-02-14T13:01:56.3359717Z                             r RECORD;
2026-02-14T13:01:56.3359869Z                         BEGIN
2026-02-14T13:01:56.3359944Z                             FOR r IN (
2026-02-14T13:01:56.3360046Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3360134Z                                 FROM pg_tables
2026-02-14T13:01:56.3360334Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3360399Z                             )
2026-02-14T13:01:56.3360474Z                             LOOP
2026-02-14T13:01:56.3360788Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3360858Z                             END LOOP;
2026-02-14T13:01:56.3360931Z                         END $$;
2026-02-14T13:01:56.3360995Z                     """)
2026-02-14T13:01:56.3361310Z                 except psycopg2.Error:
2026-02-14T13:01:56.3361519Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3361594Z                     pass
2026-02-14T13:01:56.3361652Z     
2026-02-14T13:01:56.3361823Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3361943Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3362018Z                 if init_dir.exists():
2026-02-14T13:01:56.3362122Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3362217Z                     for script_path in scripts:
2026-02-14T13:01:56.3362345Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3362420Z                             sql = f.read()
2026-02-14T13:01:56.3362625Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3362761Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3362842Z                             statements = []
2026-02-14T13:01:56.3362899Z     
2026-02-14T13:01:56.3363085Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3363160Z                             do_blocks = []
2026-02-14T13:01:56.3363265Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3363337Z     
2026-02-14T13:01:56.3363434Z                             def replace_do_block(match):
2026-02-14T13:01:56.3363526Z                                 block = match.group(0)
2026-02-14T13:01:56.3363651Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3363751Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3363839Z                                 return placeholder
2026-02-14T13:01:56.3363896Z     
2026-02-14T13:01:56.3364011Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3364114Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3364195Z                                                     ^^
2026-02-14T13:01:56.3364387Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3364458Z                             )
2026-02-14T13:01:56.3364568Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3364574Z 
2026-02-14T13:01:56.3364681Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3364874Z _____ ERROR at setup of TestDocumentsPage.test_get_resume_by_id_not_found ______
2026-02-14T13:01:56.3364879Z 
2026-02-14T13:01:56.3365178Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3365184Z 
2026-02-14T13:01:56.3365273Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3365381Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3365447Z         """
2026-02-14T13:01:56.3365717Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3365778Z     
2026-02-14T13:01:56.3365918Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3366044Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3366205Z         """
2026-02-14T13:01:56.3366300Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3366430Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3366486Z     
2026-02-14T13:01:56.3366592Z         # Parse connection string to get database name
2026-02-14T13:01:56.3366840Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3366901Z     
2026-02-14T13:01:56.3367087Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3367316Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3367372Z     
2026-02-14T13:01:56.3367520Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3367629Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3367709Z         if len(parts) >= 4:
2026-02-14T13:01:56.3367826Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3367891Z         else:
2026-02-14T13:01:56.3367995Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3368051Z     
2026-02-14T13:01:56.3368145Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3368377Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3368443Z         import time
2026-02-14T13:01:56.3368500Z     
2026-02-14T13:01:56.3368567Z         max_retries = 5
2026-02-14T13:01:56.3368640Z         retry_delay = 2
2026-02-14T13:01:56.3368700Z     
2026-02-14T13:01:56.3368784Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3368851Z             try:
2026-02-14T13:01:56.3368955Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3369047Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3369128Z                 conn.autocommit = True
2026-02-14T13:01:56.3369195Z                 try:
2026-02-14T13:01:56.3369275Z                     cur = conn.cursor()
2026-02-14T13:01:56.3369461Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3369546Z                     if not cur.fetchone():
2026-02-14T13:01:56.3369697Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3369814Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3369891Z                     cur.close()
2026-02-14T13:01:56.3369957Z                 finally:
2026-02-14T13:01:56.3370032Z                     conn.close()
2026-02-14T13:01:56.3370101Z                 break  # Success
2026-02-14T13:01:56.3370300Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3370389Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3370458Z                     print(
2026-02-14T13:01:56.3370679Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3370748Z                     )
2026-02-14T13:01:56.3370831Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3370898Z                 else:
2026-02-14T13:01:56.3371233Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3371416Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3371483Z                     pass
2026-02-14T13:01:56.3371607Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3371684Z                 break  # Already exists
2026-02-14T13:01:56.3371740Z     
2026-02-14T13:01:56.3372077Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3372260Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3372388Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3373033Z     
2026-02-14T13:01:56.3373106Z         close_all_pools()
2026-02-14T13:01:56.3373163Z     
2026-02-14T13:01:56.3373278Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3373448Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3373586Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3373666Z             conn.autocommit = True
2026-02-14T13:01:56.3373754Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3373946Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3374038Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3374120Z                 cur.execute(
2026-02-14T13:01:56.3374185Z                     """
2026-02-14T13:01:56.3374282Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3374362Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3374467Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3374556Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3374620Z                     """
2026-02-14T13:01:56.3374686Z                 )
2026-02-14T13:01:56.3374744Z     
2026-02-14T13:01:56.3374936Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3375124Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3375189Z                 try:
2026-02-14T13:01:56.3375307Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3375382Z                     cur.execute("""
2026-02-14T13:01:56.3375459Z                         DO $$
2026-02-14T13:01:56.3375528Z                         DECLARE
2026-02-14T13:01:56.3375599Z                             r RECORD;
2026-02-14T13:01:56.3375671Z                         BEGIN
2026-02-14T13:01:56.3375752Z                             FOR r IN (
2026-02-14T13:01:56.3375853Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3375933Z                                 FROM pg_views
2026-02-14T13:01:56.3376066Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3376131Z                             )
2026-02-14T13:01:56.3376201Z                             LOOP
2026-02-14T13:01:56.3376517Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3376592Z                             END LOOP;
2026-02-14T13:01:56.3376660Z                         END $$;
2026-02-14T13:01:56.3376735Z                     """)
2026-02-14T13:01:56.3376806Z                     # Drop tables
2026-02-14T13:01:56.3376914Z                     cur.execute("""
2026-02-14T13:01:56.3376981Z                         DO $$
2026-02-14T13:01:56.3377056Z                         DECLARE
2026-02-14T13:01:56.3377129Z                             r RECORD;
2026-02-14T13:01:56.3377194Z                         BEGIN
2026-02-14T13:01:56.3377269Z                             FOR r IN (
2026-02-14T13:01:56.3377369Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3377450Z                                 FROM pg_tables
2026-02-14T13:01:56.3377580Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3377643Z                             )
2026-02-14T13:01:56.3377711Z                             LOOP
2026-02-14T13:01:56.3378112Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3378192Z                             END LOOP;
2026-02-14T13:01:56.3378257Z                         END $$;
2026-02-14T13:01:56.3378323Z                     """)
2026-02-14T13:01:56.3378410Z                 except psycopg2.Error:
2026-02-14T13:01:56.3378659Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3378726Z                     pass
2026-02-14T13:01:56.3378789Z     
2026-02-14T13:01:56.3378955Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3379063Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3379138Z                 if init_dir.exists():
2026-02-14T13:01:56.3379251Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3379339Z                     for script_path in scripts:
2026-02-14T13:01:56.3379462Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3379547Z                             sql = f.read()
2026-02-14T13:01:56.3379748Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3379879Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3379965Z                             statements = []
2026-02-14T13:01:56.3380025Z     
2026-02-14T13:01:56.3380198Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3380273Z                             do_blocks = []
2026-02-14T13:01:56.3380379Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3380435Z     
2026-02-14T13:01:56.3380531Z                             def replace_do_block(match):
2026-02-14T13:01:56.3380625Z                                 block = match.group(0)
2026-02-14T13:01:56.3380750Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3380851Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3380944Z                                 return placeholder
2026-02-14T13:01:56.3381002Z     
2026-02-14T13:01:56.3381325Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3381439Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3381529Z                                                     ^^
2026-02-14T13:01:56.3381713Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3381780Z                             )
2026-02-14T13:01:56.3381892Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3381897Z 
2026-02-14T13:01:56.3381997Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3382195Z __ ERROR at setup of TestDocumentsPage.test_get_cover_letter_by_id_not_found ___
2026-02-14T13:01:56.3382201Z 
2026-02-14T13:01:56.3382500Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3382506Z 
2026-02-14T13:01:56.3382600Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3382708Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3382767Z         """
2026-02-14T13:01:56.3382911Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3382969Z     
2026-02-14T13:01:56.3383099Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3383222Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3383287Z         """
2026-02-14T13:01:56.3383381Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3383506Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3383569Z     
2026-02-14T13:01:56.3383673Z         # Parse connection string to get database name
2026-02-14T13:01:56.3383912Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3384093Z     
2026-02-14T13:01:56.3384286Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3384512Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3384669Z     
2026-02-14T13:01:56.3384817Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3384924Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3384998Z         if len(parts) >= 4:
2026-02-14T13:01:56.3385121Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3385189Z         else:
2026-02-14T13:01:56.3385288Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3385345Z     
2026-02-14T13:01:56.3385446Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3385672Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3385742Z         import time
2026-02-14T13:01:56.3385804Z     
2026-02-14T13:01:56.3385872Z         max_retries = 5
2026-02-14T13:01:56.3385940Z         retry_delay = 2
2026-02-14T13:01:56.3386004Z     
2026-02-14T13:01:56.3386092Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3386159Z             try:
2026-02-14T13:01:56.3386258Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3386358Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3386442Z                 conn.autocommit = True
2026-02-14T13:01:56.3386506Z                 try:
2026-02-14T13:01:56.3386588Z                     cur = conn.cursor()
2026-02-14T13:01:56.3386778Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3386858Z                     if not cur.fetchone():
2026-02-14T13:01:56.3387007Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3387136Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3387207Z                     cur.close()
2026-02-14T13:01:56.3387273Z                 finally:
2026-02-14T13:01:56.3387353Z                     conn.close()
2026-02-14T13:01:56.3387427Z                 break  # Success
2026-02-14T13:01:56.3387614Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3387709Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3387778Z                     print(
2026-02-14T13:01:56.3387990Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3388054Z                     )
2026-02-14T13:01:56.3388146Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3388208Z                 else:
2026-02-14T13:01:56.3388409Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3388599Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3388667Z                     pass
2026-02-14T13:01:56.3388781Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3388863Z                 break  # Already exists
2026-02-14T13:01:56.3388924Z     
2026-02-14T13:01:56.3389137Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3389315Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3389449Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3389509Z     
2026-02-14T13:01:56.3389580Z         close_all_pools()
2026-02-14T13:01:56.3389642Z     
2026-02-14T13:01:56.3389766Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3389927Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3390154Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3390236Z             conn.autocommit = True
2026-02-14T13:01:56.3390314Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3390505Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3390680Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3390751Z                 cur.execute(
2026-02-14T13:01:56.3390813Z                     """
2026-02-14T13:01:56.3390912Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3390990Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3391199Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3391294Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3391359Z                     """
2026-02-14T13:01:56.3391419Z                 )
2026-02-14T13:01:56.3391476Z     
2026-02-14T13:01:56.3391672Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3391858Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3391922Z                 try:
2026-02-14T13:01:56.3392044Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3392123Z                     cur.execute("""
2026-02-14T13:01:56.3392191Z                         DO $$
2026-02-14T13:01:56.3392262Z                         DECLARE
2026-02-14T13:01:56.3392333Z                             r RECORD;
2026-02-14T13:01:56.3392400Z                         BEGIN
2026-02-14T13:01:56.3392472Z                             FOR r IN (
2026-02-14T13:01:56.3392575Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3392655Z                                 FROM pg_views
2026-02-14T13:01:56.3392781Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3392851Z                             )
2026-02-14T13:01:56.3392925Z                             LOOP
2026-02-14T13:01:56.3393232Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3393308Z                             END LOOP;
2026-02-14T13:01:56.3393378Z                         END $$;
2026-02-14T13:01:56.3393442Z                     """)
2026-02-14T13:01:56.3393514Z                     # Drop tables
2026-02-14T13:01:56.3393592Z                     cur.execute("""
2026-02-14T13:01:56.3393660Z                         DO $$
2026-02-14T13:01:56.3393725Z                         DECLARE
2026-02-14T13:01:56.3393798Z                             r RECORD;
2026-02-14T13:01:56.3393863Z                         BEGIN
2026-02-14T13:01:56.3393933Z                             FOR r IN (
2026-02-14T13:01:56.3394031Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3394119Z                                 FROM pg_tables
2026-02-14T13:01:56.3394246Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3394310Z                             )
2026-02-14T13:01:56.3394384Z                             LOOP
2026-02-14T13:01:56.3394694Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3394769Z                             END LOOP;
2026-02-14T13:01:56.3394840Z                         END $$;
2026-02-14T13:01:56.3394902Z                     """)
2026-02-14T13:01:56.3394986Z                 except psycopg2.Error:
2026-02-14T13:01:56.3395159Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3395231Z                     pass
2026-02-14T13:01:56.3395291Z     
2026-02-14T13:01:56.3395458Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3395571Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3395768Z                 if init_dir.exists():
2026-02-14T13:01:56.3395874Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3395969Z                     for script_path in scripts:
2026-02-14T13:01:56.3396092Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3396270Z                             sql = f.read()
2026-02-14T13:01:56.3396477Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3396615Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3396693Z                             statements = []
2026-02-14T13:01:56.3396751Z     
2026-02-14T13:01:56.3396934Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3397008Z                             do_blocks = []
2026-02-14T13:01:56.3397109Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3397181Z     
2026-02-14T13:01:56.3397278Z                             def replace_do_block(match):
2026-02-14T13:01:56.3397369Z                                 block = match.group(0)
2026-02-14T13:01:56.3397494Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3397603Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3397689Z                                 return placeholder
2026-02-14T13:01:56.3397748Z     
2026-02-14T13:01:56.3397861Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3397959Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3398039Z                                                     ^^
2026-02-14T13:01:56.3398230Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3398297Z                             )
2026-02-14T13:01:56.3398412Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3398417Z 
2026-02-14T13:01:56.3398524Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3398736Z _ ERROR at setup of TestDocumentsPage.test_download_text_based_cover_letter_fails _
2026-02-14T13:01:56.3398746Z 
2026-02-14T13:01:56.3399035Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3399040Z 
2026-02-14T13:01:56.3399130Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3399236Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3399301Z         """
2026-02-14T13:01:56.3399434Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3399491Z     
2026-02-14T13:01:56.3399628Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3399752Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3399811Z         """
2026-02-14T13:01:56.3399919Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3400050Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3400107Z     
2026-02-14T13:01:56.3400211Z         # Parse connection string to get database name
2026-02-14T13:01:56.3400457Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3400524Z     
2026-02-14T13:01:56.3400710Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3400941Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3400999Z     
2026-02-14T13:01:56.3401416Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3401536Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3401611Z         if len(parts) >= 4:
2026-02-14T13:01:56.3401729Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3401790Z         else:
2026-02-14T13:01:56.3402076Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3402139Z     
2026-02-14T13:01:56.3402241Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3402481Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3402653Z         import time
2026-02-14T13:01:56.3402712Z     
2026-02-14T13:01:56.3402780Z         max_retries = 5
2026-02-14T13:01:56.3402852Z         retry_delay = 2
2026-02-14T13:01:56.3402909Z     
2026-02-14T13:01:56.3402995Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3403061Z             try:
2026-02-14T13:01:56.3403163Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3403256Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3403339Z                 conn.autocommit = True
2026-02-14T13:01:56.3403408Z                 try:
2026-02-14T13:01:56.3403486Z                     cur = conn.cursor()
2026-02-14T13:01:56.3403681Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3403767Z                     if not cur.fetchone():
2026-02-14T13:01:56.3403919Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3404042Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3404118Z                     cur.close()
2026-02-14T13:01:56.3404185Z                 finally:
2026-02-14T13:01:56.3404255Z                     conn.close()
2026-02-14T13:01:56.3404325Z                 break  # Success
2026-02-14T13:01:56.3404517Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3404605Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3404674Z                     print(
2026-02-14T13:01:56.3404896Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3404966Z                     )
2026-02-14T13:01:56.3405048Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3405117Z                 else:
2026-02-14T13:01:56.3405324Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3405509Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3405581Z                     pass
2026-02-14T13:01:56.3405695Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3405772Z                 break  # Already exists
2026-02-14T13:01:56.3405829Z     
2026-02-14T13:01:56.3406053Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3406237Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3406368Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3406432Z     
2026-02-14T13:01:56.3406509Z         close_all_pools()
2026-02-14T13:01:56.3406566Z     
2026-02-14T13:01:56.3406681Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3406851Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3406993Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3407073Z             conn.autocommit = True
2026-02-14T13:01:56.3407159Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3407350Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3407442Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3407519Z                 cur.execute(
2026-02-14T13:01:56.3407589Z                     """
2026-02-14T13:01:56.3407684Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3407769Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3407961Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3408054Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3408121Z                     """
2026-02-14T13:01:56.3408186Z                 )
2026-02-14T13:01:56.3408244Z     
2026-02-14T13:01:56.3408513Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3408702Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3408767Z                 try:
2026-02-14T13:01:56.3408884Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3408960Z                     cur.execute("""
2026-02-14T13:01:56.3409037Z                         DO $$
2026-02-14T13:01:56.3409108Z                         DECLARE
2026-02-14T13:01:56.3409181Z                             r RECORD;
2026-02-14T13:01:56.3409254Z                         BEGIN
2026-02-14T13:01:56.3409324Z                             FOR r IN (
2026-02-14T13:01:56.3409426Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3409515Z                                 FROM pg_views
2026-02-14T13:01:56.3409646Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3409717Z                             )
2026-02-14T13:01:56.3409786Z                             LOOP
2026-02-14T13:01:56.3410103Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3410174Z                             END LOOP;
2026-02-14T13:01:56.3410241Z                         END $$;
2026-02-14T13:01:56.3410309Z                     """)
2026-02-14T13:01:56.3410379Z                     # Drop tables
2026-02-14T13:01:56.3410451Z                     cur.execute("""
2026-02-14T13:01:56.3410518Z                         DO $$
2026-02-14T13:01:56.3410586Z                         DECLARE
2026-02-14T13:01:56.3410654Z                             r RECORD;
2026-02-14T13:01:56.3410721Z                         BEGIN
2026-02-14T13:01:56.3410798Z                             FOR r IN (
2026-02-14T13:01:56.3410895Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3410977Z                                 FROM pg_tables
2026-02-14T13:01:56.3411235Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3411300Z                             )
2026-02-14T13:01:56.3411369Z                             LOOP
2026-02-14T13:01:56.3411683Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3411758Z                             END LOOP;
2026-02-14T13:01:56.3411822Z                         END $$;
2026-02-14T13:01:56.3411885Z                     """)
2026-02-14T13:01:56.3411972Z                 except psycopg2.Error:
2026-02-14T13:01:56.3412154Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3412220Z                     pass
2026-02-14T13:01:56.3412281Z     
2026-02-14T13:01:56.3412446Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3412558Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3412635Z                 if init_dir.exists():
2026-02-14T13:01:56.3412746Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3412835Z                     for script_path in scripts:
2026-02-14T13:01:56.3412959Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3413041Z                             sql = f.read()
2026-02-14T13:01:56.3413245Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3413375Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3413577Z                             statements = []
2026-02-14T13:01:56.3413636Z     
2026-02-14T13:01:56.3413812Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3413892Z                             do_blocks = []
2026-02-14T13:01:56.3414109Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3414165Z     
2026-02-14T13:01:56.3414263Z                             def replace_do_block(match):
2026-02-14T13:01:56.3414358Z                                 block = match.group(0)
2026-02-14T13:01:56.3414485Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3414581Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3414672Z                                 return placeholder
2026-02-14T13:01:56.3414729Z     
2026-02-14T13:01:56.3414837Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3414948Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3415029Z                                                     ^^
2026-02-14T13:01:56.3415214Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3415287Z                             )
2026-02-14T13:01:56.3415399Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3415404Z 
2026-02-14T13:01:56.3415506Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3415709Z ___ ERROR at setup of TestDocumentsPage.test_upload_resume_invalid_file_type ___
2026-02-14T13:01:56.3415714Z 
2026-02-14T13:01:56.3416016Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3416021Z 
2026-02-14T13:01:56.3416116Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3416219Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3416278Z         """
2026-02-14T13:01:56.3416424Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3416481Z     
2026-02-14T13:01:56.3416617Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3416738Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3416810Z         """
2026-02-14T13:01:56.3416904Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3417027Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3417091Z     
2026-02-14T13:01:56.3417197Z         # Parse connection string to get database name
2026-02-14T13:01:56.3417442Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3417506Z     
2026-02-14T13:01:56.3417687Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3417912Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3417969Z     
2026-02-14T13:01:56.3418122Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3418229Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3418304Z         if len(parts) >= 4:
2026-02-14T13:01:56.3418425Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3418492Z         else:
2026-02-14T13:01:56.3418591Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3418653Z     
2026-02-14T13:01:56.3418745Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3418975Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3419046Z         import time
2026-02-14T13:01:56.3419111Z     
2026-02-14T13:01:56.3419183Z         max_retries = 5
2026-02-14T13:01:56.3419250Z         retry_delay = 2
2026-02-14T13:01:56.3419313Z     
2026-02-14T13:01:56.3419402Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3419462Z             try:
2026-02-14T13:01:56.3419651Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3419756Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3419837Z                 conn.autocommit = True
2026-02-14T13:01:56.3419902Z                 try:
2026-02-14T13:01:56.3420064Z                     cur = conn.cursor()
2026-02-14T13:01:56.3420250Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3420329Z                     if not cur.fetchone():
2026-02-14T13:01:56.3420486Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3420604Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3420677Z                     cur.close()
2026-02-14T13:01:56.3420745Z                 finally:
2026-02-14T13:01:56.3420822Z                     conn.close()
2026-02-14T13:01:56.3420892Z                 break  # Success
2026-02-14T13:01:56.3421366Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3421472Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3421541Z                     print(
2026-02-14T13:01:56.3421760Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3421835Z                     )
2026-02-14T13:01:56.3421917Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3421981Z                 else:
2026-02-14T13:01:56.3422186Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3422372Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3422439Z                     pass
2026-02-14T13:01:56.3422551Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3422633Z                 break  # Already exists
2026-02-14T13:01:56.3422689Z     
2026-02-14T13:01:56.3422907Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3423089Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3423217Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3423279Z     
2026-02-14T13:01:56.3423350Z         close_all_pools()
2026-02-14T13:01:56.3423410Z     
2026-02-14T13:01:56.3423524Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3423685Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3423830Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3423911Z             conn.autocommit = True
2026-02-14T13:01:56.3423989Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3424181Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3424276Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3424352Z                 cur.execute(
2026-02-14T13:01:56.3424416Z                     """
2026-02-14T13:01:56.3424516Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3424597Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3424695Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3424791Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3424854Z                     """
2026-02-14T13:01:56.3424913Z                 )
2026-02-14T13:01:56.3424969Z     
2026-02-14T13:01:56.3425161Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3425341Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3425405Z                 try:
2026-02-14T13:01:56.3425526Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3425600Z                     cur.execute("""
2026-02-14T13:01:56.3425801Z                         DO $$
2026-02-14T13:01:56.3425878Z                         DECLARE
2026-02-14T13:01:56.3425950Z                             r RECORD;
2026-02-14T13:01:56.3426017Z                         BEGIN
2026-02-14T13:01:56.3426190Z                             FOR r IN (
2026-02-14T13:01:56.3426295Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3426379Z                                 FROM pg_views
2026-02-14T13:01:56.3426506Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3426576Z                             )
2026-02-14T13:01:56.3426645Z                             LOOP
2026-02-14T13:01:56.3426954Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3427031Z                             END LOOP;
2026-02-14T13:01:56.3427097Z                         END $$;
2026-02-14T13:01:56.3427169Z                     """)
2026-02-14T13:01:56.3427241Z                     # Drop tables
2026-02-14T13:01:56.3427318Z                     cur.execute("""
2026-02-14T13:01:56.3427384Z                         DO $$
2026-02-14T13:01:56.3427449Z                         DECLARE
2026-02-14T13:01:56.3427527Z                             r RECORD;
2026-02-14T13:01:56.3427592Z                         BEGIN
2026-02-14T13:01:56.3427662Z                             FOR r IN (
2026-02-14T13:01:56.3427758Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3427847Z                                 FROM pg_tables
2026-02-14T13:01:56.3427972Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3428037Z                             )
2026-02-14T13:01:56.3428111Z                             LOOP
2026-02-14T13:01:56.3428423Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3428498Z                             END LOOP;
2026-02-14T13:01:56.3428570Z                         END $$;
2026-02-14T13:01:56.3428633Z                     """)
2026-02-14T13:01:56.3428714Z                 except psycopg2.Error:
2026-02-14T13:01:56.3428893Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3428965Z                     pass
2026-02-14T13:01:56.3429021Z     
2026-02-14T13:01:56.3429193Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3429310Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3429385Z                 if init_dir.exists():
2026-02-14T13:01:56.3429490Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3429584Z                     for script_path in scripts:
2026-02-14T13:01:56.3429707Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3429788Z                             sql = f.read()
2026-02-14T13:01:56.3429998Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3430131Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3430212Z                             statements = []
2026-02-14T13:01:56.3430269Z     
2026-02-14T13:01:56.3430451Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3430528Z                             do_blocks = []
2026-02-14T13:01:56.3430632Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3430695Z     
2026-02-14T13:01:56.3430792Z                             def replace_do_block(match):
2026-02-14T13:01:56.3430884Z                                 block = match.group(0)
2026-02-14T13:01:56.3431016Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3431360Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3431454Z                                 return placeholder
2026-02-14T13:01:56.3431512Z     
2026-02-14T13:01:56.3431631Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3431832Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3431915Z                                                     ^^
2026-02-14T13:01:56.3432104Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3432169Z                             )
2026-02-14T13:01:56.3432277Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3432282Z 
2026-02-14T13:01:56.3432388Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3432595Z _ ERROR at setup of TestDocumentsPage.test_upload_cover_letter_invalid_file_type _
2026-02-14T13:01:56.3432599Z 
2026-02-14T13:01:56.3432897Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3432903Z 
2026-02-14T13:01:56.3432987Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3433092Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3433158Z         """
2026-02-14T13:01:56.3433297Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3433353Z     
2026-02-14T13:01:56.3433488Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3433613Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3433672Z         """
2026-02-14T13:01:56.3433773Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3433896Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3433952Z     
2026-02-14T13:01:56.3434057Z         # Parse connection string to get database name
2026-02-14T13:01:56.3434309Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3434371Z     
2026-02-14T13:01:56.3434555Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3434785Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3434846Z     
2026-02-14T13:01:56.3434988Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3435103Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3435178Z         if len(parts) >= 4:
2026-02-14T13:01:56.3435293Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3435354Z         else:
2026-02-14T13:01:56.3435459Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3435519Z     
2026-02-14T13:01:56.3435612Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3435843Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3435914Z         import time
2026-02-14T13:01:56.3435971Z     
2026-02-14T13:01:56.3436039Z         max_retries = 5
2026-02-14T13:01:56.3436115Z         retry_delay = 2
2026-02-14T13:01:56.3436171Z     
2026-02-14T13:01:56.3436256Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3436330Z             try:
2026-02-14T13:01:56.3436429Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3436522Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3436609Z                 conn.autocommit = True
2026-02-14T13:01:56.3436672Z                 try:
2026-02-14T13:01:56.3436750Z                     cur = conn.cursor()
2026-02-14T13:01:56.3436935Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3437023Z                     if not cur.fetchone():
2026-02-14T13:01:56.3437172Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3437382Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3437460Z                     cur.close()
2026-02-14T13:01:56.3437529Z                 finally:
2026-02-14T13:01:56.3437599Z                     conn.close()
2026-02-14T13:01:56.3437747Z                 break  # Success
2026-02-14T13:01:56.3437945Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3438034Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3438104Z                     print(
2026-02-14T13:01:56.3438327Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3438390Z                     )
2026-02-14T13:01:56.3438475Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3438544Z                 else:
2026-02-14T13:01:56.3438746Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3438933Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3439008Z                     pass
2026-02-14T13:01:56.3439122Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3439199Z                 break  # Already exists
2026-02-14T13:01:56.3439261Z     
2026-02-14T13:01:56.3439483Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3439661Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3439791Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3439854Z     
2026-02-14T13:01:56.3439926Z         close_all_pools()
2026-02-14T13:01:56.3439982Z     
2026-02-14T13:01:56.3440098Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3440266Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3440407Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3440489Z             conn.autocommit = True
2026-02-14T13:01:56.3440574Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3440769Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3440863Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3440944Z                 cur.execute(
2026-02-14T13:01:56.3441008Z                     """
2026-02-14T13:01:56.3441334Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3441421Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3441521Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3441611Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3441677Z                     """
2026-02-14T13:01:56.3441743Z                 )
2026-02-14T13:01:56.3441801Z     
2026-02-14T13:01:56.3441991Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3442186Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3442254Z                 try:
2026-02-14T13:01:56.3442371Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3442451Z                     cur.execute("""
2026-02-14T13:01:56.3442524Z                         DO $$
2026-02-14T13:01:56.3442592Z                         DECLARE
2026-02-14T13:01:56.3442666Z                             r RECORD;
2026-02-14T13:01:56.3442739Z                         BEGIN
2026-02-14T13:01:56.3442811Z                             FOR r IN (
2026-02-14T13:01:56.3442912Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3443002Z                                 FROM pg_views
2026-02-14T13:01:56.3443127Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3443191Z                             )
2026-02-14T13:01:56.3443380Z                             LOOP
2026-02-14T13:01:56.3443699Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3443770Z                             END LOOP;
2026-02-14T13:01:56.3443976Z                         END $$;
2026-02-14T13:01:56.3444046Z                     """)
2026-02-14T13:01:56.3444118Z                     # Drop tables
2026-02-14T13:01:56.3444189Z                     cur.execute("""
2026-02-14T13:01:56.3444260Z                         DO $$
2026-02-14T13:01:56.3444323Z                         DECLARE
2026-02-14T13:01:56.3444391Z                             r RECORD;
2026-02-14T13:01:56.3444456Z                         BEGIN
2026-02-14T13:01:56.3444530Z                             FOR r IN (
2026-02-14T13:01:56.3444628Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3444709Z                                 FROM pg_tables
2026-02-14T13:01:56.3444840Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3444905Z                             )
2026-02-14T13:01:56.3444973Z                             LOOP
2026-02-14T13:01:56.3445289Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3445365Z                             END LOOP;
2026-02-14T13:01:56.3445429Z                         END $$;
2026-02-14T13:01:56.3445492Z                     """)
2026-02-14T13:01:56.3445579Z                 except psycopg2.Error:
2026-02-14T13:01:56.3445750Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3445817Z                     pass
2026-02-14T13:01:56.3445879Z     
2026-02-14T13:01:56.3446048Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3446155Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3446234Z                 if init_dir.exists():
2026-02-14T13:01:56.3446344Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3446432Z                     for script_path in scripts:
2026-02-14T13:01:56.3446562Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3446643Z                             sql = f.read()
2026-02-14T13:01:56.3446847Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3446975Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3447062Z                             statements = []
2026-02-14T13:01:56.3447119Z     
2026-02-14T13:01:56.3447292Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3447372Z                             do_blocks = []
2026-02-14T13:01:56.3447474Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3447536Z     
2026-02-14T13:01:56.3447631Z                             def replace_do_block(match):
2026-02-14T13:01:56.3447727Z                                 block = match.group(0)
2026-02-14T13:01:56.3447851Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3447950Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3448041Z                                 return placeholder
2026-02-14T13:01:56.3448101Z     
2026-02-14T13:01:56.3448207Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3448311Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3448392Z                                                     ^^
2026-02-14T13:01:56.3448575Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3448639Z                             )
2026-02-14T13:01:56.3448838Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3448844Z 
2026-02-14T13:01:56.3448944Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3449151Z _ ERROR at setup of TestExtractNormalizeRankFlow.test_extract_jobs_to_raw_layer _
2026-02-14T13:01:56.3449231Z 
2026-02-14T13:01:56.3449527Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3449532Z 
2026-02-14T13:01:56.3449625Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3449727Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3449788Z         """
2026-02-14T13:01:56.3449927Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3449984Z     
2026-02-14T13:01:56.3450121Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3450243Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3450307Z         """
2026-02-14T13:01:56.3450400Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3450526Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3450590Z     
2026-02-14T13:01:56.3450695Z         # Parse connection string to get database name
2026-02-14T13:01:56.3450934Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3451001Z     
2026-02-14T13:01:56.3451310Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3451537Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3451603Z     
2026-02-14T13:01:56.3455868Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3456007Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3456089Z         if len(parts) >= 4:
2026-02-14T13:01:56.3456223Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3456289Z         else:
2026-02-14T13:01:56.3456406Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3456465Z     
2026-02-14T13:01:56.3456571Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3456806Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3456880Z         import time
2026-02-14T13:01:56.3456946Z     
2026-02-14T13:01:56.3457017Z         max_retries = 5
2026-02-14T13:01:56.3457085Z         retry_delay = 2
2026-02-14T13:01:56.3457155Z     
2026-02-14T13:01:56.3457244Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3457306Z             try:
2026-02-14T13:01:56.3457412Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3457514Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3457595Z                 conn.autocommit = True
2026-02-14T13:01:56.3457657Z                 try:
2026-02-14T13:01:56.3457745Z                     cur = conn.cursor()
2026-02-14T13:01:56.3457944Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3458028Z                     if not cur.fetchone():
2026-02-14T13:01:56.3458179Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3458308Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3458381Z                     cur.close()
2026-02-14T13:01:56.3458449Z                 finally:
2026-02-14T13:01:56.3458533Z                     conn.close()
2026-02-14T13:01:56.3458604Z                 break  # Success
2026-02-14T13:01:56.3458792Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3458887Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3458960Z                     print(
2026-02-14T13:01:56.3459180Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3459415Z                     )
2026-02-14T13:01:56.3459512Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3459577Z                 else:
2026-02-14T13:01:56.3459790Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3460101Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3460171Z                     pass
2026-02-14T13:01:56.3460289Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3460373Z                 break  # Already exists
2026-02-14T13:01:56.3460431Z     
2026-02-14T13:01:56.3460655Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3460848Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3460983Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3461267Z     
2026-02-14T13:01:56.3461412Z         close_all_pools()
2026-02-14T13:01:56.3461481Z     
2026-02-14T13:01:56.3461604Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3461770Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3461928Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3462008Z             conn.autocommit = True
2026-02-14T13:01:56.3462086Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3462278Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3462376Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3462449Z                 cur.execute(
2026-02-14T13:01:56.3462516Z                     """
2026-02-14T13:01:56.3462621Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3462700Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3462801Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3462900Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3462967Z                     """
2026-02-14T13:01:56.3463028Z                 )
2026-02-14T13:01:56.3463083Z     
2026-02-14T13:01:56.3463284Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3463467Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3463531Z                 try:
2026-02-14T13:01:56.3463655Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3463733Z                     cur.execute("""
2026-02-14T13:01:56.3463801Z                         DO $$
2026-02-14T13:01:56.3463875Z                         DECLARE
2026-02-14T13:01:56.3463947Z                             r RECORD;
2026-02-14T13:01:56.3464013Z                         BEGIN
2026-02-14T13:01:56.3464085Z                             FOR r IN (
2026-02-14T13:01:56.3464200Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3464282Z                                 FROM pg_views
2026-02-14T13:01:56.3464409Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3464489Z                             )
2026-02-14T13:01:56.3464557Z                             LOOP
2026-02-14T13:01:56.3464869Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3464947Z                             END LOOP;
2026-02-14T13:01:56.3465013Z                         END $$;
2026-02-14T13:01:56.3465078Z                     """)
2026-02-14T13:01:56.3465149Z                     # Drop tables
2026-02-14T13:01:56.3465229Z                     cur.execute("""
2026-02-14T13:01:56.3465295Z                         DO $$
2026-02-14T13:01:56.3465360Z                         DECLARE
2026-02-14T13:01:56.3465434Z                             r RECORD;
2026-02-14T13:01:56.3465624Z                         BEGIN
2026-02-14T13:01:56.3465700Z                             FOR r IN (
2026-02-14T13:01:56.3465801Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3465889Z                                 FROM pg_tables
2026-02-14T13:01:56.3466118Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3466184Z                             )
2026-02-14T13:01:56.3466258Z                             LOOP
2026-02-14T13:01:56.3466568Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3466640Z                             END LOOP;
2026-02-14T13:01:56.3466713Z                         END $$;
2026-02-14T13:01:56.3466779Z                     """)
2026-02-14T13:01:56.3466864Z                 except psycopg2.Error:
2026-02-14T13:01:56.3467045Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3467120Z                     pass
2026-02-14T13:01:56.3467176Z     
2026-02-14T13:01:56.3467349Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3467475Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3467552Z                 if init_dir.exists():
2026-02-14T13:01:56.3467657Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3467752Z                     for script_path in scripts:
2026-02-14T13:01:56.3467878Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3467955Z                             sql = f.read()
2026-02-14T13:01:56.3468162Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3468296Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3468379Z                             statements = []
2026-02-14T13:01:56.3468437Z     
2026-02-14T13:01:56.3468620Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3468695Z                             do_blocks = []
2026-02-14T13:01:56.3468801Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3468865Z     
2026-02-14T13:01:56.3468961Z                             def replace_do_block(match):
2026-02-14T13:01:56.3469054Z                                 block = match.group(0)
2026-02-14T13:01:56.3469187Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3469283Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3469369Z                                 return placeholder
2026-02-14T13:01:56.3469426Z     
2026-02-14T13:01:56.3469542Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3469646Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3469729Z                                                     ^^
2026-02-14T13:01:56.3469921Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3469991Z                             )
2026-02-14T13:01:56.3470100Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3470107Z 
2026-02-14T13:01:56.3470214Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3470424Z _ ERROR at setup of TestExtractNormalizeRankFlow.test_normalize_jobs_to_staging _
2026-02-14T13:01:56.3470429Z 
2026-02-14T13:01:56.3470751Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3470757Z 
2026-02-14T13:01:56.3470847Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3470954Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3471023Z         """
2026-02-14T13:01:56.3471439Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3471509Z     
2026-02-14T13:01:56.3471653Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3471786Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3471954Z         """
2026-02-14T13:01:56.3472055Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3472183Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3472241Z     
2026-02-14T13:01:56.3472352Z         # Parse connection string to get database name
2026-02-14T13:01:56.3472607Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3472664Z     
2026-02-14T13:01:56.3472845Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3473079Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3473135Z     
2026-02-14T13:01:56.3473285Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3473399Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3473475Z         if len(parts) >= 4:
2026-02-14T13:01:56.3473593Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3473659Z         else:
2026-02-14T13:01:56.3473765Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3473822Z     
2026-02-14T13:01:56.3473917Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3474147Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3474213Z         import time
2026-02-14T13:01:56.3474269Z     
2026-02-14T13:01:56.3474340Z         max_retries = 5
2026-02-14T13:01:56.3474414Z         retry_delay = 2
2026-02-14T13:01:56.3474471Z     
2026-02-14T13:01:56.3474555Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3474622Z             try:
2026-02-14T13:01:56.3474726Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3474819Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3474909Z                 conn.autocommit = True
2026-02-14T13:01:56.3474973Z                 try:
2026-02-14T13:01:56.3475054Z                     cur = conn.cursor()
2026-02-14T13:01:56.3475242Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3475328Z                     if not cur.fetchone():
2026-02-14T13:01:56.3475481Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3475599Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3475676Z                     cur.close()
2026-02-14T13:01:56.3475742Z                 finally:
2026-02-14T13:01:56.3475814Z                     conn.close()
2026-02-14T13:01:56.3475885Z                 break  # Success
2026-02-14T13:01:56.3476085Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3476174Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3476242Z                     print(
2026-02-14T13:01:56.3476467Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3476534Z                     )
2026-02-14T13:01:56.3476616Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3476686Z                 else:
2026-02-14T13:01:56.3476922Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3477106Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3477180Z                     pass
2026-02-14T13:01:56.3477294Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3477370Z                 break  # Already exists
2026-02-14T13:01:56.3477426Z     
2026-02-14T13:01:56.3477732Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3477916Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3478049Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3478193Z     
2026-02-14T13:01:56.3478269Z         close_all_pools()
2026-02-14T13:01:56.3478326Z     
2026-02-14T13:01:56.3478443Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3478614Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3478753Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3478834Z             conn.autocommit = True
2026-02-14T13:01:56.3478919Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3479110Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3479201Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3479284Z                 cur.execute(
2026-02-14T13:01:56.3479349Z                     """
2026-02-14T13:01:56.3479452Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3479529Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3479640Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3479728Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3479791Z                     """
2026-02-14T13:01:56.3479868Z                 )
2026-02-14T13:01:56.3479928Z     
2026-02-14T13:01:56.3480118Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3480308Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3480375Z                 try:
2026-02-14T13:01:56.3480492Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3480565Z                     cur.execute("""
2026-02-14T13:01:56.3480643Z                         DO $$
2026-02-14T13:01:56.3480711Z                         DECLARE
2026-02-14T13:01:56.3480786Z                             r RECORD;
2026-02-14T13:01:56.3480858Z                         BEGIN
2026-02-14T13:01:56.3480935Z                             FOR r IN (
2026-02-14T13:01:56.3481237Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3481384Z                                 FROM pg_views
2026-02-14T13:01:56.3481517Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3481584Z                             )
2026-02-14T13:01:56.3481653Z                             LOOP
2026-02-14T13:01:56.3481970Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3482042Z                             END LOOP;
2026-02-14T13:01:56.3482112Z                         END $$;
2026-02-14T13:01:56.3482189Z                     """)
2026-02-14T13:01:56.3482259Z                     # Drop tables
2026-02-14T13:01:56.3482332Z                     cur.execute("""
2026-02-14T13:01:56.3482407Z                         DO $$
2026-02-14T13:01:56.3482471Z                         DECLARE
2026-02-14T13:01:56.3482543Z                             r RECORD;
2026-02-14T13:01:56.3482617Z                         BEGIN
2026-02-14T13:01:56.3482687Z                             FOR r IN (
2026-02-14T13:01:56.3482787Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3482872Z                                 FROM pg_tables
2026-02-14T13:01:56.3482997Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3483060Z                             )
2026-02-14T13:01:56.3483127Z                             LOOP
2026-02-14T13:01:56.3483566Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3483640Z                             END LOOP;
2026-02-14T13:01:56.3483704Z                         END $$;
2026-02-14T13:01:56.3483774Z                     """)
2026-02-14T13:01:56.3483853Z                 except psycopg2.Error:
2026-02-14T13:01:56.3484129Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3484203Z                     pass
2026-02-14T13:01:56.3484260Z     
2026-02-14T13:01:56.3484429Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3484535Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3484617Z                 if init_dir.exists():
2026-02-14T13:01:56.3484720Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3484809Z                     for script_path in scripts:
2026-02-14T13:01:56.3484940Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3485020Z                             sql = f.read()
2026-02-14T13:01:56.3485223Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3485359Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3485440Z                             statements = []
2026-02-14T13:01:56.3485498Z     
2026-02-14T13:01:56.3485672Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3485754Z                             do_blocks = []
2026-02-14T13:01:56.3485855Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3485913Z     
2026-02-14T13:01:56.3486015Z                             def replace_do_block(match):
2026-02-14T13:01:56.3486105Z                                 block = match.group(0)
2026-02-14T13:01:56.3486229Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3486334Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3486422Z                                 return placeholder
2026-02-14T13:01:56.3486480Z     
2026-02-14T13:01:56.3486587Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3486693Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3486773Z                                                     ^^
2026-02-14T13:01:56.3486957Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3487029Z                             )
2026-02-14T13:01:56.3487134Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3487139Z 
2026-02-14T13:01:56.3487238Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3487449Z _ ERROR at setup of TestExtractNormalizeRankFlow.test_build_marts_and_rank_jobs _
2026-02-14T13:01:56.3487453Z 
2026-02-14T13:01:56.3487757Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3487762Z 
2026-02-14T13:01:56.3487852Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3487957Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3488023Z         """
2026-02-14T13:01:56.3488165Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3488221Z     
2026-02-14T13:01:56.3488354Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3488484Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3488543Z         """
2026-02-14T13:01:56.3488636Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3488765Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3488822Z     
2026-02-14T13:01:56.3488929Z         # Parse connection string to get database name
2026-02-14T13:01:56.3489178Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3489326Z     
2026-02-14T13:01:56.3489511Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3489734Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3489875Z     
2026-02-14T13:01:56.3490018Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3490125Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3490206Z         if len(parts) >= 4:
2026-02-14T13:01:56.3490325Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3490386Z         else:
2026-02-14T13:01:56.3490490Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3490547Z     
2026-02-14T13:01:56.3490643Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3490868Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3490944Z         import time
2026-02-14T13:01:56.3491004Z     
2026-02-14T13:01:56.3491191Z         max_retries = 5
2026-02-14T13:01:56.3491267Z         retry_delay = 2
2026-02-14T13:01:56.3491323Z     
2026-02-14T13:01:56.3491408Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3491475Z             try:
2026-02-14T13:01:56.3491582Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3491676Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3491757Z                 conn.autocommit = True
2026-02-14T13:01:56.3491826Z                 try:
2026-02-14T13:01:56.3491904Z                     cur = conn.cursor()
2026-02-14T13:01:56.3492094Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3492174Z                     if not cur.fetchone():
2026-02-14T13:01:56.3492332Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3492453Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3492526Z                     cur.close()
2026-02-14T13:01:56.3492599Z                 finally:
2026-02-14T13:01:56.3492670Z                     conn.close()
2026-02-14T13:01:56.3492745Z                 break  # Success
2026-02-14T13:01:56.3492943Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3493032Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3493101Z                     print(
2026-02-14T13:01:56.3493323Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3493395Z                     )
2026-02-14T13:01:56.3493477Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3493540Z                 else:
2026-02-14T13:01:56.3493746Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3493931Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3494001Z                     pass
2026-02-14T13:01:56.3494120Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3494196Z                 break  # Already exists
2026-02-14T13:01:56.3494257Z     
2026-02-14T13:01:56.3494472Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3494658Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3494790Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3494849Z     
2026-02-14T13:01:56.3494929Z         close_all_pools()
2026-02-14T13:01:56.3494989Z     
2026-02-14T13:01:56.3495106Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3495273Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3495532Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3495616Z             conn.autocommit = True
2026-02-14T13:01:56.3495695Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3495894Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3496131Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3496205Z                 cur.execute(
2026-02-14T13:01:56.3496279Z                     """
2026-02-14T13:01:56.3496376Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3496455Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3496555Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3496646Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3496710Z                     """
2026-02-14T13:01:56.3496770Z                 )
2026-02-14T13:01:56.3496836Z     
2026-02-14T13:01:56.3497026Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3497213Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3497284Z                 try:
2026-02-14T13:01:56.3497399Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3497480Z                     cur.execute("""
2026-02-14T13:01:56.3497554Z                         DO $$
2026-02-14T13:01:56.3497621Z                         DECLARE
2026-02-14T13:01:56.3497693Z                             r RECORD;
2026-02-14T13:01:56.3497761Z                         BEGIN
2026-02-14T13:01:56.3497838Z                             FOR r IN (
2026-02-14T13:01:56.3497937Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3498020Z                                 FROM pg_views
2026-02-14T13:01:56.3498158Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3498222Z                             )
2026-02-14T13:01:56.3498297Z                             LOOP
2026-02-14T13:01:56.3498619Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3498691Z                             END LOOP;
2026-02-14T13:01:56.3498763Z                         END $$;
2026-02-14T13:01:56.3498827Z                     """)
2026-02-14T13:01:56.3498904Z                     # Drop tables
2026-02-14T13:01:56.3498978Z                     cur.execute("""
2026-02-14T13:01:56.3499043Z                         DO $$
2026-02-14T13:01:56.3499112Z                         DECLARE
2026-02-14T13:01:56.3499182Z                             r RECORD;
2026-02-14T13:01:56.3499245Z                         BEGIN
2026-02-14T13:01:56.3499316Z                             FOR r IN (
2026-02-14T13:01:56.3499431Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3499517Z                                 FROM pg_tables
2026-02-14T13:01:56.3499648Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3499717Z                             )
2026-02-14T13:01:56.3499790Z                             LOOP
2026-02-14T13:01:56.3500105Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3500182Z                             END LOOP;
2026-02-14T13:01:56.3500254Z                         END $$;
2026-02-14T13:01:56.3500327Z                     """)
2026-02-14T13:01:56.3500412Z                 except psycopg2.Error:
2026-02-14T13:01:56.3500597Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3500664Z                     pass
2026-02-14T13:01:56.3500723Z     
2026-02-14T13:01:56.3500898Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3501016Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3501448Z                 if init_dir.exists():
2026-02-14T13:01:56.3501568Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3501671Z                     for script_path in scripts:
2026-02-14T13:01:56.3501800Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3501990Z                             sql = f.read()
2026-02-14T13:01:56.3502205Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3502336Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3502415Z                             statements = []
2026-02-14T13:01:56.3502473Z     
2026-02-14T13:01:56.3502657Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3502733Z                             do_blocks = []
2026-02-14T13:01:56.3502835Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3502901Z     
2026-02-14T13:01:56.3502997Z                             def replace_do_block(match):
2026-02-14T13:01:56.3503087Z                                 block = match.group(0)
2026-02-14T13:01:56.3503219Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3503319Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3503404Z                                 return placeholder
2026-02-14T13:01:56.3503460Z     
2026-02-14T13:01:56.3503573Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3503668Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3503748Z                                                     ^^
2026-02-14T13:01:56.3503936Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3504004Z                             )
2026-02-14T13:01:56.3504118Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3504124Z 
2026-02-14T13:01:56.3504228Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3504433Z _ ERROR at setup of TestExtractNormalizeRankFlow.test_complete_flow_end_to_end _
2026-02-14T13:01:56.3504442Z 
2026-02-14T13:01:56.3504738Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3504744Z 
2026-02-14T13:01:56.3504830Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3504939Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3504998Z         """
2026-02-14T13:01:56.3505133Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3505189Z     
2026-02-14T13:01:56.3505326Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3505448Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3505506Z         """
2026-02-14T13:01:56.3505605Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3505736Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3505792Z     
2026-02-14T13:01:56.3505901Z         # Parse connection string to get database name
2026-02-14T13:01:56.3506154Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3506216Z     
2026-02-14T13:01:56.3506404Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3506639Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3506695Z     
2026-02-14T13:01:56.3506837Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3506951Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3507026Z         if len(parts) >= 4:
2026-02-14T13:01:56.3507143Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3507204Z         else:
2026-02-14T13:01:56.3507397Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3507456Z     
2026-02-14T13:01:56.3507552Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3507786Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3507931Z         import time
2026-02-14T13:01:56.3507988Z     
2026-02-14T13:01:56.3508063Z         max_retries = 5
2026-02-14T13:01:56.3508130Z         retry_delay = 2
2026-02-14T13:01:56.3508188Z     
2026-02-14T13:01:56.3508274Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3508340Z             try:
2026-02-14T13:01:56.3508440Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3508535Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3508619Z                 conn.autocommit = True
2026-02-14T13:01:56.3508683Z                 try:
2026-02-14T13:01:56.3508761Z                     cur = conn.cursor()
2026-02-14T13:01:56.3508950Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3509038Z                     if not cur.fetchone():
2026-02-14T13:01:56.3509189Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3509315Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3509392Z                     cur.close()
2026-02-14T13:01:56.3509458Z                 finally:
2026-02-14T13:01:56.3509529Z                     conn.close()
2026-02-14T13:01:56.3509605Z                 break  # Success
2026-02-14T13:01:56.3509793Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3509884Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3509953Z                     print(
2026-02-14T13:01:56.3510177Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3510245Z                     )
2026-02-14T13:01:56.3510327Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3510398Z                 else:
2026-02-14T13:01:56.3510599Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3510784Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3510857Z                     pass
2026-02-14T13:01:56.3510971Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3511165Z                 break  # Already exists
2026-02-14T13:01:56.3511225Z     
2026-02-14T13:01:56.3511451Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3511635Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3511766Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3511830Z     
2026-02-14T13:01:56.3511910Z         close_all_pools()
2026-02-14T13:01:56.3511969Z     
2026-02-14T13:01:56.3512092Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3512259Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3512403Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3512485Z             conn.autocommit = True
2026-02-14T13:01:56.3512572Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3512764Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3512855Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3512933Z                 cur.execute(
2026-02-14T13:01:56.3512998Z                     """
2026-02-14T13:01:56.3513095Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3513179Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3513408Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3513503Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3513567Z                     """
2026-02-14T13:01:56.3513633Z                 )
2026-02-14T13:01:56.3513689Z     
2026-02-14T13:01:56.3513979Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3514169Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3514232Z                 try:
2026-02-14T13:01:56.3514347Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3514427Z                     cur.execute("""
2026-02-14T13:01:56.3514493Z                         DO $$
2026-02-14T13:01:56.3514559Z                         DECLARE
2026-02-14T13:01:56.3514629Z                             r RECORD;
2026-02-14T13:01:56.3514699Z                         BEGIN
2026-02-14T13:01:56.3514769Z                             FOR r IN (
2026-02-14T13:01:56.3514873Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3514958Z                                 FROM pg_views
2026-02-14T13:01:56.3515085Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3515153Z                             )
2026-02-14T13:01:56.3515223Z                             LOOP
2026-02-14T13:01:56.3515541Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3515612Z                             END LOOP;
2026-02-14T13:01:56.3515676Z                         END $$;
2026-02-14T13:01:56.3515745Z                     """)
2026-02-14T13:01:56.3515815Z                     # Drop tables
2026-02-14T13:01:56.3515886Z                     cur.execute("""
2026-02-14T13:01:56.3515956Z                         DO $$
2026-02-14T13:01:56.3516019Z                         DECLARE
2026-02-14T13:01:56.3516087Z                             r RECORD;
2026-02-14T13:01:56.3516154Z                         BEGIN
2026-02-14T13:01:56.3516228Z                             FOR r IN (
2026-02-14T13:01:56.3516327Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3516409Z                                 FROM pg_tables
2026-02-14T13:01:56.3516543Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3516609Z                             )
2026-02-14T13:01:56.3516677Z                             LOOP
2026-02-14T13:01:56.3516993Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3517063Z                             END LOOP;
2026-02-14T13:01:56.3517128Z                         END $$;
2026-02-14T13:01:56.3517192Z                     """)
2026-02-14T13:01:56.3517279Z                 except psycopg2.Error:
2026-02-14T13:01:56.3517454Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3517521Z                     pass
2026-02-14T13:01:56.3517583Z     
2026-02-14T13:01:56.3517753Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3517865Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3517947Z                 if init_dir.exists():
2026-02-14T13:01:56.3518052Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3518139Z                     for script_path in scripts:
2026-02-14T13:01:56.3518263Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3518343Z                             sql = f.read()
2026-02-14T13:01:56.3518548Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3518678Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3518845Z                             statements = []
2026-02-14T13:01:56.3518905Z     
2026-02-14T13:01:56.3519084Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3519163Z                             do_blocks = []
2026-02-14T13:01:56.3519343Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3519400Z     
2026-02-14T13:01:56.3519495Z                             def replace_do_block(match):
2026-02-14T13:01:56.3519591Z                                 block = match.group(0)
2026-02-14T13:01:56.3519715Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3519811Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3519902Z                                 return placeholder
2026-02-14T13:01:56.3519958Z     
2026-02-14T13:01:56.3520065Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3520172Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3520253Z                                                     ^^
2026-02-14T13:01:56.3520438Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3520508Z                             )
2026-02-14T13:01:56.3520623Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3520629Z 
2026-02-14T13:01:56.3520727Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3520971Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_record_job_found_creates_history _
2026-02-14T13:01:56.3520982Z 
2026-02-14T13:01:56.3521494Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3521501Z 
2026-02-14T13:01:56.3521600Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3521706Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3521767Z         """
2026-02-14T13:01:56.3521912Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3521970Z     
2026-02-14T13:01:56.3522102Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3522232Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3522297Z         """
2026-02-14T13:01:56.3522391Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3522513Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3522579Z     
2026-02-14T13:01:56.3522683Z         # Parse connection string to get database name
2026-02-14T13:01:56.3522930Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3522993Z     
2026-02-14T13:01:56.3523184Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3523418Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3523482Z     
2026-02-14T13:01:56.3523632Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3523742Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3523816Z         if len(parts) >= 4:
2026-02-14T13:01:56.3523944Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3524011Z         else:
2026-02-14T13:01:56.3524110Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3524172Z     
2026-02-14T13:01:56.3524268Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3524496Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3524562Z         import time
2026-02-14T13:01:56.3524625Z     
2026-02-14T13:01:56.3524692Z         max_retries = 5
2026-02-14T13:01:56.3524758Z         retry_delay = 2
2026-02-14T13:01:56.3524819Z     
2026-02-14T13:01:56.3524903Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3524964Z             try:
2026-02-14T13:01:56.3525187Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3525292Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3525375Z                 conn.autocommit = True
2026-02-14T13:01:56.3525544Z                 try:
2026-02-14T13:01:56.3525627Z                     cur = conn.cursor()
2026-02-14T13:01:56.3525815Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3525894Z                     if not cur.fetchone():
2026-02-14T13:01:56.3526048Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3526164Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3526236Z                     cur.close()
2026-02-14T13:01:56.3526302Z                 finally:
2026-02-14T13:01:56.3526378Z                     conn.close()
2026-02-14T13:01:56.3526447Z                 break  # Success
2026-02-14T13:01:56.3526643Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3526739Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3526809Z                     print(
2026-02-14T13:01:56.3527028Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3527102Z                     )
2026-02-14T13:01:56.3527186Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3527251Z                 else:
2026-02-14T13:01:56.3527454Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3527642Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3527709Z                     pass
2026-02-14T13:01:56.3527824Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3527908Z                 break  # Already exists
2026-02-14T13:01:56.3527964Z     
2026-02-14T13:01:56.3528183Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3528371Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3528501Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3528561Z     
2026-02-14T13:01:56.3528632Z         close_all_pools()
2026-02-14T13:01:56.3528696Z     
2026-02-14T13:01:56.3528811Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3528972Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3529117Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3529198Z             conn.autocommit = True
2026-02-14T13:01:56.3529275Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3529476Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3529574Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3529646Z                 cur.execute(
2026-02-14T13:01:56.3529711Z                     """
2026-02-14T13:01:56.3529814Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3529898Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3529999Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3530094Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3530157Z                     """
2026-02-14T13:01:56.3530216Z                 )
2026-02-14T13:01:56.3530281Z     
2026-02-14T13:01:56.3530467Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3530649Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3530714Z                 try:
2026-02-14T13:01:56.3530835Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3530910Z                     cur.execute("""
2026-02-14T13:01:56.3531204Z                         DO $$
2026-02-14T13:01:56.3531287Z                         DECLARE
2026-02-14T13:01:56.3531362Z                             r RECORD;
2026-02-14T13:01:56.3531428Z                         BEGIN
2026-02-14T13:01:56.3531606Z                             FOR r IN (
2026-02-14T13:01:56.3531719Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3531802Z                                 FROM pg_views
2026-02-14T13:01:56.3531934Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3532005Z                             )
2026-02-14T13:01:56.3532073Z                             LOOP
2026-02-14T13:01:56.3532393Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3532472Z                             END LOOP;
2026-02-14T13:01:56.3532537Z                         END $$;
2026-02-14T13:01:56.3532607Z                     """)
2026-02-14T13:01:56.3532679Z                     # Drop tables
2026-02-14T13:01:56.3532760Z                     cur.execute("""
2026-02-14T13:01:56.3532825Z                         DO $$
2026-02-14T13:01:56.3532898Z                         DECLARE
2026-02-14T13:01:56.3532975Z                             r RECORD;
2026-02-14T13:01:56.3533042Z                         BEGIN
2026-02-14T13:01:56.3533111Z                             FOR r IN (
2026-02-14T13:01:56.3533218Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3533302Z                                 FROM pg_tables
2026-02-14T13:01:56.3533426Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3533492Z                             )
2026-02-14T13:01:56.3533567Z                             LOOP
2026-02-14T13:01:56.3533895Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3533969Z                             END LOOP;
2026-02-14T13:01:56.3534040Z                         END $$;
2026-02-14T13:01:56.3534104Z                     """)
2026-02-14T13:01:56.3534189Z                 except psycopg2.Error:
2026-02-14T13:01:56.3534373Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3534440Z                     pass
2026-02-14T13:01:56.3534497Z     
2026-02-14T13:01:56.3534669Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3534787Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3534864Z                 if init_dir.exists():
2026-02-14T13:01:56.3534969Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3535066Z                     for script_path in scripts:
2026-02-14T13:01:56.3535191Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3535270Z                             sql = f.read()
2026-02-14T13:01:56.3535480Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3535610Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3535691Z                             statements = []
2026-02-14T13:01:56.3535748Z     
2026-02-14T13:01:56.3535929Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3536002Z                             do_blocks = []
2026-02-14T13:01:56.3536103Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3536164Z     
2026-02-14T13:01:56.3536258Z                             def replace_do_block(match):
2026-02-14T13:01:56.3536348Z                                 block = match.group(0)
2026-02-14T13:01:56.3536477Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3536677Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3536766Z                                 return placeholder
2026-02-14T13:01:56.3536823Z     
2026-02-14T13:01:56.3536935Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3537113Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3537194Z                                                     ^^
2026-02-14T13:01:56.3537382Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3537450Z                             )
2026-02-14T13:01:56.3537556Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3537562Z 
2026-02-14T13:01:56.3537667Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3537913Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_record_ai_update_creates_history _
2026-02-14T13:01:56.3537918Z 
2026-02-14T13:01:56.3538211Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3538216Z 
2026-02-14T13:01:56.3538304Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3538412Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3538477Z         """
2026-02-14T13:01:56.3538611Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3538668Z     
2026-02-14T13:01:56.3538804Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3538926Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3538986Z         """
2026-02-14T13:01:56.3539085Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3539206Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3539262Z     
2026-02-14T13:01:56.3539367Z         # Parse connection string to get database name
2026-02-14T13:01:56.3539618Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3539677Z     
2026-02-14T13:01:56.3539860Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3540090Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3540152Z     
2026-02-14T13:01:56.3540293Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3540407Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3540490Z         if len(parts) >= 4:
2026-02-14T13:01:56.3540607Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3540673Z         else:
2026-02-14T13:01:56.3540772Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3540829Z     
2026-02-14T13:01:56.3540922Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3541385Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3541460Z         import time
2026-02-14T13:01:56.3541517Z     
2026-02-14T13:01:56.3541595Z         max_retries = 5
2026-02-14T13:01:56.3541662Z         retry_delay = 2
2026-02-14T13:01:56.3541719Z     
2026-02-14T13:01:56.3541810Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3541876Z             try:
2026-02-14T13:01:56.3541976Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3542070Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3542156Z                 conn.autocommit = True
2026-02-14T13:01:56.3542219Z                 try:
2026-02-14T13:01:56.3542296Z                     cur = conn.cursor()
2026-02-14T13:01:56.3542480Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3542567Z                     if not cur.fetchone():
2026-02-14T13:01:56.3542717Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3542997Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3543077Z                     cur.close()
2026-02-14T13:01:56.3543143Z                 finally:
2026-02-14T13:01:56.3543213Z                     conn.close()
2026-02-14T13:01:56.3543396Z                 break  # Success
2026-02-14T13:01:56.3543584Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3543672Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3543741Z                     print(
2026-02-14T13:01:56.3543969Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3544032Z                     )
2026-02-14T13:01:56.3544114Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3544184Z                 else:
2026-02-14T13:01:56.3544388Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3544574Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3544651Z                     pass
2026-02-14T13:01:56.3544765Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3544843Z                 break  # Already exists
2026-02-14T13:01:56.3544906Z     
2026-02-14T13:01:56.3545128Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3545310Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3545442Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3545510Z     
2026-02-14T13:01:56.3545584Z         close_all_pools()
2026-02-14T13:01:56.3545644Z     
2026-02-14T13:01:56.3545766Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3545928Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3546072Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3546153Z             conn.autocommit = True
2026-02-14T13:01:56.3546239Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3546429Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3546525Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3546602Z                 cur.execute(
2026-02-14T13:01:56.3546665Z                     """
2026-02-14T13:01:56.3546760Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3546844Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3546938Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3547028Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3547091Z                     """
2026-02-14T13:01:56.3547160Z                 )
2026-02-14T13:01:56.3547216Z     
2026-02-14T13:01:56.3547409Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3547595Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3547657Z                 try:
2026-02-14T13:01:56.3547773Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3547856Z                     cur.execute("""
2026-02-14T13:01:56.3547923Z                         DO $$
2026-02-14T13:01:56.3547989Z                         DECLARE
2026-02-14T13:01:56.3548061Z                             r RECORD;
2026-02-14T13:01:56.3548130Z                         BEGIN
2026-02-14T13:01:56.3548200Z                             FOR r IN (
2026-02-14T13:01:56.3548302Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3548386Z                                 FROM pg_views
2026-02-14T13:01:56.3548514Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3548579Z                             )
2026-02-14T13:01:56.3548741Z                             LOOP
2026-02-14T13:01:56.3549051Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3549122Z                             END LOOP;
2026-02-14T13:01:56.3549263Z                         END $$;
2026-02-14T13:01:56.3549332Z                     """)
2026-02-14T13:01:56.3549403Z                     # Drop tables
2026-02-14T13:01:56.3549477Z                     cur.execute("""
2026-02-14T13:01:56.3549550Z                         DO $$
2026-02-14T13:01:56.3549614Z                         DECLARE
2026-02-14T13:01:56.3549680Z                             r RECORD;
2026-02-14T13:01:56.3549745Z                         BEGIN
2026-02-14T13:01:56.3549822Z                             FOR r IN (
2026-02-14T13:01:56.3549921Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3550001Z                                 FROM pg_tables
2026-02-14T13:01:56.3550136Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3550199Z                             )
2026-02-14T13:01:56.3550267Z                             LOOP
2026-02-14T13:01:56.3550584Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3550658Z                             END LOOP;
2026-02-14T13:01:56.3550723Z                         END $$;
2026-02-14T13:01:56.3550786Z                     """)
2026-02-14T13:01:56.3550876Z                 except psycopg2.Error:
2026-02-14T13:01:56.3551186Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3551256Z                     pass
2026-02-14T13:01:56.3551318Z     
2026-02-14T13:01:56.3551486Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3551596Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3551680Z                 if init_dir.exists():
2026-02-14T13:01:56.3551784Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3551872Z                     for script_path in scripts:
2026-02-14T13:01:56.3552002Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3552081Z                             sql = f.read()
2026-02-14T13:01:56.3552286Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3552415Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3552497Z                             statements = []
2026-02-14T13:01:56.3552554Z     
2026-02-14T13:01:56.3552730Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3552810Z                             do_blocks = []
2026-02-14T13:01:56.3552915Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3552972Z     
2026-02-14T13:01:56.3553075Z                             def replace_do_block(match):
2026-02-14T13:01:56.3553164Z                                 block = match.group(0)
2026-02-14T13:01:56.3553295Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3553389Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3553480Z                                 return placeholder
2026-02-14T13:01:56.3553538Z     
2026-02-14T13:01:56.3553644Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3553746Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3553827Z                                                     ^^
2026-02-14T13:01:56.3554009Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3554081Z                             )
2026-02-14T13:01:56.3554306Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3554313Z 
2026-02-14T13:01:56.3554417Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3554685Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_record_chatgpt_update_creates_history _
2026-02-14T13:01:56.3554794Z 
2026-02-14T13:01:56.3555249Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3555255Z 
2026-02-14T13:01:56.3555357Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3555462Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3555525Z         """
2026-02-14T13:01:56.3555664Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3555722Z     
2026-02-14T13:01:56.3555855Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3555984Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3556044Z         """
2026-02-14T13:01:56.3556144Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3556268Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3556336Z     
2026-02-14T13:01:56.3556445Z         # Parse connection string to get database name
2026-02-14T13:01:56.3556693Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3556759Z     
2026-02-14T13:01:56.3556943Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3557168Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3557231Z     
2026-02-14T13:01:56.3557372Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3557479Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3557552Z         if len(parts) >= 4:
2026-02-14T13:01:56.3557675Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3557740Z         else:
2026-02-14T13:01:56.3557843Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3557903Z     
2026-02-14T13:01:56.3557996Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3558224Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3558294Z         import time
2026-02-14T13:01:56.3558350Z     
2026-02-14T13:01:56.3558419Z         max_retries = 5
2026-02-14T13:01:56.3558485Z         retry_delay = 2
2026-02-14T13:01:56.3558547Z     
2026-02-14T13:01:56.3558631Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3558694Z             try:
2026-02-14T13:01:56.3558797Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3558889Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3558968Z                 conn.autocommit = True
2026-02-14T13:01:56.3559030Z                 try:
2026-02-14T13:01:56.3559117Z                     cur = conn.cursor()
2026-02-14T13:01:56.3559301Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3559379Z                     if not cur.fetchone():
2026-02-14T13:01:56.3559531Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3559652Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3559721Z                     cur.close()
2026-02-14T13:01:56.3559792Z                 finally:
2026-02-14T13:01:56.3559864Z                     conn.close()
2026-02-14T13:01:56.3559933Z                 break  # Success
2026-02-14T13:01:56.3560120Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3560221Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3560289Z                     print(
2026-02-14T13:01:56.3560598Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3560671Z                     )
2026-02-14T13:01:56.3560754Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3560817Z                 else:
2026-02-14T13:01:56.3561023Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3561584Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3561658Z                     pass
2026-02-14T13:01:56.3561778Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3561866Z                 break  # Already exists
2026-02-14T13:01:56.3561924Z     
2026-02-14T13:01:56.3562146Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3562333Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3562466Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3562530Z     
2026-02-14T13:01:56.3562609Z         close_all_pools()
2026-02-14T13:01:56.3562666Z     
2026-02-14T13:01:56.3562782Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3562949Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3563101Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3563184Z             conn.autocommit = True
2026-02-14T13:01:56.3563264Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3563463Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3563556Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3563628Z                 cur.execute(
2026-02-14T13:01:56.3563693Z                     """
2026-02-14T13:01:56.3563797Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3563877Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3563977Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3564073Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3564136Z                     """
2026-02-14T13:01:56.3564196Z                 )
2026-02-14T13:01:56.3564263Z     
2026-02-14T13:01:56.3564453Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3564638Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3564702Z                 try:
2026-02-14T13:01:56.3564824Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3564897Z                     cur.execute("""
2026-02-14T13:01:56.3564966Z                         DO $$
2026-02-14T13:01:56.3565039Z                         DECLARE
2026-02-14T13:01:56.3565110Z                             r RECORD;
2026-02-14T13:01:56.3565176Z                         BEGIN
2026-02-14T13:01:56.3565252Z                             FOR r IN (
2026-02-14T13:01:56.3565356Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3565436Z                                 FROM pg_views
2026-02-14T13:01:56.3565563Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3565641Z                             )
2026-02-14T13:01:56.3565709Z                             LOOP
2026-02-14T13:01:56.3566021Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3566103Z                             END LOOP;
2026-02-14T13:01:56.3566170Z                         END $$;
2026-02-14T13:01:56.3566235Z                     """)
2026-02-14T13:01:56.3566315Z                     # Drop tables
2026-02-14T13:01:56.3566387Z                     cur.execute("""
2026-02-14T13:01:56.3566453Z                         DO $$
2026-02-14T13:01:56.3566519Z                         DECLARE
2026-02-14T13:01:56.3566711Z                             r RECORD;
2026-02-14T13:01:56.3566780Z                         BEGIN
2026-02-14T13:01:56.3566852Z                             FOR r IN (
2026-02-14T13:01:56.3566959Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3567124Z                                 FROM pg_tables
2026-02-14T13:01:56.3567250Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3567316Z                             )
2026-02-14T13:01:56.3567393Z                             LOOP
2026-02-14T13:01:56.3567706Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3567777Z                             END LOOP;
2026-02-14T13:01:56.3567849Z                         END $$;
2026-02-14T13:01:56.3567913Z                     """)
2026-02-14T13:01:56.3567999Z                 except psycopg2.Error:
2026-02-14T13:01:56.3568180Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3568249Z                     pass
2026-02-14T13:01:56.3568305Z     
2026-02-14T13:01:56.3568474Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3568592Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3568666Z                 if init_dir.exists():
2026-02-14T13:01:56.3568772Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3568865Z                     for script_path in scripts:
2026-02-14T13:01:56.3568989Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3569062Z                             sql = f.read()
2026-02-14T13:01:56.3569271Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3569400Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3569485Z                             statements = []
2026-02-14T13:01:56.3569547Z     
2026-02-14T13:01:56.3569725Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3569800Z                             do_blocks = []
2026-02-14T13:01:56.3569905Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3569967Z     
2026-02-14T13:01:56.3570064Z                             def replace_do_block(match):
2026-02-14T13:01:56.3570154Z                                 block = match.group(0)
2026-02-14T13:01:56.3570286Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3570379Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3570466Z                                 return placeholder
2026-02-14T13:01:56.3570528Z     
2026-02-14T13:01:56.3570640Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3570741Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3570823Z                                                     ^^
2026-02-14T13:01:56.3571012Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3571194Z                             )
2026-02-14T13:01:56.3571302Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3571308Z 
2026-02-14T13:01:56.3571417Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3571688Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_record_document_change_creates_history _
2026-02-14T13:01:56.3571693Z 
2026-02-14T13:01:56.3572006Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3572011Z 
2026-02-14T13:01:56.3572098Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3572205Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3572266Z         """
2026-02-14T13:01:56.3572523Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3572586Z     
2026-02-14T13:01:56.3572725Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3572846Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3573013Z         """
2026-02-14T13:01:56.3573113Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3573238Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3573296Z     
2026-02-14T13:01:56.3573407Z         # Parse connection string to get database name
2026-02-14T13:01:56.3573647Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3573704Z     
2026-02-14T13:01:56.3573887Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3574121Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3574183Z     
2026-02-14T13:01:56.3574329Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3574444Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3574520Z         if len(parts) >= 4:
2026-02-14T13:01:56.3574648Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3574715Z         else:
2026-02-14T13:01:56.3574813Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3574870Z     
2026-02-14T13:01:56.3574963Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3575194Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3575260Z         import time
2026-02-14T13:01:56.3575317Z     
2026-02-14T13:01:56.3575391Z         max_retries = 5
2026-02-14T13:01:56.3575460Z         retry_delay = 2
2026-02-14T13:01:56.3575517Z     
2026-02-14T13:01:56.3575604Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3575676Z             try:
2026-02-14T13:01:56.3575775Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3575868Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3575956Z                 conn.autocommit = True
2026-02-14T13:01:56.3576023Z                 try:
2026-02-14T13:01:56.3576100Z                     cur = conn.cursor()
2026-02-14T13:01:56.3576293Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3576371Z                     if not cur.fetchone():
2026-02-14T13:01:56.3576520Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3576635Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3576712Z                     cur.close()
2026-02-14T13:01:56.3576779Z                 finally:
2026-02-14T13:01:56.3576850Z                     conn.close()
2026-02-14T13:01:56.3576986Z                 break  # Success
2026-02-14T13:01:56.3577182Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3577272Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3577349Z                     print(
2026-02-14T13:01:56.3577567Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3577632Z                     )
2026-02-14T13:01:56.3577716Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3577787Z                 else:
2026-02-14T13:01:56.3577994Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3578176Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3578248Z                     pass
2026-02-14T13:01:56.3578361Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3578437Z                 break  # Already exists
2026-02-14T13:01:56.3578587Z     
2026-02-14T13:01:56.3578807Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3578989Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3579195Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3579260Z     
2026-02-14T13:01:56.3579333Z         close_all_pools()
2026-02-14T13:01:56.3579389Z     
2026-02-14T13:01:56.3579511Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3579673Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3579812Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3579906Z             conn.autocommit = True
2026-02-14T13:01:56.3579983Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3580172Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3580266Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3580342Z                 cur.execute(
2026-02-14T13:01:56.3580406Z                     """
2026-02-14T13:01:56.3580504Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3580594Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3580688Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3580778Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3580847Z                     """
2026-02-14T13:01:56.3580906Z                 )
2026-02-14T13:01:56.3580962Z     
2026-02-14T13:01:56.3581403Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3581600Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3581665Z                 try:
2026-02-14T13:01:56.3581780Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3581864Z                     cur.execute("""
2026-02-14T13:01:56.3581933Z                         DO $$
2026-02-14T13:01:56.3582000Z                         DECLARE
2026-02-14T13:01:56.3582073Z                             r RECORD;
2026-02-14T13:01:56.3582148Z                         BEGIN
2026-02-14T13:01:56.3582218Z                             FOR r IN (
2026-02-14T13:01:56.3582317Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3582403Z                                 FROM pg_views
2026-02-14T13:01:56.3582530Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3582594Z                             )
2026-02-14T13:01:56.3582667Z                             LOOP
2026-02-14T13:01:56.3582978Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3583049Z                             END LOOP;
2026-02-14T13:01:56.3583119Z                         END $$;
2026-02-14T13:01:56.3583193Z                     """)
2026-02-14T13:01:56.3583263Z                     # Drop tables
2026-02-14T13:01:56.3583335Z                     cur.execute("""
2026-02-14T13:01:56.3583407Z                         DO $$
2026-02-14T13:01:56.3583476Z                         DECLARE
2026-02-14T13:01:56.3583548Z                             r RECORD;
2026-02-14T13:01:56.3583618Z                         BEGIN
2026-02-14T13:01:56.3583690Z                             FOR r IN (
2026-02-14T13:01:56.3583789Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3583872Z                                 FROM pg_tables
2026-02-14T13:01:56.3584002Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3584067Z                             )
2026-02-14T13:01:56.3584134Z                             LOOP
2026-02-14T13:01:56.3584573Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3584649Z                             END LOOP;
2026-02-14T13:01:56.3584714Z                         END $$;
2026-02-14T13:01:56.3584784Z                     """)
2026-02-14T13:01:56.3584969Z                 except psycopg2.Error:
2026-02-14T13:01:56.3585141Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3585207Z                     pass
2026-02-14T13:01:56.3585268Z     
2026-02-14T13:01:56.3585440Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3585549Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3585629Z                 if init_dir.exists():
2026-02-14T13:01:56.3585735Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3585824Z                     for script_path in scripts:
2026-02-14T13:01:56.3585961Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3586037Z                             sql = f.read()
2026-02-14T13:01:56.3586242Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3586378Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3586461Z                             statements = []
2026-02-14T13:01:56.3586519Z     
2026-02-14T13:01:56.3586693Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3586773Z                             do_blocks = []
2026-02-14T13:01:56.3586872Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3586929Z     
2026-02-14T13:01:56.3587030Z                             def replace_do_block(match):
2026-02-14T13:01:56.3587120Z                                 block = match.group(0)
2026-02-14T13:01:56.3587250Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3587347Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3587440Z                                 return placeholder
2026-02-14T13:01:56.3587503Z     
2026-02-14T13:01:56.3587617Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3587724Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3587804Z                                                     ^^
2026-02-14T13:01:56.3587988Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3588061Z                             )
2026-02-14T13:01:56.3588167Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3588172Z 
2026-02-14T13:01:56.3588270Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3588530Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_record_note_change_creates_history _
2026-02-14T13:01:56.3588535Z 
2026-02-14T13:01:56.3588934Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3588948Z 
2026-02-14T13:01:56.3589036Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3589140Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3589206Z         """
2026-02-14T13:01:56.3589348Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3589406Z     
2026-02-14T13:01:56.3589538Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3589670Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3589731Z         """
2026-02-14T13:01:56.3589825Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3589949Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3590011Z     
2026-02-14T13:01:56.3590115Z         # Parse connection string to get database name
2026-02-14T13:01:56.3590493Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3590561Z     
2026-02-14T13:01:56.3590745Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3590969Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3591230Z     
2026-02-14T13:01:56.3591376Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3591485Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3591559Z         if len(parts) >= 4:
2026-02-14T13:01:56.3591682Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3591747Z         else:
2026-02-14T13:01:56.3591845Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3591910Z     
2026-02-14T13:01:56.3592006Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3592241Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3592314Z         import time
2026-02-14T13:01:56.3592372Z     
2026-02-14T13:01:56.3592440Z         max_retries = 5
2026-02-14T13:01:56.3592508Z         retry_delay = 2
2026-02-14T13:01:56.3592577Z     
2026-02-14T13:01:56.3592661Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3592722Z             try:
2026-02-14T13:01:56.3592826Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3592919Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3593001Z                 conn.autocommit = True
2026-02-14T13:01:56.3593064Z                 try:
2026-02-14T13:01:56.3593145Z                     cur = conn.cursor()
2026-02-14T13:01:56.3593333Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3593410Z                     if not cur.fetchone():
2026-02-14T13:01:56.3593569Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3593686Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3593756Z                     cur.close()
2026-02-14T13:01:56.3593828Z                 finally:
2026-02-14T13:01:56.3593907Z                     conn.close()
2026-02-14T13:01:56.3593976Z                 break  # Success
2026-02-14T13:01:56.3594165Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3594259Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3594327Z                     print(
2026-02-14T13:01:56.3594542Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3594611Z                     )
2026-02-14T13:01:56.3594692Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3594755Z                 else:
2026-02-14T13:01:56.3594963Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3595149Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3595216Z                     pass
2026-02-14T13:01:56.3595330Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3595417Z                 break  # Already exists
2026-02-14T13:01:56.3595475Z     
2026-02-14T13:01:56.3595690Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3595878Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3596006Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3596064Z     
2026-02-14T13:01:56.3596143Z         close_all_pools()
2026-02-14T13:01:56.3596200Z     
2026-02-14T13:01:56.3596314Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3596474Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3596757Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3596847Z             conn.autocommit = True
2026-02-14T13:01:56.3596925Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3597123Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3597317Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3597391Z                 cur.execute(
2026-02-14T13:01:56.3597463Z                     """
2026-02-14T13:01:56.3597559Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3597639Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3597733Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3597827Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3597891Z                     """
2026-02-14T13:01:56.3597951Z                 )
2026-02-14T13:01:56.3598014Z     
2026-02-14T13:01:56.3598209Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3598389Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3598457Z                 try:
2026-02-14T13:01:56.3598580Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3598654Z                     cur.execute("""
2026-02-14T13:01:56.3598721Z                         DO $$
2026-02-14T13:01:56.3598795Z                         DECLARE
2026-02-14T13:01:56.3598867Z                             r RECORD;
2026-02-14T13:01:56.3598933Z                         BEGIN
2026-02-14T13:01:56.3599015Z                             FOR r IN (
2026-02-14T13:01:56.3599119Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3599200Z                                 FROM pg_views
2026-02-14T13:01:56.3599328Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3599404Z                             )
2026-02-14T13:01:56.3599474Z                             LOOP
2026-02-14T13:01:56.3599783Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3599866Z                             END LOOP;
2026-02-14T13:01:56.3599933Z                         END $$;
2026-02-14T13:01:56.3599999Z                     """)
2026-02-14T13:01:56.3600078Z                     # Drop tables
2026-02-14T13:01:56.3600151Z                     cur.execute("""
2026-02-14T13:01:56.3600215Z                         DO $$
2026-02-14T13:01:56.3600280Z                         DECLARE
2026-02-14T13:01:56.3600357Z                             r RECORD;
2026-02-14T13:01:56.3600424Z                         BEGIN
2026-02-14T13:01:56.3600496Z                             FOR r IN (
2026-02-14T13:01:56.3600602Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3600690Z                                 FROM pg_tables
2026-02-14T13:01:56.3600817Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3600891Z                             )
2026-02-14T13:01:56.3600962Z                             LOOP
2026-02-14T13:01:56.3601527Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3601602Z                             END LOOP;
2026-02-14T13:01:56.3601675Z                         END $$;
2026-02-14T13:01:56.3601738Z                     """)
2026-02-14T13:01:56.3601820Z                 except psycopg2.Error:
2026-02-14T13:01:56.3601999Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3602065Z                     pass
2026-02-14T13:01:56.3602122Z     
2026-02-14T13:01:56.3602298Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3602547Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3602632Z                 if init_dir.exists():
2026-02-14T13:01:56.3602739Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3602831Z                     for script_path in scripts:
2026-02-14T13:01:56.3603060Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3603133Z                             sql = f.read()
2026-02-14T13:01:56.3603338Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3603472Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3603550Z                             statements = []
2026-02-14T13:01:56.3603611Z     
2026-02-14T13:01:56.3603787Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3603863Z                             do_blocks = []
2026-02-14T13:01:56.3603969Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3604031Z     
2026-02-14T13:01:56.3604126Z                             def replace_do_block(match):
2026-02-14T13:01:56.3604219Z                                 block = match.group(0)
2026-02-14T13:01:56.3604357Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3604452Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3604539Z                                 return placeholder
2026-02-14T13:01:56.3604602Z     
2026-02-14T13:01:56.3604709Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3604806Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3604886Z                                                     ^^
2026-02-14T13:01:56.3605076Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3605145Z                             )
2026-02-14T13:01:56.3605251Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3605257Z 
2026-02-14T13:01:56.3605361Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3605595Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_upsert_status_records_history _
2026-02-14T13:01:56.3605604Z 
2026-02-14T13:01:56.3605903Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3605908Z 
2026-02-14T13:01:56.3605993Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3606103Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3606164Z         """
2026-02-14T13:01:56.3606297Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3606362Z     
2026-02-14T13:01:56.3606495Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3606617Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3606677Z         """
2026-02-14T13:01:56.3606782Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3606903Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3606960Z     
2026-02-14T13:01:56.3607073Z         # Parse connection string to get database name
2026-02-14T13:01:56.3607320Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3607377Z     
2026-02-14T13:01:56.3607559Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3607791Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3607847Z     
2026-02-14T13:01:56.3607990Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3608101Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3608174Z         if len(parts) >= 4:
2026-02-14T13:01:56.3608409Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3608484Z         else:
2026-02-14T13:01:56.3608586Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3608644Z     
2026-02-14T13:01:56.3608739Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3609059Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3609124Z         import time
2026-02-14T13:01:56.3609183Z     
2026-02-14T13:01:56.3609260Z         max_retries = 5
2026-02-14T13:01:56.3609327Z         retry_delay = 2
2026-02-14T13:01:56.3609383Z     
2026-02-14T13:01:56.3609468Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3609536Z             try:
2026-02-14T13:01:56.3609635Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3609728Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3609813Z                 conn.autocommit = True
2026-02-14T13:01:56.3609877Z                 try:
2026-02-14T13:01:56.3609959Z                     cur = conn.cursor()
2026-02-14T13:01:56.3610152Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3610232Z                     if not cur.fetchone():
2026-02-14T13:01:56.3610388Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3610504Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3610582Z                     cur.close()
2026-02-14T13:01:56.3610649Z                 finally:
2026-02-14T13:01:56.3610722Z                     conn.close()
2026-02-14T13:01:56.3610803Z                 break  # Success
2026-02-14T13:01:56.3610990Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3611354Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3611437Z                     print(
2026-02-14T13:01:56.3611660Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3611725Z                     )
2026-02-14T13:01:56.3611808Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3611877Z                 else:
2026-02-14T13:01:56.3612086Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3612268Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3612341Z                     pass
2026-02-14T13:01:56.3612457Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3612534Z                 break  # Already exists
2026-02-14T13:01:56.3612597Z     
2026-02-14T13:01:56.3612810Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3612992Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3613127Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3613192Z     
2026-02-14T13:01:56.3613262Z         close_all_pools()
2026-02-14T13:01:56.3613319Z     
2026-02-14T13:01:56.3613442Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3613612Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3613749Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3613834Z             conn.autocommit = True
2026-02-14T13:01:56.3613910Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3614099Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3614189Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3614265Z                 cur.execute(
2026-02-14T13:01:56.3614333Z                     """
2026-02-14T13:01:56.3614430Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3614513Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3614731Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3614829Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3614900Z                     """
2026-02-14T13:01:56.3614962Z                 )
2026-02-14T13:01:56.3615121Z     
2026-02-14T13:01:56.3615314Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3615499Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3615563Z                 try:
2026-02-14T13:01:56.3615679Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3615758Z                     cur.execute("""
2026-02-14T13:01:56.3615824Z                         DO $$
2026-02-14T13:01:56.3615891Z                         DECLARE
2026-02-14T13:01:56.3615961Z                             r RECORD;
2026-02-14T13:01:56.3616031Z                         BEGIN
2026-02-14T13:01:56.3616110Z                             FOR r IN (
2026-02-14T13:01:56.3616212Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3616299Z                                 FROM pg_views
2026-02-14T13:01:56.3616429Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3616500Z                             )
2026-02-14T13:01:56.3616572Z                             LOOP
2026-02-14T13:01:56.3616883Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3616958Z                             END LOOP;
2026-02-14T13:01:56.3617030Z                         END $$;
2026-02-14T13:01:56.3617095Z                     """)
2026-02-14T13:01:56.3617166Z                     # Drop tables
2026-02-14T13:01:56.3617240Z                     cur.execute("""
2026-02-14T13:01:56.3617312Z                         DO $$
2026-02-14T13:01:56.3617379Z                         DECLARE
2026-02-14T13:01:56.3617452Z                             r RECORD;
2026-02-14T13:01:56.3617525Z                         BEGIN
2026-02-14T13:01:56.3617594Z                             FOR r IN (
2026-02-14T13:01:56.3617693Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3617777Z                                 FROM pg_tables
2026-02-14T13:01:56.3617907Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3617972Z                             )
2026-02-14T13:01:56.3618040Z                             LOOP
2026-02-14T13:01:56.3618355Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3618426Z                             END LOOP;
2026-02-14T13:01:56.3618492Z                         END $$;
2026-02-14T13:01:56.3618560Z                     """)
2026-02-14T13:01:56.3618645Z                 except psycopg2.Error:
2026-02-14T13:01:56.3618823Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3618890Z                     pass
2026-02-14T13:01:56.3618953Z     
2026-02-14T13:01:56.3619120Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3619233Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3619312Z                 if init_dir.exists():
2026-02-14T13:01:56.3619416Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3619504Z                     for script_path in scripts:
2026-02-14T13:01:56.3619633Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3619708Z                             sql = f.read()
2026-02-14T13:01:56.3619913Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3620137Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3620223Z                             statements = []
2026-02-14T13:01:56.3620282Z     
2026-02-14T13:01:56.3620456Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3620616Z                             do_blocks = []
2026-02-14T13:01:56.3620718Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3620775Z     
2026-02-14T13:01:56.3620880Z                             def replace_do_block(match):
2026-02-14T13:01:56.3620974Z                                 block = match.group(0)
2026-02-14T13:01:56.3621338Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3621450Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3621548Z                                 return placeholder
2026-02-14T13:01:56.3621606Z     
2026-02-14T13:01:56.3621714Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3621823Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3621905Z                                                     ^^
2026-02-14T13:01:56.3622090Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3622167Z                             )
2026-02-14T13:01:56.3622275Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3622280Z 
2026-02-14T13:01:56.3622379Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3622661Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_get_user_status_history_returns_all_jobs _
2026-02-14T13:01:56.3622666Z 
2026-02-14T13:01:56.3622942Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3622953Z 
2026-02-14T13:01:56.3623038Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3623142Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3623202Z         """
2026-02-14T13:01:56.3623345Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3623403Z     
2026-02-14T13:01:56.3623534Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3623663Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3623728Z         """
2026-02-14T13:01:56.3623820Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3623949Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3624006Z     
2026-02-14T13:01:56.3624110Z         # Parse connection string to get database name
2026-02-14T13:01:56.3624355Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3624416Z     
2026-02-14T13:01:56.3624597Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3624825Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3624890Z     
2026-02-14T13:01:56.3625030Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3625136Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3625219Z         if len(parts) >= 4:
2026-02-14T13:01:56.3625334Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3625394Z         else:
2026-02-14T13:01:56.3625492Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3625557Z     
2026-02-14T13:01:56.3625651Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3625876Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3625945Z         import time
2026-02-14T13:01:56.3626002Z     
2026-02-14T13:01:56.3626070Z         max_retries = 5
2026-02-14T13:01:56.3626137Z         retry_delay = 2
2026-02-14T13:01:56.3626201Z     
2026-02-14T13:01:56.3626413Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3626479Z             try:
2026-02-14T13:01:56.3626584Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3626679Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3626861Z                 conn.autocommit = True
2026-02-14T13:01:56.3626922Z                 try:
2026-02-14T13:01:56.3627004Z                     cur = conn.cursor()
2026-02-14T13:01:56.3627189Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3627268Z                     if not cur.fetchone():
2026-02-14T13:01:56.3627423Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3627539Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3627609Z                     cur.close()
2026-02-14T13:01:56.3627681Z                 finally:
2026-02-14T13:01:56.3627752Z                     conn.close()
2026-02-14T13:01:56.3627825Z                 break  # Success
2026-02-14T13:01:56.3628013Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3628108Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3628178Z                     print(
2026-02-14T13:01:56.3628398Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3628468Z                     )
2026-02-14T13:01:56.3628550Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3628614Z                 else:
2026-02-14T13:01:56.3628822Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3629002Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3629068Z                     pass
2026-02-14T13:01:56.3629181Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3629268Z                 break  # Already exists
2026-02-14T13:01:56.3629326Z     
2026-02-14T13:01:56.3629541Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3629726Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3629860Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3629918Z     
2026-02-14T13:01:56.3629995Z         close_all_pools()
2026-02-14T13:01:56.3630052Z     
2026-02-14T13:01:56.3630169Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3630330Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3630474Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3630554Z             conn.autocommit = True
2026-02-14T13:01:56.3630634Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3630836Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3630927Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3631000Z                 cur.execute(
2026-02-14T13:01:56.3631192Z                     """
2026-02-14T13:01:56.3631291Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3631374Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3631467Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3631562Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3631625Z                     """
2026-02-14T13:01:56.3631685Z                 )
2026-02-14T13:01:56.3631748Z     
2026-02-14T13:01:56.3631947Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3636122Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3636222Z                 try:
2026-02-14T13:01:56.3636517Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3636604Z                     cur.execute("""
2026-02-14T13:01:56.3636677Z                         DO $$
2026-02-14T13:01:56.3636755Z                         DECLARE
2026-02-14T13:01:56.3636831Z                             r RECORD;
2026-02-14T13:01:56.3637050Z                         BEGIN
2026-02-14T13:01:56.3637135Z                             FOR r IN (
2026-02-14T13:01:56.3637243Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3637328Z                                 FROM pg_views
2026-02-14T13:01:56.3637462Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3637538Z                             )
2026-02-14T13:01:56.3637613Z                             LOOP
2026-02-14T13:01:56.3637937Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3638019Z                             END LOOP;
2026-02-14T13:01:56.3638093Z                         END $$;
2026-02-14T13:01:56.3638161Z                     """)
2026-02-14T13:01:56.3638240Z                     # Drop tables
2026-02-14T13:01:56.3638313Z                     cur.execute("""
2026-02-14T13:01:56.3638385Z                         DO $$
2026-02-14T13:01:56.3638452Z                         DECLARE
2026-02-14T13:01:56.3638529Z                             r RECORD;
2026-02-14T13:01:56.3638593Z                         BEGIN
2026-02-14T13:01:56.3638665Z                             FOR r IN (
2026-02-14T13:01:56.3638776Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3638860Z                                 FROM pg_tables
2026-02-14T13:01:56.3638990Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3639062Z                             )
2026-02-14T13:01:56.3639132Z                             LOOP
2026-02-14T13:01:56.3639451Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3639521Z                             END LOOP;
2026-02-14T13:01:56.3639591Z                         END $$;
2026-02-14T13:01:56.3639659Z                     """)
2026-02-14T13:01:56.3639746Z                 except psycopg2.Error:
2026-02-14T13:01:56.3639934Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3640007Z                     pass
2026-02-14T13:01:56.3640066Z     
2026-02-14T13:01:56.3640254Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3640369Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3640448Z                 if init_dir.exists():
2026-02-14T13:01:56.3640560Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3640656Z                     for script_path in scripts:
2026-02-14T13:01:56.3640786Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3640865Z                             sql = f.read()
2026-02-14T13:01:56.3641243Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3641391Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3641470Z                             statements = []
2026-02-14T13:01:56.3641536Z     
2026-02-14T13:01:56.3641714Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3641790Z                             do_blocks = []
2026-02-14T13:01:56.3641893Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3641958Z     
2026-02-14T13:01:56.3642054Z                             def replace_do_block(match):
2026-02-14T13:01:56.3642147Z                                 block = match.group(0)
2026-02-14T13:01:56.3642404Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3642503Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3642592Z                                 return placeholder
2026-02-14T13:01:56.3642765Z     
2026-02-14T13:01:56.3642877Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3642977Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3643060Z                                                     ^^
2026-02-14T13:01:56.3643259Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3643329Z                             )
2026-02-14T13:01:56.3643438Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3643445Z 
2026-02-14T13:01:56.3643553Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3643835Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_get_job_status_history_returns_all_users _
2026-02-14T13:01:56.3643841Z 
2026-02-14T13:01:56.3644148Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3644153Z 
2026-02-14T13:01:56.3644245Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3644364Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3644426Z         """
2026-02-14T13:01:56.3644564Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3644628Z     
2026-02-14T13:01:56.3644764Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3644891Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3644952Z         """
2026-02-14T13:01:56.3645057Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3645181Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3645238Z     
2026-02-14T13:01:56.3645351Z         # Parse connection string to get database name
2026-02-14T13:01:56.3645606Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3645666Z     
2026-02-14T13:01:56.3645855Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3646093Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3646150Z     
2026-02-14T13:01:56.3646291Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3646406Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3646480Z         if len(parts) >= 4:
2026-02-14T13:01:56.3646602Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3646669Z         else:
2026-02-14T13:01:56.3646768Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3646827Z     
2026-02-14T13:01:56.3646922Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3647160Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3647226Z         import time
2026-02-14T13:01:56.3647283Z     
2026-02-14T13:01:56.3647358Z         max_retries = 5
2026-02-14T13:01:56.3647425Z         retry_delay = 2
2026-02-14T13:01:56.3647486Z     
2026-02-14T13:01:56.3647580Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3647643Z             try:
2026-02-14T13:01:56.3647745Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3647839Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3647928Z                 conn.autocommit = True
2026-02-14T13:01:56.3647993Z                 try:
2026-02-14T13:01:56.3648071Z                     cur = conn.cursor()
2026-02-14T13:01:56.3648268Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3648350Z                     if not cur.fetchone():
2026-02-14T13:01:56.3648592Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3648711Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3648793Z                     cur.close()
2026-02-14T13:01:56.3648859Z                 finally:
2026-02-14T13:01:56.3649016Z                     conn.close()
2026-02-14T13:01:56.3649094Z                 break  # Success
2026-02-14T13:01:56.3649290Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3649381Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3649458Z                     print(
2026-02-14T13:01:56.3649682Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3649746Z                     )
2026-02-14T13:01:56.3649833Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3649903Z                 else:
2026-02-14T13:01:56.3650112Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3650295Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3650371Z                     pass
2026-02-14T13:01:56.3650485Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3650572Z                 break  # Already exists
2026-02-14T13:01:56.3650635Z     
2026-02-14T13:01:56.3650853Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3651187Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3651324Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3651388Z     
2026-02-14T13:01:56.3651461Z         close_all_pools()
2026-02-14T13:01:56.3651518Z     
2026-02-14T13:01:56.3651639Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3651809Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3651949Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3652033Z             conn.autocommit = True
2026-02-14T13:01:56.3652112Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3652307Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3652397Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3652474Z                 cur.execute(
2026-02-14T13:01:56.3652537Z                     """
2026-02-14T13:01:56.3652633Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3652718Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3652812Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3652900Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3652968Z                     """
2026-02-14T13:01:56.3653031Z                 )
2026-02-14T13:01:56.3653087Z     
2026-02-14T13:01:56.3653278Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3653467Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3653534Z                 try:
2026-02-14T13:01:56.3653649Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3653731Z                     cur.execute("""
2026-02-14T13:01:56.3653799Z                         DO $$
2026-02-14T13:01:56.3653866Z                         DECLARE
2026-02-14T13:01:56.3653944Z                             r RECORD;
2026-02-14T13:01:56.3654010Z                         BEGIN
2026-02-14T13:01:56.3654081Z                             FOR r IN (
2026-02-14T13:01:56.3654181Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3654269Z                                 FROM pg_views
2026-02-14T13:01:56.3654398Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3654582Z                             )
2026-02-14T13:01:56.3654663Z                             LOOP
2026-02-14T13:01:56.3654975Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3655148Z                             END LOOP;
2026-02-14T13:01:56.3655220Z                         END $$;
2026-02-14T13:01:56.3655285Z                     """)
2026-02-14T13:01:56.3655356Z                     # Drop tables
2026-02-14T13:01:56.3655427Z                     cur.execute("""
2026-02-14T13:01:56.3655499Z                         DO $$
2026-02-14T13:01:56.3655563Z                         DECLARE
2026-02-14T13:01:56.3655630Z                             r RECORD;
2026-02-14T13:01:56.3655701Z                         BEGIN
2026-02-14T13:01:56.3655770Z                             FOR r IN (
2026-02-14T13:01:56.3655868Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3655954Z                                 FROM pg_tables
2026-02-14T13:01:56.3656085Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3656150Z                             )
2026-02-14T13:01:56.3656224Z                             LOOP
2026-02-14T13:01:56.3656544Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3656614Z                             END LOOP;
2026-02-14T13:01:56.3656679Z                         END $$;
2026-02-14T13:01:56.3656749Z                     """)
2026-02-14T13:01:56.3656828Z                 except psycopg2.Error:
2026-02-14T13:01:56.3656999Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3657066Z                     pass
2026-02-14T13:01:56.3657130Z     
2026-02-14T13:01:56.3657298Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3657416Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3657498Z                 if init_dir.exists():
2026-02-14T13:01:56.3657601Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3657696Z                     for script_path in scripts:
2026-02-14T13:01:56.3657830Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3657906Z                             sql = f.read()
2026-02-14T13:01:56.3658112Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3658243Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3658329Z                             statements = []
2026-02-14T13:01:56.3658389Z     
2026-02-14T13:01:56.3658563Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3658650Z                             do_blocks = []
2026-02-14T13:01:56.3658751Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3658810Z     
2026-02-14T13:01:56.3658915Z                             def replace_do_block(match):
2026-02-14T13:01:56.3659011Z                                 block = match.group(0)
2026-02-14T13:01:56.3659136Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3659238Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3659327Z                                 return placeholder
2026-02-14T13:01:56.3659384Z     
2026-02-14T13:01:56.3659494Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3659597Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3659677Z                                                     ^^
2026-02-14T13:01:56.3659861Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3660028Z                             )
2026-02-14T13:01:56.3660136Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3660142Z 
2026-02-14T13:01:56.3660244Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3660607Z _ ERROR at setup of TestJobStatusHistoryIntegration.test_history_metadata_stores_json_correctly _
2026-02-14T13:01:56.3660613Z 
2026-02-14T13:01:56.3660894Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3660899Z 
2026-02-14T13:01:56.3660990Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3661330Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3661440Z         """
2026-02-14T13:01:56.3661669Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3661777Z     
2026-02-14T13:01:56.3661965Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3662104Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3662175Z         """
2026-02-14T13:01:56.3662272Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3662403Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3662463Z     
2026-02-14T13:01:56.3662578Z         # Parse connection string to get database name
2026-02-14T13:01:56.3662824Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3662889Z     
2026-02-14T13:01:56.3663075Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3663305Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3663366Z     
2026-02-14T13:01:56.3663508Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3663623Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3663699Z         if len(parts) >= 4:
2026-02-14T13:01:56.3663821Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3663882Z         else:
2026-02-14T13:01:56.3663990Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3664046Z     
2026-02-14T13:01:56.3664145Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3664375Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3664442Z         import time
2026-02-14T13:01:56.3664498Z     
2026-02-14T13:01:56.3664566Z         max_retries = 5
2026-02-14T13:01:56.3664643Z         retry_delay = 2
2026-02-14T13:01:56.3664699Z     
2026-02-14T13:01:56.3664785Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3664853Z             try:
2026-02-14T13:01:56.3664955Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3665049Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3665130Z                 conn.autocommit = True
2026-02-14T13:01:56.3665209Z                 try:
2026-02-14T13:01:56.3665288Z                     cur = conn.cursor()
2026-02-14T13:01:56.3665479Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3665572Z                     if not cur.fetchone():
2026-02-14T13:01:56.3665722Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3665841Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3665920Z                     cur.close()
2026-02-14T13:01:56.3665989Z                 finally:
2026-02-14T13:01:56.3666061Z                     conn.close()
2026-02-14T13:01:56.3666132Z                 break  # Success
2026-02-14T13:01:56.3666330Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3666421Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3666493Z                     print(
2026-02-14T13:01:56.3666863Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3666935Z                     )
2026-02-14T13:01:56.3667023Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3667197Z                 else:
2026-02-14T13:01:56.3667402Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3667585Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3667653Z                     pass
2026-02-14T13:01:56.3667780Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3667856Z                 break  # Already exists
2026-02-14T13:01:56.3667913Z     
2026-02-14T13:01:56.3668134Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3668316Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3668453Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3668517Z     
2026-02-14T13:01:56.3668588Z         close_all_pools()
2026-02-14T13:01:56.3668646Z     
2026-02-14T13:01:56.3668765Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3668938Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3669077Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3669158Z             conn.autocommit = True
2026-02-14T13:01:56.3669241Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3669433Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3669525Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3669601Z                 cur.execute(
2026-02-14T13:01:56.3669666Z                     """
2026-02-14T13:01:56.3669765Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3669848Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3669948Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3670038Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3670101Z                     """
2026-02-14T13:01:56.3670176Z                 )
2026-02-14T13:01:56.3670234Z     
2026-02-14T13:01:56.3670418Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3670606Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3670669Z                 try:
2026-02-14T13:01:56.3670786Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3670860Z                     cur.execute("""
2026-02-14T13:01:56.3670935Z                         DO $$
2026-02-14T13:01:56.3671003Z                         DECLARE
2026-02-14T13:01:56.3671323Z                             r RECORD;
2026-02-14T13:01:56.3671459Z                         BEGIN
2026-02-14T13:01:56.3671537Z                             FOR r IN (
2026-02-14T13:01:56.3671638Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3671721Z                                 FROM pg_views
2026-02-14T13:01:56.3671868Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3671934Z                             )
2026-02-14T13:01:56.3672003Z                             LOOP
2026-02-14T13:01:56.3672326Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3672400Z                             END LOOP;
2026-02-14T13:01:56.3672467Z                         END $$;
2026-02-14T13:01:56.3672538Z                     """)
2026-02-14T13:01:56.3672611Z                     # Drop tables
2026-02-14T13:01:56.3672683Z                     cur.execute("""
2026-02-14T13:01:56.3672749Z                         DO $$
2026-02-14T13:01:56.3672955Z                         DECLARE
2026-02-14T13:01:56.3673030Z                             r RECORD;
2026-02-14T13:01:56.3673095Z                         BEGIN
2026-02-14T13:01:56.3673176Z                             FOR r IN (
2026-02-14T13:01:56.3673383Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3673467Z                                 FROM pg_tables
2026-02-14T13:01:56.3673599Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3673666Z                             )
2026-02-14T13:01:56.3673735Z                             LOOP
2026-02-14T13:01:56.3674048Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3674125Z                             END LOOP;
2026-02-14T13:01:56.3674191Z                         END $$;
2026-02-14T13:01:56.3674255Z                     """)
2026-02-14T13:01:56.3674353Z                 except psycopg2.Error:
2026-02-14T13:01:56.3674532Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3674600Z                     pass
2026-02-14T13:01:56.3674663Z     
2026-02-14T13:01:56.3674841Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3674951Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3675026Z                 if init_dir.exists():
2026-02-14T13:01:56.3675138Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3675226Z                     for script_path in scripts:
2026-02-14T13:01:56.3675350Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3675434Z                             sql = f.read()
2026-02-14T13:01:56.3675639Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3675775Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3675861Z                             statements = []
2026-02-14T13:01:56.3675920Z     
2026-02-14T13:01:56.3676097Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3676176Z                             do_blocks = []
2026-02-14T13:01:56.3676286Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3676344Z     
2026-02-14T13:01:56.3676442Z                             def replace_do_block(match):
2026-02-14T13:01:56.3676540Z                                 block = match.group(0)
2026-02-14T13:01:56.3676665Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3676761Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3676857Z                                 return placeholder
2026-02-14T13:01:56.3676958Z     
2026-02-14T13:01:56.3677074Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3677174Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3677262Z                                                     ^^
2026-02-14T13:01:56.3677448Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3677524Z                             )
2026-02-14T13:01:56.3677639Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3677645Z 
2026-02-14T13:01:56.3677746Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3677916Z _______________ ERROR at setup of test_auth_login_returns_token ________________
2026-02-14T13:01:56.3677921Z 
2026-02-14T13:01:56.3678213Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3678218Z 
2026-02-14T13:01:56.3678316Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3678420Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3678581Z         """
2026-02-14T13:01:56.3678723Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3678780Z     
2026-02-14T13:01:56.3678911Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3679113Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3679178Z         """
2026-02-14T13:01:56.3679271Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3679397Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3679460Z     
2026-02-14T13:01:56.3679572Z         # Parse connection string to get database name
2026-02-14T13:01:56.3679824Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3679882Z     
2026-02-14T13:01:56.3680080Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3680320Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3680377Z     
2026-02-14T13:01:56.3680525Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3680633Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3680714Z         if len(parts) >= 4:
2026-02-14T13:01:56.3680837Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3680898Z         else:
2026-02-14T13:01:56.3681006Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3681212Z     
2026-02-14T13:01:56.3681316Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3681543Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3681610Z         import time
2026-02-14T13:01:56.3681667Z     
2026-02-14T13:01:56.3681743Z         max_retries = 5
2026-02-14T13:01:56.3681812Z         retry_delay = 2
2026-02-14T13:01:56.3681868Z     
2026-02-14T13:01:56.3681965Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3682028Z             try:
2026-02-14T13:01:56.3682128Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3682223Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3682317Z                 conn.autocommit = True
2026-02-14T13:01:56.3682381Z                 try:
2026-02-14T13:01:56.3682458Z                     cur = conn.cursor()
2026-02-14T13:01:56.3682653Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3682732Z                     if not cur.fetchone():
2026-02-14T13:01:56.3682885Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3683007Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3683078Z                     cur.close()
2026-02-14T13:01:56.3683146Z                 finally:
2026-02-14T13:01:56.3683224Z                     conn.close()
2026-02-14T13:01:56.3683304Z                 break  # Success
2026-02-14T13:01:56.3683493Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3683581Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3683660Z                     print(
2026-02-14T13:01:56.3683876Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3683938Z                     )
2026-02-14T13:01:56.3684026Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3684089Z                 else:
2026-02-14T13:01:56.3684287Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3684465Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3684537Z                     pass
2026-02-14T13:01:56.3684650Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3684850Z                 break  # Already exists
2026-02-14T13:01:56.3684918Z     
2026-02-14T13:01:56.3685136Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3685321Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3685608Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3685666Z     
2026-02-14T13:01:56.3685738Z         close_all_pools()
2026-02-14T13:01:56.3685794Z     
2026-02-14T13:01:56.3685914Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3686078Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3686219Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3686306Z             conn.autocommit = True
2026-02-14T13:01:56.3686385Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3686584Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3686683Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3686756Z                 cur.execute(
2026-02-14T13:01:56.3686819Z                     """
2026-02-14T13:01:56.3686921Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3687007Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3687099Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3687189Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3687257Z                     """
2026-02-14T13:01:56.3687319Z                 )
2026-02-14T13:01:56.3687376Z     
2026-02-14T13:01:56.3687563Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3687750Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3687814Z                 try:
2026-02-14T13:01:56.3687934Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3688014Z                     cur.execute("""
2026-02-14T13:01:56.3688082Z                         DO $$
2026-02-14T13:01:56.3688150Z                         DECLARE
2026-02-14T13:01:56.3688231Z                             r RECORD;
2026-02-14T13:01:56.3688297Z                         BEGIN
2026-02-14T13:01:56.3688368Z                             FOR r IN (
2026-02-14T13:01:56.3688468Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3688555Z                                 FROM pg_views
2026-02-14T13:01:56.3688684Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3688748Z                             )
2026-02-14T13:01:56.3688823Z                             LOOP
2026-02-14T13:01:56.3689134Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3689215Z                             END LOOP;
2026-02-14T13:01:56.3689286Z                         END $$;
2026-02-14T13:01:56.3689353Z                     """)
2026-02-14T13:01:56.3689425Z                     # Drop tables
2026-02-14T13:01:56.3689497Z                     cur.execute("""
2026-02-14T13:01:56.3689573Z                         DO $$
2026-02-14T13:01:56.3689639Z                         DECLARE
2026-02-14T13:01:56.3689709Z                             r RECORD;
2026-02-14T13:01:56.3689781Z                         BEGIN
2026-02-14T13:01:56.3689851Z                             FOR r IN (
2026-02-14T13:01:56.3689950Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3690033Z                                 FROM pg_tables
2026-02-14T13:01:56.3690166Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3690230Z                             )
2026-02-14T13:01:56.3690299Z                             LOOP
2026-02-14T13:01:56.3690703Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3690776Z                             END LOOP;
2026-02-14T13:01:56.3690841Z                         END $$;
2026-02-14T13:01:56.3690987Z                     """)
2026-02-14T13:01:56.3691207Z                 except psycopg2.Error:
2026-02-14T13:01:56.3691386Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3691459Z                     pass
2026-02-14T13:01:56.3691517Z     
2026-02-14T13:01:56.3691687Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3691796Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3691879Z                 if init_dir.exists():
2026-02-14T13:01:56.3691983Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3692072Z                     for script_path in scripts:
2026-02-14T13:01:56.3692206Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3692283Z                             sql = f.read()
2026-02-14T13:01:56.3692488Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3692629Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3692708Z                             statements = []
2026-02-14T13:01:56.3692765Z     
2026-02-14T13:01:56.3692942Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3693026Z                             do_blocks = []
2026-02-14T13:01:56.3693128Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3693186Z     
2026-02-14T13:01:56.3693291Z                             def replace_do_block(match):
2026-02-14T13:01:56.3693380Z                                 block = match.group(0)
2026-02-14T13:01:56.3693513Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3693616Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3693704Z                                 return placeholder
2026-02-14T13:01:56.3693766Z     
2026-02-14T13:01:56.3693874Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3693981Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3694065Z                                                     ^^
2026-02-14T13:01:56.3694250Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3694323Z                             )
2026-02-14T13:01:56.3694429Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3694434Z 
2026-02-14T13:01:56.3694533Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3694716Z ____________ ERROR at setup of test_update_campaign_with_jwt_token _____________
2026-02-14T13:01:56.3694721Z 
2026-02-14T13:01:56.3694996Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3695001Z 
2026-02-14T13:01:56.3695086Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3695192Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3695253Z         """
2026-02-14T13:01:56.3695391Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3695448Z     
2026-02-14T13:01:56.3695579Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3695706Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3695765Z         """
2026-02-14T13:01:56.3695857Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3695985Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3696041Z     
2026-02-14T13:01:56.3696146Z         # Parse connection string to get database name
2026-02-14T13:01:56.3696512Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3696577Z     
2026-02-14T13:01:56.3696760Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3697092Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3697154Z     
2026-02-14T13:01:56.3697296Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3697401Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3697481Z         if len(parts) >= 4:
2026-02-14T13:01:56.3697596Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3697657Z         else:
2026-02-14T13:01:56.3697757Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3697819Z     
2026-02-14T13:01:56.3697912Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3698142Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3698213Z         import time
2026-02-14T13:01:56.3698268Z     
2026-02-14T13:01:56.3698338Z         max_retries = 5
2026-02-14T13:01:56.3698410Z         retry_delay = 2
2026-02-14T13:01:56.3698472Z     
2026-02-14T13:01:56.3698558Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3698619Z             try:
2026-02-14T13:01:56.3698724Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3698817Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3698900Z                 conn.autocommit = True
2026-02-14T13:01:56.3698974Z                 try:
2026-02-14T13:01:56.3699050Z                     cur = conn.cursor()
2026-02-14T13:01:56.3699237Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3699317Z                     if not cur.fetchone():
2026-02-14T13:01:56.3699476Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3699593Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3699665Z                     cur.close()
2026-02-14T13:01:56.3699744Z                 finally:
2026-02-14T13:01:56.3699817Z                     conn.close()
2026-02-14T13:01:56.3699886Z                 break  # Success
2026-02-14T13:01:56.3700079Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3700169Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3700237Z                     print(
2026-02-14T13:01:56.3700458Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3700527Z                     )
2026-02-14T13:01:56.3700608Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3700671Z                 else:
2026-02-14T13:01:56.3700883Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3701262Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3701377Z                     pass
2026-02-14T13:01:56.3701509Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3701587Z                 break  # Already exists
2026-02-14T13:01:56.3701648Z     
2026-02-14T13:01:56.3701861Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3702046Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3702179Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3702236Z     
2026-02-14T13:01:56.3702314Z         close_all_pools()
2026-02-14T13:01:56.3702370Z     
2026-02-14T13:01:56.3702485Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3702792Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3702936Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3703018Z             conn.autocommit = True
2026-02-14T13:01:56.3703096Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3703409Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3703501Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3703575Z                 cur.execute(
2026-02-14T13:01:56.3703652Z                     """
2026-02-14T13:01:56.3703748Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3703829Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3703932Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3704022Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3704087Z                     """
2026-02-14T13:01:56.3704147Z                 )
2026-02-14T13:01:56.3704213Z     
2026-02-14T13:01:56.3704404Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3704583Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3704660Z                 try:
2026-02-14T13:01:56.3704777Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3704852Z                     cur.execute("""
2026-02-14T13:01:56.3704921Z                         DO $$
2026-02-14T13:01:56.3704994Z                         DECLARE
2026-02-14T13:01:56.3705066Z                             r RECORD;
2026-02-14T13:01:56.3705136Z                         BEGIN
2026-02-14T13:01:56.3705216Z                             FOR r IN (
2026-02-14T13:01:56.3705316Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3705398Z                                 FROM pg_views
2026-02-14T13:01:56.3705535Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3705600Z                             )
2026-02-14T13:01:56.3705669Z                             LOOP
2026-02-14T13:01:56.3705981Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3706062Z                             END LOOP;
2026-02-14T13:01:56.3706129Z                         END $$;
2026-02-14T13:01:56.3706194Z                     """)
2026-02-14T13:01:56.3706273Z                     # Drop tables
2026-02-14T13:01:56.3706344Z                     cur.execute("""
2026-02-14T13:01:56.3706410Z                         DO $$
2026-02-14T13:01:56.3706480Z                         DECLARE
2026-02-14T13:01:56.3706549Z                             r RECORD;
2026-02-14T13:01:56.3706613Z                         BEGIN
2026-02-14T13:01:56.3706683Z                             FOR r IN (
2026-02-14T13:01:56.3706793Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3706877Z                                 FROM pg_tables
2026-02-14T13:01:56.3707002Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3707072Z                             )
2026-02-14T13:01:56.3707148Z                             LOOP
2026-02-14T13:01:56.3707459Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3707538Z                             END LOOP;
2026-02-14T13:01:56.3707603Z                         END $$;
2026-02-14T13:01:56.3707668Z                     """)
2026-02-14T13:01:56.3707750Z                 except psycopg2.Error:
2026-02-14T13:01:56.3707928Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3707994Z                     pass
2026-02-14T13:01:56.3708051Z     
2026-02-14T13:01:56.3708310Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3708422Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3708497Z                 if init_dir.exists():
2026-02-14T13:01:56.3708612Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3708793Z                     for script_path in scripts:
2026-02-14T13:01:56.3708917Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3708993Z                             sql = f.read()
2026-02-14T13:01:56.3709202Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3709333Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3709411Z                             statements = []
2026-02-14T13:01:56.3709473Z     
2026-02-14T13:01:56.3709649Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3709728Z                             do_blocks = []
2026-02-14T13:01:56.3709837Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3709895Z     
2026-02-14T13:01:56.3709991Z                             def replace_do_block(match):
2026-02-14T13:01:56.3710087Z                                 block = match.group(0)
2026-02-14T13:01:56.3710219Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3710314Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3710399Z                                 return placeholder
2026-02-14T13:01:56.3710463Z     
2026-02-14T13:01:56.3710579Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3710675Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3710759Z                                                     ^^
2026-02-14T13:01:56.3710945Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3711016Z                             )
2026-02-14T13:01:56.3711394Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3711409Z 
2026-02-14T13:01:56.3711521Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3711729Z ______ ERROR at setup of TestMultiNoteIntegration.test_add_multiple_notes ______
2026-02-14T13:01:56.3711734Z 
2026-02-14T13:01:56.3712011Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3712016Z 
2026-02-14T13:01:56.3712102Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3712212Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3712274Z         """
2026-02-14T13:01:56.3712409Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3712472Z     
2026-02-14T13:01:56.3712601Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3712727Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3712791Z         """
2026-02-14T13:01:56.3712897Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3713020Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3713077Z     
2026-02-14T13:01:56.3713194Z         # Parse connection string to get database name
2026-02-14T13:01:56.3713435Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3713492Z     
2026-02-14T13:01:56.3713679Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3713904Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3713962Z     
2026-02-14T13:01:56.3714103Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3714223Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3714298Z         if len(parts) >= 4:
2026-02-14T13:01:56.3714546Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3714620Z         else:
2026-02-14T13:01:56.3714722Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3714783Z     
2026-02-14T13:01:56.3714994Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3715222Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3715291Z         import time
2026-02-14T13:01:56.3715348Z     
2026-02-14T13:01:56.3715426Z         max_retries = 5
2026-02-14T13:01:56.3715493Z         retry_delay = 2
2026-02-14T13:01:56.3715551Z     
2026-02-14T13:01:56.3715642Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3715705Z             try:
2026-02-14T13:01:56.3715803Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3715897Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3715983Z                 conn.autocommit = True
2026-02-14T13:01:56.3716051Z                 try:
2026-02-14T13:01:56.3716127Z                     cur = conn.cursor()
2026-02-14T13:01:56.3716317Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3716402Z                     if not cur.fetchone():
2026-02-14T13:01:56.3716552Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3716673Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3716742Z                     cur.close()
2026-02-14T13:01:56.3716809Z                 finally:
2026-02-14T13:01:56.3716882Z                     conn.close()
2026-02-14T13:01:56.3716956Z                 break  # Success
2026-02-14T13:01:56.3717142Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3717229Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3717304Z                     print(
2026-02-14T13:01:56.3717522Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3717585Z                     )
2026-02-14T13:01:56.3717675Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3717741Z                 else:
2026-02-14T13:01:56.3717946Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3718124Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3718195Z                     pass
2026-02-14T13:01:56.3718308Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3718386Z                 break  # Already exists
2026-02-14T13:01:56.3718447Z     
2026-02-14T13:01:56.3718660Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3718837Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3718977Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3719035Z     
2026-02-14T13:01:56.3719107Z         close_all_pools()
2026-02-14T13:01:56.3719163Z     
2026-02-14T13:01:56.3719285Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3719450Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3719589Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3719675Z             conn.autocommit = True
2026-02-14T13:01:56.3719754Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3719944Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3720039Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3720111Z                 cur.execute(
2026-02-14T13:01:56.3720174Z                     """
2026-02-14T13:01:56.3720269Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3720455Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3720551Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3720639Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3720709Z                     """
2026-02-14T13:01:56.3720845Z                 )
2026-02-14T13:01:56.3720903Z     
2026-02-14T13:01:56.3721234Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3721427Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3721490Z                 try:
2026-02-14T13:01:56.3721605Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3721686Z                     cur.execute("""
2026-02-14T13:01:56.3721754Z                         DO $$
2026-02-14T13:01:56.3721822Z                         DECLARE
2026-02-14T13:01:56.3721901Z                             r RECORD;
2026-02-14T13:01:56.3721972Z                         BEGIN
2026-02-14T13:01:56.3722044Z                             FOR r IN (
2026-02-14T13:01:56.3722143Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3722229Z                                 FROM pg_views
2026-02-14T13:01:56.3722363Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3722428Z                             )
2026-02-14T13:01:56.3722504Z                             LOOP
2026-02-14T13:01:56.3722811Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3722884Z                             END LOOP;
2026-02-14T13:01:56.3722954Z                         END $$;
2026-02-14T13:01:56.3723021Z                     """)
2026-02-14T13:01:56.3723092Z                     # Drop tables
2026-02-14T13:01:56.3723164Z                     cur.execute("""
2026-02-14T13:01:56.3723236Z                         DO $$
2026-02-14T13:01:56.3723305Z                         DECLARE
2026-02-14T13:01:56.3723375Z                             r RECORD;
2026-02-14T13:01:56.3723447Z                         BEGIN
2026-02-14T13:01:56.3723517Z                             FOR r IN (
2026-02-14T13:01:56.3723619Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3723707Z                                 FROM pg_tables
2026-02-14T13:01:56.3723830Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3723894Z                             )
2026-02-14T13:01:56.3723962Z                             LOOP
2026-02-14T13:01:56.3724278Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3724348Z                             END LOOP;
2026-02-14T13:01:56.3724419Z                         END $$;
2026-02-14T13:01:56.3724497Z                     """)
2026-02-14T13:01:56.3724583Z                 except psycopg2.Error:
2026-02-14T13:01:56.3724755Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3724828Z                     pass
2026-02-14T13:01:56.3724885Z     
2026-02-14T13:01:56.3725057Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3725165Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3725248Z                 if init_dir.exists():
2026-02-14T13:01:56.3725351Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3725441Z                     for script_path in scripts:
2026-02-14T13:01:56.3725571Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3725646Z                             sql = f.read()
2026-02-14T13:01:56.3725848Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3726129Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3726214Z                             statements = []
2026-02-14T13:01:56.3726272Z     
2026-02-14T13:01:56.3726448Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3726636Z                             do_blocks = []
2026-02-14T13:01:56.3726736Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3726792Z     
2026-02-14T13:01:56.3726897Z                             def replace_do_block(match):
2026-02-14T13:01:56.3726986Z                                 block = match.group(0)
2026-02-14T13:01:56.3727116Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3727216Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3727302Z                                 return placeholder
2026-02-14T13:01:56.3727359Z     
2026-02-14T13:01:56.3727472Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3727573Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3727653Z                                                     ^^
2026-02-14T13:01:56.3727836Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3727916Z                             )
2026-02-14T13:01:56.3728022Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3728028Z 
2026-02-14T13:01:56.3728126Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3728330Z __ ERROR at setup of TestMultiNoteIntegration.test_notes_ordered_newest_first __
2026-02-14T13:01:56.3728335Z 
2026-02-14T13:01:56.3728614Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3728619Z 
2026-02-14T13:01:56.3728705Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3728809Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3728873Z         """
2026-02-14T13:01:56.3729011Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3729067Z     
2026-02-14T13:01:56.3729196Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3729327Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3729388Z         """
2026-02-14T13:01:56.3729483Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3729608Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3729665Z     
2026-02-14T13:01:56.3729768Z         # Parse connection string to get database name
2026-02-14T13:01:56.3730005Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3730067Z     
2026-02-14T13:01:56.3730247Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3730482Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3730545Z     
2026-02-14T13:01:56.3730686Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3730794Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3730878Z         if len(parts) >= 4:
2026-02-14T13:01:56.3730995Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3731184Z         else:
2026-02-14T13:01:56.3731289Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3731351Z     
2026-02-14T13:01:56.3731445Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3731671Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3731743Z         import time
2026-02-14T13:01:56.3731800Z     
2026-02-14T13:01:56.3731868Z         max_retries = 5
2026-02-14T13:01:56.3731941Z         retry_delay = 2
2026-02-14T13:01:56.3731998Z     
2026-02-14T13:01:56.3732257Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3732321Z             try:
2026-02-14T13:01:56.3732427Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3732521Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3732718Z                 conn.autocommit = True
2026-02-14T13:01:56.3732787Z                 try:
2026-02-14T13:01:56.3732863Z                     cur = conn.cursor()
2026-02-14T13:01:56.3733047Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3733127Z                     if not cur.fetchone():
2026-02-14T13:01:56.3733283Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3733396Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3733469Z                     cur.close()
2026-02-14T13:01:56.3733543Z                 finally:
2026-02-14T13:01:56.3733616Z                     conn.close()
2026-02-14T13:01:56.3733692Z                 break  # Success
2026-02-14T13:01:56.3733885Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3733973Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3734047Z                     print(
2026-02-14T13:01:56.3734264Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3734334Z                     )
2026-02-14T13:01:56.3734416Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3734483Z                 else:
2026-02-14T13:01:56.3734693Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3734868Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3734936Z                     pass
2026-02-14T13:01:56.3735053Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3735133Z                 break  # Already exists
2026-02-14T13:01:56.3735192Z     
2026-02-14T13:01:56.3735407Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3735593Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3735730Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3735787Z     
2026-02-14T13:01:56.3735869Z         close_all_pools()
2026-02-14T13:01:56.3735927Z     
2026-02-14T13:01:56.3736047Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3736221Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3736362Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3736442Z             conn.autocommit = True
2026-02-14T13:01:56.3736521Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3736723Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3736814Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3736889Z                 cur.execute(
2026-02-14T13:01:56.3736960Z                     """
2026-02-14T13:01:56.3737060Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3737139Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3737239Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3737327Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3737391Z                     """
2026-02-14T13:01:56.3737451Z                 )
2026-02-14T13:01:56.3737516Z     
2026-02-14T13:01:56.3737702Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3737884Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3737954Z                 try:
2026-02-14T13:01:56.3738157Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3738234Z                     cur.execute("""
2026-02-14T13:01:56.3738304Z                         DO $$
2026-02-14T13:01:56.3738378Z                         DECLARE
2026-02-14T13:01:56.3738525Z                             r RECORD;
2026-02-14T13:01:56.3738591Z                         BEGIN
2026-02-14T13:01:56.3738669Z                             FOR r IN (
2026-02-14T13:01:56.3738768Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3738847Z                                 FROM pg_views
2026-02-14T13:01:56.3738976Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3739041Z                             )
2026-02-14T13:01:56.3739110Z                             LOOP
2026-02-14T13:01:56.3739418Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3739498Z                             END LOOP;
2026-02-14T13:01:56.3739566Z                         END $$;
2026-02-14T13:01:56.3739630Z                     """)
2026-02-14T13:01:56.3739707Z                     # Drop tables
2026-02-14T13:01:56.3739777Z                     cur.execute("""
2026-02-14T13:01:56.3739847Z                         DO $$
2026-02-14T13:01:56.3739915Z                         DECLARE
2026-02-14T13:01:56.3739985Z                             r RECORD;
2026-02-14T13:01:56.3740049Z                         BEGIN
2026-02-14T13:01:56.3740125Z                             FOR r IN (
2026-02-14T13:01:56.3740228Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3740309Z                                 FROM pg_tables
2026-02-14T13:01:56.3740432Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3740502Z                             )
2026-02-14T13:01:56.3740570Z                             LOOP
2026-02-14T13:01:56.3740880Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3740956Z                             END LOOP;
2026-02-14T13:01:56.3741021Z                         END $$;
2026-02-14T13:01:56.3741222Z                     """)
2026-02-14T13:01:56.3741302Z                 except psycopg2.Error:
2026-02-14T13:01:56.3741479Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3741545Z                     pass
2026-02-14T13:01:56.3741601Z     
2026-02-14T13:01:56.3741777Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3741884Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3741960Z                 if init_dir.exists():
2026-02-14T13:01:56.3742068Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3742157Z                     for script_path in scripts:
2026-02-14T13:01:56.3742284Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3742357Z                             sql = f.read()
2026-02-14T13:01:56.3742566Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3742699Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3742778Z                             statements = []
2026-02-14T13:01:56.3742841Z     
2026-02-14T13:01:56.3743019Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3743095Z                             do_blocks = []
2026-02-14T13:01:56.3743201Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3743259Z     
2026-02-14T13:01:56.3743353Z                             def replace_do_block(match):
2026-02-14T13:01:56.3743442Z                                 block = match.group(0)
2026-02-14T13:01:56.3743695Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3743796Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3743884Z                                 return placeholder
2026-02-14T13:01:56.3744064Z     
2026-02-14T13:01:56.3744171Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3744267Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3744352Z                                                     ^^
2026-02-14T13:01:56.3744537Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3744603Z                             )
2026-02-14T13:01:56.3744712Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3744724Z 
2026-02-14T13:01:56.3744822Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3745016Z _________ ERROR at setup of TestMultiNoteIntegration.test_update_note __________
2026-02-14T13:01:56.3745022Z 
2026-02-14T13:01:56.3745291Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3745296Z 
2026-02-14T13:01:56.3745381Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3745498Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3745557Z         """
2026-02-14T13:01:56.3745690Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3745753Z     
2026-02-14T13:01:56.3745884Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3746006Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3746066Z         """
2026-02-14T13:01:56.3746167Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3746292Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3746349Z     
2026-02-14T13:01:56.3746461Z         # Parse connection string to get database name
2026-02-14T13:01:56.3746705Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3746764Z     
2026-02-14T13:01:56.3746951Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3747179Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3747236Z     
2026-02-14T13:01:56.3747376Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3747494Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3747568Z         if len(parts) >= 4:
2026-02-14T13:01:56.3747684Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3747752Z         else:
2026-02-14T13:01:56.3747851Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3747908Z     
2026-02-14T13:01:56.3748007Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3748236Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3748303Z         import time
2026-02-14T13:01:56.3748360Z     
2026-02-14T13:01:56.3748435Z         max_retries = 5
2026-02-14T13:01:56.3748507Z         retry_delay = 2
2026-02-14T13:01:56.3748564Z     
2026-02-14T13:01:56.3748660Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3748722Z             try:
2026-02-14T13:01:56.3748819Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3748910Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3748995Z                 conn.autocommit = True
2026-02-14T13:01:56.3749057Z                 try:
2026-02-14T13:01:56.3749134Z                     cur = conn.cursor()
2026-02-14T13:01:56.3749322Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3749400Z                     if not cur.fetchone():
2026-02-14T13:01:56.3749641Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3749765Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3749835Z                     cur.close()
2026-02-14T13:01:56.3749976Z                 finally:
2026-02-14T13:01:56.3750047Z                     conn.close()
2026-02-14T13:01:56.3750126Z                 break  # Success
2026-02-14T13:01:56.3750315Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3750402Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3750485Z                     print(
2026-02-14T13:01:56.3750695Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3750758Z                     )
2026-02-14T13:01:56.3750845Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3750906Z                 else:
2026-02-14T13:01:56.3751364Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3751564Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3751638Z                     pass
2026-02-14T13:01:56.3751761Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3751839Z                 break  # Already exists
2026-02-14T13:01:56.3751905Z     
2026-02-14T13:01:56.3752120Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3752300Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3752435Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3752492Z     
2026-02-14T13:01:56.3752564Z         close_all_pools()
2026-02-14T13:01:56.3752620Z     
2026-02-14T13:01:56.3752747Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3752910Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3753050Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3753136Z             conn.autocommit = True
2026-02-14T13:01:56.3753215Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3753408Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3753504Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3753575Z                 cur.execute(
2026-02-14T13:01:56.3753640Z                     """
2026-02-14T13:01:56.3753736Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3753823Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3753916Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3754005Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3754073Z                     """
2026-02-14T13:01:56.3754133Z                 )
2026-02-14T13:01:56.3754190Z     
2026-02-14T13:01:56.3754383Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3754572Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3754638Z                 try:
2026-02-14T13:01:56.3754753Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3754833Z                     cur.execute("""
2026-02-14T13:01:56.3754900Z                         DO $$
2026-02-14T13:01:56.3754967Z                         DECLARE
2026-02-14T13:01:56.3755043Z                             r RECORD;
2026-02-14T13:01:56.3755109Z                         BEGIN
2026-02-14T13:01:56.3755181Z                             FOR r IN (
2026-02-14T13:01:56.3755279Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3755364Z                                 FROM pg_views
2026-02-14T13:01:56.3755492Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3755704Z                             )
2026-02-14T13:01:56.3755786Z                             LOOP
2026-02-14T13:01:56.3756099Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3756274Z                             END LOOP;
2026-02-14T13:01:56.3756346Z                         END $$;
2026-02-14T13:01:56.3756410Z                     """)
2026-02-14T13:01:56.3756481Z                     # Drop tables
2026-02-14T13:01:56.3756553Z                     cur.execute("""
2026-02-14T13:01:56.3756627Z                         DO $$
2026-02-14T13:01:56.3756691Z                         DECLARE
2026-02-14T13:01:56.3756761Z                             r RECORD;
2026-02-14T13:01:56.3756832Z                         BEGIN
2026-02-14T13:01:56.3756903Z                             FOR r IN (
2026-02-14T13:01:56.3757002Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3757096Z                                 FROM pg_tables
2026-02-14T13:01:56.3757221Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3757286Z                             )
2026-02-14T13:01:56.3757364Z                             LOOP
2026-02-14T13:01:56.3757681Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3757753Z                             END LOOP;
2026-02-14T13:01:56.3757818Z                         END $$;
2026-02-14T13:01:56.3757889Z                     """)
2026-02-14T13:01:56.3757973Z                 except psycopg2.Error:
2026-02-14T13:01:56.3758148Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3758220Z                     pass
2026-02-14T13:01:56.3758282Z     
2026-02-14T13:01:56.3758460Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3758568Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3758651Z                 if init_dir.exists():
2026-02-14T13:01:56.3758760Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3758854Z                     for script_path in scripts:
2026-02-14T13:01:56.3758984Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3759058Z                             sql = f.read()
2026-02-14T13:01:56.3759262Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3759401Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3759482Z                             statements = []
2026-02-14T13:01:56.3759541Z     
2026-02-14T13:01:56.3759719Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3759804Z                             do_blocks = []
2026-02-14T13:01:56.3759904Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3759960Z     
2026-02-14T13:01:56.3760059Z                             def replace_do_block(match):
2026-02-14T13:01:56.3760154Z                                 block = match.group(0)
2026-02-14T13:01:56.3760282Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3760383Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3760472Z                                 return placeholder
2026-02-14T13:01:56.3760529Z     
2026-02-14T13:01:56.3760634Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3760734Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3760814Z                                                     ^^
2026-02-14T13:01:56.3760998Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3761326Z                             )
2026-02-14T13:01:56.3761442Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3761448Z 
2026-02-14T13:01:56.3761549Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3761851Z _________ ERROR at setup of TestMultiNoteIntegration.test_delete_note __________
2026-02-14T13:01:56.3761855Z 
2026-02-14T13:01:56.3762134Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3762140Z 
2026-02-14T13:01:56.3762224Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3762327Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3762392Z         """
2026-02-14T13:01:56.3762524Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3762582Z     
2026-02-14T13:01:56.3762710Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3762837Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3762902Z         """
2026-02-14T13:01:56.3762995Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3763121Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3763177Z     
2026-02-14T13:01:56.3763286Z         # Parse connection string to get database name
2026-02-14T13:01:56.3763521Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3763583Z     
2026-02-14T13:01:56.3763765Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3763988Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3764050Z     
2026-02-14T13:01:56.3764190Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3764298Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3764376Z         if len(parts) >= 4:
2026-02-14T13:01:56.3764495Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3764558Z         else:
2026-02-14T13:01:56.3764656Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3764718Z     
2026-02-14T13:01:56.3764818Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3765042Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3765114Z         import time
2026-02-14T13:01:56.3765171Z     
2026-02-14T13:01:56.3765240Z         max_retries = 5
2026-02-14T13:01:56.3765313Z         retry_delay = 2
2026-02-14T13:01:56.3765370Z     
2026-02-14T13:01:56.3765454Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3765518Z             try:
2026-02-14T13:01:56.3765621Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3765713Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3765791Z                 conn.autocommit = True
2026-02-14T13:01:56.3765862Z                 try:
2026-02-14T13:01:56.3765937Z                     cur = conn.cursor()
2026-02-14T13:01:56.3766123Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3766205Z                     if not cur.fetchone():
2026-02-14T13:01:56.3766360Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3766475Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3766545Z                     cur.close()
2026-02-14T13:01:56.3766621Z                 finally:
2026-02-14T13:01:56.3766693Z                     conn.close()
2026-02-14T13:01:56.3766762Z                 break  # Success
2026-02-14T13:01:56.3766954Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3767041Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3767110Z                     print(
2026-02-14T13:01:56.3767414Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3767487Z                     )
2026-02-14T13:01:56.3767568Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3767631Z                 else:
2026-02-14T13:01:56.3767918Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3768097Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3768170Z                     pass
2026-02-14T13:01:56.3768295Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3768372Z                 break  # Already exists
2026-02-14T13:01:56.3768431Z     
2026-02-14T13:01:56.3768645Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3768831Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3768967Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3769025Z     
2026-02-14T13:01:56.3769104Z         close_all_pools()
2026-02-14T13:01:56.3769166Z     
2026-02-14T13:01:56.3769282Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3769454Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3769592Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3769673Z             conn.autocommit = True
2026-02-14T13:01:56.3769749Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3769948Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3770038Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3770108Z                 cur.execute(
2026-02-14T13:01:56.3770179Z                     """
2026-02-14T13:01:56.3770274Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3770366Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3770465Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3770553Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3770616Z                     """
2026-02-14T13:01:56.3770680Z                 )
2026-02-14T13:01:56.3770743Z     
2026-02-14T13:01:56.3770930Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3771237Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3771306Z                 try:
2026-02-14T13:01:56.3771423Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3771496Z                     cur.execute("""
2026-02-14T13:01:56.3771568Z                         DO $$
2026-02-14T13:01:56.3771635Z                         DECLARE
2026-02-14T13:01:56.3771707Z                             r RECORD;
2026-02-14T13:01:56.3771773Z                         BEGIN
2026-02-14T13:01:56.3771859Z                             FOR r IN (
2026-02-14T13:01:56.3771962Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3772042Z                                 FROM pg_views
2026-02-14T13:01:56.3772180Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3772245Z                             )
2026-02-14T13:01:56.3772314Z                             LOOP
2026-02-14T13:01:56.3772628Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3772700Z                             END LOOP;
2026-02-14T13:01:56.3772771Z                         END $$;
2026-02-14T13:01:56.3772836Z                     """)
2026-02-14T13:01:56.3772914Z                     # Drop tables
2026-02-14T13:01:56.3772985Z                     cur.execute("""
2026-02-14T13:01:56.3773050Z                         DO $$
2026-02-14T13:01:56.3773264Z                         DECLARE
2026-02-14T13:01:56.3773338Z                             r RECORD;
2026-02-14T13:01:56.3773403Z                         BEGIN
2026-02-14T13:01:56.3773473Z                             FOR r IN (
2026-02-14T13:01:56.3773681Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3773762Z                                 FROM pg_tables
2026-02-14T13:01:56.3773887Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3773957Z                             )
2026-02-14T13:01:56.3774025Z                             LOOP
2026-02-14T13:01:56.3774338Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3774415Z                             END LOOP;
2026-02-14T13:01:56.3774480Z                         END $$;
2026-02-14T13:01:56.3774543Z                     """)
2026-02-14T13:01:56.3774629Z                 except psycopg2.Error:
2026-02-14T13:01:56.3774805Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3774872Z                     pass
2026-02-14T13:01:56.3774928Z     
2026-02-14T13:01:56.3775106Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3775213Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3775288Z                 if init_dir.exists():
2026-02-14T13:01:56.3775397Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3775485Z                     for script_path in scripts:
2026-02-14T13:01:56.3775609Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3775684Z                             sql = f.read()
2026-02-14T13:01:56.3775893Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3776027Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3776104Z                             statements = []
2026-02-14T13:01:56.3776167Z     
2026-02-14T13:01:56.3776347Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3776431Z                             do_blocks = []
2026-02-14T13:01:56.3776538Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3776596Z     
2026-02-14T13:01:56.3776692Z                             def replace_do_block(match):
2026-02-14T13:01:56.3776781Z                                 block = match.group(0)
2026-02-14T13:01:56.3776919Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3777057Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3777146Z                                 return placeholder
2026-02-14T13:01:56.3777209Z     
2026-02-14T13:01:56.3777320Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3777415Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3777500Z                                                     ^^
2026-02-14T13:01:56.3777684Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3777755Z                             )
2026-02-14T13:01:56.3777868Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3777873Z 
2026-02-14T13:01:56.3777971Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3778170Z __ ERROR at setup of TestMultiNoteIntegration.test_note_count_in_job_listing ___
2026-02-14T13:01:56.3778175Z 
2026-02-14T13:01:56.3778450Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3778455Z 
2026-02-14T13:01:56.3778544Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3778650Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3778841Z         """
2026-02-14T13:01:56.3778977Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3779038Z     
2026-02-14T13:01:56.3779168Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3779371Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3779438Z         """
2026-02-14T13:01:56.3779535Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3779657Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3779715Z     
2026-02-14T13:01:56.3779826Z         # Parse connection string to get database name
2026-02-14T13:01:56.3780066Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3780123Z     
2026-02-14T13:01:56.3780317Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3780547Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3780605Z     
2026-02-14T13:01:56.3780752Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3780860Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3780941Z         if len(parts) >= 4:
2026-02-14T13:01:56.3781250Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3781367Z         else:
2026-02-14T13:01:56.3781474Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3781535Z     
2026-02-14T13:01:56.3781640Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3781869Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3781935Z         import time
2026-02-14T13:01:56.3781991Z     
2026-02-14T13:01:56.3782065Z         max_retries = 5
2026-02-14T13:01:56.3782132Z         retry_delay = 2
2026-02-14T13:01:56.3782189Z     
2026-02-14T13:01:56.3782283Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3782343Z             try:
2026-02-14T13:01:56.3782444Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3782538Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3782629Z                 conn.autocommit = True
2026-02-14T13:01:56.3782692Z                 try:
2026-02-14T13:01:56.3782766Z                     cur = conn.cursor()
2026-02-14T13:01:56.3782955Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3783033Z                     if not cur.fetchone():
2026-02-14T13:01:56.3783183Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3783302Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3783371Z                     cur.close()
2026-02-14T13:01:56.3783437Z                 finally:
2026-02-14T13:01:56.3783506Z                     conn.close()
2026-02-14T13:01:56.3783584Z                 break  # Success
2026-02-14T13:01:56.3783770Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3783859Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3783935Z                     print(
2026-02-14T13:01:56.3784151Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3784215Z                     )
2026-02-14T13:01:56.3784301Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3784364Z                 else:
2026-02-14T13:01:56.3784564Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3784746Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3784819Z                     pass
2026-02-14T13:01:56.3784933Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3785134Z                 break  # Already exists
2026-02-14T13:01:56.3785201Z     
2026-02-14T13:01:56.3785418Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3785597Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3785837Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3785893Z     
2026-02-14T13:01:56.3785966Z         close_all_pools()
2026-02-14T13:01:56.3786025Z     
2026-02-14T13:01:56.3786147Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3786307Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3786447Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3786536Z             conn.autocommit = True
2026-02-14T13:01:56.3786613Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3786813Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3786908Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3786978Z                 cur.execute(
2026-02-14T13:01:56.3787042Z                     """
2026-02-14T13:01:56.3787146Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3787230Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3787324Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3787414Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3787484Z                     """
2026-02-14T13:01:56.3787544Z                 )
2026-02-14T13:01:56.3787603Z     
2026-02-14T13:01:56.3787796Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3787981Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3788044Z                 try:
2026-02-14T13:01:56.3788164Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3788244Z                     cur.execute("""
2026-02-14T13:01:56.3788312Z                         DO $$
2026-02-14T13:01:56.3788379Z                         DECLARE
2026-02-14T13:01:56.3788457Z                             r RECORD;
2026-02-14T13:01:56.3788529Z                         BEGIN
2026-02-14T13:01:56.3788600Z                             FOR r IN (
2026-02-14T13:01:56.3788700Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3788787Z                                 FROM pg_views
2026-02-14T13:01:56.3788910Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3788974Z                             )
2026-02-14T13:01:56.3789051Z                             LOOP
2026-02-14T13:01:56.3789362Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3789437Z                             END LOOP;
2026-02-14T13:01:56.3789509Z                         END $$;
2026-02-14T13:01:56.3789572Z                     """)
2026-02-14T13:01:56.3789644Z                     # Drop tables
2026-02-14T13:01:56.3789715Z                     cur.execute("""
2026-02-14T13:01:56.3789792Z                         DO $$
2026-02-14T13:01:56.3789859Z                         DECLARE
2026-02-14T13:01:56.3789928Z                             r RECORD;
2026-02-14T13:01:56.3789999Z                         BEGIN
2026-02-14T13:01:56.3790070Z                             FOR r IN (
2026-02-14T13:01:56.3790168Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3790256Z                                 FROM pg_tables
2026-02-14T13:01:56.3790380Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3790444Z                             )
2026-02-14T13:01:56.3790513Z                             LOOP
2026-02-14T13:01:56.3790928Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3791002Z                             END LOOP;
2026-02-14T13:01:56.3791252Z                         END $$;
2026-02-14T13:01:56.3791473Z                     """)
2026-02-14T13:01:56.3791564Z                 except psycopg2.Error:
2026-02-14T13:01:56.3791744Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3791820Z                     pass
2026-02-14T13:01:56.3791878Z     
2026-02-14T13:01:56.3792055Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3792170Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3792253Z                 if init_dir.exists():
2026-02-14T13:01:56.3792359Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3792450Z                     for script_path in scripts:
2026-02-14T13:01:56.3792590Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3792668Z                             sql = f.read()
2026-02-14T13:01:56.3792875Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3793019Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3793096Z                             statements = []
2026-02-14T13:01:56.3793153Z     
2026-02-14T13:01:56.3793332Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3793413Z                             do_blocks = []
2026-02-14T13:01:56.3793512Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3793570Z     
2026-02-14T13:01:56.3793671Z                             def replace_do_block(match):
2026-02-14T13:01:56.3793760Z                                 block = match.group(0)
2026-02-14T13:01:56.3793889Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3793987Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3794073Z                                 return placeholder
2026-02-14T13:01:56.3794134Z     
2026-02-14T13:01:56.3794240Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3794342Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3794422Z                                                     ^^
2026-02-14T13:01:56.3794606Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3794682Z                             )
2026-02-14T13:01:56.3794792Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3794798Z 
2026-02-14T13:01:56.3794898Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3795188Z _ ERROR at setup of TestMultiNoteIntegration.test_authorization_user_cannot_access_other_users_notes _
2026-02-14T13:01:56.3795193Z 
2026-02-14T13:01:56.3795479Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3795483Z 
2026-02-14T13:01:56.3795573Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3795682Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3795748Z         """
2026-02-14T13:01:56.3795884Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3795942Z     
2026-02-14T13:01:56.3796074Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3796202Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3796262Z         """
2026-02-14T13:01:56.3796359Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3796489Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3796545Z     
2026-02-14T13:01:56.3796652Z         # Parse connection string to get database name
2026-02-14T13:01:56.3797019Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3797081Z     
2026-02-14T13:01:56.3797270Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3797581Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3797644Z     
2026-02-14T13:01:56.3797785Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3797893Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3797976Z         if len(parts) >= 4:
2026-02-14T13:01:56.3798091Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3798153Z         else:
2026-02-14T13:01:56.3798258Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3798317Z     
2026-02-14T13:01:56.3798411Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3798641Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3798714Z         import time
2026-02-14T13:01:56.3798771Z     
2026-02-14T13:01:56.3798838Z         max_retries = 5
2026-02-14T13:01:56.3798916Z         retry_delay = 2
2026-02-14T13:01:56.3798974Z     
2026-02-14T13:01:56.3799059Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3799120Z             try:
2026-02-14T13:01:56.3799227Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3799320Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3799401Z                 conn.autocommit = True
2026-02-14T13:01:56.3799472Z                 try:
2026-02-14T13:01:56.3799549Z                     cur = conn.cursor()
2026-02-14T13:01:56.3799734Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3799820Z                     if not cur.fetchone():
2026-02-14T13:01:56.3799975Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3800092Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3800163Z                     cur.close()
2026-02-14T13:01:56.3800239Z                 finally:
2026-02-14T13:01:56.3800309Z                     conn.close()
2026-02-14T13:01:56.3800380Z                 break  # Success
2026-02-14T13:01:56.3800580Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3800671Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3800741Z                     print(
2026-02-14T13:01:56.3800957Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3801158Z                     )
2026-02-14T13:01:56.3801243Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3801306Z                 else:
2026-02-14T13:01:56.3801523Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3801706Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3801775Z                     pass
2026-02-14T13:01:56.3801903Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3801981Z                 break  # Already exists
2026-02-14T13:01:56.3802039Z     
2026-02-14T13:01:56.3802258Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3802457Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3802589Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3802648Z     
2026-02-14T13:01:56.3802729Z         close_all_pools()
2026-02-14T13:01:56.3802787Z     
2026-02-14T13:01:56.3802903Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3803191Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3803417Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3803559Z             conn.autocommit = True
2026-02-14T13:01:56.3803682Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3804080Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3804174Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3804249Z                 cur.execute(
2026-02-14T13:01:56.3804320Z                     """
2026-02-14T13:01:56.3804418Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3804497Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3804599Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3804689Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3804751Z                     """
2026-02-14T13:01:56.3804810Z                 )
2026-02-14T13:01:56.3804879Z     
2026-02-14T13:01:56.3805066Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3805249Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3805323Z                 try:
2026-02-14T13:01:56.3805440Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3805515Z                     cur.execute("""
2026-02-14T13:01:56.3805589Z                         DO $$
2026-02-14T13:01:56.3805656Z                         DECLARE
2026-02-14T13:01:56.3805727Z                             r RECORD;
2026-02-14T13:01:56.3805793Z                         BEGIN
2026-02-14T13:01:56.3805869Z                             FOR r IN (
2026-02-14T13:01:56.3805968Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3806047Z                                 FROM pg_views
2026-02-14T13:01:56.3806183Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3806247Z                             )
2026-02-14T13:01:56.3806315Z                             LOOP
2026-02-14T13:01:56.3806631Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3806709Z                             END LOOP;
2026-02-14T13:01:56.3806775Z                         END $$;
2026-02-14T13:01:56.3806840Z                     """)
2026-02-14T13:01:56.3806916Z                     # Drop tables
2026-02-14T13:01:56.3806988Z                     cur.execute("""
2026-02-14T13:01:56.3807054Z                         DO $$
2026-02-14T13:01:56.3807123Z                         DECLARE
2026-02-14T13:01:56.3807190Z                             r RECORD;
2026-02-14T13:01:56.3807255Z                         BEGIN
2026-02-14T13:01:56.3807327Z                             FOR r IN (
2026-02-14T13:01:56.3807431Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3807517Z                                 FROM pg_tables
2026-02-14T13:01:56.3807642Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3807713Z                             )
2026-02-14T13:01:56.3807784Z                             LOOP
2026-02-14T13:01:56.3808093Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3808170Z                             END LOOP;
2026-02-14T13:01:56.3808236Z                         END $$;
2026-02-14T13:01:56.3808301Z                     """)
2026-02-14T13:01:56.3808385Z                 except psycopg2.Error:
2026-02-14T13:01:56.3808562Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3808630Z                     pass
2026-02-14T13:01:56.3808687Z     
2026-02-14T13:01:56.3808956Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3809068Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3809144Z                 if init_dir.exists():
2026-02-14T13:01:56.3809254Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3809422Z                     for script_path in scripts:
2026-02-14T13:01:56.3809544Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3809618Z                             sql = f.read()
2026-02-14T13:01:56.3809828Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3809957Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3810034Z                             statements = []
2026-02-14T13:01:56.3810096Z     
2026-02-14T13:01:56.3810274Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3810354Z                             do_blocks = []
2026-02-14T13:01:56.3810460Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3810518Z     
2026-02-14T13:01:56.3810613Z                             def replace_do_block(match):
2026-02-14T13:01:56.3810714Z                                 block = match.group(0)
2026-02-14T13:01:56.3810841Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3810943Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3811162Z                                 return placeholder
2026-02-14T13:01:56.3811230Z     
2026-02-14T13:01:56.3811339Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3811436Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3811520Z                                                     ^^
2026-02-14T13:01:56.3811708Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3811775Z                             )
2026-02-14T13:01:56.3811891Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3811897Z 
2026-02-14T13:01:56.3816368Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3816641Z _______ ERROR at setup of TestMultiNoteIntegration.test_is_modified_flag _______
2026-02-14T13:01:56.3816649Z 
2026-02-14T13:01:56.3816971Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3816978Z 
2026-02-14T13:01:56.3817080Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3817202Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3817269Z         """
2026-02-14T13:01:56.3817411Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3817480Z     
2026-02-14T13:01:56.3817625Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3817764Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3817834Z         """
2026-02-14T13:01:56.3817935Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3818062Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3818124Z     
2026-02-14T13:01:56.3818248Z         # Parse connection string to get database name
2026-02-14T13:01:56.3818500Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3818560Z     
2026-02-14T13:01:56.3818763Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3818994Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3819053Z     
2026-02-14T13:01:56.3819204Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3819317Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3819395Z         if len(parts) >= 4:
2026-02-14T13:01:56.3819710Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3819788Z         else:
2026-02-14T13:01:56.3819891Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3819955Z     
2026-02-14T13:01:56.3820171Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3820400Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3820475Z         import time
2026-02-14T13:01:56.3820533Z     
2026-02-14T13:01:56.3820610Z         max_retries = 5
2026-02-14T13:01:56.3820680Z         retry_delay = 2
2026-02-14T13:01:56.3820741Z     
2026-02-14T13:01:56.3820833Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3820895Z             try:
2026-02-14T13:01:56.3820998Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3821291Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3821383Z                 conn.autocommit = True
2026-02-14T13:01:56.3821455Z                 try:
2026-02-14T13:01:56.3821535Z                     cur = conn.cursor()
2026-02-14T13:01:56.3821736Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3821826Z                     if not cur.fetchone():
2026-02-14T13:01:56.3821981Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3822105Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3822178Z                     cur.close()
2026-02-14T13:01:56.3822248Z                 finally:
2026-02-14T13:01:56.3822322Z                     conn.close()
2026-02-14T13:01:56.3822398Z                 break  # Success
2026-02-14T13:01:56.3822590Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3822681Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3822759Z                     print(
2026-02-14T13:01:56.3822983Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3823048Z                     )
2026-02-14T13:01:56.3823139Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3823208Z                 else:
2026-02-14T13:01:56.3823411Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3823594Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3823670Z                     pass
2026-02-14T13:01:56.3823788Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3823871Z                 break  # Already exists
2026-02-14T13:01:56.3823936Z     
2026-02-14T13:01:56.3824158Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3824343Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3824495Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3824556Z     
2026-02-14T13:01:56.3824628Z         close_all_pools()
2026-02-14T13:01:56.3824686Z     
2026-02-14T13:01:56.3824808Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3824976Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3825116Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3825205Z             conn.autocommit = True
2026-02-14T13:01:56.3825284Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3825475Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3825573Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3825647Z                 cur.execute(
2026-02-14T13:01:56.3825715Z                     """
2026-02-14T13:01:56.3825812Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3826026Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3826129Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3826220Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3826291Z                     """
2026-02-14T13:01:56.3826497Z                 )
2026-02-14T13:01:56.3826556Z     
2026-02-14T13:01:56.3826752Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3826937Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3827005Z                 try:
2026-02-14T13:01:56.3827125Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3827209Z                     cur.execute("""
2026-02-14T13:01:56.3827280Z                         DO $$
2026-02-14T13:01:56.3827348Z                         DECLARE
2026-02-14T13:01:56.3827429Z                             r RECORD;
2026-02-14T13:01:56.3827503Z                         BEGIN
2026-02-14T13:01:56.3827576Z                             FOR r IN (
2026-02-14T13:01:56.3827677Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3827766Z                                 FROM pg_views
2026-02-14T13:01:56.3827902Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3827969Z                             )
2026-02-14T13:01:56.3828046Z                             LOOP
2026-02-14T13:01:56.3828367Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3828441Z                             END LOOP;
2026-02-14T13:01:56.3828515Z                         END $$;
2026-02-14T13:01:56.3828582Z                     """)
2026-02-14T13:01:56.3828654Z                     # Drop tables
2026-02-14T13:01:56.3828728Z                     cur.execute("""
2026-02-14T13:01:56.3828802Z                         DO $$
2026-02-14T13:01:56.3828873Z                         DECLARE
2026-02-14T13:01:56.3828944Z                             r RECORD;
2026-02-14T13:01:56.3829021Z                         BEGIN
2026-02-14T13:01:56.3829092Z                             FOR r IN (
2026-02-14T13:01:56.3829201Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3829290Z                                 FROM pg_tables
2026-02-14T13:01:56.3829415Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3829483Z                             )
2026-02-14T13:01:56.3829554Z                             LOOP
2026-02-14T13:01:56.3829875Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3829947Z                             END LOOP;
2026-02-14T13:01:56.3830013Z                         END $$;
2026-02-14T13:01:56.3830086Z                     """)
2026-02-14T13:01:56.3830176Z                 except psycopg2.Error:
2026-02-14T13:01:56.3830352Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3830427Z                     pass
2026-02-14T13:01:56.3830484Z     
2026-02-14T13:01:56.3830659Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3830768Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3830853Z                 if init_dir.exists():
2026-02-14T13:01:56.3830960Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3831246Z                     for script_path in scripts:
2026-02-14T13:01:56.3831450Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3831532Z                             sql = f.read()
2026-02-14T13:01:56.3831738Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3832008Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3832092Z                             statements = []
2026-02-14T13:01:56.3832152Z     
2026-02-14T13:01:56.3832330Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3832520Z                             do_blocks = []
2026-02-14T13:01:56.3832625Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3832683Z     
2026-02-14T13:01:56.3832786Z                             def replace_do_block(match):
2026-02-14T13:01:56.3832877Z                                 block = match.group(0)
2026-02-14T13:01:56.3833004Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3833106Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3833192Z                                 return placeholder
2026-02-14T13:01:56.3833250Z     
2026-02-14T13:01:56.3833363Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3833471Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3833553Z                                                     ^^
2026-02-14T13:01:56.3833746Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3833820Z                             )
2026-02-14T13:01:56.3833927Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3833934Z 
2026-02-14T13:01:56.3834033Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3834231Z _______ ERROR at setup of TestMultiNoteIntegration.test_empty_note_list ________
2026-02-14T13:01:56.3834236Z 
2026-02-14T13:01:56.3834523Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3834528Z 
2026-02-14T13:01:56.3834618Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3834723Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3834796Z         """
2026-02-14T13:01:56.3834934Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3834993Z     
2026-02-14T13:01:56.3835132Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3835270Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3835331Z         """
2026-02-14T13:01:56.3835426Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3835560Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3835618Z     
2026-02-14T13:01:56.3835726Z         # Parse connection string to get database name
2026-02-14T13:01:56.3835980Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3836043Z     
2026-02-14T13:01:56.3836227Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3836458Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3836528Z     
2026-02-14T13:01:56.3836671Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3836778Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3836863Z         if len(parts) >= 4:
2026-02-14T13:01:56.3836983Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3837045Z         else:
2026-02-14T13:01:56.3837151Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3837211Z     
2026-02-14T13:01:56.3837307Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3837532Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3837606Z         import time
2026-02-14T13:01:56.3837665Z     
2026-02-14T13:01:56.3837734Z         max_retries = 5
2026-02-14T13:01:56.3837812Z         retry_delay = 2
2026-02-14T13:01:56.3837870Z     
2026-02-14T13:01:56.3838051Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3838118Z             try:
2026-02-14T13:01:56.3838228Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3838322Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3838484Z                 conn.autocommit = True
2026-02-14T13:01:56.3838555Z                 try:
2026-02-14T13:01:56.3838634Z                     cur = conn.cursor()
2026-02-14T13:01:56.3838823Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3838904Z                     if not cur.fetchone():
2026-02-14T13:01:56.3839060Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3839177Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3839252Z                     cur.close()
2026-02-14T13:01:56.3839328Z                 finally:
2026-02-14T13:01:56.3839407Z                     conn.close()
2026-02-14T13:01:56.3839479Z                 break  # Success
2026-02-14T13:01:56.3839676Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3839770Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3839850Z                     print(
2026-02-14T13:01:56.3840072Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3840144Z                     )
2026-02-14T13:01:56.3840229Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3840293Z                 else:
2026-02-14T13:01:56.3840503Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3840688Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3840757Z                     pass
2026-02-14T13:01:56.3840883Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3840965Z                 break  # Already exists
2026-02-14T13:01:56.3841023Z     
2026-02-14T13:01:56.3841393Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3841584Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3841723Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3841783Z     
2026-02-14T13:01:56.3841867Z         close_all_pools()
2026-02-14T13:01:56.3841928Z     
2026-02-14T13:01:56.3842046Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3842218Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3842360Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3842441Z             conn.autocommit = True
2026-02-14T13:01:56.3842520Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3842721Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3842813Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3842888Z                 cur.execute(
2026-02-14T13:01:56.3842962Z                     """
2026-02-14T13:01:56.3843064Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3843144Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3843247Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3843341Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3843405Z                     """
2026-02-14T13:01:56.3843466Z                 )
2026-02-14T13:01:56.3843527Z     
2026-02-14T13:01:56.3843723Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3843927Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3843995Z                 try:
2026-02-14T13:01:56.3844237Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3844325Z                     cur.execute("""
2026-02-14T13:01:56.3844396Z                         DO $$
2026-02-14T13:01:56.3844465Z                         DECLARE
2026-02-14T13:01:56.3844639Z                             r RECORD;
2026-02-14T13:01:56.3844713Z                         BEGIN
2026-02-14T13:01:56.3844788Z                             FOR r IN (
2026-02-14T13:01:56.3844895Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3844986Z                                 FROM pg_views
2026-02-14T13:01:56.3845120Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3845186Z                             )
2026-02-14T13:01:56.3845261Z                             LOOP
2026-02-14T13:01:56.3845582Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3845660Z                             END LOOP;
2026-02-14T13:01:56.3845729Z                         END $$;
2026-02-14T13:01:56.3845805Z                     """)
2026-02-14T13:01:56.3845878Z                     # Drop tables
2026-02-14T13:01:56.3845953Z                     cur.execute("""
2026-02-14T13:01:56.3846035Z                         DO $$
2026-02-14T13:01:56.3846101Z                         DECLARE
2026-02-14T13:01:56.3846172Z                             r RECORD;
2026-02-14T13:01:56.3846239Z                         BEGIN
2026-02-14T13:01:56.3846317Z                             FOR r IN (
2026-02-14T13:01:56.3846424Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3846509Z                                 FROM pg_tables
2026-02-14T13:01:56.3846644Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3846712Z                             )
2026-02-14T13:01:56.3846786Z                             LOOP
2026-02-14T13:01:56.3847112Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3847186Z                             END LOOP;
2026-02-14T13:01:56.3847254Z                         END $$;
2026-02-14T13:01:56.3847327Z                     """)
2026-02-14T13:01:56.3847419Z                 except psycopg2.Error:
2026-02-14T13:01:56.3847598Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3847668Z                     pass
2026-02-14T13:01:56.3847735Z     
2026-02-14T13:01:56.3847908Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3848021Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3848104Z                 if init_dir.exists():
2026-02-14T13:01:56.3848213Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3848308Z                     for script_path in scripts:
2026-02-14T13:01:56.3848438Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3848524Z                             sql = f.read()
2026-02-14T13:01:56.3848731Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3848870Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3848957Z                             statements = []
2026-02-14T13:01:56.3849019Z     
2026-02-14T13:01:56.3849200Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3849285Z                             do_blocks = []
2026-02-14T13:01:56.3849388Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3849446Z     
2026-02-14T13:01:56.3849542Z                             def replace_do_block(match):
2026-02-14T13:01:56.3849643Z                                 block = match.group(0)
2026-02-14T13:01:56.3849863Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3849961Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3850054Z                                 return placeholder
2026-02-14T13:01:56.3850191Z     
2026-02-14T13:01:56.3850302Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3850407Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3850491Z                                                     ^^
2026-02-14T13:01:56.3850689Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3850763Z                             )
2026-02-14T13:01:56.3850873Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3850879Z 
2026-02-14T13:01:56.3850981Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3851319Z _____ ERROR at setup of TestMultiNoteIntegration.test_whitespace_stripping _____
2026-02-14T13:01:56.3851330Z 
2026-02-14T13:01:56.3851604Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3851609Z 
2026-02-14T13:01:56.3851702Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3851814Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3851876Z         """
2026-02-14T13:01:56.3852018Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3852076Z     
2026-02-14T13:01:56.3852208Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3852339Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3852400Z         """
2026-02-14T13:01:56.3852494Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3852618Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3852680Z     
2026-02-14T13:01:56.3852786Z         # Parse connection string to get database name
2026-02-14T13:01:56.3853037Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3853102Z     
2026-02-14T13:01:56.3853287Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3853520Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3853585Z     
2026-02-14T13:01:56.3853727Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3853836Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3853913Z         if len(parts) >= 4:
2026-02-14T13:01:56.3854039Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3854101Z         else:
2026-02-14T13:01:56.3854202Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3854266Z     
2026-02-14T13:01:56.3854362Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3854594Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3854662Z         import time
2026-02-14T13:01:56.3854725Z     
2026-02-14T13:01:56.3854795Z         max_retries = 5
2026-02-14T13:01:56.3854869Z         retry_delay = 2
2026-02-14T13:01:56.3854933Z     
2026-02-14T13:01:56.3855021Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3855084Z             try:
2026-02-14T13:01:56.3855184Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3855286Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3855370Z                 conn.autocommit = True
2026-02-14T13:01:56.3855436Z                 try:
2026-02-14T13:01:56.3855519Z                     cur = conn.cursor()
2026-02-14T13:01:56.3855708Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3855790Z                     if not cur.fetchone():
2026-02-14T13:01:56.3856068Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3856190Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3856263Z                     cur.close()
2026-02-14T13:01:56.3856435Z                 finally:
2026-02-14T13:01:56.3856516Z                     conn.close()
2026-02-14T13:01:56.3856586Z                 break  # Success
2026-02-14T13:01:56.3856781Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3856879Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3856951Z                     print(
2026-02-14T13:01:56.3857169Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3857240Z                     )
2026-02-14T13:01:56.3857325Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3857390Z                 else:
2026-02-14T13:01:56.3857599Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3857792Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3857861Z                     pass
2026-02-14T13:01:56.3857982Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3858069Z                 break  # Already exists
2026-02-14T13:01:56.3858127Z     
2026-02-14T13:01:56.3858343Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3858527Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3858660Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3858719Z     
2026-02-14T13:01:56.3858792Z         close_all_pools()
2026-02-14T13:01:56.3858854Z     
2026-02-14T13:01:56.3858972Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3859141Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3859287Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3859368Z             conn.autocommit = True
2026-02-14T13:01:56.3859448Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3859648Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3859739Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3859815Z                 cur.execute(
2026-02-14T13:01:56.3859880Z                     """
2026-02-14T13:01:56.3859981Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3860061Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3860156Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3860250Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3860315Z                     """
2026-02-14T13:01:56.3860379Z                 )
2026-02-14T13:01:56.3860446Z     
2026-02-14T13:01:56.3860636Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3860819Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3860888Z                 try:
2026-02-14T13:01:56.3861009Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3861336Z                     cur.execute("""
2026-02-14T13:01:56.3861430Z                         DO $$
2026-02-14T13:01:56.3861502Z                         DECLARE
2026-02-14T13:01:56.3861591Z                             r RECORD;
2026-02-14T13:01:56.3861659Z                         BEGIN
2026-02-14T13:01:56.3861733Z                             FOR r IN (
2026-02-14T13:01:56.3861845Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3861931Z                                 FROM pg_views
2026-02-14T13:01:56.3862217Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3862289Z                             )
2026-02-14T13:01:56.3862370Z                             LOOP
2026-02-14T13:01:56.3862688Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3862869Z                             END LOOP;
2026-02-14T13:01:56.3862942Z                         END $$;
2026-02-14T13:01:56.3863008Z                     """)
2026-02-14T13:01:56.3863081Z                     # Drop tables
2026-02-14T13:01:56.3863163Z                     cur.execute("""
2026-02-14T13:01:56.3863230Z                         DO $$
2026-02-14T13:01:56.3863298Z                         DECLARE
2026-02-14T13:01:56.3863368Z                             r RECORD;
2026-02-14T13:01:56.3863441Z                         BEGIN
2026-02-14T13:01:56.3863512Z                             FOR r IN (
2026-02-14T13:01:56.3863615Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3863712Z                                 FROM pg_tables
2026-02-14T13:01:56.3863842Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3863909Z                             )
2026-02-14T13:01:56.3863985Z                             LOOP
2026-02-14T13:01:56.3864308Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3864380Z                             END LOOP;
2026-02-14T13:01:56.3864446Z                         END $$;
2026-02-14T13:01:56.3864519Z                     """)
2026-02-14T13:01:56.3864601Z                 except psycopg2.Error:
2026-02-14T13:01:56.3864775Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3864848Z                     pass
2026-02-14T13:01:56.3864905Z     
2026-02-14T13:01:56.3865085Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3865200Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3865281Z                 if init_dir.exists():
2026-02-14T13:01:56.3865387Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3865483Z                     for script_path in scripts:
2026-02-14T13:01:56.3865613Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3865691Z                             sql = f.read()
2026-02-14T13:01:56.3865898Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3866038Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3866116Z                             statements = []
2026-02-14T13:01:56.3866174Z     
2026-02-14T13:01:56.3866356Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3866438Z                             do_blocks = []
2026-02-14T13:01:56.3866541Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3866598Z     
2026-02-14T13:01:56.3866701Z                             def replace_do_block(match):
2026-02-14T13:01:56.3866796Z                                 block = match.group(0)
2026-02-14T13:01:56.3866923Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3867026Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3867115Z                                 return placeholder
2026-02-14T13:01:56.3867173Z     
2026-02-14T13:01:56.3867285Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3867384Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3867466Z                                                     ^^
2026-02-14T13:01:56.3867738Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3867814Z                             )
2026-02-14T13:01:56.3867922Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3867927Z 
2026-02-14T13:01:56.3868031Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3868333Z _ ERROR at setup of TestRankerValidation.test_ranker_validates_jobs_before_ranking _
2026-02-14T13:01:56.3868338Z 
2026-02-14T13:01:56.3868617Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3868622Z 
2026-02-14T13:01:56.3868710Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3868816Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3868883Z         """
2026-02-14T13:01:56.3869019Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3869078Z     
2026-02-14T13:01:56.3869210Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3869345Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3869406Z         """
2026-02-14T13:01:56.3869501Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3869633Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3869692Z     
2026-02-14T13:01:56.3869804Z         # Parse connection string to get database name
2026-02-14T13:01:56.3870054Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3870115Z     
2026-02-14T13:01:56.3870299Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3870532Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3870597Z     
2026-02-14T13:01:56.3870738Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3870848Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3870929Z         if len(parts) >= 4:
2026-02-14T13:01:56.3871240Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3871345Z         else:
2026-02-14T13:01:56.3871460Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3871521Z     
2026-02-14T13:01:56.3871625Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3871857Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3871930Z         import time
2026-02-14T13:01:56.3871989Z     
2026-02-14T13:01:56.3872058Z         max_retries = 5
2026-02-14T13:01:56.3872131Z         retry_delay = 2
2026-02-14T13:01:56.3872189Z     
2026-02-14T13:01:56.3872274Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3872336Z             try:
2026-02-14T13:01:56.3872440Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3872537Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3872616Z                 conn.autocommit = True
2026-02-14T13:01:56.3872693Z                 try:
2026-02-14T13:01:56.3872770Z                     cur = conn.cursor()
2026-02-14T13:01:56.3872958Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3873052Z                     if not cur.fetchone():
2026-02-14T13:01:56.3873203Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3873322Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3873394Z                     cur.close()
2026-02-14T13:01:56.3873472Z                 finally:
2026-02-14T13:01:56.3873545Z                     conn.close()
2026-02-14T13:01:56.3873615Z                 break  # Success
2026-02-14T13:01:56.3873811Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3873902Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3873972Z                     print(
2026-02-14T13:01:56.3874354Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3874425Z                     )
2026-02-14T13:01:56.3874510Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3874717Z                 else:
2026-02-14T13:01:56.3874926Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3875109Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3875178Z                     pass
2026-02-14T13:01:56.3875300Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3875378Z                 break  # Already exists
2026-02-14T13:01:56.3875437Z     
2026-02-14T13:01:56.3875658Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3875836Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3875971Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3876030Z     
2026-02-14T13:01:56.3876109Z         close_all_pools()
2026-02-14T13:01:56.3876166Z     
2026-02-14T13:01:56.3876282Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3876453Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3876592Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3876673Z             conn.autocommit = True
2026-02-14T13:01:56.3876755Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3876945Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3877079Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3877153Z                 cur.execute(
2026-02-14T13:01:56.3877223Z                     """
2026-02-14T13:01:56.3877321Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3877406Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3877505Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3877593Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3877656Z                     """
2026-02-14T13:01:56.3877720Z                 )
2026-02-14T13:01:56.3877782Z     
2026-02-14T13:01:56.3877969Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3878153Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3878221Z                 try:
2026-02-14T13:01:56.3878338Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3878413Z                     cur.execute("""
2026-02-14T13:01:56.3878484Z                         DO $$
2026-02-14T13:01:56.3878551Z                         DECLARE
2026-02-14T13:01:56.3878622Z                             r RECORD;
2026-02-14T13:01:56.3878694Z                         BEGIN
2026-02-14T13:01:56.3878772Z                             FOR r IN (
2026-02-14T13:01:56.3878872Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3878953Z                                 FROM pg_views
2026-02-14T13:01:56.3879091Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3879158Z                             )
2026-02-14T13:01:56.3879227Z                             LOOP
2026-02-14T13:01:56.3879544Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3879618Z                             END LOOP;
2026-02-14T13:01:56.3879685Z                         END $$;
2026-02-14T13:01:56.3879752Z                     """)
2026-02-14T13:01:56.3879830Z                     # Drop tables
2026-02-14T13:01:56.3879902Z                     cur.execute("""
2026-02-14T13:01:56.3879969Z                         DO $$
2026-02-14T13:01:56.3880129Z                         DECLARE
2026-02-14T13:01:56.3880201Z                             r RECORD;
2026-02-14T13:01:56.3880267Z                         BEGIN
2026-02-14T13:01:56.3880344Z                             FOR r IN (
2026-02-14T13:01:56.3880520Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3880602Z                                 FROM pg_tables
2026-02-14T13:01:56.3880729Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3880800Z                             )
2026-02-14T13:01:56.3880869Z                             LOOP
2026-02-14T13:01:56.3881300Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3881380Z                             END LOOP;
2026-02-14T13:01:56.3881450Z                         END $$;
2026-02-14T13:01:56.3881515Z                     """)
2026-02-14T13:01:56.3881609Z                 except psycopg2.Error:
2026-02-14T13:01:56.3881783Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3881851Z                     pass
2026-02-14T13:01:56.3881908Z     
2026-02-14T13:01:56.3882087Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3882195Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3882273Z                 if init_dir.exists():
2026-02-14T13:01:56.3882384Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3882474Z                     for script_path in scripts:
2026-02-14T13:01:56.3882600Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3882687Z                             sql = f.read()
2026-02-14T13:01:56.3882894Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3883033Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3883112Z                             statements = []
2026-02-14T13:01:56.3883176Z     
2026-02-14T13:01:56.3883351Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3883432Z                             do_blocks = []
2026-02-14T13:01:56.3883540Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3883600Z     
2026-02-14T13:01:56.3883698Z                             def replace_do_block(match):
2026-02-14T13:01:56.3883796Z                                 block = match.group(0)
2026-02-14T13:01:56.3883923Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3884020Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3884108Z                                 return placeholder
2026-02-14T13:01:56.3884174Z     
2026-02-14T13:01:56.3884287Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3884384Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3884470Z                                                     ^^
2026-02-14T13:01:56.3884659Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3884726Z                             )
2026-02-14T13:01:56.3884839Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3884845Z 
2026-02-14T13:01:56.3884945Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3885154Z _ ERROR at setup of TestRankerValidation.test_ranker_skips_jobs_not_in_fact_jobs _
2026-02-14T13:01:56.3885159Z 
2026-02-14T13:01:56.3885444Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3885448Z 
2026-02-14T13:01:56.3885536Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3885648Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3885840Z         """
2026-02-14T13:01:56.3885978Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3886046Z     
2026-02-14T13:01:56.3886177Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3886404Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3886471Z         """
2026-02-14T13:01:56.3886567Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3886691Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3886751Z     
2026-02-14T13:01:56.3886865Z         # Parse connection string to get database name
2026-02-14T13:01:56.3887110Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3887170Z     
2026-02-14T13:01:56.3887361Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3887590Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3887648Z     
2026-02-14T13:01:56.3887795Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3887904Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3887984Z         if len(parts) >= 4:
2026-02-14T13:01:56.3888100Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3888168Z         else:
2026-02-14T13:01:56.3888268Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3888325Z     
2026-02-14T13:01:56.3888424Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3888651Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3888717Z         import time
2026-02-14T13:01:56.3888780Z     
2026-02-14T13:01:56.3888849Z         max_retries = 5
2026-02-14T13:01:56.3888916Z         retry_delay = 2
2026-02-14T13:01:56.3888973Z     
2026-02-14T13:01:56.3889068Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3889131Z             try:
2026-02-14T13:01:56.3889230Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3889330Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3889414Z                 conn.autocommit = True
2026-02-14T13:01:56.3889478Z                 try:
2026-02-14T13:01:56.3889554Z                     cur = conn.cursor()
2026-02-14T13:01:56.3889743Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3889824Z                     if not cur.fetchone():
2026-02-14T13:01:56.3889974Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3890097Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3890167Z                     cur.close()
2026-02-14T13:01:56.3890234Z                 finally:
2026-02-14T13:01:56.3890319Z                     conn.close()
2026-02-14T13:01:56.3890390Z                 break  # Success
2026-02-14T13:01:56.3890576Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3890664Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3890753Z                     print(
2026-02-14T13:01:56.3890970Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3891162Z                     )
2026-02-14T13:01:56.3891256Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3891321Z                 else:
2026-02-14T13:01:56.3891523Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3891713Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3891785Z                     pass
2026-02-14T13:01:56.3891901Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3892095Z                 break  # Already exists
2026-02-14T13:01:56.3892162Z     
2026-02-14T13:01:56.3892378Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3892559Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3892810Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3892870Z     
2026-02-14T13:01:56.3892943Z         close_all_pools()
2026-02-14T13:01:56.3893006Z     
2026-02-14T13:01:56.3893125Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3893289Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3893429Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3893517Z             conn.autocommit = True
2026-02-14T13:01:56.3893596Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3893796Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3893894Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3893967Z                 cur.execute(
2026-02-14T13:01:56.3894033Z                     """
2026-02-14T13:01:56.3894141Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3894220Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3894315Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3894403Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3894474Z                     """
2026-02-14T13:01:56.3894535Z                 )
2026-02-14T13:01:56.3894594Z     
2026-02-14T13:01:56.3894789Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3894972Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3895036Z                 try:
2026-02-14T13:01:56.3895158Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3895240Z                     cur.execute("""
2026-02-14T13:01:56.3895313Z                         DO $$
2026-02-14T13:01:56.3895383Z                         DECLARE
2026-02-14T13:01:56.3895467Z                             r RECORD;
2026-02-14T13:01:56.3895533Z                         BEGIN
2026-02-14T13:01:56.3895604Z                             FOR r IN (
2026-02-14T13:01:56.3895711Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3895792Z                                 FROM pg_views
2026-02-14T13:01:56.3895921Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3895988Z                             )
2026-02-14T13:01:56.3896064Z                             LOOP
2026-02-14T13:01:56.3896376Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3896458Z                             END LOOP;
2026-02-14T13:01:56.3896531Z                         END $$;
2026-02-14T13:01:56.3896596Z                     """)
2026-02-14T13:01:56.3896668Z                     # Drop tables
2026-02-14T13:01:56.3896747Z                     cur.execute("""
2026-02-14T13:01:56.3896818Z                         DO $$
2026-02-14T13:01:56.3896885Z                         DECLARE
2026-02-14T13:01:56.3896954Z                             r RECORD;
2026-02-14T13:01:56.3897026Z                         BEGIN
2026-02-14T13:01:56.3897096Z                             FOR r IN (
2026-02-14T13:01:56.3897194Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3897281Z                                 FROM pg_tables
2026-02-14T13:01:56.3897406Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3897471Z                             )
2026-02-14T13:01:56.3897544Z                             LOOP
2026-02-14T13:01:56.3897947Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3898022Z                             END LOOP;
2026-02-14T13:01:56.3898087Z                         END $$;
2026-02-14T13:01:56.3898237Z                     """)
2026-02-14T13:01:56.3898317Z                 except psycopg2.Error:
2026-02-14T13:01:56.3898489Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3898561Z                     pass
2026-02-14T13:01:56.3898618Z     
2026-02-14T13:01:56.3898787Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3898900Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3898977Z                 if init_dir.exists():
2026-02-14T13:01:56.3899080Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3899176Z                     for script_path in scripts:
2026-02-14T13:01:56.3899306Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3899382Z                             sql = f.read()
2026-02-14T13:01:56.3899586Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3899725Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3899803Z                             statements = []
2026-02-14T13:01:56.3899861Z     
2026-02-14T13:01:56.3900039Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3900115Z                             do_blocks = []
2026-02-14T13:01:56.3900214Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3900273Z     
2026-02-14T13:01:56.3900375Z                             def replace_do_block(match):
2026-02-14T13:01:56.3900465Z                                 block = match.group(0)
2026-02-14T13:01:56.3900596Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3900698Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3900794Z                                 return placeholder
2026-02-14T13:01:56.3900855Z     
2026-02-14T13:01:56.3900966Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3901355Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3901494Z                                                     ^^
2026-02-14T13:01:56.3901781Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3901893Z                             )
2026-02-14T13:01:56.3902067Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3902076Z 
2026-02-14T13:01:56.3902248Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3902510Z _ ERROR at setup of TestRankerValidation.test_ranker_handles_mixed_valid_and_invalid_jobs _
2026-02-14T13:01:56.3902517Z 
2026-02-14T13:01:56.3902809Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3902814Z 
2026-02-14T13:01:56.3902903Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3903014Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3903081Z         """
2026-02-14T13:01:56.3903214Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3903272Z     
2026-02-14T13:01:56.3903402Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3903531Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3903590Z         """
2026-02-14T13:01:56.3903684Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3903814Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3903872Z     
2026-02-14T13:01:56.3903978Z         # Parse connection string to get database name
2026-02-14T13:01:56.3904378Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3904442Z     
2026-02-14T13:01:56.3904629Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3904960Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3905025Z     
2026-02-14T13:01:56.3905169Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3905279Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3905362Z         if len(parts) >= 4:
2026-02-14T13:01:56.3905480Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3905542Z         else:
2026-02-14T13:01:56.3905647Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3905704Z     
2026-02-14T13:01:56.3905799Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3906031Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3906104Z         import time
2026-02-14T13:01:56.3906162Z     
2026-02-14T13:01:56.3906230Z         max_retries = 5
2026-02-14T13:01:56.3906317Z         retry_delay = 2
2026-02-14T13:01:56.3906377Z     
2026-02-14T13:01:56.3906463Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3906525Z             try:
2026-02-14T13:01:56.3906632Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3906728Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3906809Z                 conn.autocommit = True
2026-02-14T13:01:56.3906881Z                 try:
2026-02-14T13:01:56.3906959Z                     cur = conn.cursor()
2026-02-14T13:01:56.3907143Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3907230Z                     if not cur.fetchone():
2026-02-14T13:01:56.3907385Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3907502Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3907577Z                     cur.close()
2026-02-14T13:01:56.3907656Z                 finally:
2026-02-14T13:01:56.3907726Z                     conn.close()
2026-02-14T13:01:56.3907797Z                 break  # Success
2026-02-14T13:01:56.3907991Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3908081Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3908151Z                     print(
2026-02-14T13:01:56.3908376Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3908441Z                     )
2026-02-14T13:01:56.3908524Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3908588Z                 else:
2026-02-14T13:01:56.3908808Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3908990Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3909057Z                     pass
2026-02-14T13:01:56.3909181Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3909256Z                 break  # Already exists
2026-02-14T13:01:56.3909313Z     
2026-02-14T13:01:56.3909531Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3909712Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3909842Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3909901Z     
2026-02-14T13:01:56.3909979Z         close_all_pools()
2026-02-14T13:01:56.3910037Z     
2026-02-14T13:01:56.3910154Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3910407Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3910551Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3910635Z             conn.autocommit = True
2026-02-14T13:01:56.3910716Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3910994Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3911322Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3911415Z                 cur.execute(
2026-02-14T13:01:56.3911485Z                     """
2026-02-14T13:01:56.3911585Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3911665Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3911765Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3911856Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3911920Z                     """
2026-02-14T13:01:56.3911986Z                 )
2026-02-14T13:01:56.3912051Z     
2026-02-14T13:01:56.3912239Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3912425Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3912502Z                 try:
2026-02-14T13:01:56.3912620Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3912694Z                     cur.execute("""
2026-02-14T13:01:56.3912773Z                         DO $$
2026-02-14T13:01:56.3912840Z                         DECLARE
2026-02-14T13:01:56.3912913Z                             r RECORD;
2026-02-14T13:01:56.3912985Z                         BEGIN
2026-02-14T13:01:56.3913063Z                             FOR r IN (
2026-02-14T13:01:56.3913163Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3913244Z                                 FROM pg_views
2026-02-14T13:01:56.3913380Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3913444Z                             )
2026-02-14T13:01:56.3913514Z                             LOOP
2026-02-14T13:01:56.3913831Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3913908Z                             END LOOP;
2026-02-14T13:01:56.3913976Z                         END $$;
2026-02-14T13:01:56.3914042Z                     """)
2026-02-14T13:01:56.3914118Z                     # Drop tables
2026-02-14T13:01:56.3914190Z                     cur.execute("""
2026-02-14T13:01:56.3914258Z                         DO $$
2026-02-14T13:01:56.3914331Z                         DECLARE
2026-02-14T13:01:56.3914400Z                             r RECORD;
2026-02-14T13:01:56.3914465Z                         BEGIN
2026-02-14T13:01:56.3914542Z                             FOR r IN (
2026-02-14T13:01:56.3914646Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3914730Z                                 FROM pg_tables
2026-02-14T13:01:56.3914858Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3914932Z                             )
2026-02-14T13:01:56.3915005Z                             LOOP
2026-02-14T13:01:56.3915317Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3915396Z                             END LOOP;
2026-02-14T13:01:56.3915463Z                         END $$;
2026-02-14T13:01:56.3915530Z                     """)
2026-02-14T13:01:56.3915618Z                 except psycopg2.Error:
2026-02-14T13:01:56.3915794Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3915863Z                     pass
2026-02-14T13:01:56.3915920Z     
2026-02-14T13:01:56.3916229Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3916343Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3916422Z                 if init_dir.exists():
2026-02-14T13:01:56.3916530Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3916722Z                     for script_path in scripts:
2026-02-14T13:01:56.3916847Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3916931Z                             sql = f.read()
2026-02-14T13:01:56.3917138Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3917270Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3917347Z                             statements = []
2026-02-14T13:01:56.3917417Z     
2026-02-14T13:01:56.3917594Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3917678Z                             do_blocks = []
2026-02-14T13:01:56.3917786Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3917845Z     
2026-02-14T13:01:56.3917941Z                             def replace_do_block(match):
2026-02-14T13:01:56.3918042Z                                 block = match.group(0)
2026-02-14T13:01:56.3918171Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3918271Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3918363Z                                 return placeholder
2026-02-14T13:01:56.3918428Z     
2026-02-14T13:01:56.3918535Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3918632Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3918724Z                                                     ^^
2026-02-14T13:01:56.3918914Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3918984Z                             )
2026-02-14T13:01:56.3919098Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3919103Z 
2026-02-14T13:01:56.3919205Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3919414Z _ ERROR at setup of TestRankerValidation.test_validation_query_works_correctly _
2026-02-14T13:01:56.3919419Z 
2026-02-14T13:01:56.3919700Z test_db_connection_string = '***127.0.0.1:5432/job_search_test'
2026-02-14T13:01:56.3919705Z 
2026-02-14T13:01:56.3919797Z     @pytest.fixture(scope="function")
2026-02-14T13:01:56.3919902Z     def test_database(test_db_connection_string):
2026-02-14T13:01:56.3919962Z         """
2026-02-14T13:01:56.3920095Z         Set up and tear down test database for integration tests.
2026-02-14T13:01:56.3920159Z     
2026-02-14T13:01:56.3920290Z         Creates schemas and tables, then cleans up after tests.
2026-02-14T13:01:56.3920417Z         This fixture requires a running PostgreSQL database.
2026-02-14T13:01:56.3920483Z         """
2026-02-14T13:01:56.3920577Z         # Read schema and table creation scripts
2026-02-14T13:01:56.3920710Z         project_root = Path(__file__).parent.parent.parent
2026-02-14T13:01:56.3920772Z     
2026-02-14T13:01:56.3920887Z         # Parse connection string to get database name
2026-02-14T13:01:56.3921267Z         db_name = test_db_connection_string.split("/")[-1].split("?")[0]  # Remove query params if any
2026-02-14T13:01:56.3921327Z     
2026-02-14T13:01:56.3921521Z         # Use 127.0.0.1 instead of localhost to avoid IPv6 issues in some environments
2026-02-14T13:01:56.3921746Z         test_db_connection_string = test_db_connection_string.replace("@localhost", "@127.0.0.1")
2026-02-14T13:01:56.3921805Z     
2026-02-14T13:01:56.3921954Z         # Try to create base connection string to 'postgres' database
2026-02-14T13:01:56.3922064Z         parts = test_db_connection_string.split("/")
2026-02-14T13:01:56.3922139Z         if len(parts) >= 4:
2026-02-14T13:01:56.3922416Z             base_conn_str = "/".join(parts[:-1]) + "/postgres"
2026-02-14T13:01:56.3922487Z         else:
2026-02-14T13:01:56.3922587Z             base_conn_str = test_db_connection_string
2026-02-14T13:01:56.3922646Z     
2026-02-14T13:01:56.3922846Z         # Create test database if it doesn't exist
2026-02-14T13:01:56.3923073Z         # Note: CREATE DATABASE must be executed with autocommit=True and outside context manager
2026-02-14T13:01:56.3923140Z         import time
2026-02-14T13:01:56.3923202Z     
2026-02-14T13:01:56.3923270Z         max_retries = 5
2026-02-14T13:01:56.3923337Z         retry_delay = 2
2026-02-14T13:01:56.3923394Z     
2026-02-14T13:01:56.3923486Z         for attempt in range(max_retries):
2026-02-14T13:01:56.3923547Z             try:
2026-02-14T13:01:56.3923647Z                 conn = psycopg2.connect(base_conn_str)
2026-02-14T13:01:56.3923745Z                 # Set autocommit before using cursor
2026-02-14T13:01:56.3923833Z                 conn.autocommit = True
2026-02-14T13:01:56.3923897Z                 try:
2026-02-14T13:01:56.3923976Z                     cur = conn.cursor()
2026-02-14T13:01:56.3924170Z                     cur.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
2026-02-14T13:01:56.3924258Z                     if not cur.fetchone():
2026-02-14T13:01:56.3924409Z                         # CREATE DATABASE must be executed with autocommit enabled
2026-02-14T13:01:56.3924530Z                         cur.execute(f'CREATE DATABASE "{db_name}"')
2026-02-14T13:01:56.3924602Z                     cur.close()
2026-02-14T13:01:56.3924670Z                 finally:
2026-02-14T13:01:56.3924749Z                     conn.close()
2026-02-14T13:01:56.3924819Z                 break  # Success
2026-02-14T13:01:56.3925007Z             except (psycopg2.OperationalError, psycopg2.ProgrammingError) as e:
2026-02-14T13:01:56.3925097Z                 if attempt < max_retries - 1:
2026-02-14T13:01:56.3925175Z                     print(
2026-02-14T13:01:56.3925396Z                         f"Connection attempt {attempt + 1} failed: {e}. Retrying in {retry_delay}s..."
2026-02-14T13:01:56.3925461Z                     )
2026-02-14T13:01:56.3925550Z                     time.sleep(retry_delay)
2026-02-14T13:01:56.3925618Z                 else:
2026-02-14T13:01:56.3925820Z                     # Last attempt failed, but we might be connecting directly to an existing DB
2026-02-14T13:01:56.3926009Z                     # Proceed and let the next connection attempt fail if it's a real issue
2026-02-14T13:01:56.3926078Z                     pass
2026-02-14T13:01:56.3926195Z             except psycopg2.errors.DuplicateDatabase:
2026-02-14T13:01:56.3926274Z                 break  # Already exists
2026-02-14T13:01:56.3926338Z     
2026-02-14T13:01:56.3926555Z         # Close connection pools before pg_terminate_backend - otherwise pooled connections
2026-02-14T13:01:56.3926737Z         # get killed and subsequent tests receive dead connections from the pool.
2026-02-14T13:01:56.3926880Z         from services.shared.database import close_all_pools
2026-02-14T13:01:56.3926939Z     
2026-02-14T13:01:56.3927013Z         close_all_pools()
2026-02-14T13:01:56.3927080Z     
2026-02-14T13:01:56.3927199Z         # Connect to test database and set up schemas/tables
2026-02-14T13:01:56.3927368Z         # Note: We use autocommit=True, so each statement executes immediately
2026-02-14T13:01:56.3927511Z         with psycopg2.connect(test_db_connection_string) as conn:
2026-02-14T13:01:56.3927598Z             conn.autocommit = True
2026-02-14T13:01:56.3927675Z             with conn.cursor() as cur:
2026-02-14T13:01:56.3927870Z                 # Terminate any lingering connections to avoid lock issues during cleanup
2026-02-14T13:01:56.3927969Z                 # EXCEPT our current connection
2026-02-14T13:01:56.3928040Z                 cur.execute(
2026-02-14T13:01:56.3928108Z                     """
2026-02-14T13:01:56.3928210Z                     SELECT pg_terminate_backend(pid)
2026-02-14T13:01:56.3928379Z                     FROM pg_stat_activity
2026-02-14T13:01:56.3928480Z                     WHERE datname = current_database()
2026-02-14T13:01:56.3928572Z                       AND pid <> pg_backend_pid()
2026-02-14T13:01:56.3928719Z                     """
2026-02-14T13:01:56.3928782Z                 )
2026-02-14T13:01:56.3928840Z     
2026-02-14T13:01:56.3929038Z                 # Drop all existing tables and views in test schemas to ensure clean state
2026-02-14T13:01:56.3929221Z                 # This prevents issues with old schema (e.g., profile_id vs campaign_id)
2026-02-14T13:01:56.3929293Z                 try:
2026-02-14T13:01:56.3929418Z                     # Drop views first (they may depend on tables)
2026-02-14T13:01:56.3929494Z                     cur.execute("""
2026-02-14T13:01:56.3929563Z                         DO $$
2026-02-14T13:01:56.3929633Z                         DECLARE
2026-02-14T13:01:56.3929717Z                             r RECORD;
2026-02-14T13:01:56.3929790Z                         BEGIN
2026-02-14T13:01:56.3929863Z                             FOR r IN (
2026-02-14T13:01:56.3929975Z                                 SELECT schemaname, viewname
2026-02-14T13:01:56.3930061Z                                 FROM pg_views
2026-02-14T13:01:56.3930198Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3930265Z                             )
2026-02-14T13:01:56.3930341Z                             LOOP
2026-02-14T13:01:56.3930650Z                                 EXECUTE 'DROP VIEW IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.viewname) || ' CASCADE';
2026-02-14T13:01:56.3930723Z                             END LOOP;
2026-02-14T13:01:56.3930797Z                         END $$;
2026-02-14T13:01:56.3930862Z                     """)
2026-02-14T13:01:56.3930939Z                     # Drop tables
2026-02-14T13:01:56.3931017Z                     cur.execute("""
2026-02-14T13:01:56.3931240Z                         DO $$
2026-02-14T13:01:56.3931308Z                         DECLARE
2026-02-14T13:01:56.3931378Z                             r RECORD;
2026-02-14T13:01:56.3931451Z                         BEGIN
2026-02-14T13:01:56.3931521Z                             FOR r IN (
2026-02-14T13:01:56.3931628Z                                 SELECT schemaname, tablename
2026-02-14T13:01:56.3931713Z                                 FROM pg_tables
2026-02-14T13:01:56.3931839Z                                 WHERE schemaname IN ('raw', 'staging', 'marts')
2026-02-14T13:01:56.3931903Z                             )
2026-02-14T13:01:56.3931977Z                             LOOP
2026-02-14T13:01:56.3932288Z                                 EXECUTE 'DROP TABLE IF EXISTS ' || quote_ident(r.schemaname) || '.' || quote_ident(r.tablename) || ' CASCADE';
2026-02-14T13:01:56.3932359Z                             END LOOP;
2026-02-14T13:01:56.3932430Z                         END $$;
2026-02-14T13:01:56.3932498Z                     """)
2026-02-14T13:01:56.3932582Z                 except psycopg2.Error:
2026-02-14T13:01:56.3932755Z                     # If dropping fails, that's okay - tables/views might not exist yet
2026-02-14T13:01:56.3932830Z                     pass
2026-02-14T13:01:56.3932892Z     
2026-02-14T13:01:56.3933061Z                 # Read and execute all scripts in docker/init in alphabetical order
2026-02-14T13:01:56.3933177Z                 init_dir = project_root / "docker" / "init"
2026-02-14T13:01:56.3933253Z                 if init_dir.exists():
2026-02-14T13:01:56.3933358Z                     scripts = sorted(init_dir.glob("*.sql"))
2026-02-14T13:01:56.3933448Z                     for script_path in scripts:
2026-02-14T13:01:56.3933579Z                         with open(script_path, encoding="utf-8") as f:
2026-02-14T13:01:56.3933656Z                             sql = f.read()
2026-02-14T13:01:56.3933859Z                             # Split the script into individual statements to handle errors gracefully
2026-02-14T13:01:56.3934138Z                             # and avoid transaction aborts for the whole script
2026-02-14T13:01:56.3934222Z                             statements = []
2026-02-14T13:01:56.3934280Z     
2026-02-14T13:01:56.3934462Z                             # First, extract all DO blocks and replace them with placeholders
2026-02-14T13:01:56.3934640Z                             do_blocks = []
2026-02-14T13:01:56.3934742Z                             do_pattern = r"DO\s+\$\$.*?\$\$\s*;"
2026-02-14T13:01:56.3934801Z     
2026-02-14T13:01:56.3934909Z                             def replace_do_block(match):
2026-02-14T13:01:56.3934999Z                                 block = match.group(0)
2026-02-14T13:01:56.3935125Z                                 placeholder = f"__DO_BLOCK_{len(do_blocks)}__"
2026-02-14T13:01:56.3935224Z                                 do_blocks.append(block)
2026-02-14T13:01:56.3935312Z                                 return placeholder
2026-02-14T13:01:56.3935369Z     
2026-02-14T13:01:56.3935487Z                             # Replace DO blocks with placeholders
2026-02-14T13:01:56.3935585Z >                           sql_with_placeholders = re.sub(
2026-02-14T13:01:56.3935667Z                                                     ^^
2026-02-14T13:01:56.3935858Z                                 do_pattern, replace_do_block, sql, flags=re.DOTALL | re.IGNORECASE
2026-02-14T13:01:56.3935932Z                             )
2026-02-14T13:01:56.3936040Z E                           NameError: name 're' is not defined
2026-02-14T13:01:56.3936045Z 
2026-02-14T13:01:56.3936147Z tests/integration/conftest.py:168: NameError
2026-02-14T13:01:56.3936276Z =============================== warnings summary ===============================
2026-02-14T13:01:56.3936554Z ../../../../../opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/PyPDF2/__init__.py:21
2026-02-14T13:01:56.3937097Z   /opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/PyPDF2/__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.
2026-02-14T13:01:56.3937175Z     warnings.warn(
2026-02-14T13:01:56.3937180Z 
2026-02-14T13:01:56.3937371Z -- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
2026-02-14T13:01:56.3937498Z ================================ tests coverage ================================
2026-02-14T13:01:56.3937673Z _______________ coverage: platform linux, python 3.11.14-final-0 _______________
2026-02-14T13:01:56.3937678Z 
2026-02-14T13:01:56.3937811Z Name                                                  Stmts   Miss  Cover   Missing
2026-02-14T13:01:56.3937959Z -----------------------------------------------------------------------------------
2026-02-14T13:01:56.3938111Z services/__init__.py                                      0      0   100%
2026-02-14T13:01:56.3938279Z services/airflow_client/__init__.py                       2      0   100%
2026-02-14T13:01:56.3938522Z services/airflow_client/airflow_client.py                81     15    81%   50-64, 74, 140-141, 154-157
2026-02-14T13:01:56.3938676Z services/auth/__init__.py                                 3      0   100%
2026-02-14T13:01:56.3938837Z services/auth/auth_service.py                            32      0   100%
2026-02-14T13:01:56.3938987Z services/auth/queries.py                                  6      0   100%
2026-02-14T13:01:56.3939219Z services/auth/user_service.py                           110     44    60%   89-92, 111, 130, 149, 173-178, 190-239
2026-02-14T13:01:56.3939386Z services/campaign_management/__init__.py                  2      0   100%
2026-02-14T13:01:56.3940014Z services/campaign_management/campaign_service.py        317    221    30%   51, 63-72, 85-112, 122-137, 187-245, 292-342, 353-454, 471-510, 525-538, 563-654, 680-706, 717-734, 746-751, 763-770, 866-872, 898-909, 920-923, 941, 972-973, 995-996, 1021-1025
2026-02-14T13:01:56.3940185Z services/campaign_management/queries.py                  15      0   100%
2026-02-14T13:01:56.3940430Z services/documents/__init__.py                            7      0   100%
2026-02-14T13:01:56.3940751Z services/documents/cover_letter_generator.py            122     15    88%   12-13, 38, 46, 101, 103, 105, 107, 204, 225-226, 314-315, 328, 349
2026-02-14T13:01:56.3941538Z services/documents/cover_letter_service.py              212     86    59%   84, 92, 97, 104, 123-128, 177, 180, 183-184, 220, 248, 251, 254-255, 278-286, 318, 321-323, 339-356, 378, 381-382, 408-424, 451, 455-461, 490-494, 498-500, 518-537
2026-02-14T13:01:56.3941991Z services/documents/document_service.py                   97     18    81%   78, 81, 84-85, 109-111, 135, 138-140, 198, 201-202, 211, 213, 215, 225-227
2026-02-14T13:01:56.3942157Z services/documents/queries.py                            17      0   100%
2026-02-14T13:01:56.3942564Z services/documents/resume_service.py                    180     54    70%   121-129, 184, 187, 190-191, 225-226, 246, 249-251, 277, 280-281, 298-311, 338, 345-349, 379-381, 399-415
2026-02-14T13:01:56.3942843Z services/documents/resume_text_extractor.py              97     15    85%   19-20, 25-26, 69, 79, 84, 97, 102-105, 145-147
2026-02-14T13:01:56.3943144Z services/documents/storage_service.py                    71     47    34%   91-92, 104-113, 128-132, 148-157, 172-179, 193-202, 213-217, 229
2026-02-14T13:01:56.3943312Z services/enricher/__init__.py                             3      0   100%
2026-02-14T13:01:56.3944550Z services/enricher/chatgpt_enricher.py                   785    429    45%   22-23, 51-57, 116, 245-248, 251-266, 269, 356, 400-401, 408-409, 423-426, 434-437, 495, 585-587, 611, 618, 624-629, 653-657, 673-805, 821, 847-854, 859, 861-865, 880, 882, 936, 975-978, 985-987, 995-997, 1004-1066, 1082-1113, 1146-1153, 1158, 1160-1164, 1184, 1186, 1239, 1244-1248, 1327-1346, 1356-1358, 1371, 1377-1379, 1387, 1392-1399, 1412, 1415-1417, 1428-1437, 1449-1533, 1558-1600, 1621-1703, 1715-1800, 1815-1840, 1858-1903
2026-02-14T13:01:56.3944725Z services/enricher/chatgpt_queries.py                      3      0   100%
2026-02-14T13:01:56.3945292Z services/enricher/job_enricher.py                       364     79    78%   15-16, 73-76, 81, 86, 95-97, 187-201, 313, 424, 437-438, 523, 545, 565, 572, 575-578, 620, 665-666, 675, 677, 679-682, 684-687, 704-705, 709, 813-829, 866, 876-882, 966-969, 990-1010
2026-02-14T13:01:56.3945453Z services/enricher/queries.py                              4      0   100%
2026-02-14T13:01:56.3945628Z services/enricher/remote_patterns.py                      1      0   100%
2026-02-14T13:01:56.3945795Z services/enricher/seniority_patterns.py                   1      0   100%
2026-02-14T13:01:56.3945980Z services/enricher/technical_skills.py                     8      1    88%   310
2026-02-14T13:01:56.3946175Z services/enrichment_analysis/__init__.py                  2      2     0%   8-10
2026-02-14T13:01:56.3946373Z services/enrichment_analysis/enrichment_analyzer.py     250    250     0%   7-753
2026-02-14T13:01:56.3946562Z services/enrichment_analysis/queries.py                   7      7     0%   8-195
2026-02-14T13:01:56.3946723Z services/extractor/__init__.py                            5      0   100%
2026-02-14T13:01:56.3946963Z services/extractor/base_client.py                        52     35    33%   53-71, 75-83, 91, 111, 126-134, 140-148
2026-02-14T13:01:56.3947327Z services/extractor/company_extractor.py                 145     81    44%   52, 54, 88-91, 110-111, 125-211, 270-277, 287-310, 314, 318, 322-323, 327-328, 340-368
2026-02-14T13:01:56.3947543Z services/extractor/glassdoor_client.py                   28     18    36%   42, 67-88, 104-106
2026-02-14T13:01:56.3947793Z services/extractor/job_extractor.py                     124    106    15%   52-61, 69-75, 87-123, 138-251, 259-279
2026-02-14T13:01:56.3947997Z services/extractor/jsearch_client.py                     39     29    26%   42, 67-88, 119-139
2026-02-14T13:01:56.3948158Z services/extractor/queries.py                            12      0   100%
2026-02-14T13:01:56.3948416Z services/jobs/__init__.py                                 4      0   100%
2026-02-14T13:01:56.3948615Z services/jobs/job_note_service.py                        85      5    94%   52, 69, 91, 109, 134
2026-02-14T13:01:56.3948824Z services/jobs/job_service.py                             75     29    61%   70, 115, 134-144, 156-173, 190-199
2026-02-14T13:01:56.3949231Z services/jobs/job_status_service.py                     165     22    87%   90, 128, 184-187, 238, 243-247, 365-366, 382-383, 415, 429-430, 458, 472-473
2026-02-14T13:01:56.3949383Z services/jobs/queries.py                                 15      0   100%
2026-02-14T13:01:56.3949534Z services/notifier/__init__.py                             4      0   100%
2026-02-14T13:01:56.3949750Z services/notifier/base_notifier.py                       42     31    26%   30, 46, 62-110, 129-164
2026-02-14T13:01:56.3949948Z services/notifier/email_notifier.py                      46     33    28%   52-63, 78-112
2026-02-14T13:01:56.3950211Z services/notifier/notification_coordinator.py            62     49    21%   46-53, 62-69, 86-97, 109-133, 142-165
2026-02-14T13:01:56.3950374Z services/notifier/queries.py                              2      0   100%
2026-02-14T13:01:56.3950520Z services/ranker/__init__.py                               2      0   100%
2026-02-14T13:01:56.3951763Z services/ranker/job_ranker.py                           510    187    63%   51, 64-71, 211-231, 286, 290-295, 313, 320-333, 350, 356, 363, 373, 388, 394-395, 407, 409, 411, 413, 415, 426-452, 467-468, 473-489, 502, 516-533, 557, 560, 571-573, 581-583, 596-599, 602, 608-611, 614, 621-626, 630, 633-636, 662-663, 670-673, 724-726, 746, 750, 775, 778, 788, 796-804, 807, 816-823, 867, 912, 919, 924, 930, 973-974, 981-986, 1029-1045, 1060-1064, 1178-1199
2026-02-14T13:01:56.3951930Z services/ranker/queries.py                                5      0   100%
2026-02-14T13:01:56.3952077Z services/shared/__init__.py                               3      0   100%
2026-02-14T13:01:56.3952284Z services/shared/database.py                              51     28    45%   27-41, 48-51, 93-96, 113-127
2026-02-14T13:01:56.3952483Z services/shared/metrics_recorder.py                      36     25    31%   40-42, 85-166
2026-02-14T13:01:56.3952668Z services/shared/structured_logging.py                    28     28     0%   7-99
2026-02-14T13:01:56.3952837Z services/staging_management/__init__.py                   2      0   100%
2026-02-14T13:01:56.3953006Z services/staging_management/queries.py                    5      0   100%
2026-02-14T13:01:56.3953254Z services/staging_management/staging_service.py           80     40    50%   37, 69, 95-98, 132-165, 173-182
2026-02-14T13:01:56.3953407Z -----------------------------------------------------------------------------------
2026-02-14T13:01:56.3953520Z TOTAL                                                  4426   2029    54%
2026-02-14T13:01:56.3953608Z Coverage HTML written to dir htmlcov
2026-02-14T13:01:56.3953736Z =========================== short test summary info ============================
2026-02-14T13:01:56.3954176Z ERROR tests/integration/test_bug_fixes.py::TestBug3Deduplication::test_extractor_skips_duplicate_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3954595Z ERROR tests/integration/test_bug_fixes.py::TestBug3Deduplication::test_extractor_handles_mixed_duplicates - NameError: name 're' is not defined
2026-02-14T13:01:56.3954967Z ERROR tests/integration/test_bug_fixes.py::TestBug5UKCountryCode::test_ranker_uses_gb_not_uk - NameError: name 're' is not defined
2026-02-14T13:01:56.3955395Z ERROR tests/integration/test_bug_fixes.py::TestBug5UKCountryCode::test_campaign_stored_with_gb_country_code - NameError: name 're' is not defined
2026-02-14T13:01:56.3955793Z ERROR tests/integration/test_bug_fixes.py::TestBug7JobNotFound::test_job_retrievable_from_own_campaign - NameError: name 're' is not defined
2026-02-14T13:01:56.3956204Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignUniqueness::test_campaign_ids_are_unique - NameError: name 're' is not defined
2026-02-14T13:01:56.3956737Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignUniqueness::test_campaign_ids_increment - NameError: name 're' is not defined
2026-02-14T13:01:56.3957191Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignUniqueness::test_campaign_id_primary_key_constraint - NameError: name 're' is not defined
2026-02-14T13:01:56.3957725Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_rankings - NameError: name 're' is not defined
2026-02-14T13:01:56.3958161Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_fact_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3958607Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_staging_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3959053Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_removes_etl_metrics - NameError: name 're' is not defined
2026-02-14T13:01:56.3959507Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_delete_campaign_comprehensive_cleanup - NameError: name 're' is not defined
2026-02-14T13:01:56.3959938Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_new_campaign_does_not_show_old_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3960397Z ERROR tests/integration/test_campaign_deletion.py::TestCampaignDeletion::test_job_queries_only_show_existing_campaigns - NameError: name 're' is not defined
2026-02-14T13:01:56.3960881Z ERROR tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_companies_identified_from_staging_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3961457Z ERROR tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_company_extracted_to_raw_layer - NameError: name 're' is not defined
2026-02-14T13:01:56.3961898Z ERROR tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_enrichment_queue_updated - NameError: name 're' is not defined
2026-02-14T13:01:56.3962352Z ERROR tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_normalize_companies_to_staging - NameError: name 're' is not defined
2026-02-14T13:01:56.3962810Z ERROR tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_companies_in_marts_dim_companies - NameError: name 're' is not defined
2026-02-14T13:01:56.3963269Z ERROR tests/integration/test_company_enrichment.py::TestCompanyEnrichmentFlow::test_complete_company_enrichment_flow - NameError: name 're' is not defined
2026-02-14T13:01:56.3963669Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_after_successful_dag - NameError: name 're' is not defined
2026-02-14T13:01:56.3964057Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_after_failed_dag - NameError: name 're' is not defined
2026-02-14T13:01:56.3964456Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_no_cooldown_before_first_run - NameError: name 're' is not defined
2026-02-14T13:01:56.3964859Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_expires_after_one_hour - NameError: name 're' is not defined
2026-02-14T13:01:56.3965305Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_multiple_campaigns_independent_cooldown - NameError: name 're' is not defined
2026-02-14T13:01:56.3965740Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_concurrent_dag_triggers_same_campaign - NameError: name 're' is not defined
2026-02-14T13:01:56.3966127Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_dag_completion_with_no_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3966530Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_page_refresh_preserves_cooldown - NameError: name 're' is not defined
2026-02-14T13:01:56.3967041Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_force_start_bypasses_cooldown - NameError: name 're' is not defined
2026-02-14T13:01:56.3967453Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_calculation_edge_cases - NameError: name 're' is not defined
2026-02-14T13:01:56.3967938Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_status_derived_from_metrics - NameError: name 're' is not defined
2026-02-14T13:01:56.3968366Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_concurrent_triggers_different_users - NameError: name 're' is not defined
2026-02-14T13:01:56.3968759Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_with_timezone_issues - NameError: name 're' is not defined
2026-02-14T13:01:56.3969149Z ERROR tests/integration/test_cooldown_logic.py::TestCooldownLogic::test_cooldown_reset_on_force_start - NameError: name 're' is not defined
2026-02-14T13:01:56.3969585Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_invalid_campaign_id_handling - NameError: name 're' is not defined
2026-02-14T13:01:56.3970001Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_missing_dag_run_id_handling - NameError: name 're' is not defined
2026-02-14T13:01:56.3970466Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_concurrent_status_check_race_condition - NameError: name 're' is not defined
2026-02-14T13:01:56.3970904Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_airflow_api_timeout_simulation - NameError: name 're' is not defined
2026-02-14T13:01:56.3971480Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_airflow_connection_error_simulation - NameError: name 're' is not defined
2026-02-14T13:01:56.3971880Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_response_validation - NameError: name 're' is not defined
2026-02-14T13:01:56.3972326Z ERROR tests/integration/test_cooldown_logic.py::TestTriggerLogicEdgeCases::test_campaign_ownership_validation - NameError: name 're' is not defined
2026-02-14T13:01:56.3972823Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_success - NameError: name 're' is not defined
2026-02-14T13:01:56.3973338Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_with_comments - NameError: name 're' is not defined
2026-02-14T13:01:56.3973868Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_missing_resume_id - NameError: name 're' is not defined
2026-02-14T13:01:56.3974389Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_invalid_resume_id - NameError: name 're' is not defined
2026-02-14T13:01:56.3974893Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_not_json - NameError: name 're' is not defined
2026-02-14T13:01:56.3975415Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_generation_error - NameError: name 're' is not defined
2026-02-14T13:01:56.3975937Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_validation_error - NameError: name 're' is not defined
2026-02-14T13:01:56.3976455Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_requires_login - NameError: name 're' is not defined
2026-02-14T13:01:56.3977018Z ERROR tests/integration/test_cover_letter_generation_ui.py::TestCoverLetterGenerationRoute::test_generate_cover_letter_general_exception - NameError: name 're' is not defined
2026-02-14T13:01:56.3977461Z ERROR tests/integration/test_dag_end_to_end.py::test_dag_end_to_end_full_pipeline - NameError: name 're' is not defined
2026-02-14T13:01:56.3977987Z ERROR tests/integration/test_data_preservation.py::TestDataPreservation::test_fact_jobs_preserves_all_campaigns_on_single_campaign_dag - NameError: name 're' is not defined
2026-02-14T13:01:56.3978574Z ERROR tests/integration/test_data_preservation.py::TestDataPreservation::test_staging_incremental_preserves_other_campaigns - NameError: name 're' is not defined
2026-02-14T13:01:56.3979086Z ERROR tests/integration/test_data_preservation.py::TestDataPreservation::test_incremental_materialization_processes_only_new_records - NameError: name 're' is not defined
2026-02-14T13:01:56.3979565Z ERROR tests/integration/test_data_preservation.py::TestDataPreservation::test_fact_jobs_incremental_without_campaign_filter - NameError: name 're' is not defined
2026-02-14T13:01:56.3980028Z ERROR tests/integration/test_data_preservation.py::TestDataPreservation::test_ranking_upsert_preserves_other_campaigns - NameError: name 're' is not defined
2026-02-14T13:01:56.3980484Z ERROR tests/integration/test_data_preservation.py::TestDataPreservation::test_ranking_upsert_updates_existing_rankings - NameError: name 're' is not defined
2026-02-14T13:01:56.3980971Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_resume_linked_to_multiple_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3981554Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_delete_resume_linked_to_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3982063Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_cover_letter_same_name_different_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.3982573Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_switch_from_inline_text_to_cover_letter_id - NameError: name 're' is not defined
2026-02-14T13:01:56.3983082Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_switch_from_cover_letter_id_to_inline_text - NameError: name 're' is not defined
2026-02-14T13:01:56.3983576Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_concurrent_updates_same_document - NameError: name 're' is not defined
2026-02-14T13:01:56.3984077Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_file_with_special_characters_in_name - NameError: name 're' is not defined
2026-02-14T13:01:56.3984543Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_very_long_cover_letter_text - NameError: name 're' is not defined
2026-02-14T13:01:56.3985012Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_multiple_resumes_same_name - NameError: name 're' is not defined
2026-02-14T13:01:56.3985509Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_get_documents_for_nonexistent_user - NameError: name 're' is not defined
2026-02-14T13:01:56.3986004Z ERROR tests/integration/test_document_edge_cases.py::TestDocumentEdgeCasesIntegration::test_update_document_with_all_none_values - NameError: name 're' is not defined
2026-02-14T13:01:56.3986493Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_upload_resume_and_link_to_job - NameError: name 're' is not defined
2026-02-14T13:01:56.3986988Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_create_text_cover_letter_and_link - NameError: name 're' is not defined
2026-02-14T13:01:56.3987478Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_upload_cover_letter_file_and_link - NameError: name 're' is not defined
2026-02-14T13:01:56.3988130Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_update_job_application_document - NameError: name 're' is not defined
2026-02-14T13:01:56.3988614Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_delete_resume_removes_file - NameError: name 're' is not defined
2026-02-14T13:01:56.3989180Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_get_user_resumes_list - NameError: name 're' is not defined
2026-02-14T13:01:56.3989671Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_inline_cover_letter_text_workflow - NameError: name 're' is not defined
2026-02-14T13:01:56.3990151Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_mixed_document_types_workflow - NameError: name 're' is not defined
2026-02-14T13:01:56.3990661Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_get_user_cover_letters_filtered_by_job - NameError: name 're' is not defined
2026-02-14T13:01:56.3991487Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_documents_uploaded_from_job_details_not_in_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.3992082Z ERROR tests/integration/test_document_management.py::TestDocumentManagementIntegration::test_only_documents_section_documents_in_job_attachment_dropdowns - NameError: name 're' is not defined
2026-02-14T13:01:56.3992498Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_upload_resume_route_success - NameError: name 're' is not defined
2026-02-14T13:01:56.3992898Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_resume_route_success - NameError: name 're' is not defined
2026-02-14T13:01:56.3993313Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_inline_text - NameError: name 're' is not defined
2026-02-14T13:01:56.3993732Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_text_based - NameError: name 're' is not defined
2026-02-14T13:01:56.3994118Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_link_resume_to_job_route - NameError: name 're' is not defined
2026-02-14T13:01:56.3994544Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_update_application_documents_route - NameError: name 're' is not defined
2026-02-14T13:01:56.3994928Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_get_user_resumes_api - NameError: name 're' is not defined
2026-02-14T13:01:56.3995318Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_get_user_cover_letters_api - NameError: name 're' is not defined
2026-02-14T13:01:56.3995728Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_file_based - NameError: name 're' is not defined
2026-02-14T13:01:56.3996201Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_download_cover_letter_text_based_raises_error - NameError: name 're' is not defined
2026-02-14T13:01:56.3996643Z ERROR tests/integration/test_document_routes.py::TestDocumentRoutes::test_cover_letter_download_handles_both_types - NameError: name 're' is not defined
2026-02-14T13:01:56.3997066Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_resume_from_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.3997555Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_resume_from_job_details_not_in_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.3997975Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_resume_from_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.3998420Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_create_cover_letter_from_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.3999041Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_create_cover_letter_from_job_details_not_in_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.3999481Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_cover_letter_from_documents_section - NameError: name 're' is not defined
2026-02-14T13:01:56.4000074Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_only_documents_section_resumes_appear_in_job_attachment - NameError: name 're' is not defined
2026-02-14T13:01:56.4000573Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_only_documents_section_cover_letters_appear_in_job_attachment - NameError: name 're' is not defined
2026-02-14T13:01:56.4000960Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_nonexistent_resume - NameError: name 're' is not defined
2026-02-14T13:01:56.4001500Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_delete_nonexistent_cover_letter - NameError: name 're' is not defined
2026-02-14T13:01:56.4001881Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_get_resume_by_id_not_found - NameError: name 're' is not defined
2026-02-14T13:01:56.4002284Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_get_cover_letter_by_id_not_found - NameError: name 're' is not defined
2026-02-14T13:01:56.4002718Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_download_text_based_cover_letter_fails - NameError: name 're' is not defined
2026-02-14T13:01:56.4003119Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_resume_invalid_file_type - NameError: name 're' is not defined
2026-02-14T13:01:56.4003540Z ERROR tests/integration/test_documents_page.py::TestDocumentsPage::test_upload_cover_letter_invalid_file_type - NameError: name 're' is not defined
2026-02-14T13:01:56.5364578Z ERROR tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_extract_jobs_to_raw_layer - NameError: name 're' is not defined
2026-02-14T13:01:56.5365331Z ERROR tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_normalize_jobs_to_staging - NameError: name 're' is not defined
2026-02-14T13:01:56.5365943Z ERROR tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_build_marts_and_rank_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.5366529Z ERROR tests/integration/test_extract_normalize_rank.py::TestExtractNormalizeRankFlow::test_complete_flow_end_to_end - NameError: name 're' is not defined
2026-02-14T13:01:56.5367191Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_job_found_creates_history - NameError: name 're' is not defined
2026-02-14T13:01:56.5367850Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_ai_update_creates_history - NameError: name 're' is not defined
2026-02-14T13:01:56.5368519Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_chatgpt_update_creates_history - NameError: name 're' is not defined
2026-02-14T13:01:56.5369200Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_document_change_creates_history - NameError: name 're' is not defined
2026-02-14T13:01:56.5369860Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_record_note_change_creates_history - NameError: name 're' is not defined
2026-02-14T13:01:56.5370490Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_upsert_status_records_history - NameError: name 're' is not defined
2026-02-14T13:01:56.5371811Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_get_user_status_history_returns_all_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.5372539Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_get_job_status_history_returns_all_users - NameError: name 're' is not defined
2026-02-14T13:01:56.5373377Z ERROR tests/integration/test_job_status_history_integration.py::TestJobStatusHistoryIntegration::test_history_metadata_stores_json_correctly - NameError: name 're' is not defined
2026-02-14T13:01:56.5373730Z ERROR tests/integration/test_jwt_auth_api.py::test_auth_login_returns_token - NameError: name 're' is not defined
2026-02-14T13:01:56.5374068Z ERROR tests/integration/test_jwt_auth_api.py::test_update_campaign_with_jwt_token - NameError: name 're' is not defined
2026-02-14T13:01:56.5374493Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_add_multiple_notes - NameError: name 're' is not defined
2026-02-14T13:01:56.5374950Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_notes_ordered_newest_first - NameError: name 're' is not defined
2026-02-14T13:01:56.5375345Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_update_note - NameError: name 're' is not defined
2026-02-14T13:01:56.5375735Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_delete_note - NameError: name 're' is not defined
2026-02-14T13:01:56.5376173Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_note_count_in_job_listing - NameError: name 're' is not defined
2026-02-14T13:01:56.5376698Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_authorization_user_cannot_access_other_users_notes - NameError: name 're' is not defined
2026-02-14T13:01:56.5377109Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_is_modified_flag - NameError: name 're' is not defined
2026-02-14T13:01:56.5377517Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_empty_note_list - NameError: name 're' is not defined
2026-02-14T13:01:56.5377941Z ERROR tests/integration/test_multi_note_integration.py::TestMultiNoteIntegration::test_whitespace_stripping - NameError: name 're' is not defined
2026-02-14T13:01:56.5378386Z ERROR tests/integration/test_ranker_validation.py::TestRankerValidation::test_ranker_validates_jobs_before_ranking - NameError: name 're' is not defined
2026-02-14T13:01:56.5378824Z ERROR tests/integration/test_ranker_validation.py::TestRankerValidation::test_ranker_skips_jobs_not_in_fact_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.5379287Z ERROR tests/integration/test_ranker_validation.py::TestRankerValidation::test_ranker_handles_mixed_valid_and_invalid_jobs - NameError: name 're' is not defined
2026-02-14T13:01:56.5379712Z ERROR tests/integration/test_ranker_validation.py::TestRankerValidation::test_validation_query_works_correctly - NameError: name 're' is not defined
2026-02-14T13:01:56.5379887Z ============ 334 passed, 8 skipped, 1 warning, 134 errors in 25.21s ============
2026-02-14T13:01:56.8224612Z ##[error]Process completed with exit code 1.
2026-02-14T13:01:56.8310454Z Post job cleanup.
2026-02-14T13:01:56.9334917Z [command]/usr/bin/git version
2026-02-14T13:01:56.9381926Z git version 2.52.0
2026-02-14T13:01:56.9430209Z Temporarily overriding HOME='/home/runner/work/_temp/6e18b840-f836-4dbc-aa11-8a2966d3253f' before making global git config changes
2026-02-14T13:01:56.9431649Z Adding repository directory to the temporary git global config as a safe directory
2026-02-14T13:01:56.9439091Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/job-etl-project/job-etl-project
2026-02-14T13:01:56.9491819Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2026-02-14T13:01:56.9537313Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2026-02-14T13:01:56.9857063Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2026-02-14T13:01:56.9885208Z http.https://github.com/.extraheader
2026-02-14T13:01:56.9901299Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2026-02-14T13:01:56.9942477Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2026-02-14T13:01:57.0234366Z [command]/usr/bin/git config --local --name-only --get-regexp ^includeIf\.gitdir:
2026-02-14T13:01:57.0274406Z [command]/usr/bin/git submodule foreach --recursive git config --local --show-origin --name-only --get-regexp remote.origin.url
2026-02-14T13:01:57.0671690Z Print service container logs: abae9058ae674410bf9fa3ccfc161078_postgres15_27ffaa
2026-02-14T13:01:57.0676114Z ##[command]/usr/bin/docker logs --details 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:01:57.0806400Z  The files belonging to this database system will be owned by user "postgres".
2026-02-14T13:01:57.0810587Z  initdb: warning: enabling "trust" authentication for local connections
2026-02-14T13:01:57.0811721Z  This user must also own the server process.
2026-02-14T13:01:57.0812413Z  
2026-02-14T13:01:57.0812851Z  The database cluster will be initialized with locale "en_US.utf8".
2026-02-14T13:01:57.0814031Z  The default database encoding has accordingly been set to "UTF8".
2026-02-14T13:01:57.0814948Z  The default text search configuration will be set to "english".
2026-02-14T13:01:57.0815699Z  
2026-02-14T13:01:57.0815982Z  Data page checksums are disabled.
2026-02-14T13:01:57.0816523Z  
2026-02-14T13:01:57.0817006Z  fixing permissions on existing directory /var/lib/postgresql/data ... ok
2026-02-14T13:01:57.0818177Z  creating subdirectories ... ok
2026-02-14T13:01:57.0818677Z  selecting dynamic shared memory implementation ... posix
2026-02-14T13:01:57.0819222Z  selecting default max_connections ... 100
2026-02-14T13:01:57.0819670Z  selecting default shared_buffers ... 128MB
2026-02-14T13:01:57.0820115Z  selecting default time zone ... Etc/UTC
2026-02-14T13:01:57.0820548Z  creating configuration files ... ok
2026-02-14T13:01:57.0820969Z  running bootstrap script ... ok
2026-02-14T13:01:57.0821594Z  performing post-bootstrap initialization ... ok
2026-02-14T13:01:57.0822071Z  syncing data to disk ... ok
2026-02-14T13:01:57.0822412Z  
2026-02-14T13:01:57.0822646Z  
2026-02-14T13:01:57.0822986Z  Success. You can now start the database server using:
2026-02-14T13:01:57.0823458Z  
2026-02-14T13:01:57.0823816Z      pg_ctl -D /var/lib/postgresql/data -l logfile start
2026-02-14T13:01:57.0824288Z  
2026-02-14T13:01:57.0825366Z  waiting for server to start....2026-02-14 13:00:40.818 UTC [48] LOG:  starting PostgreSQL 15.16 (Debian 15.16-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
2026-02-14T13:01:57.0826848Z  2026-02-14 13:00:40.819 UTC [48] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
2026-02-14T13:01:57.0827764Z  2026-02-14 13:00:40.822 UTC [51] LOG:  database system was shut down at 2026-02-14 13:00:40 UTC
2026-02-14T13:01:57.0828608Z  2026-02-14 13:00:40.826 UTC [48] LOG:  database system is ready to accept connections
2026-02-14T13:01:57.0829248Z   done
2026-02-14T13:01:57.0829500Z  server started
2026-02-14T13:01:57.0829765Z  CREATE DATABASE
2026-02-14T13:01:57.0830040Z  
2026-02-14T13:01:57.0830265Z  
2026-02-14T13:01:57.0830736Z  /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
2026-02-14T13:01:57.0831543Z  
2026-02-14T13:01:57.0831912Z  2026-02-14 13:00:41.007 UTC [48] LOG:  received fast shutdown request
2026-02-14T13:01:57.0832766Z  waiting for server to shut down....2026-02-14 13:00:41.008 UTC [48] LOG:  aborting any active transactions
2026-02-14T13:01:57.0833882Z  2026-02-14 13:00:41.011 UTC [48] LOG:  background worker "logical replication launcher" (PID 54) exited with exit code 1
2026-02-14T13:01:57.0834710Z  2026-02-14 13:00:41.011 UTC [49] LOG:  shutting down
2026-02-14T13:01:57.0835273Z  2026-02-14 13:00:41.012 UTC [49] LOG:  checkpoint starting: shutdown immediate
2026-02-14T13:01:57.0837114Z  2026-02-14 13:00:41.030 UTC [49] LOG:  checkpoint complete: wrote 922 buffers (5.6%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.016 s, sync=0.002 s, total=0.020 s; sync files=301, longest=0.001 s, average=0.001 s; distance=4239 kB, estimate=4239 kB
2026-02-14T13:01:57.0838662Z  2026-02-14 13:00:41.037 UTC [48] LOG:  database system is shut down
2026-02-14T13:01:57.0839138Z   done
2026-02-14T13:01:57.0839380Z  server stopped
2026-02-14T13:01:57.0839632Z  
2026-02-14T13:01:57.0839963Z  PostgreSQL init process complete; ready for start up.
2026-02-14T13:01:57.0840657Z  
2026-02-14T13:01:57.0841731Z  initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.
2026-02-14T13:01:57.0843302Z  2026-02-14 13:00:41.128 UTC [1] LOG:  starting PostgreSQL 15.16 (Debian 15.16-1.pgdg13+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 14.2.0-19) 14.2.0, 64-bit
2026-02-14T13:01:57.0844495Z  2026-02-14 13:00:41.129 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
2026-02-14T13:01:57.0845228Z  2026-02-14 13:00:41.129 UTC [1] LOG:  listening on IPv6 address "::", port 5432
2026-02-14T13:01:57.0846300Z  2026-02-14 13:00:41.130 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
2026-02-14T13:01:57.0847248Z  2026-02-14 13:00:41.133 UTC [64] LOG:  database system was shut down at 2026-02-14 13:00:41 UTC
2026-02-14T13:01:57.0848077Z  2026-02-14 13:00:41.137 UTC [1] LOG:  database system is ready to accept connections
2026-02-14T13:01:57.0848753Z  2026-02-14 13:00:50.209 UTC [75] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0849132Z  2026-02-14 13:01:00.275 UTC [83] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0849505Z  2026-02-14 13:01:10.339 UTC [105] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0849890Z  2026-02-14 13:01:20.410 UTC [114] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0850267Z  2026-02-14 13:01:30.486 UTC [122] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0850721Z  2026-02-14 13:01:35.040 UTC [125] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0851494Z  2026-02-14 13:01:35.085 UTC [127] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0852009Z  2026-02-14 13:01:35.129 UTC [129] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0852506Z  2026-02-14 13:01:35.172 UTC [131] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0853016Z  2026-02-14 13:01:35.214 UTC [133] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0853524Z  2026-02-14 13:01:35.256 UTC [135] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0854027Z  2026-02-14 13:01:35.297 UTC [137] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0854527Z  2026-02-14 13:01:35.339 UTC [139] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0855036Z  2026-02-14 13:01:35.381 UTC [141] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0855538Z  2026-02-14 13:01:35.424 UTC [143] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0856060Z  2026-02-14 13:01:35.469 UTC [145] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0856562Z  2026-02-14 13:01:35.511 UTC [147] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0857062Z  2026-02-14 13:01:35.554 UTC [149] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0857563Z  2026-02-14 13:01:35.596 UTC [151] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0858066Z  2026-02-14 13:01:35.640 UTC [153] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0858561Z  2026-02-14 13:01:35.683 UTC [155] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0859246Z  2026-02-14 13:01:35.725 UTC [157] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0859745Z  2026-02-14 13:01:35.767 UTC [159] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0860243Z  2026-02-14 13:01:35.808 UTC [161] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0860751Z  2026-02-14 13:01:35.851 UTC [163] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0861590Z  2026-02-14 13:01:35.892 UTC [165] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0862281Z  2026-02-14 13:01:35.934 UTC [167] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0862824Z  2026-02-14 13:01:35.976 UTC [169] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0863332Z  2026-02-14 13:01:36.018 UTC [171] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0863840Z  2026-02-14 13:01:36.061 UTC [173] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0864346Z  2026-02-14 13:01:36.171 UTC [175] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0864842Z  2026-02-14 13:01:36.215 UTC [177] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0865348Z  2026-02-14 13:01:36.259 UTC [179] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0865849Z  2026-02-14 13:01:36.302 UTC [181] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0866350Z  2026-02-14 13:01:36.346 UTC [183] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0866852Z  2026-02-14 13:01:36.389 UTC [185] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0867357Z  2026-02-14 13:01:36.431 UTC [187] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0867850Z  2026-02-14 13:01:36.476 UTC [189] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0868358Z  2026-02-14 13:01:36.521 UTC [191] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0868858Z  2026-02-14 13:01:36.565 UTC [193] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0869358Z  2026-02-14 13:01:36.606 UTC [195] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0869863Z  2026-02-14 13:01:36.649 UTC [197] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0870372Z  2026-02-14 13:01:36.693 UTC [199] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0870869Z  2026-02-14 13:01:36.736 UTC [201] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0871650Z  2026-02-14 13:01:36.780 UTC [203] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0872170Z  2026-02-14 13:01:36.823 UTC [205] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0872674Z  2026-02-14 13:01:36.867 UTC [207] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0873174Z  2026-02-14 13:01:36.910 UTC [209] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0873689Z  2026-02-14 13:01:36.953 UTC [211] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0874184Z  2026-02-14 13:01:36.996 UTC [213] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0874690Z  2026-02-14 13:01:37.040 UTC [215] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0875189Z  2026-02-14 13:01:37.083 UTC [217] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0875686Z  2026-02-14 13:01:37.126 UTC [219] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0876190Z  2026-02-14 13:01:37.168 UTC [221] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0876826Z  2026-02-14 13:01:37.211 UTC [223] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0877331Z  2026-02-14 13:01:37.263 UTC [225] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0877835Z  2026-02-14 13:01:37.310 UTC [227] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0878329Z  2026-02-14 13:01:37.353 UTC [229] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0878827Z  2026-02-14 13:01:37.394 UTC [231] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0879444Z  2026-02-14 13:01:37.437 UTC [233] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0879940Z  2026-02-14 13:01:37.481 UTC [235] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0880440Z  2026-02-14 13:01:37.523 UTC [237] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0880939Z  2026-02-14 13:01:37.566 UTC [239] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0881795Z  2026-02-14 13:01:37.610 UTC [241] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0882302Z  2026-02-14 13:01:37.654 UTC [243] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0882803Z  2026-02-14 13:01:37.697 UTC [245] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0883297Z  2026-02-14 13:01:37.741 UTC [247] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0883818Z  2026-02-14 13:01:37.785 UTC [249] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0884317Z  2026-02-14 13:01:37.827 UTC [251] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0884812Z  2026-02-14 13:01:37.869 UTC [253] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0885310Z  2026-02-14 13:01:37.911 UTC [255] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0885822Z  2026-02-14 13:01:37.952 UTC [257] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0886317Z  2026-02-14 13:01:37.994 UTC [259] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0886834Z  2026-02-14 13:01:38.037 UTC [261] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0887338Z  2026-02-14 13:01:38.079 UTC [263] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0887845Z  2026-02-14 13:01:38.186 UTC [265] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0888340Z  2026-02-14 13:01:38.230 UTC [267] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0888840Z  2026-02-14 13:01:38.274 UTC [269] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0889340Z  2026-02-14 13:01:38.318 UTC [271] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0889840Z  2026-02-14 13:01:38.362 UTC [273] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0890339Z  2026-02-14 13:01:38.406 UTC [275] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0890838Z  2026-02-14 13:01:38.449 UTC [277] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0891564Z  2026-02-14 13:01:38.496 UTC [279] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0892073Z  2026-02-14 13:01:38.539 UTC [281] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0892574Z  2026-02-14 13:01:38.581 UTC [283] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0893065Z  2026-02-14 13:01:38.625 UTC [285] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0893561Z  2026-02-14 13:01:38.669 UTC [287] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0894242Z  2026-02-14 13:01:38.711 UTC [289] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0894737Z  2026-02-14 13:01:38.754 UTC [291] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0895232Z  2026-02-14 13:01:38.797 UTC [293] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0895739Z  2026-02-14 13:01:38.841 UTC [295] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0896273Z  2026-02-14 13:01:38.884 UTC [297] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0896958Z  2026-02-14 13:01:38.927 UTC [299] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0897474Z  2026-02-14 13:01:38.970 UTC [301] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0897966Z  2026-02-14 13:01:39.012 UTC [303] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0898463Z  2026-02-14 13:01:39.054 UTC [305] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0898964Z  2026-02-14 13:01:39.096 UTC [307] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0899458Z  2026-02-14 13:01:39.139 UTC [309] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0899955Z  2026-02-14 13:01:39.181 UTC [311] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0900446Z  2026-02-14 13:01:39.223 UTC [313] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0900944Z  2026-02-14 13:01:39.265 UTC [315] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0901687Z  2026-02-14 13:01:39.307 UTC [317] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0902178Z  2026-02-14 13:01:39.350 UTC [319] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0902677Z  2026-02-14 13:01:39.392 UTC [321] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0903180Z  2026-02-14 13:01:39.435 UTC [323] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0903673Z  2026-02-14 13:01:39.479 UTC [325] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0904172Z  2026-02-14 13:01:39.522 UTC [327] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0904673Z  2026-02-14 13:01:39.566 UTC [329] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0905169Z  2026-02-14 13:01:39.608 UTC [331] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0905670Z  2026-02-14 13:01:39.652 UTC [333] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0906168Z  2026-02-14 13:01:39.695 UTC [335] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0906667Z  2026-02-14 13:01:39.737 UTC [337] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0907173Z  2026-02-14 13:01:39.780 UTC [339] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0907672Z  2026-02-14 13:01:39.822 UTC [341] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0908166Z  2026-02-14 13:01:39.865 UTC [343] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0908671Z  2026-02-14 13:01:39.908 UTC [345] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0909171Z  2026-02-14 13:01:39.952 UTC [347] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0909664Z  2026-02-14 13:01:39.995 UTC [349] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0910161Z  2026-02-14 13:01:40.039 UTC [351] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0910661Z  2026-02-14 13:01:40.082 UTC [353] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0911325Z  2026-02-14 13:01:40.183 UTC [355] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0911965Z  2026-02-14 13:01:40.226 UTC [357] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0912469Z  2026-02-14 13:01:40.270 UTC [359] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0912964Z  2026-02-14 13:01:40.312 UTC [361] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0913476Z  2026-02-14 13:01:40.355 UTC [363] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0914080Z  2026-02-14 13:01:40.397 UTC [365] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0914581Z  2026-02-14 13:01:40.441 UTC [367] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0915082Z  2026-02-14 13:01:40.484 UTC [369] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0915575Z  2026-02-14 13:01:40.535 UTC [371] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0916022Z  2026-02-14 13:01:40.557 UTC [381] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0916461Z  2026-02-14 13:01:40.580 UTC [379] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0916955Z  2026-02-14 13:01:40.624 UTC [383] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0917455Z  2026-02-14 13:01:40.669 UTC [385] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0917960Z  2026-02-14 13:01:40.713 UTC [387] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0918461Z  2026-02-14 13:01:40.757 UTC [389] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0918963Z  2026-02-14 13:01:40.802 UTC [391] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0919465Z  2026-02-14 13:01:40.845 UTC [393] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0919960Z  2026-02-14 13:01:40.890 UTC [395] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0920457Z  2026-02-14 13:01:40.935 UTC [397] FATAL:  terminating connection due to administrator command
2026-02-14T13:01:57.0920894Z  2026-02-14 13:01:50.624 UTC [407] FATAL:  role "root" does not exist
2026-02-14T13:01:57.0927095Z Stop and remove container: abae9058ae674410bf9fa3ccfc161078_postgres15_27ffaa
2026-02-14T13:01:57.0932164Z ##[command]/usr/bin/docker rm --force 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:01:57.3768782Z 3debacd7110e49c80c87d792da0b26d993669a32f77fd8adb4698f3788298505
2026-02-14T13:01:57.3797310Z Remove container network: github_network_57f4fd6cd88f4d4cb79575ba7eeeead5
2026-02-14T13:01:57.3801887Z ##[command]/usr/bin/docker network rm github_network_57f4fd6cd88f4d4cb79575ba7eeeead5
2026-02-14T13:01:57.4618275Z github_network_57f4fd6cd88f4d4cb79575ba7eeeead5
2026-02-14T13:01:57.4686267Z Cleaning up orphan processes
