---
alwaysApply: true
description: "Job Postings Data Platform – Cursor AI Rules"
---

## Sections in This File
1. [**Project Context**](#project-context)
2. [**Core Principles**](#core-principles)
3. [**User Request Handling**](#user-request-handling)
4. [**Code Quality Standards**](#code-quality-standards)
5. [**Project Structure**](#project-structure)
6. [**Architecture Patterns**](#architecture-patterns)
7. [**Testing Standards**](#testing-standards)
8. [**Version Control Strategy**](#version-control-strategy)
   - [**GitHub Operations via MCP**](#github-operations-via-mcp)
9. [**Code Review Checklist**](#code-review-checklist)
10. [**Reference Documents**](#reference-documents)

## Project Context
You are working on a **job postings data platform** that ingests, models, enriches, and ranks job postings.

- **Primary Role of the Developer**: Junior data engineer / analytics engineer (explanations should be teaching-oriented and pragmatic).
- **Core Language & Runtime**: Python (3.11+ assumed).
- **Data Stack**:
  - **Database / Warehouse**: PostgreSQL using a **Medallion architecture** (`raw`, `staging`, `marts` schemas).
  - **Transformations**: dbt project.
  - **Orchestration**: Apache Airflow DAG for daily batch execution.
  - **Extraction Services**: Python services for JSearch job postings, Glassdoor company data, and future sources.
  - **Enrichment / Ranking Services**: Python services for skills/seniority enrichment (spaCy + rules) and ranking logic.
  - **Containerization**: Docker / Docker Compose for local development; later AWS (ECS, RDS, S3, EC2).
  - **Testing & Quality**: `pytest` for unit/integration tests; `ruff` for linting + basic formatting.
- **Downstream Consumers**:
  - Daily **email digests** of ranked jobs per profile.
  - **Tableau** dashboards connected to the `marts` schema.
  - Lightweight **profile management interface** (e.g., small Flask app) backed by `marts.profile_preferences`.

- **Key Reference Documents (read and respect)**:
  - Product requirements: `Project Documentation/job-postings-prd.md`
  - API usage examples: `Project Documentation/jsearch.md`, `Project Documentation/glassdoor_companies.md`
  - Naming standards: `Project Documentation/naming_conventions.md`

When in doubt about requirements or naming, prefer the PRD and naming conventions over improvisation.

---

## Core Principles

1. **Explain as you code**
   - When generating or refactoring code or SQL/dbt models, briefly explain:
     - What the change does.
     - How not trivial syntax work. 
     - Why it matches specific design.
     - Any trade-offs or assumptions.

2. **Confirm before major changes**
   - Ask for confirmation **before**:
     - Renaming tables, schemas, or core entities.
     - Changing dbt model contracts.
     - Modifying Airflow DAG structure.
     - Deleting or deprecating code, models, or jobs.

3. **Respect system boundaries**
   - Keep clear separation between:
     - **Extraction** (Python services → `raw`).
     - **Transformation** (dbt → `staging` + `marts`).
     - **Orchestration** (Airflow DAGs).
     - **Consumption** (email digests, Tableau, profile UI).
   - Do not push heavy transformation logic into Airflow or the profile UI; keep it in dbt or dedicated services.

4. **Learning-oriented behavior**
   - Assume the developer is learning data engineering:
     - Prefer clear, readable examples over clever one-liners.
     - Show how to test and validate changes (pytest, dbt tests, manual SQL checks).
     - When you introduce a new pattern (e.g., dbt macro, Airflow operator), explain how it fits the overall design.

5. **Clarify ambiguous requirements**
   - When a task is unclear, documentation is incomplete, or there are multiple valid approaches:
     - **Stop and ask** the user to clarify the preferred approach before proceeding.
     - Present the available options with pros/cons if applicable.
     - Do not assume or guess when the requirements are ambiguous.

6. **Human-like codebase**
   - The codebase should appear as if it was written entirely by a human developer.
   - **Never** include comments, docstrings, commit messages, or documentation that mention:
     - AI, AI assistants, or AI tools (e.g., "Generated by AI", "AI-suggested", "Created with ChatGPT").
     - Automated code generation tools.
     - Any references to AI assistance in the development process.
   - Write code, comments, and documentation in a natural, professional developer voice.
   - Keep all the documentation short. 

---

## User Request Handling

### When User Requests Implementation

When the user requests to implement something, follow this workflow:

1. **Review necessary files**
   - Read relevant code, documentation, and configuration files.
   - Understand the current implementation and architecture.
   - Identify dependencies and related components.

2. **Clarify uncertainties**
   - Follow [Core Principle #5](#core-principles): If requirements are unclear, documentation is incomplete, or multiple approaches exist, stop and ask the user to clarify before proceeding.

3. **Explain steps briefly**
   - Follow [Core Principle #1](#core-principles): Provide a short explanation of each major step as you implement, explaining what the change does and why it matches the design.

4. **Verify design alignment**
   - Confirm the implementation follows:
     - Medallion architecture (raw → staging → marts).
     - Service boundaries (extractor, enricher, ranker).
     - Naming conventions and project structure.
     - Patterns defined in the PRD.

5. **Verify implementation**
   - After implementation, verify changes by:
     - Running unit tests (`pytest`).
     - Running integration tests where applicable.
     - Running linting (`ruff`).
     - Running dbt compilation and tests for SQL/dbt changes.
     - Manual verification if needed.

6. **Conduct thorough code review**
   - Review the code against the [Code Review Checklist](#code-review-checklist).
   - Check for:
     - Correctness and alignment with requirements.
     - Code quality (type hints, docstrings, naming).
     - Test coverage.
     - Operational concerns (error handling, logging, secrets).

7. **Offer adjustments**
   - Suggest what should be adjusted or fixed.
   - Highlight any potential issues or improvements.
   - Recommend refactoring if code quality can be improved.

8. **Proceed with deployment**
   - Only after all verification and review steps are complete.
   - Ensure the implementation is ready for deployment.

### When User Asks a Question

When the user asks a question about code or concepts, explain it briefly and clearly as if teaching a junior developer:

- **What the code does overall**: Provide a high-level summary of the code's purpose and functionality.
- **What each main part/block is responsible for**: Break down the code into logical sections and explain each part's role.
- **Key concepts or terms**: Define important concepts, patterns, or terminology they should know.
- **Avoid unnecessary details**: Focus on what's essential for understanding, skip advanced theory unless relevant.
- **Explain advanced syntax**: If complex Python features, SQL patterns, or dbt macros are used, explain how they work.
- **Keep it short and simple**: Use clear, concise language. Aim for understanding over completeness.

---

## Code Quality Standards

### Python Style & Structure

- **Style Guide**:
  - Follow **PEP 8** with a **maximum line length of 100 characters**.
  - Use **4 spaces** for indentation (no tabs).
  - Organize imports:
    1. Standard library.
    2. Third-party packages.
    3. Local modules.
  - Remove unused imports and variables.

- **Naming** (align with `Project Documentation/naming_conventions.md`):
  - **Python code**:
    - Modules and packages: `snake_case.py` (e.g., `jsearch_client.py`, `jobs_repository.py`).
    - Functions/methods: `snake_case` (e.g., `fetch_jobs_for_profile`, `calculate_rank_score`).
    - Classes: `PascalCase` (e.g., `JSearchClient`, `RankerService`, `ProfileRepository`).
    - Constants: `UPPER_SNAKE_CASE` (e.g., `DEFAULT_PAGE_SIZE`, `JSEARCH_BASE_URL`).
    - Private helpers: prefix with `_` (e.g., `_normalize_employment_types`).
  - **dbt models**:
    - Raw/Staging: `<sourcesystem>_<entity>.sql` (e.g., `jsearch_job_postings.sql`, `glassdoor_companies.sql`).
    - Marts Facts/Dimensions: `<category>_<entity>.sql` (e.g., `fact_jobs.sql`, `dim_companies.sql`, `dim_ranking.sql`).
  - **Airflow DAGs**: `snake_case.py` with descriptive names (e.g., `jobs_etl_daily.py`).
  - **Tests**:
    - Unit: `test_[module].py` (e.g., `test_ranker_service.py`).
    - Integration: `test_[area]_[behavior].py` (e.g., `test_jobs_etl_end_to_end.py`).
  - **Database tables** (see dbt model naming above):
    - Raw/Staging: `<sourcesystem>_<entity>` (e.g., `jsearch_job_postings`, `glassdoor_companies`).
    - Marts: `<category>_<entity>` (e.g., `fact_jobs`, `dim_companies`, `dim_ranking`).
    - Surrogate keys: `<table_name>_key` (e.g., `job_posting_key`, `company_key`).
    - Technical columns: `dwh_<column_name>` (e.g., `dwh_load_date`, `dwh_load_timestamp`).

### Python Type Hints (Required)

- All public functions, methods, and core internal helpers **must** include type hints for parameters and return values.
- Use standard typing imports (`List`, `Dict`, `Optional`, `Literal`, `TypedDict`, `Protocol`, etc.) where helpful.
- Example:

```python
from typing import Dict, List, Optional

class JSearchClient:
    def fetch_jobs(
        self,
        profile_id: int,
        query_params: Dict[str, str],
    ) -> List[Dict]:
        """
        Call JSearch API for a given profile and return a list of job posting payloads.
        """
        ...
```

### Docstrings (Required)

- Provide docstrings for:
  - Public classes.
  - Public functions/methods.
  - Any function that implements a non-trivial business rule (e.g., ranking logic).

- Use Google-style.

```python
def calculate_rank_score(
    job: Dict[str, str],
    profile: Dict[str, str],
) -> float:
    """
    Compute a relevance score for a single job/profile pair.

    Args:
        job: Normalized job posting fields from marts.fact_jobs.
        profile: Profile preferences from marts.profile_preferences.

    Returns:
        A score in the range [0.0, 100.0].
    """
    ...
```

### dbt SQL & Model Standards

- **Formatting**:
  - Use lowercase SQL keywords where practical, and align joins/conditions for readability.
  - One column per line in `SELECT` clauses for core models.
  - Prefer CTEs for complex logic, each with a clear, descriptive name.

- **Model Types**:
  - `raw` and `staging` models: typically **views** or **incremental** where appropriate.
  - `marts` models: prefer **tables** or **incremental** materializations.

- **Tests**: See [dbt Tests](#dbt-tests) section for detailed testing requirements.

### Linting & Formatting

- **Tooling**:
  - Use `ruff` as the primary linter.
  - Ensure no:
    - Unused imports.
    - Unused variables.
    - Bare `except:` clauses.
    - Debugging artifacts (`print`, stray logging, `pdb.set_trace()`).

- Before committing:
  - Run `ruff` on Python packages/services.
  - Run `dbt compile` (and `dbt test` if applicable) for SQL/dbt changes.

---

## Project Structure

> Note: This project is under active development; these guidelines describe the **intended** final structure based on the PRD. When implementing new files, follow this structure even if all folders do not yet exist.

### High-Level Organization (Example Target Layout)

```text
.
├── Project Documentation/          # PRDs, API docs, diagrams, naming conventions
├── services/
│   ├── extractor/                  # Python extraction service(s) for JSearch, Glassdoor, etc.
│   ├── enricher/                   # Python enrichment service(s) for skills/seniority
│   └── ranker/                     # Python ranking service(s)
├── airflow/
│   ├── dags/                       # Airflow DAGs (e.g., jobs_etl_daily)
│   ├── plugins/                    # Custom operators/sensors if needed
│   └── config/                     # Connections, environment configs (non-secret)
├── dbt/
│   ├── models/
│   │   ├── raw/                    # raw.* models
│   │   ├── staging/                # staging.* models
│   │   └── marts/                  # marts.* models (fact/dim)
│   ├── tests/                      # dbt schema + data tests
│   └── macros/                     # Common SQL macros
├── ui/
│   └── profile_manager/            # Lightweight profile management UI (Flask or similar)
├── infra/
│   ├── docker/                     # Dockerfiles, docker-compose definitions
│   ├── sql/                        # Schema and table initialization scripts (tables created before services run)
│   └── ci-cd/                      # CI/CD scripts and configs
├── tests/
│   ├── unit/                       # Python unit tests
│   └── integration/                # Integration tests (db, services, Airflow)
└── .cursor/
    └── rules/                      # Cursor configuration
```

---

## Architecture Patterns

### Medallion Architecture (Raw → Staging → Marts)

- **Raw (`raw` schema / Bronze)**:
  - Stores near-original JSON payloads from JSearch, Glassdoor, and future APIs.
  - Minimal transformation: mainly unpacking API responses into rows and capturing metadata.
  - Tables are created automatically by Docker initialization scripts before services run (see [Orchestration with Airflow](#orchestration-with-airflow)).

- **Staging (`staging` schema / Silver)**:
  - Normalized, cleaned, and de-duplicated relational data.
  - Columns typed appropriately (dates, numeric fields, booleans, enums).
  - Includes technical columns with `dwh_` prefix (see [Naming conventions](#code-quality-standards)).

- **Marts (`marts` schema / Gold)**:
  - Business-ready **fact** and **dimension** tables plus configuration tables:
    - `fact_jobs`
    - `dim_companies`
    - `dim_ranking`
    - `profile_preferences`

### Service Boundaries

- **Extractor Service(s)**:
  - Responsibilities:
    - Handle API authentication, rate limiting, retries, and logging.
    - Map profile preferences to API calls.
    - Write raw payloads into `raw.*` tables with appropriate technical metadata.
  - Must **not** contain downstream transformation or ranking logic.

- **Enricher Service(s)**:
  - Responsibilities:
    - Skill extraction (e.g., via spaCy models).
    - Seniority extraction using well-documented rules.
    - Write enrichment fields back into staging (e.g., `staging.jsearch_job_postings`).

- **Ranker Service(s)**:
  - Responsibilities:
    - Implement ranking algorithms per the PRD (MVP then extended).
    - Read from `marts.fact_jobs` and `marts.profile_preferences`.
    - Write to `marts.dim_ranking` with `rank_score` and later `rank_explain`.
  - Should be deterministic and testable via unit tests and small fixtures.

### Orchestration with Airflow

- DAG `jobs_etl_daily` should:
  - Follow the task list and order from the PRD (extract → normalize → enrich → model → rank → test → notify).
  - Use clearly named tasks reflecting each stage (e.g., `extract_job_postings`, `normalize_jobs`, `rank_jobs`).
  - Use IDs, not names, in dependencies (`task1 >> task2`).
  - Have retry and timeout policies appropriate to each task (e.g., longer for external APIs).
  - Note: Tables are created automatically by Docker initialization scripts (`docker/init/02_create_tables.sql`) before DAG execution, so no initialization task is needed.

---

## Testing Standards

### Python Tests (pytest)

- **Unit Tests**:
  - Cover:
    - API client parameter construction and error handling.
    - Core transformation helpers (e.g., normalizing JSON fields before dbt).
    - Ranking logic (e.g., scores for known job/profile combinations).
  - Use small, focused fixtures and avoid external dependencies.

- **Integration Tests**:
  - Validate end-to-end flows in a constrained scope:
    - Extractor → raw tables (using a test DB).
    - dbt models from raw to staging to marts.
    - Ranker service reading from and writing to marts.
  - Mark appropriately (e.g., `@pytest.mark.integration`) so they can be included/excluded in CI.

### dbt Tests

- For **every core model** (especially in `marts`):
  - Define `unique` and `not_null` tests on primary keys (e.g., `job_posting_key`).
  - Define `relationships` tests between facts and dimensions.
  - Add business rule tests where feasible (e.g., `rank_score between 0 and 100`).

### Airflow DAG & Pipeline Tests

- Keep pipeline tests pragmatic:
  - At minimum, have tests that:
    - Import DAG files without errors.
    - Assert DAG has expected tasks and dependencies.
  - Optionally, use Airflow test facilities or custom harnesses for critical operators.

---

## Version Control Strategy

### GitHub Operations via MCP

**IMPORTANT**: When performing GitHub-specific operations, **always use MCP (Model Context Protocol) GitHub tools** instead of direct git commands or manual GitHub UI interactions.

- **Use MCP GitHub tools for**:
  - Creating, updating, and managing issues
  - Creating, updating, reviewing, and merging pull requests
  - Creating and managing branches
  - Searching code, repositories, issues, and pull requests
  - Managing releases and tags
  - Getting repository information, file contents, and commit details
  - Any GitHub API operations

- **Use standard git commands only for**:
  - Local git operations (commit, add, status, log, etc.)
  - Local branch operations
  - Local file operations

- **When to use MCP GitHub tools**:
  - Creating pull requests: Use `mcp_github_create_pull_request` instead of pushing and creating PR manually
  - Reviewing PRs: Use `mcp_github_pull_request_read` and review tools instead of manual review
  - Managing issues: Use `mcp_github_create_issue`, `mcp_github_update_issue`, etc.
  - Searching codebase: Use `mcp_github_search_code` for cross-repository searches
  - Getting file contents from GitHub: Use `mcp_github_get_file_contents` instead of cloning

- **Best practices**:
  - Always check repository owner and name before making MCP calls
  - Use `mcp_github_get_me` to get authenticated user information when needed
  - For PR reviews, create a pending review first, add comments, then submit
  - Verify branch names and PR numbers before operations
  - Handle errors gracefully and provide clear feedback

### Branch Naming

- Format: `[type]/[short-description]`
- Types:
  - `feature/` – New features or major components (e.g., `feature/add-ranker-service`).
  - `bugfix/` – Bug fixes (e.g., `bugfix/fix-dbt-key-violation`).
  - `chore/` – Maintenance, tooling, or config (e.g., `chore/update-ruff-config`).
  - `docs/` – Documentation changes (e.g., `docs/update-job-postings-prd`).
  - `experiment/` – Throwaway experiments or spikes (should not merge directly).

### Commit Messages

- Use a simple, consistent structure:

```text
[TYPE]: Brief description (max 50 chars)

Optional longer description wrapped at ~72 chars.

- Bullet points for key changes
- Reference tickets/issues where relevant (e.g., #123)
```

- Example:

```text
feature: Add initial jobs extractor service

- Implement JSearch API client with basic params
- Write responses into raw.jsearch_job_postings
- Add unit tests for query construction
```


### Commit Hygiene

- Keep commits **atomic**:
  - One logical change per commit (e.g., do not mix dbt refactors and Airflow DAG restructuring).
- Ensure:
  - Python tests pass (or are updated) for affected areas.
  - dbt models at least compile for schema-altering changes.
  - Linting (ruff) is clean for changed files.

---

## Code Review Checklist

Before considering code "done", check:

- **Correctness & Requirements**
  - [ ] Implementation aligns with `Project Documentation/job-postings-prd.md`.
  - [ ] Data structures (schemas, tables, columns) follow naming conventions.
  - [ ] No behavior conflicts with the Medallion architecture or service boundaries.

- **Python Code Quality**
  - [ ] Functions and classes have appropriate type hints.
  - [ ] Public functions/methods have meaningful docstrings.
  - [ ] No unused imports or variables.
  - [ ] Logging is used instead of `print`, with appropriate log levels.
  - [ ] Code follows bets practicel like DRY code and Separation Of Concerns.

- **dbt Models & SQL**
  - [ ] Model names and schema locations are correct (raw/staging/marts).
  - [ ] CTEs are named clearly; complex logic is broken into manageable pieces.
  - [ ] dbt schema files updated with relevant tests for new/changed models.

- **Testing**
  - [ ] New logic is covered by unit tests where feasible.
  - [ ] Relevant integration or pipeline tests updated or added.
  - [ ] `dbt test` succeeds for impacted models (where applicable).

- **Operational Concerns**
  - [ ] Airflow DAG changes preserve task order and idempotency where needed.
  - [ ] External API usage (JSearch, Glassdoor) respects rate limits and handles errors.
  - [ ] Secrets are not hard-coded (use env vars).

- **Documentation**
  - [ ] Documentation updated where needed (PRD sections, design notes, or inline comments).

---

## Reference Documents

When making design or implementation decisions, consult:

- **Product Requirements**:
  - `Project Documentation/job-postings-prd.md`
- **API Usage and Payloads**:
  - `Project Documentation/jsearch.md`
  - `Project Documentation/glassdoor_companies.md` (if present)
- **Data Modeling & Naming**:
  - `Project Documentation/naming_conventions.md`
  - Any data modeling diagrams in `Project Documentation/` (e.g., data modeling and architecture diagrams).
- **Implementation Planning**:
  - `Project Documentation/implementation-todo.md` (if present) or similar planning docs.

If new patterns, tables, or services are introduced, they should be:

1. Consistent with these rules.
2. Reflected in the PRD and/or supporting documentation.
3. Explained in code comments/docstrings where non-obvious.


